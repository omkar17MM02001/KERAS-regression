{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data=pd.read_csv(\"concrete_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>47.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>43.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>36.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>39.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>90</td>\n",
       "      <td>38.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>28</td>\n",
       "      <td>28.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>427.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>43.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>190.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>42.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>304.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>47.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>52.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>90</td>\n",
       "      <td>39.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>342.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>365</td>\n",
       "      <td>56.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>90</td>\n",
       "      <td>40.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>180</td>\n",
       "      <td>42.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>427.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>180</td>\n",
       "      <td>41.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>28</td>\n",
       "      <td>28.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>3</td>\n",
       "      <td>8.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>180</td>\n",
       "      <td>44.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>365</td>\n",
       "      <td>52.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>270</td>\n",
       "      <td>53.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>41.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>342.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>180</td>\n",
       "      <td>52.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>427.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>37.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>7</td>\n",
       "      <td>38.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>141.9</td>\n",
       "      <td>166.6</td>\n",
       "      <td>129.7</td>\n",
       "      <td>173.5</td>\n",
       "      <td>10.9</td>\n",
       "      <td>882.6</td>\n",
       "      <td>785.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>297.8</td>\n",
       "      <td>137.2</td>\n",
       "      <td>106.9</td>\n",
       "      <td>201.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>878.4</td>\n",
       "      <td>655.3</td>\n",
       "      <td>28</td>\n",
       "      <td>53.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>321.3</td>\n",
       "      <td>164.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>870.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>28</td>\n",
       "      <td>57.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>366.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>824.3</td>\n",
       "      <td>756.9</td>\n",
       "      <td>28</td>\n",
       "      <td>65.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>279.8</td>\n",
       "      <td>128.9</td>\n",
       "      <td>100.4</td>\n",
       "      <td>172.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>825.1</td>\n",
       "      <td>804.9</td>\n",
       "      <td>28</td>\n",
       "      <td>52.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>252.1</td>\n",
       "      <td>97.1</td>\n",
       "      <td>75.6</td>\n",
       "      <td>193.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>835.5</td>\n",
       "      <td>821.4</td>\n",
       "      <td>28</td>\n",
       "      <td>33.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>164.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.4</td>\n",
       "      <td>181.6</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1023.3</td>\n",
       "      <td>728.9</td>\n",
       "      <td>28</td>\n",
       "      <td>18.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>155.6</td>\n",
       "      <td>243.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.3</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>697.7</td>\n",
       "      <td>28</td>\n",
       "      <td>37.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>160.2</td>\n",
       "      <td>188.0</td>\n",
       "      <td>146.4</td>\n",
       "      <td>203.2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>828.7</td>\n",
       "      <td>709.7</td>\n",
       "      <td>28</td>\n",
       "      <td>35.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>298.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>186.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>879.0</td>\n",
       "      <td>815.2</td>\n",
       "      <td>28</td>\n",
       "      <td>42.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>317.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>209.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>860.5</td>\n",
       "      <td>736.6</td>\n",
       "      <td>28</td>\n",
       "      <td>40.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>287.3</td>\n",
       "      <td>120.5</td>\n",
       "      <td>93.9</td>\n",
       "      <td>187.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>904.4</td>\n",
       "      <td>695.9</td>\n",
       "      <td>28</td>\n",
       "      <td>43.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>325.6</td>\n",
       "      <td>166.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>881.6</td>\n",
       "      <td>790.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>355.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.6</td>\n",
       "      <td>193.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>801.4</td>\n",
       "      <td>778.4</td>\n",
       "      <td>28</td>\n",
       "      <td>40.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>132.0</td>\n",
       "      <td>206.5</td>\n",
       "      <td>160.9</td>\n",
       "      <td>178.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>866.9</td>\n",
       "      <td>735.6</td>\n",
       "      <td>28</td>\n",
       "      <td>33.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>322.5</td>\n",
       "      <td>148.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.8</td>\n",
       "      <td>8.5</td>\n",
       "      <td>951.0</td>\n",
       "      <td>709.5</td>\n",
       "      <td>28</td>\n",
       "      <td>52.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>164.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.1</td>\n",
       "      <td>181.2</td>\n",
       "      <td>12.6</td>\n",
       "      <td>849.3</td>\n",
       "      <td>846.0</td>\n",
       "      <td>28</td>\n",
       "      <td>15.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>313.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.6</td>\n",
       "      <td>169.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>925.3</td>\n",
       "      <td>782.9</td>\n",
       "      <td>28</td>\n",
       "      <td>38.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>321.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.9</td>\n",
       "      <td>182.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>870.1</td>\n",
       "      <td>779.7</td>\n",
       "      <td>28</td>\n",
       "      <td>37.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>139.7</td>\n",
       "      <td>163.9</td>\n",
       "      <td>127.7</td>\n",
       "      <td>236.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>868.6</td>\n",
       "      <td>655.6</td>\n",
       "      <td>28</td>\n",
       "      <td>35.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>288.4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>907.9</td>\n",
       "      <td>829.5</td>\n",
       "      <td>28</td>\n",
       "      <td>42.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>298.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>209.7</td>\n",
       "      <td>11.1</td>\n",
       "      <td>879.6</td>\n",
       "      <td>744.2</td>\n",
       "      <td>28</td>\n",
       "      <td>31.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>264.5</td>\n",
       "      <td>111.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>195.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>832.6</td>\n",
       "      <td>790.4</td>\n",
       "      <td>28</td>\n",
       "      <td>41.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>159.8</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1049.3</td>\n",
       "      <td>688.2</td>\n",
       "      <td>28</td>\n",
       "      <td>39.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>166.0</td>\n",
       "      <td>259.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>858.8</td>\n",
       "      <td>826.8</td>\n",
       "      <td>28</td>\n",
       "      <td>37.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0      540.0                 0.0      0.0  162.0               2.5   \n",
       "1      540.0                 0.0      0.0  162.0               2.5   \n",
       "2      332.5               142.5      0.0  228.0               0.0   \n",
       "3      332.5               142.5      0.0  228.0               0.0   \n",
       "4      198.6               132.4      0.0  192.0               0.0   \n",
       "5      266.0               114.0      0.0  228.0               0.0   \n",
       "6      380.0                95.0      0.0  228.0               0.0   \n",
       "7      380.0                95.0      0.0  228.0               0.0   \n",
       "8      266.0               114.0      0.0  228.0               0.0   \n",
       "9      475.0                 0.0      0.0  228.0               0.0   \n",
       "10     198.6               132.4      0.0  192.0               0.0   \n",
       "11     198.6               132.4      0.0  192.0               0.0   \n",
       "12     427.5                47.5      0.0  228.0               0.0   \n",
       "13     190.0               190.0      0.0  228.0               0.0   \n",
       "14     304.0                76.0      0.0  228.0               0.0   \n",
       "15     380.0                 0.0      0.0  228.0               0.0   \n",
       "16     139.6               209.4      0.0  192.0               0.0   \n",
       "17     342.0                38.0      0.0  228.0               0.0   \n",
       "18     380.0                95.0      0.0  228.0               0.0   \n",
       "19     475.0                 0.0      0.0  228.0               0.0   \n",
       "20     427.5                47.5      0.0  228.0               0.0   \n",
       "21     139.6               209.4      0.0  192.0               0.0   \n",
       "22     139.6               209.4      0.0  192.0               0.0   \n",
       "23     139.6               209.4      0.0  192.0               0.0   \n",
       "24     380.0                 0.0      0.0  228.0               0.0   \n",
       "25     380.0                 0.0      0.0  228.0               0.0   \n",
       "26     380.0                95.0      0.0  228.0               0.0   \n",
       "27     342.0                38.0      0.0  228.0               0.0   \n",
       "28     427.5                47.5      0.0  228.0               0.0   \n",
       "29     475.0                 0.0      0.0  228.0               0.0   \n",
       "...      ...                 ...      ...    ...               ...   \n",
       "1000   141.9               166.6    129.7  173.5              10.9   \n",
       "1001   297.8               137.2    106.9  201.3               6.0   \n",
       "1002   321.3               164.2      0.0  190.5               4.6   \n",
       "1003   366.0               187.0      0.0  191.3               6.6   \n",
       "1004   279.8               128.9    100.4  172.4               9.5   \n",
       "1005   252.1                97.1     75.6  193.8               8.3   \n",
       "1006   164.6                 0.0    150.4  181.6              11.7   \n",
       "1007   155.6               243.5      0.0  180.3              10.7   \n",
       "1008   160.2               188.0    146.4  203.2              11.3   \n",
       "1009   298.1                 0.0    107.0  186.4               6.1   \n",
       "1010   317.9                 0.0    126.5  209.7               5.7   \n",
       "1011   287.3               120.5     93.9  187.6               9.2   \n",
       "1012   325.6               166.4      0.0  174.0               8.9   \n",
       "1013   355.9                 0.0    141.6  193.3              11.0   \n",
       "1014   132.0               206.5    160.9  178.9               5.5   \n",
       "1015   322.5               148.6      0.0  185.8               8.5   \n",
       "1016   164.2                 0.0    200.1  181.2              12.6   \n",
       "1017   313.8                 0.0    112.6  169.9              10.1   \n",
       "1018   321.4                 0.0    127.9  182.5              11.5   \n",
       "1019   139.7               163.9    127.7  236.7               5.8   \n",
       "1020   288.4               121.0      0.0  177.4               7.0   \n",
       "1021   298.2                 0.0    107.0  209.7              11.1   \n",
       "1022   264.5               111.0     86.5  195.5               5.9   \n",
       "1023   159.8               250.0      0.0  168.4              12.2   \n",
       "1024   166.0               259.7      0.0  183.2              12.7   \n",
       "1025   276.4               116.0     90.3  179.6               8.9   \n",
       "1026   322.2                 0.0    115.6  196.0              10.4   \n",
       "1027   148.5               139.4    108.6  192.7               6.1   \n",
       "1028   159.1               186.7      0.0  175.6              11.3   \n",
       "1029   260.9               100.5     78.3  200.6               8.6   \n",
       "\n",
       "      Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0               1040.0           676.0   28     79.99  \n",
       "1               1055.0           676.0   28     61.89  \n",
       "2                932.0           594.0  270     40.27  \n",
       "3                932.0           594.0  365     41.05  \n",
       "4                978.4           825.5  360     44.30  \n",
       "5                932.0           670.0   90     47.03  \n",
       "6                932.0           594.0  365     43.70  \n",
       "7                932.0           594.0   28     36.45  \n",
       "8                932.0           670.0   28     45.85  \n",
       "9                932.0           594.0   28     39.29  \n",
       "10               978.4           825.5   90     38.07  \n",
       "11               978.4           825.5   28     28.02  \n",
       "12               932.0           594.0  270     43.01  \n",
       "13               932.0           670.0   90     42.33  \n",
       "14               932.0           670.0   28     47.81  \n",
       "15               932.0           670.0   90     52.91  \n",
       "16              1047.0           806.9   90     39.36  \n",
       "17               932.0           670.0  365     56.14  \n",
       "18               932.0           594.0   90     40.56  \n",
       "19               932.0           594.0  180     42.62  \n",
       "20               932.0           594.0  180     41.84  \n",
       "21              1047.0           806.9   28     28.24  \n",
       "22              1047.0           806.9    3      8.06  \n",
       "23              1047.0           806.9  180     44.21  \n",
       "24               932.0           670.0  365     52.52  \n",
       "25               932.0           670.0  270     53.30  \n",
       "26               932.0           594.0  270     41.15  \n",
       "27               932.0           670.0  180     52.12  \n",
       "28               932.0           594.0   28     37.43  \n",
       "29               932.0           594.0    7     38.60  \n",
       "...                ...             ...  ...       ...  \n",
       "1000             882.6           785.3   28     44.61  \n",
       "1001             878.4           655.3   28     53.52  \n",
       "1002             870.0           774.0   28     57.22  \n",
       "1003             824.3           756.9   28     65.91  \n",
       "1004             825.1           804.9   28     52.83  \n",
       "1005             835.5           821.4   28     33.40  \n",
       "1006            1023.3           728.9   28     18.03  \n",
       "1007            1022.0           697.7   28     37.36  \n",
       "1008             828.7           709.7   28     35.31  \n",
       "1009             879.0           815.2   28     42.64  \n",
       "1010             860.5           736.6   28     40.06  \n",
       "1011             904.4           695.9   28     43.80  \n",
       "1012             881.6           790.0   28     61.24  \n",
       "1013             801.4           778.4   28     40.87  \n",
       "1014             866.9           735.6   28     33.31  \n",
       "1015             951.0           709.5   28     52.43  \n",
       "1016             849.3           846.0   28     15.09  \n",
       "1017             925.3           782.9   28     38.46  \n",
       "1018             870.1           779.7   28     37.27  \n",
       "1019             868.6           655.6   28     35.23  \n",
       "1020             907.9           829.5   28     42.14  \n",
       "1021             879.6           744.2   28     31.88  \n",
       "1022             832.6           790.4   28     41.54  \n",
       "1023            1049.3           688.2   28     39.46  \n",
       "1024             858.8           826.8   28     37.92  \n",
       "1025             870.1           768.3   28     44.28  \n",
       "1026             817.9           813.4   28     31.18  \n",
       "1027             892.4           780.0   28     23.70  \n",
       "1028             989.6           788.9   28     32.77  \n",
       "1029             864.5           761.5   28     32.40  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns\n",
    "\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "predictors_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = predictors_norm.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 114042.0635 - val_loss: 82743.4803\n",
      "Epoch 2/50\n",
      " - 0s - loss: 66748.0575 - val_loss: 48475.6654\n",
      "Epoch 3/50\n",
      " - 0s - loss: 40278.1573 - val_loss: 29654.5898\n",
      "Epoch 4/50\n",
      " - 0s - loss: 25635.8303 - val_loss: 18997.3442\n",
      "Epoch 5/50\n",
      " - 0s - loss: 16994.6095 - val_loss: 12763.9823\n",
      "Epoch 6/50\n",
      " - 0s - loss: 11703.8434 - val_loss: 9190.2976\n",
      "Epoch 7/50\n",
      " - 0s - loss: 8579.6806 - val_loss: 7079.6222\n",
      "Epoch 8/50\n",
      " - 0s - loss: 6788.5850 - val_loss: 5804.7391\n",
      "Epoch 9/50\n",
      " - 0s - loss: 5723.2676 - val_loss: 5000.1665\n",
      "Epoch 10/50\n",
      " - 0s - loss: 4998.1729 - val_loss: 4424.5001\n",
      "Epoch 11/50\n",
      " - 0s - loss: 4423.2503 - val_loss: 3973.9235\n",
      "Epoch 12/50\n",
      " - 0s - loss: 3959.1034 - val_loss: 3599.3126\n",
      "Epoch 13/50\n",
      " - 0s - loss: 3571.7072 - val_loss: 3313.2796\n",
      "Epoch 14/50\n",
      " - 0s - loss: 3255.6943 - val_loss: 3071.5382\n",
      "Epoch 15/50\n",
      " - 0s - loss: 2992.8452 - val_loss: 2881.3518\n",
      "Epoch 16/50\n",
      " - 0s - loss: 2793.0149 - val_loss: 2722.5093\n",
      "Epoch 17/50\n",
      " - 0s - loss: 2631.9250 - val_loss: 2600.9548\n",
      "Epoch 18/50\n",
      " - 0s - loss: 2526.3088 - val_loss: 2507.0558\n",
      "Epoch 19/50\n",
      " - 0s - loss: 2445.3233 - val_loss: 2428.7259\n",
      "Epoch 20/50\n",
      " - 0s - loss: 2373.9556 - val_loss: 2357.0850\n",
      "Epoch 21/50\n",
      " - 0s - loss: 2309.8223 - val_loss: 2288.8391\n",
      "Epoch 22/50\n",
      " - 0s - loss: 2249.5147 - val_loss: 2225.9507\n",
      "Epoch 23/50\n",
      " - 0s - loss: 2194.2839 - val_loss: 2169.2152\n",
      "Epoch 24/50\n",
      " - 0s - loss: 2146.5954 - val_loss: 2114.1110\n",
      "Epoch 25/50\n",
      " - 0s - loss: 2100.4577 - val_loss: 2067.4452\n",
      "Epoch 26/50\n",
      " - 0s - loss: 2061.7035 - val_loss: 2021.9806\n",
      "Epoch 27/50\n",
      " - 0s - loss: 2024.5459 - val_loss: 1977.6066\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1989.5894 - val_loss: 1937.5048\n",
      "Epoch 29/50\n",
      " - 0s - loss: 1959.5197 - val_loss: 1895.9054\n",
      "Epoch 30/50\n",
      " - 0s - loss: 1928.9499 - val_loss: 1859.7663\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1902.0683 - val_loss: 1824.9603\n",
      "Epoch 32/50\n",
      " - 0s - loss: 1878.3751 - val_loss: 1791.1609\n",
      "Epoch 33/50\n",
      " - 0s - loss: 1856.6067 - val_loss: 1760.3100\n",
      "Epoch 34/50\n",
      " - 0s - loss: 1837.4933 - val_loss: 1732.2261\n",
      "Epoch 35/50\n",
      " - 0s - loss: 1820.9426 - val_loss: 1704.0876\n",
      "Epoch 36/50\n",
      " - 0s - loss: 1805.3006 - val_loss: 1682.5781\n",
      "Epoch 37/50\n",
      " - 0s - loss: 1793.3341 - val_loss: 1660.7030\n",
      "Epoch 38/50\n",
      " - 0s - loss: 1783.4552 - val_loss: 1641.4114\n",
      "Epoch 39/50\n",
      " - 0s - loss: 1775.2030 - val_loss: 1625.5031\n",
      "Epoch 40/50\n",
      " - 0s - loss: 1768.6445 - val_loss: 1610.8246\n",
      "Epoch 41/50\n",
      " - 0s - loss: 1763.0662 - val_loss: 1597.7605\n",
      "Epoch 42/50\n",
      " - 0s - loss: 1758.3409 - val_loss: 1585.2209\n",
      "Epoch 43/50\n",
      " - 0s - loss: 1753.7336 - val_loss: 1574.4184\n",
      "Epoch 44/50\n",
      " - 0s - loss: 1749.5799 - val_loss: 1564.1385\n",
      "Epoch 45/50\n",
      " - 0s - loss: 1745.4577 - val_loss: 1553.4594\n",
      "Epoch 46/50\n",
      " - 0s - loss: 1741.4541 - val_loss: 1541.7485\n",
      "Epoch 47/50\n",
      " - 0s - loss: 1737.4684 - val_loss: 1529.8383\n",
      "Epoch 48/50\n",
      " - 0s - loss: 1733.4790 - val_loss: 1519.3925\n",
      "Epoch 49/50\n",
      " - 0s - loss: 1729.6459 - val_loss: 1510.1374\n",
      "Epoch 50/50\n",
      " - 0s - loss: 1726.1366 - val_loss: 1498.7328\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 28685.1825 - val_loss: 11335.8969\n",
      "Epoch 2/50\n",
      " - 0s - loss: 4679.8343 - val_loss: 1070.9236\n",
      "Epoch 3/50\n",
      " - 0s - loss: 868.6080 - val_loss: 519.4103\n",
      "Epoch 4/50\n",
      " - 0s - loss: 789.3580 - val_loss: 515.1432\n",
      "Epoch 5/50\n",
      " - 0s - loss: 719.6544 - val_loss: 515.4425\n",
      "Epoch 6/50\n",
      " - 0s - loss: 676.1844 - val_loss: 484.8611\n",
      "Epoch 7/50\n",
      " - 0s - loss: 635.6831 - val_loss: 454.1826\n",
      "Epoch 8/50\n",
      " - 0s - loss: 596.0892 - val_loss: 443.7984\n",
      "Epoch 9/50\n",
      " - 0s - loss: 556.5452 - val_loss: 409.4976\n",
      "Epoch 10/50\n",
      " - 0s - loss: 519.4290 - val_loss: 397.0059\n",
      "Epoch 11/50\n",
      " - 0s - loss: 486.0731 - val_loss: 376.7530\n",
      "Epoch 12/50\n",
      " - 0s - loss: 455.9560 - val_loss: 364.9255\n",
      "Epoch 13/50\n",
      " - 0s - loss: 427.7521 - val_loss: 350.4333\n",
      "Epoch 14/50\n",
      " - 0s - loss: 402.7851 - val_loss: 333.2879\n",
      "Epoch 15/50\n",
      " - 0s - loss: 380.7983 - val_loss: 319.9748\n",
      "Epoch 16/50\n",
      " - 0s - loss: 358.7541 - val_loss: 304.2312\n",
      "Epoch 17/50\n",
      " - 0s - loss: 339.6756 - val_loss: 307.6327\n",
      "Epoch 18/50\n",
      " - 0s - loss: 322.7785 - val_loss: 291.8216\n",
      "Epoch 19/50\n",
      " - 0s - loss: 307.6691 - val_loss: 275.5056\n",
      "Epoch 20/50\n",
      " - 0s - loss: 292.3237 - val_loss: 271.4287\n",
      "Epoch 21/50\n",
      " - 0s - loss: 280.3988 - val_loss: 265.4553\n",
      "Epoch 22/50\n",
      " - 0s - loss: 269.5717 - val_loss: 263.0659\n",
      "Epoch 23/50\n",
      " - 0s - loss: 257.6487 - val_loss: 242.4244\n",
      "Epoch 24/50\n",
      " - 0s - loss: 249.3540 - val_loss: 242.7798\n",
      "Epoch 25/50\n",
      " - 0s - loss: 240.3305 - val_loss: 228.2011\n",
      "Epoch 26/50\n",
      " - 0s - loss: 233.2248 - val_loss: 229.3215\n",
      "Epoch 27/50\n",
      " - 0s - loss: 225.9443 - val_loss: 223.1964\n",
      "Epoch 28/50\n",
      " - 0s - loss: 220.2799 - val_loss: 221.2389\n",
      "Epoch 29/50\n",
      " - 0s - loss: 214.4397 - val_loss: 219.1476\n",
      "Epoch 30/50\n",
      " - 0s - loss: 209.5915 - val_loss: 210.1765\n",
      "Epoch 31/50\n",
      " - 0s - loss: 205.6597 - val_loss: 206.2783\n",
      "Epoch 32/50\n",
      " - 0s - loss: 200.3009 - val_loss: 209.9475\n",
      "Epoch 33/50\n",
      " - 0s - loss: 197.3238 - val_loss: 208.9917\n",
      "Epoch 34/50\n",
      " - 0s - loss: 196.6825 - val_loss: 189.0520\n",
      "Epoch 35/50\n",
      " - 0s - loss: 189.8836 - val_loss: 205.4404\n",
      "Epoch 36/50\n",
      " - 0s - loss: 186.7306 - val_loss: 191.5663\n",
      "Epoch 37/50\n",
      " - 0s - loss: 183.8061 - val_loss: 193.3718\n",
      "Epoch 38/50\n",
      " - 0s - loss: 182.3856 - val_loss: 206.2544\n",
      "Epoch 39/50\n",
      " - 0s - loss: 181.0455 - val_loss: 206.3816\n",
      "Epoch 40/50\n",
      " - 0s - loss: 178.4927 - val_loss: 196.5166\n",
      "Epoch 41/50\n",
      " - 0s - loss: 174.9605 - val_loss: 179.5374\n",
      "Epoch 42/50\n",
      " - 0s - loss: 173.4233 - val_loss: 202.1162\n",
      "Epoch 43/50\n",
      " - 0s - loss: 171.3230 - val_loss: 179.6294\n",
      "Epoch 44/50\n",
      " - 0s - loss: 169.9131 - val_loss: 191.9108\n",
      "Epoch 45/50\n",
      " - 0s - loss: 168.3874 - val_loss: 174.0994\n",
      "Epoch 46/50\n",
      " - 0s - loss: 168.7705 - val_loss: 173.3394\n",
      "Epoch 47/50\n",
      " - 0s - loss: 165.4958 - val_loss: 187.7935\n",
      "Epoch 48/50\n",
      " - 0s - loss: 163.5863 - val_loss: 177.8318\n",
      "Epoch 49/50\n",
      " - 0s - loss: 163.1277 - val_loss: 168.0207\n",
      "Epoch 50/50\n",
      " - 0s - loss: 164.1297 - val_loss: 187.1242\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 122559.3912 - val_loss: 71969.1193\n",
      "Epoch 2/50\n",
      " - 0s - loss: 42364.9101 - val_loss: 23316.0471\n",
      "Epoch 3/50\n",
      " - 0s - loss: 12445.2526 - val_loss: 7308.9438\n",
      "Epoch 4/50\n",
      " - 0s - loss: 4411.6654 - val_loss: 3297.8756\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2851.7836 - val_loss: 2486.5775\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2555.8989 - val_loss: 2300.3440\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2379.3914 - val_loss: 2173.4598\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2212.0824 - val_loss: 2094.6709\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2071.7486 - val_loss: 2009.6813\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1946.4387 - val_loss: 1949.5236\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1831.6300 - val_loss: 1871.3200\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1735.8097 - val_loss: 1800.0876\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1651.0303 - val_loss: 1733.7173\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1580.1766 - val_loss: 1695.9945\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1503.7484 - val_loss: 1628.8698\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1443.1399 - val_loss: 1588.7855\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1387.0419 - val_loss: 1543.3006\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1334.6263 - val_loss: 1510.8746\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1288.3915 - val_loss: 1485.2667\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1245.7354 - val_loss: 1444.0821\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1208.5566 - val_loss: 1415.4618\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1172.7732 - val_loss: 1382.8781\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1141.8622 - val_loss: 1354.2651\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1112.5397 - val_loss: 1342.3578\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1089.0967 - val_loss: 1298.7091\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1058.1250 - val_loss: 1288.1640\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1033.1216 - val_loss: 1270.9239\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1008.4562 - val_loss: 1235.9405\n",
      "Epoch 29/50\n",
      " - 0s - loss: 989.5472 - val_loss: 1216.4187\n",
      "Epoch 30/50\n",
      " - 0s - loss: 970.5982 - val_loss: 1196.4871\n",
      "Epoch 31/50\n",
      " - 0s - loss: 954.4603 - val_loss: 1183.8439\n",
      "Epoch 32/50\n",
      " - 0s - loss: 932.4631 - val_loss: 1161.5614\n",
      "Epoch 33/50\n",
      " - 0s - loss: 916.1944 - val_loss: 1138.5058\n",
      "Epoch 34/50\n",
      " - 0s - loss: 904.3563 - val_loss: 1118.8296\n",
      "Epoch 35/50\n",
      " - 0s - loss: 887.3624 - val_loss: 1119.3713\n",
      "Epoch 36/50\n",
      " - 0s - loss: 869.1410 - val_loss: 1075.7879\n",
      "Epoch 37/50\n",
      " - 0s - loss: 856.5561 - val_loss: 1071.2056\n",
      "Epoch 38/50\n",
      " - 0s - loss: 841.2038 - val_loss: 1046.4154\n",
      "Epoch 39/50\n",
      " - 0s - loss: 831.3379 - val_loss: 1037.7950\n",
      "Epoch 40/50\n",
      " - 0s - loss: 819.3908 - val_loss: 1006.6171\n",
      "Epoch 41/50\n",
      " - 0s - loss: 803.2459 - val_loss: 1003.2345\n",
      "Epoch 42/50\n",
      " - 0s - loss: 789.0784 - val_loss: 978.0513\n",
      "Epoch 43/50\n",
      " - 0s - loss: 779.7572 - val_loss: 966.8162\n",
      "Epoch 44/50\n",
      " - 0s - loss: 767.4978 - val_loss: 951.9348\n",
      "Epoch 45/50\n",
      " - 0s - loss: 753.2172 - val_loss: 923.9789\n",
      "Epoch 46/50\n",
      " - 0s - loss: 743.2341 - val_loss: 915.1211\n",
      "Epoch 47/50\n",
      " - 0s - loss: 732.5897 - val_loss: 894.1349\n",
      "Epoch 48/50\n",
      " - 0s - loss: 719.0929 - val_loss: 889.6411\n",
      "Epoch 49/50\n",
      " - 0s - loss: 709.8405 - val_loss: 868.4729\n",
      "Epoch 50/50\n",
      " - 0s - loss: 697.6870 - val_loss: 854.4960\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 128482.4563 - val_loss: 73509.8908\n",
      "Epoch 2/50\n",
      " - 0s - loss: 50229.9405 - val_loss: 23245.3885\n",
      "Epoch 3/50\n",
      " - 0s - loss: 14720.2492 - val_loss: 5429.1020\n",
      "Epoch 4/50\n",
      " - 0s - loss: 3665.3066 - val_loss: 1637.9868\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1720.6118 - val_loss: 1299.9118\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1541.7020 - val_loss: 1281.5024\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1503.5974 - val_loss: 1248.8800\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1464.1298 - val_loss: 1216.9493\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1423.6103 - val_loss: 1183.5023\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1385.7863 - val_loss: 1148.4561\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1344.9528 - val_loss: 1119.7908\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1307.3206 - val_loss: 1088.8536\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1269.6859 - val_loss: 1058.2412\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1233.3863 - val_loss: 1025.8461\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1196.5497 - val_loss: 996.5186\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1161.8165 - val_loss: 968.7190\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1130.2627 - val_loss: 943.9070\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1093.8041 - val_loss: 914.1441\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1062.3090 - val_loss: 888.2785\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1030.4788 - val_loss: 861.7526\n",
      "Epoch 21/50\n",
      " - 0s - loss: 999.5771 - val_loss: 838.2275\n",
      "Epoch 22/50\n",
      " - 0s - loss: 969.9060 - val_loss: 814.8413\n",
      "Epoch 23/50\n",
      " - 0s - loss: 940.8597 - val_loss: 791.1570\n",
      "Epoch 24/50\n",
      " - 0s - loss: 913.2634 - val_loss: 766.6178\n",
      "Epoch 25/50\n",
      " - 0s - loss: 886.7769 - val_loss: 742.8606\n",
      "Epoch 26/50\n",
      " - 0s - loss: 858.6733 - val_loss: 724.0291\n",
      "Epoch 27/50\n",
      " - 0s - loss: 835.1985 - val_loss: 700.7817\n",
      "Epoch 28/50\n",
      " - 0s - loss: 811.3009 - val_loss: 677.8745\n",
      "Epoch 29/50\n",
      " - 0s - loss: 784.7845 - val_loss: 660.3743\n",
      "Epoch 30/50\n",
      " - 0s - loss: 761.6467 - val_loss: 639.3989\n",
      "Epoch 31/50\n",
      " - 0s - loss: 739.4763 - val_loss: 619.3873\n",
      "Epoch 32/50\n",
      " - 0s - loss: 717.3273 - val_loss: 601.5089\n",
      "Epoch 33/50\n",
      " - 0s - loss: 695.2657 - val_loss: 583.3133\n",
      "Epoch 34/50\n",
      " - 0s - loss: 674.3063 - val_loss: 564.9583\n",
      "Epoch 35/50\n",
      " - 0s - loss: 654.3659 - val_loss: 549.3465\n",
      "Epoch 36/50\n",
      " - 0s - loss: 634.9479 - val_loss: 532.4505\n",
      "Epoch 37/50\n",
      " - 0s - loss: 616.7570 - val_loss: 517.4502\n",
      "Epoch 38/50\n",
      " - 0s - loss: 598.7749 - val_loss: 503.0738\n",
      "Epoch 39/50\n",
      " - 0s - loss: 581.4942 - val_loss: 486.5842\n",
      "Epoch 40/50\n",
      " - 0s - loss: 564.1900 - val_loss: 471.5892\n",
      "Epoch 41/50\n",
      " - 0s - loss: 549.6290 - val_loss: 458.0192\n",
      "Epoch 42/50\n",
      " - 0s - loss: 531.4662 - val_loss: 444.1199\n",
      "Epoch 43/50\n",
      " - 0s - loss: 514.8405 - val_loss: 429.0954\n",
      "Epoch 44/50\n",
      " - 0s - loss: 500.3584 - val_loss: 416.6435\n",
      "Epoch 45/50\n",
      " - 0s - loss: 485.7311 - val_loss: 403.9711\n",
      "Epoch 46/50\n",
      " - 0s - loss: 470.5032 - val_loss: 391.8470\n",
      "Epoch 47/50\n",
      " - 0s - loss: 456.3960 - val_loss: 378.9090\n",
      "Epoch 48/50\n",
      " - 0s - loss: 443.9035 - val_loss: 367.5494\n",
      "Epoch 49/50\n",
      " - 0s - loss: 430.0706 - val_loss: 355.7861\n",
      "Epoch 50/50\n",
      " - 0s - loss: 418.7546 - val_loss: 345.5622\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 5291.9103 - val_loss: 1672.6173\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1806.1905 - val_loss: 1431.6388\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1412.8539 - val_loss: 1129.4741\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1178.2501 - val_loss: 893.1862\n",
      "Epoch 5/50\n",
      " - 0s - loss: 991.1195 - val_loss: 733.9429\n",
      "Epoch 6/50\n",
      " - 0s - loss: 849.3515 - val_loss: 604.5209\n",
      "Epoch 7/50\n",
      " - 0s - loss: 728.0994 - val_loss: 507.6568\n",
      "Epoch 8/50\n",
      " - 0s - loss: 627.6245 - val_loss: 418.9516\n",
      "Epoch 9/50\n",
      " - 0s - loss: 544.3317 - val_loss: 365.4839\n",
      "Epoch 10/50\n",
      " - 0s - loss: 473.2822 - val_loss: 306.2442\n",
      "Epoch 11/50\n",
      " - 0s - loss: 410.3829 - val_loss: 278.7496\n",
      "Epoch 12/50\n",
      " - 0s - loss: 361.9730 - val_loss: 231.7140\n",
      "Epoch 13/50\n",
      " - 0s - loss: 318.0573 - val_loss: 208.3901\n",
      "Epoch 14/50\n",
      " - 0s - loss: 282.5804 - val_loss: 177.5049\n",
      "Epoch 15/50\n",
      " - 0s - loss: 256.9949 - val_loss: 169.2462\n",
      "Epoch 16/50\n",
      " - 0s - loss: 236.1752 - val_loss: 165.7934\n",
      "Epoch 17/50\n",
      " - 0s - loss: 222.8097 - val_loss: 152.0517\n",
      "Epoch 18/50\n",
      " - 0s - loss: 201.8276 - val_loss: 132.4867\n",
      "Epoch 19/50\n",
      " - 0s - loss: 193.5097 - val_loss: 137.2749\n",
      "Epoch 20/50\n",
      " - 0s - loss: 181.8053 - val_loss: 119.7972\n",
      "Epoch 21/50\n",
      " - 0s - loss: 173.0264 - val_loss: 124.9072\n",
      "Epoch 22/50\n",
      " - 0s - loss: 167.3722 - val_loss: 113.2188\n",
      "Epoch 23/50\n",
      " - 0s - loss: 160.4175 - val_loss: 108.5388\n",
      "Epoch 24/50\n",
      " - 0s - loss: 156.5475 - val_loss: 105.4204\n",
      "Epoch 25/50\n",
      " - 0s - loss: 152.6248 - val_loss: 100.8053\n",
      "Epoch 26/50\n",
      " - 0s - loss: 150.2852 - val_loss: 93.6415\n",
      "Epoch 27/50\n",
      " - 0s - loss: 146.3801 - val_loss: 100.3232\n",
      "Epoch 28/50\n",
      " - 0s - loss: 144.7354 - val_loss: 98.7688\n",
      "Epoch 29/50\n",
      " - 0s - loss: 143.3168 - val_loss: 102.8034\n",
      "Epoch 30/50\n",
      " - 0s - loss: 141.7067 - val_loss: 87.3873\n",
      "Epoch 31/50\n",
      " - 1s - loss: 139.7784 - val_loss: 88.1258\n",
      "Epoch 32/50\n",
      " - 0s - loss: 138.0153 - val_loss: 86.1765\n",
      "Epoch 33/50\n",
      " - 0s - loss: 136.5350 - val_loss: 88.7298\n",
      "Epoch 34/50\n",
      " - 0s - loss: 134.8107 - val_loss: 82.9196\n",
      "Epoch 35/50\n",
      " - 0s - loss: 135.2417 - val_loss: 87.6028\n",
      "Epoch 36/50\n",
      " - 0s - loss: 138.7084 - val_loss: 99.8820\n",
      "Epoch 37/50\n",
      " - 0s - loss: 136.6993 - val_loss: 87.9651\n",
      "Epoch 38/50\n",
      " - 0s - loss: 133.3396 - val_loss: 80.9509\n",
      "Epoch 39/50\n",
      " - 0s - loss: 132.6218 - val_loss: 82.0422\n",
      "Epoch 40/50\n",
      " - 0s - loss: 131.7237 - val_loss: 79.8609\n",
      "Epoch 41/50\n",
      " - 0s - loss: 132.4519 - val_loss: 90.3592\n",
      "Epoch 42/50\n",
      " - 0s - loss: 131.8105 - val_loss: 79.3375\n",
      "Epoch 43/50\n",
      " - 0s - loss: 131.3470 - val_loss: 77.5161\n",
      "Epoch 44/50\n",
      " - 0s - loss: 130.5736 - val_loss: 78.4857\n",
      "Epoch 45/50\n",
      " - 0s - loss: 130.1491 - val_loss: 79.8519\n",
      "Epoch 46/50\n",
      " - 0s - loss: 128.6331 - val_loss: 77.8653\n",
      "Epoch 47/50\n",
      " - 0s - loss: 129.1120 - val_loss: 79.2878\n",
      "Epoch 48/50\n",
      " - 0s - loss: 129.1036 - val_loss: 81.5012\n",
      "Epoch 49/50\n",
      " - 0s - loss: 129.0295 - val_loss: 80.0436\n",
      "Epoch 50/50\n",
      " - 0s - loss: 132.4166 - val_loss: 89.6563\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 102856.8494 - val_loss: 67628.7705\n",
      "Epoch 2/50\n",
      " - 0s - loss: 52395.8927 - val_loss: 34721.4094\n",
      "Epoch 3/50\n",
      " - 0s - loss: 26725.1553 - val_loss: 17429.7079\n",
      "Epoch 4/50\n",
      " - 0s - loss: 13333.7427 - val_loss: 8250.3707\n",
      "Epoch 5/50\n",
      " - 0s - loss: 6360.5401 - val_loss: 3654.8458\n",
      "Epoch 6/50\n",
      " - 0s - loss: 3021.4989 - val_loss: 1584.6546\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1647.7218 - val_loss: 843.5493\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1209.4641 - val_loss: 636.5777\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1092.4369 - val_loss: 585.8240\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1050.1225 - val_loss: 565.7404\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1017.0520 - val_loss: 551.9140\n",
      "Epoch 12/50\n",
      " - 0s - loss: 986.3676 - val_loss: 543.8824\n",
      "Epoch 13/50\n",
      " - 0s - loss: 956.4570 - val_loss: 529.3480\n",
      "Epoch 14/50\n",
      " - 0s - loss: 926.0932 - val_loss: 519.2462\n",
      "Epoch 15/50\n",
      " - 0s - loss: 897.5011 - val_loss: 509.7307\n",
      "Epoch 16/50\n",
      " - 0s - loss: 871.1528 - val_loss: 501.0301\n",
      "Epoch 17/50\n",
      " - 0s - loss: 844.9686 - val_loss: 490.2002\n",
      "Epoch 18/50\n",
      " - 0s - loss: 819.9035 - val_loss: 481.2449\n",
      "Epoch 19/50\n",
      " - 0s - loss: 796.8314 - val_loss: 471.4552\n",
      "Epoch 20/50\n",
      " - 0s - loss: 774.3332 - val_loss: 463.4934\n",
      "Epoch 21/50\n",
      " - 0s - loss: 753.0277 - val_loss: 458.2124\n",
      "Epoch 22/50\n",
      " - 0s - loss: 732.8810 - val_loss: 446.7560\n",
      "Epoch 23/50\n",
      " - 0s - loss: 712.8824 - val_loss: 440.2246\n",
      "Epoch 24/50\n",
      " - 0s - loss: 694.6149 - val_loss: 431.1991\n",
      "Epoch 25/50\n",
      " - 0s - loss: 676.3706 - val_loss: 422.9879\n",
      "Epoch 26/50\n",
      " - 0s - loss: 659.1563 - val_loss: 416.0615\n",
      "Epoch 27/50\n",
      " - 0s - loss: 643.1343 - val_loss: 411.2834\n",
      "Epoch 28/50\n",
      " - 0s - loss: 626.3502 - val_loss: 401.4592\n",
      "Epoch 29/50\n",
      " - 0s - loss: 611.5655 - val_loss: 393.7998\n",
      "Epoch 30/50\n",
      " - 0s - loss: 596.1631 - val_loss: 386.3566\n",
      "Epoch 31/50\n",
      " - 0s - loss: 582.4569 - val_loss: 379.5861\n",
      "Epoch 32/50\n",
      " - 0s - loss: 568.1914 - val_loss: 374.7332\n",
      "Epoch 33/50\n",
      " - 0s - loss: 554.8949 - val_loss: 367.6698\n",
      "Epoch 34/50\n",
      " - 0s - loss: 542.5619 - val_loss: 359.8028\n",
      "Epoch 35/50\n",
      " - 0s - loss: 529.9033 - val_loss: 355.7921\n",
      "Epoch 36/50\n",
      " - 0s - loss: 518.1892 - val_loss: 348.5523\n",
      "Epoch 37/50\n",
      " - 0s - loss: 506.4375 - val_loss: 340.7812\n",
      "Epoch 38/50\n",
      " - 0s - loss: 495.4553 - val_loss: 334.0907\n",
      "Epoch 39/50\n",
      " - 0s - loss: 485.0424 - val_loss: 328.8685\n",
      "Epoch 40/50\n",
      " - 0s - loss: 474.0100 - val_loss: 324.4348\n",
      "Epoch 41/50\n",
      " - 0s - loss: 463.8755 - val_loss: 315.7430\n",
      "Epoch 42/50\n",
      " - 0s - loss: 454.3616 - val_loss: 312.1600\n",
      "Epoch 43/50\n",
      " - 0s - loss: 444.7712 - val_loss: 306.0051\n",
      "Epoch 44/50\n",
      " - 0s - loss: 435.4627 - val_loss: 300.9015\n",
      "Epoch 45/50\n",
      " - 0s - loss: 426.5086 - val_loss: 293.2748\n",
      "Epoch 46/50\n",
      " - 0s - loss: 417.5162 - val_loss: 292.4749\n",
      "Epoch 47/50\n",
      " - 0s - loss: 409.1899 - val_loss: 286.6565\n",
      "Epoch 48/50\n",
      " - 0s - loss: 401.4135 - val_loss: 280.0667\n",
      "Epoch 49/50\n",
      " - 0s - loss: 394.1637 - val_loss: 277.8148\n",
      "Epoch 50/50\n",
      " - 0s - loss: 387.3938 - val_loss: 269.5627\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 2989.8355 - val_loss: 1983.8911\n",
      "Epoch 2/50\n",
      " - 0s - loss: 2384.3497 - val_loss: 1599.4937\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1957.5602 - val_loss: 1316.4689\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1648.5975 - val_loss: 1147.2788\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1360.0514 - val_loss: 964.0956\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1131.6293 - val_loss: 775.0110\n",
      "Epoch 7/50\n",
      " - 0s - loss: 949.3331 - val_loss: 643.2272\n",
      "Epoch 8/50\n",
      " - 0s - loss: 755.7003 - val_loss: 522.7307\n",
      "Epoch 9/50\n",
      " - 0s - loss: 594.8759 - val_loss: 443.5869\n",
      "Epoch 10/50\n",
      " - 0s - loss: 456.8767 - val_loss: 367.8048\n",
      "Epoch 11/50\n",
      " - 0s - loss: 364.5022 - val_loss: 296.1518\n",
      "Epoch 12/50\n",
      " - 0s - loss: 306.6418 - val_loss: 251.1043\n",
      "Epoch 13/50\n",
      " - 0s - loss: 255.9704 - val_loss: 212.1868\n",
      "Epoch 14/50\n",
      " - 0s - loss: 225.9229 - val_loss: 190.6368\n",
      "Epoch 15/50\n",
      " - 0s - loss: 200.2335 - val_loss: 166.9432\n",
      "Epoch 16/50\n",
      " - 0s - loss: 180.2700 - val_loss: 147.4107\n",
      "Epoch 17/50\n",
      " - 0s - loss: 167.6418 - val_loss: 133.9205\n",
      "Epoch 18/50\n",
      " - 0s - loss: 157.6691 - val_loss: 125.4875\n",
      "Epoch 19/50\n",
      " - 0s - loss: 150.3364 - val_loss: 119.9370\n",
      "Epoch 20/50\n",
      " - 0s - loss: 149.2620 - val_loss: 113.9773\n",
      "Epoch 21/50\n",
      " - 0s - loss: 142.7744 - val_loss: 109.6231\n",
      "Epoch 22/50\n",
      " - 0s - loss: 144.5478 - val_loss: 114.2761\n",
      "Epoch 23/50\n",
      " - 0s - loss: 140.7330 - val_loss: 104.8392\n",
      "Epoch 24/50\n",
      " - 0s - loss: 137.5141 - val_loss: 97.3552\n",
      "Epoch 25/50\n",
      " - 0s - loss: 134.2046 - val_loss: 96.3367\n",
      "Epoch 26/50\n",
      " - 0s - loss: 132.9585 - val_loss: 96.1478\n",
      "Epoch 27/50\n",
      " - 0s - loss: 134.4642 - val_loss: 96.5453\n",
      "Epoch 28/50\n",
      " - 0s - loss: 133.0430 - val_loss: 93.8635\n",
      "Epoch 29/50\n",
      " - 0s - loss: 134.1147 - val_loss: 90.5506\n",
      "Epoch 30/50\n",
      " - 0s - loss: 135.7025 - val_loss: 89.1736\n",
      "Epoch 31/50\n",
      " - 0s - loss: 130.6933 - val_loss: 88.9113\n",
      "Epoch 32/50\n",
      " - 0s - loss: 130.5229 - val_loss: 86.6847\n",
      "Epoch 33/50\n",
      " - 0s - loss: 130.0043 - val_loss: 86.6253\n",
      "Epoch 34/50\n",
      " - 0s - loss: 131.3631 - val_loss: 86.9843\n",
      "Epoch 35/50\n",
      " - 0s - loss: 133.4076 - val_loss: 84.9980\n",
      "Epoch 36/50\n",
      " - 0s - loss: 130.2753 - val_loss: 82.4383\n",
      "Epoch 37/50\n",
      " - 0s - loss: 128.8327 - val_loss: 81.9193\n",
      "Epoch 38/50\n",
      " - 0s - loss: 131.0960 - val_loss: 85.5293\n",
      "Epoch 39/50\n",
      " - 0s - loss: 132.6443 - val_loss: 86.6495\n",
      "Epoch 40/50\n",
      " - 0s - loss: 129.4889 - val_loss: 84.7952\n",
      "Epoch 41/50\n",
      " - 0s - loss: 128.6478 - val_loss: 90.4609\n",
      "Epoch 42/50\n",
      " - 0s - loss: 129.9565 - val_loss: 80.6839\n",
      "Epoch 43/50\n",
      " - 0s - loss: 132.3481 - val_loss: 78.7147\n",
      "Epoch 44/50\n",
      " - 0s - loss: 128.0728 - val_loss: 78.6546\n",
      "Epoch 45/50\n",
      " - 0s - loss: 127.2192 - val_loss: 77.2887\n",
      "Epoch 46/50\n",
      " - 0s - loss: 127.0581 - val_loss: 76.4496\n",
      "Epoch 47/50\n",
      " - 0s - loss: 127.8296 - val_loss: 78.1188\n",
      "Epoch 48/50\n",
      " - 0s - loss: 128.0813 - val_loss: 76.5414\n",
      "Epoch 49/50\n",
      " - 0s - loss: 128.6213 - val_loss: 77.1779\n",
      "Epoch 50/50\n",
      " - 0s - loss: 129.0566 - val_loss: 75.1662\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 141060.5813 - val_loss: 92330.2042\n",
      "Epoch 2/50\n",
      " - 0s - loss: 69031.3924 - val_loss: 39641.4257\n",
      "Epoch 3/50\n",
      " - 0s - loss: 28244.7867 - val_loss: 13332.8538\n",
      "Epoch 4/50\n",
      " - 0s - loss: 9179.9820 - val_loss: 3417.8901\n",
      "Epoch 5/50\n",
      " - 0s - loss: 3152.2753 - val_loss: 1639.1834\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2369.3062 - val_loss: 1565.1431\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2232.5536 - val_loss: 1481.2431\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2097.8927 - val_loss: 1420.5917\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1976.2830 - val_loss: 1369.2753\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1864.1085 - val_loss: 1320.4526\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1757.9068 - val_loss: 1272.1610\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1652.0797 - val_loss: 1239.9537\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1559.2591 - val_loss: 1195.8905\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1459.7850 - val_loss: 1174.2969\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1374.0479 - val_loss: 1146.2422\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1293.7779 - val_loss: 1109.8363\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1217.2088 - val_loss: 1090.3420\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1145.3252 - val_loss: 1075.7479\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1081.7419 - val_loss: 1040.9203\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1018.0991 - val_loss: 1037.9453\n",
      "Epoch 21/50\n",
      " - 0s - loss: 958.4295 - val_loss: 1010.0455\n",
      "Epoch 22/50\n",
      " - 0s - loss: 904.7661 - val_loss: 1001.8232\n",
      "Epoch 23/50\n",
      " - 0s - loss: 853.8386 - val_loss: 980.3917\n",
      "Epoch 24/50\n",
      " - 0s - loss: 808.1696 - val_loss: 969.4043\n",
      "Epoch 25/50\n",
      " - 0s - loss: 765.9278 - val_loss: 955.6971\n",
      "Epoch 26/50\n",
      " - 0s - loss: 728.0919 - val_loss: 934.0079\n",
      "Epoch 27/50\n",
      " - 0s - loss: 693.7103 - val_loss: 924.0118\n",
      "Epoch 28/50\n",
      " - 0s - loss: 659.4970 - val_loss: 897.4188\n",
      "Epoch 29/50\n",
      " - 0s - loss: 631.6067 - val_loss: 889.7531\n",
      "Epoch 30/50\n",
      " - 0s - loss: 602.5820 - val_loss: 860.6600\n",
      "Epoch 31/50\n",
      " - 0s - loss: 576.8158 - val_loss: 850.7057\n",
      "Epoch 32/50\n",
      " - 0s - loss: 554.1119 - val_loss: 835.1497\n",
      "Epoch 33/50\n",
      " - 0s - loss: 532.0116 - val_loss: 823.0641\n",
      "Epoch 34/50\n",
      " - 0s - loss: 511.7280 - val_loss: 800.1365\n",
      "Epoch 35/50\n",
      " - 0s - loss: 496.8741 - val_loss: 772.1112\n",
      "Epoch 36/50\n",
      " - 0s - loss: 475.0852 - val_loss: 763.1869\n",
      "Epoch 37/50\n",
      " - 0s - loss: 460.6067 - val_loss: 736.2604\n",
      "Epoch 38/50\n",
      " - 0s - loss: 442.9642 - val_loss: 715.1911\n",
      "Epoch 39/50\n",
      " - 0s - loss: 429.1416 - val_loss: 690.0996\n",
      "Epoch 40/50\n",
      " - 0s - loss: 416.7858 - val_loss: 683.3038\n",
      "Epoch 41/50\n",
      " - 0s - loss: 403.6150 - val_loss: 653.8846\n",
      "Epoch 42/50\n",
      " - 0s - loss: 392.8784 - val_loss: 643.6539\n",
      "Epoch 43/50\n",
      " - 0s - loss: 381.1334 - val_loss: 621.7081\n",
      "Epoch 44/50\n",
      " - 0s - loss: 369.9274 - val_loss: 602.0002\n",
      "Epoch 45/50\n",
      " - 0s - loss: 360.2678 - val_loss: 583.0994\n",
      "Epoch 46/50\n",
      " - 0s - loss: 352.3619 - val_loss: 578.9963\n",
      "Epoch 47/50\n",
      " - 0s - loss: 343.1635 - val_loss: 552.6682\n",
      "Epoch 48/50\n",
      " - 0s - loss: 334.2223 - val_loss: 534.5132\n",
      "Epoch 49/50\n",
      " - 0s - loss: 325.5090 - val_loss: 511.9290\n",
      "Epoch 50/50\n",
      " - 0s - loss: 318.1450 - val_loss: 509.1469\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 405547.7751 - val_loss: 256978.3410\n",
      "Epoch 2/50\n",
      " - 0s - loss: 200466.9751 - val_loss: 114562.4610\n",
      "Epoch 3/50\n",
      " - 0s - loss: 88854.5784 - val_loss: 46085.5632\n",
      "Epoch 4/50\n",
      " - 0s - loss: 36633.6408 - val_loss: 16999.6844\n",
      "Epoch 5/50\n",
      " - 0s - loss: 14423.3749 - val_loss: 6137.0919\n",
      "Epoch 6/50\n",
      " - 0s - loss: 6213.2568 - val_loss: 2798.0043\n",
      "Epoch 7/50\n",
      " - 0s - loss: 3526.7390 - val_loss: 2157.3819\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2802.1683 - val_loss: 2140.0750\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2612.9877 - val_loss: 2180.9617\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2529.7726 - val_loss: 2161.9411\n",
      "Epoch 11/50\n",
      " - 0s - loss: 2469.5081 - val_loss: 2154.7475\n",
      "Epoch 12/50\n",
      " - 0s - loss: 2412.1678 - val_loss: 2104.1707\n",
      "Epoch 13/50\n",
      " - 0s - loss: 2346.4876 - val_loss: 2052.1736\n",
      "Epoch 14/50\n",
      " - 0s - loss: 2286.1270 - val_loss: 2006.5976\n",
      "Epoch 15/50\n",
      " - 0s - loss: 2224.4049 - val_loss: 1973.0571\n",
      "Epoch 16/50\n",
      " - 0s - loss: 2162.7441 - val_loss: 1920.3313\n",
      "Epoch 17/50\n",
      " - 0s - loss: 2102.8178 - val_loss: 1877.8050\n",
      "Epoch 18/50\n",
      " - 0s - loss: 2041.5690 - val_loss: 1825.1431\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1981.2074 - val_loss: 1790.1980\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1919.6724 - val_loss: 1746.1643\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1857.8586 - val_loss: 1697.7476\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1796.4567 - val_loss: 1668.8851\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1735.1668 - val_loss: 1611.8892\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1675.7775 - val_loss: 1562.2473\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1621.1420 - val_loss: 1543.5347\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1561.8002 - val_loss: 1486.1168\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1510.8636 - val_loss: 1441.2217\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1457.5867 - val_loss: 1419.7737\n",
      "Epoch 29/50\n",
      " - 0s - loss: 1411.0225 - val_loss: 1409.9391\n",
      "Epoch 30/50\n",
      " - 0s - loss: 1361.9780 - val_loss: 1353.6864\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1316.9661 - val_loss: 1342.7317\n",
      "Epoch 32/50\n",
      " - 0s - loss: 1270.0076 - val_loss: 1291.5285\n",
      "Epoch 33/50\n",
      " - 0s - loss: 1226.4496 - val_loss: 1270.2223\n",
      "Epoch 34/50\n",
      " - 0s - loss: 1184.1122 - val_loss: 1236.1176\n",
      "Epoch 35/50\n",
      " - 0s - loss: 1142.2049 - val_loss: 1214.3597\n",
      "Epoch 36/50\n",
      " - 0s - loss: 1104.5317 - val_loss: 1193.5289\n",
      "Epoch 37/50\n",
      " - 0s - loss: 1069.2940 - val_loss: 1188.0672\n",
      "Epoch 38/50\n",
      " - 0s - loss: 1036.5104 - val_loss: 1153.5780\n",
      "Epoch 39/50\n",
      " - 0s - loss: 1004.3132 - val_loss: 1148.4756\n",
      "Epoch 40/50\n",
      " - 0s - loss: 974.6002 - val_loss: 1140.0921\n",
      "Epoch 41/50\n",
      " - 0s - loss: 946.1506 - val_loss: 1120.9430\n",
      "Epoch 42/50\n",
      " - 0s - loss: 919.5405 - val_loss: 1105.0148\n",
      "Epoch 43/50\n",
      " - 0s - loss: 895.2256 - val_loss: 1093.8674\n",
      "Epoch 44/50\n",
      " - 0s - loss: 869.6848 - val_loss: 1090.7716\n",
      "Epoch 45/50\n",
      " - 0s - loss: 847.5295 - val_loss: 1093.2561\n",
      "Epoch 46/50\n",
      " - 0s - loss: 823.7882 - val_loss: 1064.3444\n",
      "Epoch 47/50\n",
      " - 0s - loss: 804.0322 - val_loss: 1050.1810\n",
      "Epoch 48/50\n",
      " - 0s - loss: 785.1337 - val_loss: 1073.0744\n",
      "Epoch 49/50\n",
      " - 0s - loss: 764.3132 - val_loss: 1043.5894\n",
      "Epoch 50/50\n",
      " - 0s - loss: 746.5174 - val_loss: 1034.9279\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 58500.6544 - val_loss: 30550.7751\n",
      "Epoch 2/50\n",
      " - 0s - loss: 18920.1876 - val_loss: 8202.7011\n",
      "Epoch 3/50\n",
      " - 0s - loss: 4595.4191 - val_loss: 2704.6786\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2585.5065 - val_loss: 2536.2030\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2333.1247 - val_loss: 2320.7809\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2090.2007 - val_loss: 2164.0625\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1885.6205 - val_loss: 2010.8948\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1689.7318 - val_loss: 1864.2455\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1510.6860 - val_loss: 1714.2372\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1347.3607 - val_loss: 1571.5607\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1199.6593 - val_loss: 1427.8844\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1062.9678 - val_loss: 1283.1384\n",
      "Epoch 13/50\n",
      " - 0s - loss: 938.2784 - val_loss: 1152.8273\n",
      "Epoch 14/50\n",
      " - 0s - loss: 826.9801 - val_loss: 1018.1806\n",
      "Epoch 15/50\n",
      " - 0s - loss: 720.0221 - val_loss: 902.9816\n",
      "Epoch 16/50\n",
      " - 0s - loss: 627.4710 - val_loss: 788.6314\n",
      "Epoch 17/50\n",
      " - 0s - loss: 545.9545 - val_loss: 684.8134\n",
      "Epoch 18/50\n",
      " - 0s - loss: 473.3970 - val_loss: 593.4344\n",
      "Epoch 19/50\n",
      " - 0s - loss: 408.4238 - val_loss: 512.3951\n",
      "Epoch 20/50\n",
      " - 0s - loss: 354.6916 - val_loss: 441.1640\n",
      "Epoch 21/50\n",
      " - 0s - loss: 310.4071 - val_loss: 377.7376\n",
      "Epoch 22/50\n",
      " - 0s - loss: 272.2893 - val_loss: 339.1788\n",
      "Epoch 23/50\n",
      " - 0s - loss: 243.7519 - val_loss: 290.9089\n",
      "Epoch 24/50\n",
      " - 0s - loss: 218.4781 - val_loss: 258.9284\n",
      "Epoch 25/50\n",
      " - 0s - loss: 199.4637 - val_loss: 234.1007\n",
      "Epoch 26/50\n",
      " - 0s - loss: 184.6835 - val_loss: 211.6995\n",
      "Epoch 27/50\n",
      " - 0s - loss: 173.3788 - val_loss: 194.2613\n",
      "Epoch 28/50\n",
      " - 0s - loss: 164.1100 - val_loss: 187.9655\n",
      "Epoch 29/50\n",
      " - 0s - loss: 157.3295 - val_loss: 169.9333\n",
      "Epoch 30/50\n",
      " - 0s - loss: 156.1315 - val_loss: 169.4374\n",
      "Epoch 31/50\n",
      " - 0s - loss: 148.8470 - val_loss: 161.7635\n",
      "Epoch 32/50\n",
      " - 0s - loss: 145.8823 - val_loss: 155.4780\n",
      "Epoch 33/50\n",
      " - 0s - loss: 144.0840 - val_loss: 155.7112\n",
      "Epoch 34/50\n",
      " - 0s - loss: 141.2430 - val_loss: 144.4761\n",
      "Epoch 35/50\n",
      " - 0s - loss: 141.0891 - val_loss: 147.0800\n",
      "Epoch 36/50\n",
      " - 0s - loss: 139.1956 - val_loss: 140.6895\n",
      "Epoch 37/50\n",
      " - 0s - loss: 139.5027 - val_loss: 144.9533\n",
      "Epoch 38/50\n",
      " - 0s - loss: 137.4118 - val_loss: 138.0350\n",
      "Epoch 39/50\n",
      " - 0s - loss: 137.3858 - val_loss: 134.2344\n",
      "Epoch 40/50\n",
      " - 0s - loss: 136.8714 - val_loss: 142.9436\n",
      "Epoch 41/50\n",
      " - 0s - loss: 135.8581 - val_loss: 133.3254\n",
      "Epoch 42/50\n",
      " - 0s - loss: 135.8553 - val_loss: 132.0630\n",
      "Epoch 43/50\n",
      " - 0s - loss: 136.6118 - val_loss: 131.4581\n",
      "Epoch 44/50\n",
      " - 0s - loss: 134.7680 - val_loss: 140.1683\n",
      "Epoch 45/50\n",
      " - 0s - loss: 134.0256 - val_loss: 130.5269\n",
      "Epoch 46/50\n",
      " - 0s - loss: 133.3223 - val_loss: 140.7651\n",
      "Epoch 47/50\n",
      " - 0s - loss: 133.9438 - val_loss: 128.0441\n",
      "Epoch 48/50\n",
      " - 0s - loss: 134.6689 - val_loss: 128.2014\n",
      "Epoch 49/50\n",
      " - 0s - loss: 132.8054 - val_loss: 131.0614\n",
      "Epoch 50/50\n",
      " - 0s - loss: 133.7287 - val_loss: 129.1423\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 6234.5089 - val_loss: 2866.4275\n",
      "Epoch 2/50\n",
      " - 0s - loss: 4043.6149 - val_loss: 2327.6843\n",
      "Epoch 3/50\n",
      " - 0s - loss: 2629.4880 - val_loss: 2211.5970\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1611.1002 - val_loss: 1424.0095\n",
      "Epoch 5/50\n",
      " - 0s - loss: 950.1707 - val_loss: 1334.1510\n",
      "Epoch 6/50\n",
      " - 0s - loss: 641.2577 - val_loss: 1240.7562\n",
      "Epoch 7/50\n",
      " - 0s - loss: 505.7541 - val_loss: 1103.6378\n",
      "Epoch 8/50\n",
      " - 0s - loss: 439.4708 - val_loss: 1125.4555\n",
      "Epoch 9/50\n",
      " - 0s - loss: 402.2171 - val_loss: 1184.0601\n",
      "Epoch 10/50\n",
      " - 0s - loss: 379.4099 - val_loss: 1082.7181\n",
      "Epoch 11/50\n",
      " - 0s - loss: 366.2260 - val_loss: 1160.7823\n",
      "Epoch 12/50\n",
      " - 0s - loss: 350.4119 - val_loss: 1123.2716\n",
      "Epoch 13/50\n",
      " - 0s - loss: 344.8824 - val_loss: 1087.3084\n",
      "Epoch 14/50\n",
      " - 0s - loss: 330.4020 - val_loss: 995.3244\n",
      "Epoch 15/50\n",
      " - 0s - loss: 318.7849 - val_loss: 902.4963\n",
      "Epoch 16/50\n",
      " - 0s - loss: 311.9331 - val_loss: 1007.4731\n",
      "Epoch 17/50\n",
      " - 0s - loss: 297.1959 - val_loss: 837.8704\n",
      "Epoch 18/50\n",
      " - 0s - loss: 289.7863 - val_loss: 825.8438\n",
      "Epoch 19/50\n",
      " - 0s - loss: 274.5956 - val_loss: 739.3644\n",
      "Epoch 20/50\n",
      " - 0s - loss: 271.7083 - val_loss: 800.0170\n",
      "Epoch 21/50\n",
      " - 0s - loss: 259.4743 - val_loss: 828.4839\n",
      "Epoch 22/50\n",
      " - 0s - loss: 261.6000 - val_loss: 810.0304\n",
      "Epoch 23/50\n",
      " - 0s - loss: 243.4394 - val_loss: 662.3969\n",
      "Epoch 24/50\n",
      " - 0s - loss: 236.2543 - val_loss: 708.1370\n",
      "Epoch 25/50\n",
      " - 0s - loss: 225.3902 - val_loss: 703.5687\n",
      "Epoch 26/50\n",
      " - 0s - loss: 225.4505 - val_loss: 611.1389\n",
      "Epoch 27/50\n",
      " - 0s - loss: 210.3297 - val_loss: 562.7321\n",
      "Epoch 28/50\n",
      " - 0s - loss: 211.3093 - val_loss: 578.0653\n",
      "Epoch 29/50\n",
      " - 0s - loss: 199.8500 - val_loss: 520.4035\n",
      "Epoch 30/50\n",
      " - 0s - loss: 198.4363 - val_loss: 514.2887\n",
      "Epoch 31/50\n",
      " - 0s - loss: 191.4457 - val_loss: 507.0766\n",
      "Epoch 32/50\n",
      " - 0s - loss: 184.0568 - val_loss: 507.0734\n",
      "Epoch 33/50\n",
      " - 0s - loss: 180.1359 - val_loss: 408.9261\n",
      "Epoch 34/50\n",
      " - 0s - loss: 179.0768 - val_loss: 424.5661\n",
      "Epoch 35/50\n",
      " - 0s - loss: 171.0221 - val_loss: 387.8918\n",
      "Epoch 36/50\n",
      " - 0s - loss: 169.0822 - val_loss: 414.9500\n",
      "Epoch 37/50\n",
      " - 0s - loss: 168.0583 - val_loss: 398.9370\n",
      "Epoch 38/50\n",
      " - 0s - loss: 162.6530 - val_loss: 382.2620\n",
      "Epoch 39/50\n",
      " - 0s - loss: 158.6139 - val_loss: 332.2189\n",
      "Epoch 40/50\n",
      " - 0s - loss: 157.9249 - val_loss: 368.4037\n",
      "Epoch 41/50\n",
      " - 0s - loss: 154.9146 - val_loss: 318.5922\n",
      "Epoch 42/50\n",
      " - 0s - loss: 150.5544 - val_loss: 299.4422\n",
      "Epoch 43/50\n",
      " - 0s - loss: 153.8974 - val_loss: 314.9780\n",
      "Epoch 44/50\n",
      " - 0s - loss: 146.8024 - val_loss: 274.0041\n",
      "Epoch 45/50\n",
      " - 0s - loss: 146.5696 - val_loss: 342.1618\n",
      "Epoch 46/50\n",
      " - 0s - loss: 140.6599 - val_loss: 263.6478\n",
      "Epoch 47/50\n",
      " - 0s - loss: 144.5717 - val_loss: 305.5502\n",
      "Epoch 48/50\n",
      " - 0s - loss: 137.9528 - val_loss: 304.2050\n",
      "Epoch 49/50\n",
      " - 0s - loss: 138.1590 - val_loss: 241.9504\n",
      "Epoch 50/50\n",
      " - 0s - loss: 133.5061 - val_loss: 237.5888\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 5198.6685 - val_loss: 2890.6014\n",
      "Epoch 2/50\n",
      " - 0s - loss: 3382.0984 - val_loss: 2553.1458\n",
      "Epoch 3/50\n",
      " - 0s - loss: 2743.3245 - val_loss: 2292.3682\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2126.4826 - val_loss: 1940.5231\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1656.6983 - val_loss: 1597.4861\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1326.8086 - val_loss: 1285.0711\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1080.3187 - val_loss: 1046.4132\n",
      "Epoch 8/50\n",
      " - 0s - loss: 899.1390 - val_loss: 889.1330\n",
      "Epoch 9/50\n",
      " - 0s - loss: 759.9785 - val_loss: 748.7504\n",
      "Epoch 10/50\n",
      " - 0s - loss: 646.4406 - val_loss: 642.3387\n",
      "Epoch 11/50\n",
      " - 0s - loss: 565.2289 - val_loss: 544.5563\n",
      "Epoch 12/50\n",
      " - 0s - loss: 501.6384 - val_loss: 478.5731\n",
      "Epoch 13/50\n",
      " - 0s - loss: 447.7424 - val_loss: 443.0964\n",
      "Epoch 14/50\n",
      " - 0s - loss: 406.7407 - val_loss: 394.8327\n",
      "Epoch 15/50\n",
      " - 0s - loss: 373.9479 - val_loss: 386.2795\n",
      "Epoch 16/50\n",
      " - 0s - loss: 349.9382 - val_loss: 348.6967\n",
      "Epoch 17/50\n",
      " - 0s - loss: 325.5000 - val_loss: 312.5962\n",
      "Epoch 18/50\n",
      " - 0s - loss: 299.0922 - val_loss: 289.4947\n",
      "Epoch 19/50\n",
      " - 0s - loss: 277.0445 - val_loss: 258.6274\n",
      "Epoch 20/50\n",
      " - 0s - loss: 260.9732 - val_loss: 249.9953\n",
      "Epoch 21/50\n",
      " - 0s - loss: 247.8945 - val_loss: 243.5114\n",
      "Epoch 22/50\n",
      " - 0s - loss: 238.6439 - val_loss: 222.1100\n",
      "Epoch 23/50\n",
      " - 0s - loss: 227.1485 - val_loss: 182.5895\n",
      "Epoch 24/50\n",
      " - 0s - loss: 207.0245 - val_loss: 175.2133\n",
      "Epoch 25/50\n",
      " - 0s - loss: 199.0089 - val_loss: 160.0571\n",
      "Epoch 26/50\n",
      " - 0s - loss: 189.0101 - val_loss: 145.8933\n",
      "Epoch 27/50\n",
      " - 0s - loss: 180.2743 - val_loss: 138.6964\n",
      "Epoch 28/50\n",
      " - 0s - loss: 175.0335 - val_loss: 127.9010\n",
      "Epoch 29/50\n",
      " - 0s - loss: 166.5898 - val_loss: 115.6408\n",
      "Epoch 30/50\n",
      " - 0s - loss: 160.8837 - val_loss: 117.4595\n",
      "Epoch 31/50\n",
      " - 0s - loss: 157.3875 - val_loss: 111.9362\n",
      "Epoch 32/50\n",
      " - 0s - loss: 153.6020 - val_loss: 99.2641\n",
      "Epoch 33/50\n",
      " - 0s - loss: 147.8590 - val_loss: 99.3285\n",
      "Epoch 34/50\n",
      " - 0s - loss: 147.7216 - val_loss: 90.2759\n",
      "Epoch 35/50\n",
      " - 0s - loss: 140.3568 - val_loss: 85.7773\n",
      "Epoch 36/50\n",
      " - 0s - loss: 137.5109 - val_loss: 83.0262\n",
      "Epoch 37/50\n",
      " - 0s - loss: 135.4852 - val_loss: 81.8747\n",
      "Epoch 38/50\n",
      " - 0s - loss: 135.3579 - val_loss: 78.9217\n",
      "Epoch 39/50\n",
      " - 0s - loss: 133.0594 - val_loss: 77.5175\n",
      "Epoch 40/50\n",
      " - 0s - loss: 135.9990 - val_loss: 83.7245\n",
      "Epoch 41/50\n",
      " - 0s - loss: 135.0433 - val_loss: 74.7199\n",
      "Epoch 42/50\n",
      " - 0s - loss: 129.0050 - val_loss: 74.3460\n",
      "Epoch 43/50\n",
      " - 0s - loss: 128.5807 - val_loss: 72.5218\n",
      "Epoch 44/50\n",
      " - 0s - loss: 128.4015 - val_loss: 74.3746\n",
      "Epoch 45/50\n",
      " - 0s - loss: 125.7168 - val_loss: 71.4471\n",
      "Epoch 46/50\n",
      " - 0s - loss: 127.2477 - val_loss: 70.5282\n",
      "Epoch 47/50\n",
      " - 0s - loss: 125.8380 - val_loss: 71.8915\n",
      "Epoch 48/50\n",
      " - 0s - loss: 125.1156 - val_loss: 70.1967\n",
      "Epoch 49/50\n",
      " - 0s - loss: 125.4761 - val_loss: 71.0760\n",
      "Epoch 50/50\n",
      " - 0s - loss: 124.5542 - val_loss: 68.5114\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 390114.5850 - val_loss: 270076.0944\n",
      "Epoch 2/50\n",
      " - 0s - loss: 218292.1703 - val_loss: 143811.0741\n",
      "Epoch 3/50\n",
      " - 0s - loss: 113899.1645 - val_loss: 71715.3574\n",
      "Epoch 4/50\n",
      " - 0s - loss: 55862.2218 - val_loss: 33301.3921\n",
      "Epoch 5/50\n",
      " - 0s - loss: 25716.7812 - val_loss: 14277.7889\n",
      "Epoch 6/50\n",
      " - 0s - loss: 11145.6407 - val_loss: 5622.4707\n",
      "Epoch 7/50\n",
      " - 0s - loss: 4636.7877 - val_loss: 2063.9278\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1982.3037 - val_loss: 744.4340\n",
      "Epoch 9/50\n",
      " - 0s - loss: 977.7119 - val_loss: 328.8086\n",
      "Epoch 10/50\n",
      " - 0s - loss: 627.3787 - val_loss: 227.4037\n",
      "Epoch 11/50\n",
      " - 0s - loss: 511.4433 - val_loss: 216.5711\n",
      "Epoch 12/50\n",
      " - 0s - loss: 470.3477 - val_loss: 222.5418\n",
      "Epoch 13/50\n",
      " - 0s - loss: 454.4026 - val_loss: 227.7029\n",
      "Epoch 14/50\n",
      " - 0s - loss: 444.6412 - val_loss: 230.2725\n",
      "Epoch 15/50\n",
      " - 0s - loss: 435.9113 - val_loss: 225.5422\n",
      "Epoch 16/50\n",
      " - 0s - loss: 428.1208 - val_loss: 223.7312\n",
      "Epoch 17/50\n",
      " - 0s - loss: 419.6573 - val_loss: 220.4541\n",
      "Epoch 18/50\n",
      " - 0s - loss: 411.7225 - val_loss: 214.7345\n",
      "Epoch 19/50\n",
      " - 0s - loss: 403.6176 - val_loss: 210.6708\n",
      "Epoch 20/50\n",
      " - 0s - loss: 396.0576 - val_loss: 210.3991\n",
      "Epoch 21/50\n",
      " - 0s - loss: 387.7984 - val_loss: 203.6053\n",
      "Epoch 22/50\n",
      " - 0s - loss: 380.1679 - val_loss: 196.8104\n",
      "Epoch 23/50\n",
      " - 0s - loss: 372.1985 - val_loss: 194.0084\n",
      "Epoch 24/50\n",
      " - 0s - loss: 364.8822 - val_loss: 190.5717\n",
      "Epoch 25/50\n",
      " - 0s - loss: 357.4261 - val_loss: 186.9707\n",
      "Epoch 26/50\n",
      " - 0s - loss: 350.2117 - val_loss: 180.8452\n",
      "Epoch 27/50\n",
      " - 0s - loss: 342.9630 - val_loss: 177.5044\n",
      "Epoch 28/50\n",
      " - 0s - loss: 336.0942 - val_loss: 175.8622\n",
      "Epoch 29/50\n",
      " - 0s - loss: 329.6443 - val_loss: 170.5343\n",
      "Epoch 30/50\n",
      " - 0s - loss: 323.0518 - val_loss: 167.6961\n",
      "Epoch 31/50\n",
      " - 0s - loss: 316.7476 - val_loss: 163.9441\n",
      "Epoch 32/50\n",
      " - 0s - loss: 310.6175 - val_loss: 161.0054\n",
      "Epoch 33/50\n",
      " - 0s - loss: 304.3767 - val_loss: 156.8279\n",
      "Epoch 34/50\n",
      " - 0s - loss: 298.4802 - val_loss: 154.9129\n",
      "Epoch 35/50\n",
      " - 0s - loss: 292.8375 - val_loss: 151.9166\n",
      "Epoch 36/50\n",
      " - 0s - loss: 286.9956 - val_loss: 147.4038\n",
      "Epoch 37/50\n",
      " - 0s - loss: 281.8546 - val_loss: 145.0217\n",
      "Epoch 38/50\n",
      " - 0s - loss: 276.9100 - val_loss: 143.1834\n",
      "Epoch 39/50\n",
      " - 0s - loss: 271.5372 - val_loss: 138.9061\n",
      "Epoch 40/50\n",
      " - 0s - loss: 266.5653 - val_loss: 137.4188\n",
      "Epoch 41/50\n",
      " - 0s - loss: 262.2829 - val_loss: 134.7326\n",
      "Epoch 42/50\n",
      " - 0s - loss: 257.5403 - val_loss: 134.0873\n",
      "Epoch 43/50\n",
      " - 0s - loss: 253.0532 - val_loss: 130.4530\n",
      "Epoch 44/50\n",
      " - 0s - loss: 248.7694 - val_loss: 129.7438\n",
      "Epoch 45/50\n",
      " - 0s - loss: 244.6698 - val_loss: 125.6517\n",
      "Epoch 46/50\n",
      " - 0s - loss: 240.7869 - val_loss: 124.1223\n",
      "Epoch 47/50\n",
      " - 0s - loss: 236.7040 - val_loss: 121.7260\n",
      "Epoch 48/50\n",
      " - 0s - loss: 232.9783 - val_loss: 118.6744\n",
      "Epoch 49/50\n",
      " - 0s - loss: 229.0560 - val_loss: 119.2087\n",
      "Epoch 50/50\n",
      " - 0s - loss: 225.5567 - val_loss: 119.3165\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 25016.6114 - val_loss: 2066.7638\n",
      "Epoch 2/50\n",
      " - 0s - loss: 5422.9828 - val_loss: 1506.8366\n",
      "Epoch 3/50\n",
      " - 0s - loss: 4135.2219 - val_loss: 1088.6156\n",
      "Epoch 4/50\n",
      " - 0s - loss: 3358.7048 - val_loss: 874.9959\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2812.5462 - val_loss: 764.5865\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2375.2789 - val_loss: 698.3073\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2055.9524 - val_loss: 663.9436\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1796.0290 - val_loss: 636.4580\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1594.8564 - val_loss: 622.8279\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1431.9988 - val_loss: 622.3340\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1297.2189 - val_loss: 633.4545\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1185.6699 - val_loss: 632.2841\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1096.9817 - val_loss: 643.1188\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1019.5974 - val_loss: 671.6474\n",
      "Epoch 15/50\n",
      " - 0s - loss: 936.9137 - val_loss: 711.5819\n",
      "Epoch 16/50\n",
      " - 0s - loss: 877.8726 - val_loss: 715.8792\n",
      "Epoch 17/50\n",
      " - 0s - loss: 814.5190 - val_loss: 758.4040\n",
      "Epoch 18/50\n",
      " - 0s - loss: 763.0614 - val_loss: 767.1657\n",
      "Epoch 19/50\n",
      " - 0s - loss: 716.6188 - val_loss: 826.0094\n",
      "Epoch 20/50\n",
      " - 0s - loss: 675.0274 - val_loss: 809.2699\n",
      "Epoch 21/50\n",
      " - 0s - loss: 651.3890 - val_loss: 811.1525\n",
      "Epoch 22/50\n",
      " - 0s - loss: 615.3027 - val_loss: 833.7519\n",
      "Epoch 23/50\n",
      " - 0s - loss: 587.7107 - val_loss: 796.6749\n",
      "Epoch 24/50\n",
      " - 0s - loss: 564.6097 - val_loss: 803.2403\n",
      "Epoch 25/50\n",
      " - 0s - loss: 540.6468 - val_loss: 759.9600\n",
      "Epoch 26/50\n",
      " - 0s - loss: 517.4756 - val_loss: 724.0028\n",
      "Epoch 27/50\n",
      " - 0s - loss: 498.2545 - val_loss: 701.3614\n",
      "Epoch 28/50\n",
      " - 0s - loss: 473.3089 - val_loss: 687.1669\n",
      "Epoch 29/50\n",
      " - 0s - loss: 458.5385 - val_loss: 640.9292\n",
      "Epoch 30/50\n",
      " - 0s - loss: 434.7984 - val_loss: 587.9649\n",
      "Epoch 31/50\n",
      " - 0s - loss: 413.2744 - val_loss: 545.0995\n",
      "Epoch 32/50\n",
      " - 0s - loss: 401.3869 - val_loss: 532.0737\n",
      "Epoch 33/50\n",
      " - 0s - loss: 385.2157 - val_loss: 472.8527\n",
      "Epoch 34/50\n",
      " - 0s - loss: 364.4528 - val_loss: 442.4976\n",
      "Epoch 35/50\n",
      " - 0s - loss: 349.4360 - val_loss: 404.7157\n",
      "Epoch 36/50\n",
      " - 0s - loss: 338.4140 - val_loss: 390.7761\n",
      "Epoch 37/50\n",
      " - 0s - loss: 324.6930 - val_loss: 362.1613\n",
      "Epoch 38/50\n",
      " - 0s - loss: 310.5452 - val_loss: 382.2950\n",
      "Epoch 39/50\n",
      " - 0s - loss: 302.1719 - val_loss: 369.5977\n",
      "Epoch 40/50\n",
      " - 0s - loss: 289.7668 - val_loss: 332.7605\n",
      "Epoch 41/50\n",
      " - 0s - loss: 274.5141 - val_loss: 319.6565\n",
      "Epoch 42/50\n",
      " - 0s - loss: 263.0012 - val_loss: 289.3662\n",
      "Epoch 43/50\n",
      " - 0s - loss: 257.9320 - val_loss: 303.2727\n",
      "Epoch 44/50\n",
      " - 0s - loss: 246.3392 - val_loss: 263.1218\n",
      "Epoch 45/50\n",
      " - 0s - loss: 240.5303 - val_loss: 239.0912\n",
      "Epoch 46/50\n",
      " - 0s - loss: 234.9051 - val_loss: 283.7190\n",
      "Epoch 47/50\n",
      " - 0s - loss: 225.7926 - val_loss: 236.3396\n",
      "Epoch 48/50\n",
      " - 0s - loss: 221.1422 - val_loss: 239.9728\n",
      "Epoch 49/50\n",
      " - 0s - loss: 213.8295 - val_loss: 264.4365\n",
      "Epoch 50/50\n",
      " - 0s - loss: 212.4685 - val_loss: 261.5366\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 65410.9777 - val_loss: 26171.5617\n",
      "Epoch 2/50\n",
      " - 0s - loss: 15598.5702 - val_loss: 3680.9926\n",
      "Epoch 3/50\n",
      " - 0s - loss: 2970.6832 - val_loss: 1109.2922\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1489.1329 - val_loss: 876.4190\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1119.9554 - val_loss: 705.4199\n",
      "Epoch 6/50\n",
      " - 0s - loss: 943.7280 - val_loss: 622.0490\n",
      "Epoch 7/50\n",
      " - 0s - loss: 831.6032 - val_loss: 552.5476\n",
      "Epoch 8/50\n",
      " - 0s - loss: 740.4127 - val_loss: 499.8783\n",
      "Epoch 9/50\n",
      " - 0s - loss: 658.7810 - val_loss: 440.9419\n",
      "Epoch 10/50\n",
      " - 0s - loss: 584.9099 - val_loss: 406.5904\n",
      "Epoch 11/50\n",
      " - 0s - loss: 518.9794 - val_loss: 362.2279\n",
      "Epoch 12/50\n",
      " - 0s - loss: 463.4147 - val_loss: 329.6285\n",
      "Epoch 13/50\n",
      " - 0s - loss: 414.0990 - val_loss: 310.8732\n",
      "Epoch 14/50\n",
      " - 0s - loss: 372.1285 - val_loss: 285.8725\n",
      "Epoch 15/50\n",
      " - 0s - loss: 335.3844 - val_loss: 263.8310\n",
      "Epoch 16/50\n",
      " - 0s - loss: 305.0614 - val_loss: 244.3486\n",
      "Epoch 17/50\n",
      " - 0s - loss: 279.0221 - val_loss: 229.7761\n",
      "Epoch 18/50\n",
      " - 0s - loss: 257.1779 - val_loss: 220.8371\n",
      "Epoch 19/50\n",
      " - 0s - loss: 239.0566 - val_loss: 213.3402\n",
      "Epoch 20/50\n",
      " - 0s - loss: 224.7436 - val_loss: 197.6559\n",
      "Epoch 21/50\n",
      " - 0s - loss: 212.3303 - val_loss: 195.1241\n",
      "Epoch 22/50\n",
      " - 0s - loss: 202.6739 - val_loss: 187.3524\n",
      "Epoch 23/50\n",
      " - 0s - loss: 194.8145 - val_loss: 183.8925\n",
      "Epoch 24/50\n",
      " - 0s - loss: 188.0760 - val_loss: 179.7133\n",
      "Epoch 25/50\n",
      " - 0s - loss: 182.9316 - val_loss: 173.5894\n",
      "Epoch 26/50\n",
      " - 0s - loss: 178.7267 - val_loss: 174.4238\n",
      "Epoch 27/50\n",
      " - 0s - loss: 175.0785 - val_loss: 170.0591\n",
      "Epoch 28/50\n",
      " - 0s - loss: 172.2115 - val_loss: 166.7259\n",
      "Epoch 29/50\n",
      " - 0s - loss: 169.6747 - val_loss: 167.6124\n",
      "Epoch 30/50\n",
      " - 0s - loss: 167.5650 - val_loss: 163.5184\n",
      "Epoch 31/50\n",
      " - 0s - loss: 165.8263 - val_loss: 159.2669\n",
      "Epoch 32/50\n",
      " - 0s - loss: 164.7245 - val_loss: 161.7747\n",
      "Epoch 33/50\n",
      " - 0s - loss: 163.1075 - val_loss: 158.1227\n",
      "Epoch 34/50\n",
      " - 0s - loss: 162.2828 - val_loss: 160.6929\n",
      "Epoch 35/50\n",
      " - 0s - loss: 161.5303 - val_loss: 156.2495\n",
      "Epoch 36/50\n",
      " - 0s - loss: 159.5761 - val_loss: 158.8158\n",
      "Epoch 37/50\n",
      " - 0s - loss: 158.8483 - val_loss: 154.5821\n",
      "Epoch 38/50\n",
      " - 0s - loss: 158.2859 - val_loss: 154.5950\n",
      "Epoch 39/50\n",
      " - 0s - loss: 157.4183 - val_loss: 154.4667\n",
      "Epoch 40/50\n",
      " - 0s - loss: 156.6514 - val_loss: 152.9104\n",
      "Epoch 41/50\n",
      " - 0s - loss: 156.4098 - val_loss: 152.4731\n",
      "Epoch 42/50\n",
      " - 0s - loss: 155.3248 - val_loss: 152.6204\n",
      "Epoch 43/50\n",
      " - 0s - loss: 154.8046 - val_loss: 151.4601\n",
      "Epoch 44/50\n",
      " - 0s - loss: 154.2105 - val_loss: 153.3621\n",
      "Epoch 45/50\n",
      " - 0s - loss: 153.3547 - val_loss: 151.1761\n",
      "Epoch 46/50\n",
      " - 0s - loss: 152.8220 - val_loss: 152.2849\n",
      "Epoch 47/50\n",
      " - 0s - loss: 152.4174 - val_loss: 152.9102\n",
      "Epoch 48/50\n",
      " - 0s - loss: 151.6270 - val_loss: 145.9959\n",
      "Epoch 49/50\n",
      " - 0s - loss: 151.9057 - val_loss: 147.6308\n",
      "Epoch 50/50\n",
      " - 0s - loss: 150.7020 - val_loss: 149.1848\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 372886.1406 - val_loss: 278809.5733\n",
      "Epoch 2/50\n",
      " - 0s - loss: 237781.5132 - val_loss: 178728.8547\n",
      "Epoch 3/50\n",
      " - 0s - loss: 154803.1929 - val_loss: 115441.4782\n",
      "Epoch 4/50\n",
      " - 0s - loss: 100297.9437 - val_loss: 73132.4790\n",
      "Epoch 5/50\n",
      " - 0s - loss: 62875.2877 - val_loss: 44209.3275\n",
      "Epoch 6/50\n",
      " - 0s - loss: 37316.2030 - val_loss: 24999.2884\n",
      "Epoch 7/50\n",
      " - 0s - loss: 20718.5758 - val_loss: 13022.2099\n",
      "Epoch 8/50\n",
      " - 0s - loss: 10862.5930 - val_loss: 6358.5831\n",
      "Epoch 9/50\n",
      " - 0s - loss: 5571.8316 - val_loss: 3207.6538\n",
      "Epoch 10/50\n",
      " - 0s - loss: 3170.9951 - val_loss: 1871.3450\n",
      "Epoch 11/50\n",
      " - 0s - loss: 2192.2707 - val_loss: 1413.3274\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1850.7290 - val_loss: 1272.4575\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1726.4121 - val_loss: 1227.3820\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1667.4099 - val_loss: 1199.4991\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1624.7364 - val_loss: 1175.8071\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1585.9084 - val_loss: 1152.7813\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1545.6100 - val_loss: 1127.2741\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1507.5542 - val_loss: 1098.0665\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1465.5246 - val_loss: 1071.1330\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1425.2852 - val_loss: 1042.9060\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1384.5727 - val_loss: 1016.9966\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1345.0364 - val_loss: 986.8273\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1304.7360 - val_loss: 961.1437\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1264.9518 - val_loss: 934.9334\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1227.5378 - val_loss: 912.7817\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1193.4350 - val_loss: 888.3917\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1156.9533 - val_loss: 873.7521\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1125.6137 - val_loss: 850.3924\n",
      "Epoch 29/50\n",
      " - 0s - loss: 1091.4326 - val_loss: 831.9060\n",
      "Epoch 30/50\n",
      " - 0s - loss: 1059.0385 - val_loss: 812.6064\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1027.2992 - val_loss: 793.9021\n",
      "Epoch 32/50\n",
      " - 0s - loss: 995.4617 - val_loss: 774.6249\n",
      "Epoch 33/50\n",
      " - 0s - loss: 963.7947 - val_loss: 759.2643\n",
      "Epoch 34/50\n",
      " - 0s - loss: 939.1416 - val_loss: 739.4398\n",
      "Epoch 35/50\n",
      " - 0s - loss: 906.1982 - val_loss: 723.7390\n",
      "Epoch 36/50\n",
      " - 0s - loss: 877.8793 - val_loss: 712.3808\n",
      "Epoch 37/50\n",
      " - 0s - loss: 850.4884 - val_loss: 697.8622\n",
      "Epoch 38/50\n",
      " - 0s - loss: 823.5546 - val_loss: 677.4881\n",
      "Epoch 39/50\n",
      " - 0s - loss: 798.1857 - val_loss: 658.7729\n",
      "Epoch 40/50\n",
      " - 0s - loss: 773.4309 - val_loss: 652.8496\n",
      "Epoch 41/50\n",
      " - 0s - loss: 747.4020 - val_loss: 633.3201\n",
      "Epoch 42/50\n",
      " - 0s - loss: 725.6528 - val_loss: 620.2012\n",
      "Epoch 43/50\n",
      " - 0s - loss: 703.0044 - val_loss: 612.5248\n",
      "Epoch 44/50\n",
      " - 0s - loss: 683.4282 - val_loss: 595.7238\n",
      "Epoch 45/50\n",
      " - 0s - loss: 661.1395 - val_loss: 589.8834\n",
      "Epoch 46/50\n",
      " - 0s - loss: 641.8703 - val_loss: 574.4456\n",
      "Epoch 47/50\n",
      " - 0s - loss: 622.6808 - val_loss: 567.8054\n",
      "Epoch 48/50\n",
      " - 0s - loss: 606.7010 - val_loss: 551.1244\n",
      "Epoch 49/50\n",
      " - 0s - loss: 587.2733 - val_loss: 546.9951\n",
      "Epoch 50/50\n",
      " - 0s - loss: 572.0870 - val_loss: 538.1030\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 3362.8127 - val_loss: 603.6807\n",
      "Epoch 2/50\n",
      " - 0s - loss: 884.4179 - val_loss: 534.0321\n",
      "Epoch 3/50\n",
      " - 0s - loss: 606.6116 - val_loss: 499.1783\n",
      "Epoch 4/50\n",
      " - 0s - loss: 506.3806 - val_loss: 494.5991\n",
      "Epoch 5/50\n",
      " - 0s - loss: 450.0500 - val_loss: 472.4456\n",
      "Epoch 6/50\n",
      " - 0s - loss: 402.1967 - val_loss: 452.4769\n",
      "Epoch 7/50\n",
      " - 0s - loss: 374.6111 - val_loss: 426.6147\n",
      "Epoch 8/50\n",
      " - 0s - loss: 357.1638 - val_loss: 412.1270\n",
      "Epoch 9/50\n",
      " - 0s - loss: 336.6641 - val_loss: 406.5075\n",
      "Epoch 10/50\n",
      " - 0s - loss: 322.4231 - val_loss: 389.6431\n",
      "Epoch 11/50\n",
      " - 0s - loss: 310.7777 - val_loss: 372.2227\n",
      "Epoch 12/50\n",
      " - 0s - loss: 300.4857 - val_loss: 358.8765\n",
      "Epoch 13/50\n",
      " - 0s - loss: 292.5965 - val_loss: 359.5613\n",
      "Epoch 14/50\n",
      " - 0s - loss: 284.4379 - val_loss: 335.6029\n",
      "Epoch 15/50\n",
      " - 0s - loss: 276.4328 - val_loss: 331.4629\n",
      "Epoch 16/50\n",
      " - 0s - loss: 270.8855 - val_loss: 315.5172\n",
      "Epoch 17/50\n",
      " - 0s - loss: 264.2378 - val_loss: 323.3821\n",
      "Epoch 18/50\n",
      " - 0s - loss: 260.4869 - val_loss: 300.3968\n",
      "Epoch 19/50\n",
      " - 0s - loss: 256.0237 - val_loss: 287.3230\n",
      "Epoch 20/50\n",
      " - 0s - loss: 244.1839 - val_loss: 288.8919\n",
      "Epoch 21/50\n",
      " - 0s - loss: 241.0148 - val_loss: 274.8158\n",
      "Epoch 22/50\n",
      " - 0s - loss: 233.3156 - val_loss: 275.7895\n",
      "Epoch 23/50\n",
      " - 0s - loss: 232.2014 - val_loss: 274.4538\n",
      "Epoch 24/50\n",
      " - 0s - loss: 228.3460 - val_loss: 266.1619\n",
      "Epoch 25/50\n",
      " - 0s - loss: 220.3727 - val_loss: 253.8655\n",
      "Epoch 26/50\n",
      " - 0s - loss: 216.5333 - val_loss: 252.9055\n",
      "Epoch 27/50\n",
      " - 0s - loss: 212.4651 - val_loss: 245.2110\n",
      "Epoch 28/50\n",
      " - 0s - loss: 208.3739 - val_loss: 251.5913\n",
      "Epoch 29/50\n",
      " - 0s - loss: 210.4187 - val_loss: 238.2841\n",
      "Epoch 30/50\n",
      " - 0s - loss: 203.9626 - val_loss: 246.3631\n",
      "Epoch 31/50\n",
      " - 0s - loss: 198.7239 - val_loss: 232.8212\n",
      "Epoch 32/50\n",
      " - 0s - loss: 194.9261 - val_loss: 231.7928\n",
      "Epoch 33/50\n",
      " - 0s - loss: 189.8841 - val_loss: 233.8095\n",
      "Epoch 34/50\n",
      " - 0s - loss: 187.0966 - val_loss: 224.5460\n",
      "Epoch 35/50\n",
      " - 0s - loss: 185.5258 - val_loss: 220.4459\n",
      "Epoch 36/50\n",
      " - 0s - loss: 180.5898 - val_loss: 215.0681\n",
      "Epoch 37/50\n",
      " - 0s - loss: 177.1795 - val_loss: 206.2502\n",
      "Epoch 38/50\n",
      " - 0s - loss: 175.0733 - val_loss: 212.0200\n",
      "Epoch 39/50\n",
      " - 0s - loss: 171.4953 - val_loss: 200.3971\n",
      "Epoch 40/50\n",
      " - 0s - loss: 169.0889 - val_loss: 198.7718\n",
      "Epoch 41/50\n",
      " - 0s - loss: 167.7295 - val_loss: 196.7283\n",
      "Epoch 42/50\n",
      " - 0s - loss: 165.2939 - val_loss: 185.3411\n",
      "Epoch 43/50\n",
      " - 0s - loss: 161.4952 - val_loss: 185.5233\n",
      "Epoch 44/50\n",
      " - 0s - loss: 156.7955 - val_loss: 173.0632\n",
      "Epoch 45/50\n",
      " - 0s - loss: 157.0303 - val_loss: 181.6071\n",
      "Epoch 46/50\n",
      " - 0s - loss: 154.9127 - val_loss: 172.8762\n",
      "Epoch 47/50\n",
      " - 0s - loss: 152.9253 - val_loss: 170.6771\n",
      "Epoch 48/50\n",
      " - 0s - loss: 149.3295 - val_loss: 164.6008\n",
      "Epoch 49/50\n",
      " - 0s - loss: 150.3528 - val_loss: 165.4727\n",
      "Epoch 50/50\n",
      " - 0s - loss: 143.7378 - val_loss: 163.7298\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 36946.2552 - val_loss: 8194.1368\n",
      "Epoch 2/50\n",
      " - 0s - loss: 7368.4073 - val_loss: 3508.1657\n",
      "Epoch 3/50\n",
      " - 0s - loss: 5643.6820 - val_loss: 2755.2724\n",
      "Epoch 4/50\n",
      " - 0s - loss: 4699.9720 - val_loss: 2371.1742\n",
      "Epoch 5/50\n",
      " - 0s - loss: 4034.6092 - val_loss: 2094.9062\n",
      "Epoch 6/50\n",
      " - 0s - loss: 3482.1913 - val_loss: 1838.4424\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2999.7651 - val_loss: 1634.3656\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2580.3034 - val_loss: 1460.7760\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2237.7628 - val_loss: 1304.1790\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1929.9680 - val_loss: 1192.0072\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1686.1704 - val_loss: 1091.4569\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1484.1764 - val_loss: 996.6672\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1316.2638 - val_loss: 936.2022\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1170.0299 - val_loss: 866.3050\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1043.9675 - val_loss: 820.7170\n",
      "Epoch 16/50\n",
      " - 0s - loss: 942.4002 - val_loss: 773.0961\n",
      "Epoch 17/50\n",
      " - 0s - loss: 859.7251 - val_loss: 734.3049\n",
      "Epoch 18/50\n",
      " - 0s - loss: 786.2188 - val_loss: 706.9186\n",
      "Epoch 19/50\n",
      " - 0s - loss: 721.4555 - val_loss: 677.3058\n",
      "Epoch 20/50\n",
      " - 0s - loss: 668.4057 - val_loss: 643.3871\n",
      "Epoch 21/50\n",
      " - 0s - loss: 620.6130 - val_loss: 623.6209\n",
      "Epoch 22/50\n",
      " - 0s - loss: 577.8845 - val_loss: 603.5795\n",
      "Epoch 23/50\n",
      " - 0s - loss: 539.6396 - val_loss: 582.2244\n",
      "Epoch 24/50\n",
      " - 0s - loss: 505.9537 - val_loss: 560.3466\n",
      "Epoch 25/50\n",
      " - 0s - loss: 474.8300 - val_loss: 529.7444\n",
      "Epoch 26/50\n",
      " - 0s - loss: 448.1582 - val_loss: 524.2199\n",
      "Epoch 27/50\n",
      " - 0s - loss: 422.0125 - val_loss: 506.6859\n",
      "Epoch 28/50\n",
      " - 0s - loss: 399.8076 - val_loss: 489.8048\n",
      "Epoch 29/50\n",
      " - 0s - loss: 376.3548 - val_loss: 463.6710\n",
      "Epoch 30/50\n",
      " - 0s - loss: 357.3244 - val_loss: 453.1280\n",
      "Epoch 31/50\n",
      " - 0s - loss: 339.6085 - val_loss: 426.6369\n",
      "Epoch 32/50\n",
      " - 0s - loss: 321.6338 - val_loss: 430.0015\n",
      "Epoch 33/50\n",
      " - 0s - loss: 307.1831 - val_loss: 406.2276\n",
      "Epoch 34/50\n",
      " - 0s - loss: 295.7411 - val_loss: 403.6869\n",
      "Epoch 35/50\n",
      " - 0s - loss: 280.2500 - val_loss: 377.3247\n",
      "Epoch 36/50\n",
      " - 0s - loss: 270.3463 - val_loss: 378.9952\n",
      "Epoch 37/50\n",
      " - 0s - loss: 256.4554 - val_loss: 348.3186\n",
      "Epoch 38/50\n",
      " - 0s - loss: 247.8521 - val_loss: 350.2310\n",
      "Epoch 39/50\n",
      " - 0s - loss: 238.2995 - val_loss: 330.3365\n",
      "Epoch 40/50\n",
      " - 0s - loss: 230.2505 - val_loss: 323.0651\n",
      "Epoch 41/50\n",
      " - 0s - loss: 223.2415 - val_loss: 308.4375\n",
      "Epoch 42/50\n",
      " - 0s - loss: 215.4091 - val_loss: 306.5981\n",
      "Epoch 43/50\n",
      " - 0s - loss: 209.5742 - val_loss: 301.5875\n",
      "Epoch 44/50\n",
      " - 0s - loss: 203.5788 - val_loss: 290.8024\n",
      "Epoch 45/50\n",
      " - 0s - loss: 199.2909 - val_loss: 281.5116\n",
      "Epoch 46/50\n",
      " - 0s - loss: 194.2133 - val_loss: 274.8542\n",
      "Epoch 47/50\n",
      " - 0s - loss: 190.2518 - val_loss: 272.9073\n",
      "Epoch 48/50\n",
      " - 0s - loss: 185.6663 - val_loss: 258.0169\n",
      "Epoch 49/50\n",
      " - 0s - loss: 182.5752 - val_loss: 252.5974\n",
      "Epoch 50/50\n",
      " - 0s - loss: 179.6073 - val_loss: 239.0154\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 230233.6031 - val_loss: 164356.7010\n",
      "Epoch 2/50\n",
      " - 0s - loss: 133846.4563 - val_loss: 88506.1110\n",
      "Epoch 3/50\n",
      " - 0s - loss: 69608.5794 - val_loss: 43063.0582\n",
      "Epoch 4/50\n",
      " - 0s - loss: 33121.7838 - val_loss: 19764.8089\n",
      "Epoch 5/50\n",
      " - 0s - loss: 15678.2301 - val_loss: 9432.1548\n",
      "Epoch 6/50\n",
      " - 0s - loss: 8406.7211 - val_loss: 5384.7365\n",
      "Epoch 7/50\n",
      " - 0s - loss: 5539.8771 - val_loss: 3996.1800\n",
      "Epoch 8/50\n",
      " - 0s - loss: 4472.4496 - val_loss: 3501.5553\n",
      "Epoch 9/50\n",
      " - 0s - loss: 4005.1810 - val_loss: 3309.2269\n",
      "Epoch 10/50\n",
      " - 0s - loss: 3725.9909 - val_loss: 3183.8448\n",
      "Epoch 11/50\n",
      " - 0s - loss: 3509.4959 - val_loss: 3065.5880\n",
      "Epoch 12/50\n",
      " - 0s - loss: 3311.1120 - val_loss: 2947.2540\n",
      "Epoch 13/50\n",
      " - 0s - loss: 3120.8025 - val_loss: 2826.6790\n",
      "Epoch 14/50\n",
      " - 0s - loss: 2941.0171 - val_loss: 2711.9615\n",
      "Epoch 15/50\n",
      " - 0s - loss: 2769.1134 - val_loss: 2604.1895\n",
      "Epoch 16/50\n",
      " - 0s - loss: 2602.0457 - val_loss: 2496.6316\n",
      "Epoch 17/50\n",
      " - 0s - loss: 2443.2097 - val_loss: 2387.6371\n",
      "Epoch 18/50\n",
      " - 0s - loss: 2296.1519 - val_loss: 2279.7249\n",
      "Epoch 19/50\n",
      " - 0s - loss: 2151.9924 - val_loss: 2186.4949\n",
      "Epoch 20/50\n",
      " - 0s - loss: 2016.1572 - val_loss: 2086.9242\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1891.1296 - val_loss: 1998.3803\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1775.6436 - val_loss: 1910.7927\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1667.7044 - val_loss: 1830.6632\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1567.8031 - val_loss: 1762.9424\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1477.8056 - val_loss: 1694.4131\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1394.5543 - val_loss: 1629.1570\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1321.5062 - val_loss: 1564.7687\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1248.6844 - val_loss: 1515.2937\n",
      "Epoch 29/50\n",
      " - 0s - loss: 1183.2956 - val_loss: 1460.7896\n",
      "Epoch 30/50\n",
      " - 0s - loss: 1124.3861 - val_loss: 1410.4887\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1069.9232 - val_loss: 1365.9743\n",
      "Epoch 32/50\n",
      " - 0s - loss: 1021.3972 - val_loss: 1317.9244\n",
      "Epoch 33/50\n",
      " - 0s - loss: 977.1897 - val_loss: 1276.3767\n",
      "Epoch 34/50\n",
      " - 0s - loss: 935.6962 - val_loss: 1234.0420\n",
      "Epoch 35/50\n",
      " - 0s - loss: 897.7458 - val_loss: 1193.9759\n",
      "Epoch 36/50\n",
      " - 0s - loss: 863.8735 - val_loss: 1164.6603\n",
      "Epoch 37/50\n",
      " - 0s - loss: 831.7282 - val_loss: 1128.0976\n",
      "Epoch 38/50\n",
      " - 0s - loss: 802.3824 - val_loss: 1092.5122\n",
      "Epoch 39/50\n",
      " - 0s - loss: 775.4825 - val_loss: 1063.8944\n",
      "Epoch 40/50\n",
      " - 0s - loss: 752.0478 - val_loss: 1047.5907\n",
      "Epoch 41/50\n",
      " - 0s - loss: 728.3452 - val_loss: 1007.4684\n",
      "Epoch 42/50\n",
      " - 0s - loss: 706.5666 - val_loss: 991.7378\n",
      "Epoch 43/50\n",
      " - 0s - loss: 686.2396 - val_loss: 964.6969\n",
      "Epoch 44/50\n",
      " - 0s - loss: 667.8924 - val_loss: 942.4313\n",
      "Epoch 45/50\n",
      " - 0s - loss: 651.8433 - val_loss: 916.4378\n",
      "Epoch 46/50\n",
      " - 0s - loss: 636.7378 - val_loss: 901.8643\n",
      "Epoch 47/50\n",
      " - 0s - loss: 620.4963 - val_loss: 879.0630\n",
      "Epoch 48/50\n",
      " - 0s - loss: 607.9865 - val_loss: 855.8122\n",
      "Epoch 49/50\n",
      " - 0s - loss: 595.3489 - val_loss: 834.8828\n",
      "Epoch 50/50\n",
      " - 0s - loss: 581.2332 - val_loss: 826.3232\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 25718.2286 - val_loss: 7806.6313\n",
      "Epoch 2/50\n",
      " - 0s - loss: 4869.0665 - val_loss: 929.5143\n",
      "Epoch 3/50\n",
      " - 0s - loss: 2172.9490 - val_loss: 942.0860\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1924.5906 - val_loss: 731.9662\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1713.5028 - val_loss: 645.5637\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1531.5942 - val_loss: 577.9952\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1363.2393 - val_loss: 507.5878\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1219.4555 - val_loss: 465.1739\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1086.2258 - val_loss: 406.0553\n",
      "Epoch 10/50\n",
      " - 0s - loss: 975.1366 - val_loss: 375.1416\n",
      "Epoch 11/50\n",
      " - 0s - loss: 876.3961 - val_loss: 334.9743\n",
      "Epoch 12/50\n",
      " - 0s - loss: 790.4237 - val_loss: 311.8258\n",
      "Epoch 13/50\n",
      " - 0s - loss: 719.5954 - val_loss: 283.3731\n",
      "Epoch 14/50\n",
      " - 0s - loss: 655.7773 - val_loss: 263.5377\n",
      "Epoch 15/50\n",
      " - 0s - loss: 598.3091 - val_loss: 257.0094\n",
      "Epoch 16/50\n",
      " - 0s - loss: 550.1972 - val_loss: 237.2503\n",
      "Epoch 17/50\n",
      " - 0s - loss: 511.0398 - val_loss: 223.4765\n",
      "Epoch 18/50\n",
      " - 0s - loss: 476.6483 - val_loss: 218.6279\n",
      "Epoch 19/50\n",
      " - 0s - loss: 442.7071 - val_loss: 204.0208\n",
      "Epoch 20/50\n",
      " - 0s - loss: 417.7216 - val_loss: 212.0749\n",
      "Epoch 21/50\n",
      " - 0s - loss: 393.7992 - val_loss: 189.9822\n",
      "Epoch 22/50\n",
      " - 0s - loss: 372.3455 - val_loss: 196.9541\n",
      "Epoch 23/50\n",
      " - 0s - loss: 353.4265 - val_loss: 189.5231\n",
      "Epoch 24/50\n",
      " - 0s - loss: 336.0584 - val_loss: 191.0075\n",
      "Epoch 25/50\n",
      " - 0s - loss: 323.5294 - val_loss: 185.3693\n",
      "Epoch 26/50\n",
      " - 0s - loss: 308.7330 - val_loss: 178.7370\n",
      "Epoch 27/50\n",
      " - 0s - loss: 295.5582 - val_loss: 177.6627\n",
      "Epoch 28/50\n",
      " - 0s - loss: 284.4972 - val_loss: 175.7306\n",
      "Epoch 29/50\n",
      " - 0s - loss: 274.5724 - val_loss: 170.5061\n",
      "Epoch 30/50\n",
      " - 0s - loss: 265.0543 - val_loss: 173.6547\n",
      "Epoch 31/50\n",
      " - 0s - loss: 256.7168 - val_loss: 160.6740\n",
      "Epoch 32/50\n",
      " - 0s - loss: 248.6870 - val_loss: 172.2343\n",
      "Epoch 33/50\n",
      " - 0s - loss: 244.9836 - val_loss: 157.3088\n",
      "Epoch 34/50\n",
      " - 0s - loss: 235.9497 - val_loss: 153.9023\n",
      "Epoch 35/50\n",
      " - 0s - loss: 228.0991 - val_loss: 155.2899\n",
      "Epoch 36/50\n",
      " - 0s - loss: 221.9096 - val_loss: 148.3813\n",
      "Epoch 37/50\n",
      " - 0s - loss: 216.7564 - val_loss: 148.8911\n",
      "Epoch 38/50\n",
      " - 0s - loss: 211.4453 - val_loss: 143.2663\n",
      "Epoch 39/50\n",
      " - 0s - loss: 206.7490 - val_loss: 138.9453\n",
      "Epoch 40/50\n",
      " - 0s - loss: 202.0867 - val_loss: 137.4885\n",
      "Epoch 41/50\n",
      " - 0s - loss: 197.3929 - val_loss: 133.4491\n",
      "Epoch 42/50\n",
      " - 0s - loss: 193.4795 - val_loss: 127.9170\n",
      "Epoch 43/50\n",
      " - 0s - loss: 189.7920 - val_loss: 129.3956\n",
      "Epoch 44/50\n",
      " - 0s - loss: 185.9498 - val_loss: 132.3100\n",
      "Epoch 45/50\n",
      " - 0s - loss: 182.2893 - val_loss: 117.4975\n",
      "Epoch 46/50\n",
      " - 0s - loss: 180.5073 - val_loss: 129.4594\n",
      "Epoch 47/50\n",
      " - 0s - loss: 175.5950 - val_loss: 115.1836\n",
      "Epoch 48/50\n",
      " - 0s - loss: 172.9256 - val_loss: 114.8273\n",
      "Epoch 49/50\n",
      " - 0s - loss: 170.7725 - val_loss: 129.6246\n",
      "Epoch 50/50\n",
      " - 0s - loss: 167.1119 - val_loss: 103.4189\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 67391.0847 - val_loss: 46927.1180\n",
      "Epoch 2/50\n",
      " - 0s - loss: 28551.7006 - val_loss: 17956.8580\n",
      "Epoch 3/50\n",
      " - 0s - loss: 10015.0153 - val_loss: 7113.6906\n",
      "Epoch 4/50\n",
      " - 0s - loss: 6014.6347 - val_loss: 5406.5859\n",
      "Epoch 5/50\n",
      " - 0s - loss: 5009.4716 - val_loss: 4130.0448\n",
      "Epoch 6/50\n",
      " - 0s - loss: 3938.6040 - val_loss: 3060.5683\n",
      "Epoch 7/50\n",
      " - 0s - loss: 3101.9193 - val_loss: 2296.6819\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2570.2771 - val_loss: 1825.1125\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2191.4149 - val_loss: 1539.6475\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1890.7394 - val_loss: 1339.8674\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1659.2356 - val_loss: 1233.9750\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1478.4608 - val_loss: 1134.0073\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1323.4227 - val_loss: 1097.5075\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1197.4984 - val_loss: 1055.1046\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1095.1937 - val_loss: 990.7552\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1003.1475 - val_loss: 1000.9798\n",
      "Epoch 17/50\n",
      " - 0s - loss: 931.1837 - val_loss: 917.7982\n",
      "Epoch 18/50\n",
      " - 0s - loss: 852.4603 - val_loss: 898.1412\n",
      "Epoch 19/50\n",
      " - 0s - loss: 792.7733 - val_loss: 893.0460\n",
      "Epoch 20/50\n",
      " - 0s - loss: 736.6818 - val_loss: 819.2347\n",
      "Epoch 21/50\n",
      " - 0s - loss: 688.3920 - val_loss: 829.2052\n",
      "Epoch 22/50\n",
      " - 0s - loss: 662.5983 - val_loss: 746.3104\n",
      "Epoch 23/50\n",
      " - 0s - loss: 613.1420 - val_loss: 719.6389\n",
      "Epoch 24/50\n",
      " - 0s - loss: 583.1830 - val_loss: 699.0777\n",
      "Epoch 25/50\n",
      " - 0s - loss: 544.9509 - val_loss: 673.4362\n",
      "Epoch 26/50\n",
      " - 0s - loss: 521.4933 - val_loss: 631.6733\n",
      "Epoch 27/50\n",
      " - 0s - loss: 492.7442 - val_loss: 603.6674\n",
      "Epoch 28/50\n",
      " - 0s - loss: 467.7587 - val_loss: 581.2103\n",
      "Epoch 29/50\n",
      " - 0s - loss: 445.8725 - val_loss: 562.7906\n",
      "Epoch 30/50\n",
      " - 0s - loss: 427.4673 - val_loss: 531.7431\n",
      "Epoch 31/50\n",
      " - 0s - loss: 410.4309 - val_loss: 514.1014\n",
      "Epoch 32/50\n",
      " - 0s - loss: 392.9695 - val_loss: 487.0044\n",
      "Epoch 33/50\n",
      " - 0s - loss: 378.2319 - val_loss: 478.0883\n",
      "Epoch 34/50\n",
      " - 0s - loss: 368.7554 - val_loss: 464.0479\n",
      "Epoch 35/50\n",
      " - 0s - loss: 353.6396 - val_loss: 428.2454\n",
      "Epoch 36/50\n",
      " - 0s - loss: 339.7009 - val_loss: 407.9775\n",
      "Epoch 37/50\n",
      " - 0s - loss: 328.0858 - val_loss: 395.9677\n",
      "Epoch 38/50\n",
      " - 0s - loss: 319.0439 - val_loss: 381.1327\n",
      "Epoch 39/50\n",
      " - 0s - loss: 314.5150 - val_loss: 359.4668\n",
      "Epoch 40/50\n",
      " - 0s - loss: 300.0846 - val_loss: 348.3295\n",
      "Epoch 41/50\n",
      " - 0s - loss: 292.9775 - val_loss: 333.3061\n",
      "Epoch 42/50\n",
      " - 0s - loss: 285.9286 - val_loss: 321.5692\n",
      "Epoch 43/50\n",
      " - 0s - loss: 281.5095 - val_loss: 308.1598\n",
      "Epoch 44/50\n",
      " - 0s - loss: 271.1842 - val_loss: 297.8490\n",
      "Epoch 45/50\n",
      " - 0s - loss: 264.6122 - val_loss: 289.1285\n",
      "Epoch 46/50\n",
      " - 0s - loss: 258.2551 - val_loss: 280.0154\n",
      "Epoch 47/50\n",
      " - 0s - loss: 253.8121 - val_loss: 273.0584\n",
      "Epoch 48/50\n",
      " - 0s - loss: 248.2534 - val_loss: 260.1279\n",
      "Epoch 49/50\n",
      " - 0s - loss: 244.4701 - val_loss: 255.5768\n",
      "Epoch 50/50\n",
      " - 0s - loss: 236.9460 - val_loss: 245.4384\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 12030.1473 - val_loss: 18107.4057\n",
      "Epoch 2/50\n",
      " - 0s - loss: 9266.7168 - val_loss: 14174.9708\n",
      "Epoch 3/50\n",
      " - 0s - loss: 6817.9891 - val_loss: 10688.9170\n",
      "Epoch 4/50\n",
      " - 0s - loss: 4654.8658 - val_loss: 7865.3355\n",
      "Epoch 5/50\n",
      " - 0s - loss: 3231.7344 - val_loss: 5725.1897\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2187.3841 - val_loss: 4196.3107\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1461.6489 - val_loss: 2954.2412\n",
      "Epoch 8/50\n",
      " - 0s - loss: 974.8531 - val_loss: 2095.7632\n",
      "Epoch 9/50\n",
      " - 0s - loss: 663.2068 - val_loss: 1564.9899\n",
      "Epoch 10/50\n",
      " - 0s - loss: 491.8073 - val_loss: 1174.5856\n",
      "Epoch 11/50\n",
      " - 0s - loss: 376.3867 - val_loss: 904.4835\n",
      "Epoch 12/50\n",
      " - 0s - loss: 311.2229 - val_loss: 737.9690\n",
      "Epoch 13/50\n",
      " - 0s - loss: 271.3535 - val_loss: 599.6927\n",
      "Epoch 14/50\n",
      " - 0s - loss: 241.6028 - val_loss: 513.5258\n",
      "Epoch 15/50\n",
      " - 0s - loss: 220.0476 - val_loss: 439.2175\n",
      "Epoch 16/50\n",
      " - 0s - loss: 205.4990 - val_loss: 399.2166\n",
      "Epoch 17/50\n",
      " - 0s - loss: 199.4251 - val_loss: 378.2620\n",
      "Epoch 18/50\n",
      " - 0s - loss: 189.4980 - val_loss: 343.1331\n",
      "Epoch 19/50\n",
      " - 0s - loss: 185.3037 - val_loss: 300.9901\n",
      "Epoch 20/50\n",
      " - 0s - loss: 175.3855 - val_loss: 276.9881\n",
      "Epoch 21/50\n",
      " - 0s - loss: 170.8860 - val_loss: 265.4046\n",
      "Epoch 22/50\n",
      " - 0s - loss: 171.0680 - val_loss: 255.1468\n",
      "Epoch 23/50\n",
      " - 0s - loss: 162.5993 - val_loss: 237.7844\n",
      "Epoch 24/50\n",
      " - 0s - loss: 162.1626 - val_loss: 224.9134\n",
      "Epoch 25/50\n",
      " - 0s - loss: 156.9113 - val_loss: 215.5518\n",
      "Epoch 26/50\n",
      " - 0s - loss: 155.1153 - val_loss: 207.7786\n",
      "Epoch 27/50\n",
      " - 0s - loss: 151.0841 - val_loss: 202.4557\n",
      "Epoch 28/50\n",
      " - 0s - loss: 148.6802 - val_loss: 210.9114\n",
      "Epoch 29/50\n",
      " - 0s - loss: 161.7314 - val_loss: 198.0688\n",
      "Epoch 30/50\n",
      " - 0s - loss: 146.5175 - val_loss: 186.9345\n",
      "Epoch 31/50\n",
      " - 0s - loss: 146.1521 - val_loss: 180.4873\n",
      "Epoch 32/50\n",
      " - 0s - loss: 145.5622 - val_loss: 181.0620\n",
      "Epoch 33/50\n",
      " - 0s - loss: 140.7929 - val_loss: 171.8625\n",
      "Epoch 34/50\n",
      " - 0s - loss: 138.5706 - val_loss: 167.4837\n",
      "Epoch 35/50\n",
      " - 0s - loss: 137.7492 - val_loss: 164.2302\n",
      "Epoch 36/50\n",
      " - 0s - loss: 137.7689 - val_loss: 168.8619\n",
      "Epoch 37/50\n",
      " - 0s - loss: 137.2300 - val_loss: 160.4390\n",
      "Epoch 38/50\n",
      " - 0s - loss: 134.3732 - val_loss: 153.8248\n",
      "Epoch 39/50\n",
      " - 0s - loss: 134.2331 - val_loss: 156.2106\n",
      "Epoch 40/50\n",
      " - 0s - loss: 131.2874 - val_loss: 158.2104\n",
      "Epoch 41/50\n",
      " - 0s - loss: 131.0597 - val_loss: 154.5123\n",
      "Epoch 42/50\n",
      " - 0s - loss: 138.4630 - val_loss: 146.3429\n",
      "Epoch 43/50\n",
      " - 0s - loss: 139.7719 - val_loss: 147.4709\n",
      "Epoch 44/50\n",
      " - 0s - loss: 129.9488 - val_loss: 142.7875\n",
      "Epoch 45/50\n",
      " - 0s - loss: 128.5742 - val_loss: 144.3536\n",
      "Epoch 46/50\n",
      " - 0s - loss: 133.9717 - val_loss: 139.0472\n",
      "Epoch 47/50\n",
      " - 0s - loss: 128.4079 - val_loss: 140.9787\n",
      "Epoch 48/50\n",
      " - 0s - loss: 126.2759 - val_loss: 140.6168\n",
      "Epoch 49/50\n",
      " - 0s - loss: 126.2244 - val_loss: 140.0014\n",
      "Epoch 50/50\n",
      " - 0s - loss: 124.7856 - val_loss: 138.4600\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 7146.2222 - val_loss: 5610.4812\n",
      "Epoch 2/50\n",
      " - 0s - loss: 4679.9906 - val_loss: 4369.6851\n",
      "Epoch 3/50\n",
      " - 0s - loss: 3793.0665 - val_loss: 3545.7178\n",
      "Epoch 4/50\n",
      " - 0s - loss: 3197.3379 - val_loss: 2876.8139\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2680.7657 - val_loss: 2322.2998\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2234.2229 - val_loss: 1893.5349\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1879.3058 - val_loss: 1537.8361\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1576.2619 - val_loss: 1262.4313\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1324.7843 - val_loss: 1054.2139\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1114.8575 - val_loss: 855.9671\n",
      "Epoch 11/50\n",
      " - 0s - loss: 939.1368 - val_loss: 717.9590\n",
      "Epoch 12/50\n",
      " - 0s - loss: 802.2021 - val_loss: 613.2033\n",
      "Epoch 13/50\n",
      " - 0s - loss: 691.4295 - val_loss: 538.8934\n",
      "Epoch 14/50\n",
      " - 0s - loss: 597.3198 - val_loss: 493.5582\n",
      "Epoch 15/50\n",
      " - 0s - loss: 530.4060 - val_loss: 437.8971\n",
      "Epoch 16/50\n",
      " - 0s - loss: 453.6923 - val_loss: 384.4475\n",
      "Epoch 17/50\n",
      " - 0s - loss: 397.9006 - val_loss: 355.1020\n",
      "Epoch 18/50\n",
      " - 0s - loss: 360.2631 - val_loss: 323.0363\n",
      "Epoch 19/50\n",
      " - 0s - loss: 321.8176 - val_loss: 298.3132\n",
      "Epoch 20/50\n",
      " - 0s - loss: 284.7780 - val_loss: 275.3586\n",
      "Epoch 21/50\n",
      " - 0s - loss: 255.0227 - val_loss: 257.6889\n",
      "Epoch 22/50\n",
      " - 0s - loss: 234.4203 - val_loss: 235.7165\n",
      "Epoch 23/50\n",
      " - 0s - loss: 213.8700 - val_loss: 218.2378\n",
      "Epoch 24/50\n",
      " - 0s - loss: 199.5647 - val_loss: 202.6662\n",
      "Epoch 25/50\n",
      " - 0s - loss: 182.9871 - val_loss: 187.8426\n",
      "Epoch 26/50\n",
      " - 0s - loss: 172.2870 - val_loss: 174.1346\n",
      "Epoch 27/50\n",
      " - 0s - loss: 160.6805 - val_loss: 164.1892\n",
      "Epoch 28/50\n",
      " - 0s - loss: 153.5301 - val_loss: 154.3702\n",
      "Epoch 29/50\n",
      " - 0s - loss: 146.0526 - val_loss: 146.4234\n",
      "Epoch 30/50\n",
      " - 0s - loss: 139.6018 - val_loss: 138.6542\n",
      "Epoch 31/50\n",
      " - 0s - loss: 135.0947 - val_loss: 132.0423\n",
      "Epoch 32/50\n",
      " - 0s - loss: 130.3675 - val_loss: 126.9511\n",
      "Epoch 33/50\n",
      " - 0s - loss: 130.9378 - val_loss: 121.5636\n",
      "Epoch 34/50\n",
      " - 0s - loss: 125.2044 - val_loss: 120.0747\n",
      "Epoch 35/50\n",
      " - 0s - loss: 120.8329 - val_loss: 113.4610\n",
      "Epoch 36/50\n",
      " - 0s - loss: 118.3178 - val_loss: 111.0183\n",
      "Epoch 37/50\n",
      " - 0s - loss: 116.5146 - val_loss: 109.1935\n",
      "Epoch 38/50\n",
      " - 0s - loss: 117.3284 - val_loss: 107.0714\n",
      "Epoch 39/50\n",
      " - 0s - loss: 114.5468 - val_loss: 104.4282\n",
      "Epoch 40/50\n",
      " - 0s - loss: 114.1548 - val_loss: 107.0450\n",
      "Epoch 41/50\n",
      " - 0s - loss: 111.9271 - val_loss: 101.5588\n",
      "Epoch 42/50\n",
      " - 0s - loss: 110.6420 - val_loss: 100.3359\n",
      "Epoch 43/50\n",
      " - 0s - loss: 110.3228 - val_loss: 99.0594\n",
      "Epoch 44/50\n",
      " - 0s - loss: 109.7727 - val_loss: 98.8070\n",
      "Epoch 45/50\n",
      " - 0s - loss: 107.7686 - val_loss: 97.7190\n",
      "Epoch 46/50\n",
      " - 0s - loss: 107.6130 - val_loss: 96.4807\n",
      "Epoch 47/50\n",
      " - 0s - loss: 106.7596 - val_loss: 101.0193\n",
      "Epoch 48/50\n",
      " - 0s - loss: 108.4322 - val_loss: 97.2597\n",
      "Epoch 49/50\n",
      " - 0s - loss: 107.2158 - val_loss: 94.3615\n",
      "Epoch 50/50\n",
      " - 0s - loss: 106.5050 - val_loss: 94.8347\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 43985.4012 - val_loss: 25193.1781\n",
      "Epoch 2/50\n",
      " - 0s - loss: 15197.4919 - val_loss: 7997.3237\n",
      "Epoch 3/50\n",
      " - 0s - loss: 5038.1304 - val_loss: 3063.4488\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2810.0527 - val_loss: 2109.9595\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2498.6458 - val_loss: 1946.4857\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2403.5262 - val_loss: 1875.8522\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2311.9608 - val_loss: 1799.8451\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2217.6898 - val_loss: 1730.4084\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2123.0043 - val_loss: 1641.4372\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2030.7663 - val_loss: 1575.0750\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1939.1928 - val_loss: 1497.3913\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1846.5102 - val_loss: 1413.5898\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1756.2168 - val_loss: 1339.0756\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1667.7185 - val_loss: 1275.9248\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1581.2535 - val_loss: 1201.5292\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1500.5188 - val_loss: 1133.4210\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1421.2189 - val_loss: 1082.8159\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1345.3638 - val_loss: 1026.2728\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1269.7495 - val_loss: 958.2605\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1204.0691 - val_loss: 901.6759\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1139.1213 - val_loss: 870.9889\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1081.5951 - val_loss: 799.6387\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1018.8170 - val_loss: 767.7257\n",
      "Epoch 24/50\n",
      " - 0s - loss: 968.7387 - val_loss: 706.9279\n",
      "Epoch 25/50\n",
      " - 0s - loss: 911.6446 - val_loss: 669.1925\n",
      "Epoch 26/50\n",
      " - 0s - loss: 861.2811 - val_loss: 633.6128\n",
      "Epoch 27/50\n",
      " - 0s - loss: 815.6193 - val_loss: 600.2188\n",
      "Epoch 28/50\n",
      " - 0s - loss: 769.1810 - val_loss: 549.9473\n",
      "Epoch 29/50\n",
      " - 0s - loss: 727.3911 - val_loss: 528.9330\n",
      "Epoch 30/50\n",
      " - 0s - loss: 687.4742 - val_loss: 494.5983\n",
      "Epoch 31/50\n",
      " - 0s - loss: 652.2154 - val_loss: 462.1047\n",
      "Epoch 32/50\n",
      " - 0s - loss: 619.7961 - val_loss: 432.4899\n",
      "Epoch 33/50\n",
      " - 0s - loss: 582.9010 - val_loss: 413.7697\n",
      "Epoch 34/50\n",
      " - 0s - loss: 551.9625 - val_loss: 387.3726\n",
      "Epoch 35/50\n",
      " - 0s - loss: 522.5584 - val_loss: 370.8476\n",
      "Epoch 36/50\n",
      " - 0s - loss: 493.1277 - val_loss: 330.9741\n",
      "Epoch 37/50\n",
      " - 0s - loss: 469.4702 - val_loss: 319.3395\n",
      "Epoch 38/50\n",
      " - 0s - loss: 443.3832 - val_loss: 301.7909\n",
      "Epoch 39/50\n",
      " - 0s - loss: 420.0622 - val_loss: 287.6151\n",
      "Epoch 40/50\n",
      " - 0s - loss: 399.1814 - val_loss: 276.9462\n",
      "Epoch 41/50\n",
      " - 0s - loss: 378.8230 - val_loss: 255.5335\n",
      "Epoch 42/50\n",
      " - 0s - loss: 359.0023 - val_loss: 247.1340\n",
      "Epoch 43/50\n",
      " - 0s - loss: 342.4244 - val_loss: 233.0161\n",
      "Epoch 44/50\n",
      " - 0s - loss: 325.5597 - val_loss: 222.9771\n",
      "Epoch 45/50\n",
      " - 0s - loss: 310.5457 - val_loss: 213.5916\n",
      "Epoch 46/50\n",
      " - 0s - loss: 295.4883 - val_loss: 195.7166\n",
      "Epoch 47/50\n",
      " - 0s - loss: 282.7794 - val_loss: 184.8166\n",
      "Epoch 48/50\n",
      " - 0s - loss: 270.6627 - val_loss: 174.4680\n",
      "Epoch 49/50\n",
      " - 0s - loss: 258.3789 - val_loss: 183.0190\n",
      "Epoch 50/50\n",
      " - 0s - loss: 249.2001 - val_loss: 161.9852\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 6056.1600 - val_loss: 3417.7677\n",
      "Epoch 2/50\n",
      " - 0s - loss: 4112.4539 - val_loss: 2118.6261\n",
      "Epoch 3/50\n",
      " - 0s - loss: 2879.1755 - val_loss: 1554.1080\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2105.7134 - val_loss: 1235.9764\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1635.4517 - val_loss: 1045.8535\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1348.7384 - val_loss: 852.4015\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1166.5369 - val_loss: 787.0902\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1017.8276 - val_loss: 647.1058\n",
      "Epoch 9/50\n",
      " - 0s - loss: 899.8577 - val_loss: 605.2719\n",
      "Epoch 10/50\n",
      " - 0s - loss: 789.9995 - val_loss: 544.6956\n",
      "Epoch 11/50\n",
      " - 0s - loss: 703.4194 - val_loss: 486.2415\n",
      "Epoch 12/50\n",
      " - 0s - loss: 627.9677 - val_loss: 424.1929\n",
      "Epoch 13/50\n",
      " - 0s - loss: 566.3325 - val_loss: 387.6556\n",
      "Epoch 14/50\n",
      " - 0s - loss: 511.2869 - val_loss: 371.8725\n",
      "Epoch 15/50\n",
      " - 0s - loss: 467.3825 - val_loss: 329.3051\n",
      "Epoch 16/50\n",
      " - 0s - loss: 425.1251 - val_loss: 299.8989\n",
      "Epoch 17/50\n",
      " - 0s - loss: 391.9644 - val_loss: 268.7760\n",
      "Epoch 18/50\n",
      " - 0s - loss: 364.0984 - val_loss: 245.9354\n",
      "Epoch 19/50\n",
      " - 0s - loss: 339.7751 - val_loss: 254.6078\n",
      "Epoch 20/50\n",
      " - 0s - loss: 316.8389 - val_loss: 217.6623\n",
      "Epoch 21/50\n",
      " - 0s - loss: 298.5582 - val_loss: 229.2883\n",
      "Epoch 22/50\n",
      " - 0s - loss: 282.6950 - val_loss: 201.6650\n",
      "Epoch 23/50\n",
      " - 0s - loss: 261.7771 - val_loss: 188.9258\n",
      "Epoch 24/50\n",
      " - 0s - loss: 243.5184 - val_loss: 192.9319\n",
      "Epoch 25/50\n",
      " - 0s - loss: 225.2608 - val_loss: 163.0197\n",
      "Epoch 26/50\n",
      " - 0s - loss: 214.2244 - val_loss: 157.6356\n",
      "Epoch 27/50\n",
      " - 0s - loss: 197.9454 - val_loss: 163.6579\n",
      "Epoch 28/50\n",
      " - 0s - loss: 185.9572 - val_loss: 150.1110\n",
      "Epoch 29/50\n",
      " - 0s - loss: 177.4938 - val_loss: 145.9055\n",
      "Epoch 30/50\n",
      " - 0s - loss: 164.6995 - val_loss: 138.3863\n",
      "Epoch 31/50\n",
      " - 0s - loss: 156.0197 - val_loss: 137.6501\n",
      "Epoch 32/50\n",
      " - 0s - loss: 146.8918 - val_loss: 121.3404\n",
      "Epoch 33/50\n",
      " - 0s - loss: 141.0965 - val_loss: 118.3211\n",
      "Epoch 34/50\n",
      " - 0s - loss: 137.2882 - val_loss: 113.5150\n",
      "Epoch 35/50\n",
      " - 0s - loss: 133.0513 - val_loss: 115.1592\n",
      "Epoch 36/50\n",
      " - 0s - loss: 130.4935 - val_loss: 112.2093\n",
      "Epoch 37/50\n",
      " - 0s - loss: 126.3786 - val_loss: 99.9042\n",
      "Epoch 38/50\n",
      " - 0s - loss: 126.1977 - val_loss: 103.2300\n",
      "Epoch 39/50\n",
      " - 0s - loss: 120.7171 - val_loss: 91.9212\n",
      "Epoch 40/50\n",
      " - 0s - loss: 115.8876 - val_loss: 89.6123\n",
      "Epoch 41/50\n",
      " - 0s - loss: 113.7614 - val_loss: 85.2968\n",
      "Epoch 42/50\n",
      " - 0s - loss: 111.5336 - val_loss: 84.0722\n",
      "Epoch 43/50\n",
      " - 0s - loss: 109.9444 - val_loss: 82.9443\n",
      "Epoch 44/50\n",
      " - 0s - loss: 108.2382 - val_loss: 85.3414\n",
      "Epoch 45/50\n",
      " - 0s - loss: 107.2673 - val_loss: 79.7844\n",
      "Epoch 46/50\n",
      " - 0s - loss: 104.6028 - val_loss: 80.2596\n",
      "Epoch 47/50\n",
      " - 0s - loss: 103.3182 - val_loss: 77.3999\n",
      "Epoch 48/50\n",
      " - 0s - loss: 102.0641 - val_loss: 78.1615\n",
      "Epoch 49/50\n",
      " - 0s - loss: 100.9233 - val_loss: 74.0448\n",
      "Epoch 50/50\n",
      " - 0s - loss: 99.1066 - val_loss: 75.3122\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 422126.0109 - val_loss: 230233.0532\n",
      "Epoch 2/50\n",
      " - 0s - loss: 135117.5383 - val_loss: 51735.4731\n",
      "Epoch 3/50\n",
      " - 0s - loss: 22585.4915 - val_loss: 5242.2326\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2065.2258 - val_loss: 1451.1377\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1259.0392 - val_loss: 1437.4784\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1216.2257 - val_loss: 1430.1927\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1185.5769 - val_loss: 1430.0082\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1167.1812 - val_loss: 1416.0114\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1148.2034 - val_loss: 1398.8468\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1130.6871 - val_loss: 1382.9632\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1109.6356 - val_loss: 1378.0915\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1091.6689 - val_loss: 1355.7448\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1071.8223 - val_loss: 1339.7493\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1054.4204 - val_loss: 1332.1668\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1032.2918 - val_loss: 1309.9786\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1013.4370 - val_loss: 1295.6998\n",
      "Epoch 17/50\n",
      " - 0s - loss: 995.7701 - val_loss: 1282.3765\n",
      "Epoch 18/50\n",
      " - 0s - loss: 977.2240 - val_loss: 1263.5512\n",
      "Epoch 19/50\n",
      " - 0s - loss: 958.1971 - val_loss: 1248.8879\n",
      "Epoch 20/50\n",
      " - 0s - loss: 941.2585 - val_loss: 1225.5423\n",
      "Epoch 21/50\n",
      " - 0s - loss: 923.4743 - val_loss: 1210.4941\n",
      "Epoch 22/50\n",
      " - 0s - loss: 905.6789 - val_loss: 1193.4363\n",
      "Epoch 23/50\n",
      " - 0s - loss: 893.1884 - val_loss: 1175.1689\n",
      "Epoch 24/50\n",
      " - 0s - loss: 874.1212 - val_loss: 1158.5864\n",
      "Epoch 25/50\n",
      " - 0s - loss: 852.8531 - val_loss: 1137.6470\n",
      "Epoch 26/50\n",
      " - 0s - loss: 837.8520 - val_loss: 1125.5148\n",
      "Epoch 27/50\n",
      " - 0s - loss: 818.9757 - val_loss: 1098.6302\n",
      "Epoch 28/50\n",
      " - 0s - loss: 804.7919 - val_loss: 1087.7464\n",
      "Epoch 29/50\n",
      " - 0s - loss: 788.6201 - val_loss: 1064.6505\n",
      "Epoch 30/50\n",
      " - 0s - loss: 772.1419 - val_loss: 1050.4617\n",
      "Epoch 31/50\n",
      " - 0s - loss: 756.4980 - val_loss: 1030.8365\n",
      "Epoch 32/50\n",
      " - 0s - loss: 742.0647 - val_loss: 1011.4552\n",
      "Epoch 33/50\n",
      " - 0s - loss: 726.1470 - val_loss: 996.6865\n",
      "Epoch 34/50\n",
      " - 0s - loss: 710.0609 - val_loss: 976.4231\n",
      "Epoch 35/50\n",
      " - 0s - loss: 694.3320 - val_loss: 960.5616\n",
      "Epoch 36/50\n",
      " - 0s - loss: 679.7915 - val_loss: 935.4172\n",
      "Epoch 37/50\n",
      " - 0s - loss: 667.0775 - val_loss: 922.2778\n",
      "Epoch 38/50\n",
      " - 0s - loss: 651.8318 - val_loss: 904.7352\n",
      "Epoch 39/50\n",
      " - 0s - loss: 636.1350 - val_loss: 880.5343\n",
      "Epoch 40/50\n",
      " - 0s - loss: 624.0301 - val_loss: 868.8766\n",
      "Epoch 41/50\n",
      " - 0s - loss: 610.1311 - val_loss: 847.6127\n",
      "Epoch 42/50\n",
      " - 0s - loss: 599.4164 - val_loss: 834.6830\n",
      "Epoch 43/50\n",
      " - 0s - loss: 584.2759 - val_loss: 816.6629\n",
      "Epoch 44/50\n",
      " - 0s - loss: 572.6766 - val_loss: 798.9724\n",
      "Epoch 45/50\n",
      " - 0s - loss: 556.4132 - val_loss: 780.9049\n",
      "Epoch 46/50\n",
      " - 0s - loss: 540.4509 - val_loss: 767.8131\n",
      "Epoch 47/50\n",
      " - 0s - loss: 528.0180 - val_loss: 749.5278\n",
      "Epoch 48/50\n",
      " - 0s - loss: 517.7219 - val_loss: 737.3889\n",
      "Epoch 49/50\n",
      " - 0s - loss: 503.8380 - val_loss: 718.5878\n",
      "Epoch 50/50\n",
      " - 0s - loss: 492.2400 - val_loss: 704.1167\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 1128.0787 - val_loss: 1107.5158\n",
      "Epoch 2/50\n",
      " - 0s - loss: 470.0263 - val_loss: 673.5062\n",
      "Epoch 3/50\n",
      " - 0s - loss: 357.6890 - val_loss: 548.3964\n",
      "Epoch 4/50\n",
      " - 0s - loss: 320.8986 - val_loss: 486.6729\n",
      "Epoch 5/50\n",
      " - 0s - loss: 294.9069 - val_loss: 442.0309\n",
      "Epoch 6/50\n",
      " - 0s - loss: 276.1746 - val_loss: 413.7913\n",
      "Epoch 7/50\n",
      " - 0s - loss: 264.8780 - val_loss: 401.2235\n",
      "Epoch 8/50\n",
      " - 0s - loss: 256.3375 - val_loss: 380.2981\n",
      "Epoch 9/50\n",
      " - 0s - loss: 251.7554 - val_loss: 365.7232\n",
      "Epoch 10/50\n",
      " - 0s - loss: 248.2801 - val_loss: 354.0003\n",
      "Epoch 11/50\n",
      " - 0s - loss: 246.6490 - val_loss: 334.5466\n",
      "Epoch 12/50\n",
      " - 0s - loss: 242.0323 - val_loss: 319.2391\n",
      "Epoch 13/50\n",
      " - 0s - loss: 238.9246 - val_loss: 315.1748\n",
      "Epoch 14/50\n",
      " - 0s - loss: 235.6989 - val_loss: 301.2077\n",
      "Epoch 15/50\n",
      " - 0s - loss: 233.8046 - val_loss: 287.1105\n",
      "Epoch 16/50\n",
      " - 0s - loss: 231.2531 - val_loss: 283.5327\n",
      "Epoch 17/50\n",
      " - 0s - loss: 229.0496 - val_loss: 279.9806\n",
      "Epoch 18/50\n",
      " - 0s - loss: 227.3484 - val_loss: 268.4535\n",
      "Epoch 19/50\n",
      " - 0s - loss: 225.1646 - val_loss: 264.8834\n",
      "Epoch 20/50\n",
      " - 0s - loss: 222.7282 - val_loss: 258.8514\n",
      "Epoch 21/50\n",
      " - 0s - loss: 221.4326 - val_loss: 257.3498\n",
      "Epoch 22/50\n",
      " - 0s - loss: 218.5191 - val_loss: 250.5000\n",
      "Epoch 23/50\n",
      " - 0s - loss: 216.8863 - val_loss: 251.2051\n",
      "Epoch 24/50\n",
      " - 0s - loss: 214.7488 - val_loss: 246.6114\n",
      "Epoch 25/50\n",
      " - 0s - loss: 212.9406 - val_loss: 240.7166\n",
      "Epoch 26/50\n",
      " - 0s - loss: 211.3791 - val_loss: 241.3067\n",
      "Epoch 27/50\n",
      " - 0s - loss: 210.8395 - val_loss: 235.7693\n",
      "Epoch 28/50\n",
      " - 0s - loss: 207.6272 - val_loss: 236.7828\n",
      "Epoch 29/50\n",
      " - 0s - loss: 205.9257 - val_loss: 233.6500\n",
      "Epoch 30/50\n",
      " - 0s - loss: 203.7797 - val_loss: 229.3977\n",
      "Epoch 31/50\n",
      " - 0s - loss: 201.7617 - val_loss: 226.5358\n",
      "Epoch 32/50\n",
      " - 0s - loss: 200.5763 - val_loss: 226.7291\n",
      "Epoch 33/50\n",
      " - 0s - loss: 198.7234 - val_loss: 221.5352\n",
      "Epoch 34/50\n",
      " - 0s - loss: 197.4494 - val_loss: 221.0989\n",
      "Epoch 35/50\n",
      " - 0s - loss: 194.6092 - val_loss: 213.7341\n",
      "Epoch 36/50\n",
      " - 0s - loss: 193.9282 - val_loss: 214.2985\n",
      "Epoch 37/50\n",
      " - 0s - loss: 191.5212 - val_loss: 208.9365\n",
      "Epoch 38/50\n",
      " - 0s - loss: 190.1410 - val_loss: 205.3654\n",
      "Epoch 39/50\n",
      " - 0s - loss: 187.1477 - val_loss: 199.0749\n",
      "Epoch 40/50\n",
      " - 0s - loss: 185.5598 - val_loss: 197.4026\n",
      "Epoch 41/50\n",
      " - 0s - loss: 183.4376 - val_loss: 195.3260\n",
      "Epoch 42/50\n",
      " - 0s - loss: 181.2827 - val_loss: 192.7543\n",
      "Epoch 43/50\n",
      " - 0s - loss: 179.4779 - val_loss: 186.7708\n",
      "Epoch 44/50\n",
      " - 0s - loss: 177.8003 - val_loss: 191.8194\n",
      "Epoch 45/50\n",
      " - 0s - loss: 175.9493 - val_loss: 185.9229\n",
      "Epoch 46/50\n",
      " - 0s - loss: 173.6201 - val_loss: 184.3021\n",
      "Epoch 47/50\n",
      " - 0s - loss: 172.0120 - val_loss: 180.2351\n",
      "Epoch 48/50\n",
      " - 0s - loss: 170.5610 - val_loss: 180.3024\n",
      "Epoch 49/50\n",
      " - 0s - loss: 167.8061 - val_loss: 172.7446\n",
      "Epoch 50/50\n",
      " - 0s - loss: 166.2946 - val_loss: 175.1128\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 141730.1300 - val_loss: 58111.0144\n",
      "Epoch 2/50\n",
      " - 0s - loss: 38406.1561 - val_loss: 12833.5062\n",
      "Epoch 3/50\n",
      " - 0s - loss: 14763.1462 - val_loss: 7922.1681\n",
      "Epoch 4/50\n",
      " - 0s - loss: 12130.5961 - val_loss: 7725.8819\n",
      "Epoch 5/50\n",
      " - 0s - loss: 11430.6202 - val_loss: 7327.3300\n",
      "Epoch 6/50\n",
      " - 0s - loss: 10709.7341 - val_loss: 6984.6778\n",
      "Epoch 7/50\n",
      " - 0s - loss: 10047.1830 - val_loss: 6680.6306\n",
      "Epoch 8/50\n",
      " - 0s - loss: 9396.5864 - val_loss: 6367.9010\n",
      "Epoch 9/50\n",
      " - 0s - loss: 8750.5767 - val_loss: 6080.0721\n",
      "Epoch 10/50\n",
      " - 0s - loss: 8187.9669 - val_loss: 5837.8251\n",
      "Epoch 11/50\n",
      " - 0s - loss: 7618.0634 - val_loss: 5522.1263\n",
      "Epoch 12/50\n",
      " - 0s - loss: 7098.7651 - val_loss: 5306.3441\n",
      "Epoch 13/50\n",
      " - 0s - loss: 6612.5470 - val_loss: 5091.7208\n",
      "Epoch 14/50\n",
      " - 0s - loss: 6169.3772 - val_loss: 4852.3571\n",
      "Epoch 15/50\n",
      " - 0s - loss: 5746.2775 - val_loss: 4633.1711\n",
      "Epoch 16/50\n",
      " - 0s - loss: 5345.4571 - val_loss: 4452.6300\n",
      "Epoch 17/50\n",
      " - 0s - loss: 4996.6210 - val_loss: 4238.6870\n",
      "Epoch 18/50\n",
      " - 0s - loss: 4651.9695 - val_loss: 4100.3047\n",
      "Epoch 19/50\n",
      " - 0s - loss: 4344.3141 - val_loss: 3980.2352\n",
      "Epoch 20/50\n",
      " - 0s - loss: 4046.7571 - val_loss: 3761.4996\n",
      "Epoch 21/50\n",
      " - 0s - loss: 3809.6354 - val_loss: 3674.8844\n",
      "Epoch 22/50\n",
      " - 0s - loss: 3545.2690 - val_loss: 3520.8311\n",
      "Epoch 23/50\n",
      " - 0s - loss: 3311.6126 - val_loss: 3393.3773\n",
      "Epoch 24/50\n",
      " - 0s - loss: 3104.7867 - val_loss: 3255.4301\n",
      "Epoch 25/50\n",
      " - 0s - loss: 2899.5795 - val_loss: 3134.5037\n",
      "Epoch 26/50\n",
      " - 0s - loss: 2720.4614 - val_loss: 2993.3606\n",
      "Epoch 27/50\n",
      " - 0s - loss: 2545.5588 - val_loss: 2905.8338\n",
      "Epoch 28/50\n",
      " - 0s - loss: 2388.0545 - val_loss: 2763.3518\n",
      "Epoch 29/50\n",
      " - 0s - loss: 2243.9005 - val_loss: 2652.4964\n",
      "Epoch 30/50\n",
      " - 0s - loss: 2112.3144 - val_loss: 2557.4893\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1980.7739 - val_loss: 2458.2056\n",
      "Epoch 32/50\n",
      " - 0s - loss: 1849.9420 - val_loss: 2337.7692\n",
      "Epoch 33/50\n",
      " - 0s - loss: 1742.0699 - val_loss: 2259.1779\n",
      "Epoch 34/50\n",
      " - 0s - loss: 1630.1257 - val_loss: 2134.8784\n",
      "Epoch 35/50\n",
      " - 0s - loss: 1529.0864 - val_loss: 2089.3821\n",
      "Epoch 36/50\n",
      " - 0s - loss: 1439.7078 - val_loss: 1963.1759\n",
      "Epoch 37/50\n",
      " - 0s - loss: 1353.0937 - val_loss: 1860.7140\n",
      "Epoch 38/50\n",
      " - 0s - loss: 1267.2431 - val_loss: 1802.4439\n",
      "Epoch 39/50\n",
      " - 0s - loss: 1189.9116 - val_loss: 1711.8865\n",
      "Epoch 40/50\n",
      " - 0s - loss: 1116.9003 - val_loss: 1628.2942\n",
      "Epoch 41/50\n",
      " - 0s - loss: 1049.7716 - val_loss: 1541.1156\n",
      "Epoch 42/50\n",
      " - 0s - loss: 984.7006 - val_loss: 1473.8104\n",
      "Epoch 43/50\n",
      " - 0s - loss: 925.2394 - val_loss: 1422.3537\n",
      "Epoch 44/50\n",
      " - 0s - loss: 874.3471 - val_loss: 1318.4492\n",
      "Epoch 45/50\n",
      " - 0s - loss: 820.8221 - val_loss: 1291.8744\n",
      "Epoch 46/50\n",
      " - 0s - loss: 770.1456 - val_loss: 1201.1896\n",
      "Epoch 47/50\n",
      " - 0s - loss: 721.5022 - val_loss: 1147.8725\n",
      "Epoch 48/50\n",
      " - 0s - loss: 678.8067 - val_loss: 1091.5679\n",
      "Epoch 49/50\n",
      " - 0s - loss: 640.0189 - val_loss: 1017.9857\n",
      "Epoch 50/50\n",
      " - 0s - loss: 603.2378 - val_loss: 980.9001\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 402354.5661 - val_loss: 237963.4196\n",
      "Epoch 2/50\n",
      " - 0s - loss: 151298.4944 - val_loss: 76437.3053\n",
      "Epoch 3/50\n",
      " - 0s - loss: 44616.2041 - val_loss: 20599.3047\n",
      "Epoch 4/50\n",
      " - 0s - loss: 14512.4388 - val_loss: 7530.3200\n",
      "Epoch 5/50\n",
      " - 0s - loss: 8976.1261 - val_loss: 5517.4763\n",
      "Epoch 6/50\n",
      " - 0s - loss: 8279.8672 - val_loss: 5229.9121\n",
      "Epoch 7/50\n",
      " - 0s - loss: 8065.7387 - val_loss: 5140.0374\n",
      "Epoch 8/50\n",
      " - 0s - loss: 7855.3654 - val_loss: 5091.3346\n",
      "Epoch 9/50\n",
      " - 0s - loss: 7652.0576 - val_loss: 4997.1331\n",
      "Epoch 10/50\n",
      " - 0s - loss: 7436.7339 - val_loss: 4889.3677\n",
      "Epoch 11/50\n",
      " - 0s - loss: 7222.7111 - val_loss: 4806.9934\n",
      "Epoch 12/50\n",
      " - 0s - loss: 7011.8222 - val_loss: 4696.0254\n",
      "Epoch 13/50\n",
      " - 0s - loss: 6794.3244 - val_loss: 4646.2938\n",
      "Epoch 14/50\n",
      " - 0s - loss: 6572.9073 - val_loss: 4540.7587\n",
      "Epoch 15/50\n",
      " - 0s - loss: 6356.7439 - val_loss: 4479.1253\n",
      "Epoch 16/50\n",
      " - 0s - loss: 6143.3888 - val_loss: 4380.5205\n",
      "Epoch 17/50\n",
      " - 0s - loss: 5937.4809 - val_loss: 4291.8600\n",
      "Epoch 18/50\n",
      " - 0s - loss: 5734.3853 - val_loss: 4205.3466\n",
      "Epoch 19/50\n",
      " - 0s - loss: 5528.8684 - val_loss: 4147.9623\n",
      "Epoch 20/50\n",
      " - 0s - loss: 5329.0245 - val_loss: 4086.6017\n",
      "Epoch 21/50\n",
      " - 0s - loss: 5134.9938 - val_loss: 3979.4330\n",
      "Epoch 22/50\n",
      " - 0s - loss: 4946.2966 - val_loss: 3892.4605\n",
      "Epoch 23/50\n",
      " - 0s - loss: 4755.0294 - val_loss: 3829.9333\n",
      "Epoch 24/50\n",
      " - 0s - loss: 4566.1871 - val_loss: 3746.5414\n",
      "Epoch 25/50\n",
      " - 0s - loss: 4375.3872 - val_loss: 3681.2036\n",
      "Epoch 26/50\n",
      " - 0s - loss: 4183.4544 - val_loss: 3623.3714\n",
      "Epoch 27/50\n",
      " - 0s - loss: 3995.3943 - val_loss: 3536.1055\n",
      "Epoch 28/50\n",
      " - 0s - loss: 3804.0995 - val_loss: 3453.1810\n",
      "Epoch 29/50\n",
      " - 0s - loss: 3619.8281 - val_loss: 3383.1107\n",
      "Epoch 30/50\n",
      " - 0s - loss: 3450.9464 - val_loss: 3284.2902\n",
      "Epoch 31/50\n",
      " - 0s - loss: 3266.3547 - val_loss: 3180.3779\n",
      "Epoch 32/50\n",
      " - 0s - loss: 3082.6368 - val_loss: 3099.5950\n",
      "Epoch 33/50\n",
      " - 0s - loss: 2911.3720 - val_loss: 3002.7253\n",
      "Epoch 34/50\n",
      " - 0s - loss: 2744.1758 - val_loss: 2910.1763\n",
      "Epoch 35/50\n",
      " - 0s - loss: 2592.0030 - val_loss: 2792.2030\n",
      "Epoch 36/50\n",
      " - 0s - loss: 2429.2837 - val_loss: 2697.1140\n",
      "Epoch 37/50\n",
      " - 0s - loss: 2282.1931 - val_loss: 2588.2382\n",
      "Epoch 38/50\n",
      " - 0s - loss: 2133.8138 - val_loss: 2479.5227\n",
      "Epoch 39/50\n",
      " - 0s - loss: 1986.6267 - val_loss: 2362.4619\n",
      "Epoch 40/50\n",
      " - 0s - loss: 1848.9392 - val_loss: 2236.8307\n",
      "Epoch 41/50\n",
      " - 0s - loss: 1723.6384 - val_loss: 2120.3637\n",
      "Epoch 42/50\n",
      " - 0s - loss: 1607.5056 - val_loss: 2010.3405\n",
      "Epoch 43/50\n",
      " - 0s - loss: 1505.1517 - val_loss: 1917.4529\n",
      "Epoch 44/50\n",
      " - 0s - loss: 1413.5167 - val_loss: 1831.4575\n",
      "Epoch 45/50\n",
      " - 0s - loss: 1335.6127 - val_loss: 1739.9515\n",
      "Epoch 46/50\n",
      " - 0s - loss: 1264.8944 - val_loss: 1672.7289\n",
      "Epoch 47/50\n",
      " - 0s - loss: 1203.3652 - val_loss: 1604.8981\n",
      "Epoch 48/50\n",
      " - 0s - loss: 1146.8134 - val_loss: 1535.9365\n",
      "Epoch 49/50\n",
      " - 0s - loss: 1089.0960 - val_loss: 1479.9396\n",
      "Epoch 50/50\n",
      " - 0s - loss: 1039.3509 - val_loss: 1417.1656\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 89562.8187 - val_loss: 33153.3740\n",
      "Epoch 2/50\n",
      " - 0s - loss: 13513.5643 - val_loss: 3368.0349\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1762.6717 - val_loss: 2184.7499\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1648.3815 - val_loss: 2036.1129\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1473.6649 - val_loss: 1933.7618\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1376.2099 - val_loss: 1823.4783\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1282.2376 - val_loss: 1706.3907\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1200.4152 - val_loss: 1602.8151\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1093.2013 - val_loss: 1485.5543\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1010.0189 - val_loss: 1381.4861\n",
      "Epoch 11/50\n",
      " - 0s - loss: 927.1488 - val_loss: 1288.9975\n",
      "Epoch 12/50\n",
      " - 0s - loss: 855.3491 - val_loss: 1191.8946\n",
      "Epoch 13/50\n",
      " - 0s - loss: 788.0259 - val_loss: 1108.9005\n",
      "Epoch 14/50\n",
      " - 0s - loss: 724.2002 - val_loss: 1020.3232\n",
      "Epoch 15/50\n",
      " - 0s - loss: 666.7469 - val_loss: 945.2074\n",
      "Epoch 16/50\n",
      " - 0s - loss: 615.8613 - val_loss: 864.8479\n",
      "Epoch 17/50\n",
      " - 0s - loss: 568.1953 - val_loss: 810.6209\n",
      "Epoch 18/50\n",
      " - 0s - loss: 527.0793 - val_loss: 742.7912\n",
      "Epoch 19/50\n",
      " - 0s - loss: 490.5371 - val_loss: 685.6949\n",
      "Epoch 20/50\n",
      " - 0s - loss: 457.1193 - val_loss: 636.7892\n",
      "Epoch 21/50\n",
      " - 0s - loss: 428.4659 - val_loss: 591.3873\n",
      "Epoch 22/50\n",
      " - 0s - loss: 403.3778 - val_loss: 548.8621\n",
      "Epoch 23/50\n",
      " - 0s - loss: 380.7070 - val_loss: 504.9695\n",
      "Epoch 24/50\n",
      " - 0s - loss: 362.4828 - val_loss: 472.4913\n",
      "Epoch 25/50\n",
      " - 0s - loss: 342.5927 - val_loss: 441.2547\n",
      "Epoch 26/50\n",
      " - 0s - loss: 326.4831 - val_loss: 414.3574\n",
      "Epoch 27/50\n",
      " - 0s - loss: 312.9060 - val_loss: 393.0365\n",
      "Epoch 28/50\n",
      " - 0s - loss: 300.3376 - val_loss: 366.8641\n",
      "Epoch 29/50\n",
      " - 0s - loss: 289.9149 - val_loss: 351.5006\n",
      "Epoch 30/50\n",
      " - 0s - loss: 277.9629 - val_loss: 322.0708\n",
      "Epoch 31/50\n",
      " - 0s - loss: 269.8083 - val_loss: 311.9715\n",
      "Epoch 32/50\n",
      " - 0s - loss: 261.5981 - val_loss: 297.6045\n",
      "Epoch 33/50\n",
      " - 0s - loss: 254.7430 - val_loss: 281.5547\n",
      "Epoch 34/50\n",
      " - 0s - loss: 248.0283 - val_loss: 271.7168\n",
      "Epoch 35/50\n",
      " - 0s - loss: 242.2172 - val_loss: 254.0298\n",
      "Epoch 36/50\n",
      " - 0s - loss: 236.8979 - val_loss: 249.7596\n",
      "Epoch 37/50\n",
      " - 0s - loss: 231.5758 - val_loss: 237.9312\n",
      "Epoch 38/50\n",
      " - 0s - loss: 228.1820 - val_loss: 234.7264\n",
      "Epoch 39/50\n",
      " - 0s - loss: 222.5704 - val_loss: 222.9371\n",
      "Epoch 40/50\n",
      " - 0s - loss: 220.0329 - val_loss: 209.3090\n",
      "Epoch 41/50\n",
      " - 0s - loss: 216.3587 - val_loss: 212.5964\n",
      "Epoch 42/50\n",
      " - 0s - loss: 211.5119 - val_loss: 206.9368\n",
      "Epoch 43/50\n",
      " - 0s - loss: 208.7792 - val_loss: 194.8940\n",
      "Epoch 44/50\n",
      " - 0s - loss: 206.0326 - val_loss: 194.0054\n",
      "Epoch 45/50\n",
      " - 0s - loss: 202.2609 - val_loss: 187.4895\n",
      "Epoch 46/50\n",
      " - 0s - loss: 200.9297 - val_loss: 195.2992\n",
      "Epoch 47/50\n",
      " - 0s - loss: 197.3535 - val_loss: 182.2802\n",
      "Epoch 48/50\n",
      " - 0s - loss: 194.1454 - val_loss: 183.1183\n",
      "Epoch 49/50\n",
      " - 0s - loss: 192.5386 - val_loss: 184.7093\n",
      "Epoch 50/50\n",
      " - 0s - loss: 189.1751 - val_loss: 166.8004\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 4855.9192 - val_loss: 2399.1896\n",
      "Epoch 2/50\n",
      " - 0s - loss: 2139.1536 - val_loss: 2130.3306\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1700.8102 - val_loss: 1966.4408\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1455.2872 - val_loss: 1806.3462\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1251.6295 - val_loss: 1644.0817\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1075.2199 - val_loss: 1482.4361\n",
      "Epoch 7/50\n",
      " - 0s - loss: 925.3520 - val_loss: 1329.3418\n",
      "Epoch 8/50\n",
      " - 0s - loss: 803.4505 - val_loss: 1189.1521\n",
      "Epoch 9/50\n",
      " - 0s - loss: 694.2362 - val_loss: 1057.7974\n",
      "Epoch 10/50\n",
      " - 0s - loss: 603.6176 - val_loss: 935.1488\n",
      "Epoch 11/50\n",
      " - 0s - loss: 525.4314 - val_loss: 817.6730\n",
      "Epoch 12/50\n",
      " - 0s - loss: 457.8757 - val_loss: 715.7664\n",
      "Epoch 13/50\n",
      " - 0s - loss: 403.4149 - val_loss: 609.8078\n",
      "Epoch 14/50\n",
      " - 0s - loss: 350.8512 - val_loss: 524.0159\n",
      "Epoch 15/50\n",
      " - 0s - loss: 311.4473 - val_loss: 445.0608\n",
      "Epoch 16/50\n",
      " - 0s - loss: 274.4846 - val_loss: 380.3258\n",
      "Epoch 17/50\n",
      " - 0s - loss: 247.3375 - val_loss: 322.6953\n",
      "Epoch 18/50\n",
      " - 0s - loss: 220.3335 - val_loss: 278.4854\n",
      "Epoch 19/50\n",
      " - 0s - loss: 199.2635 - val_loss: 243.7633\n",
      "Epoch 20/50\n",
      " - 0s - loss: 187.4656 - val_loss: 210.0835\n",
      "Epoch 21/50\n",
      " - 0s - loss: 171.8623 - val_loss: 185.3481\n",
      "Epoch 22/50\n",
      " - 0s - loss: 161.9458 - val_loss: 171.0072\n",
      "Epoch 23/50\n",
      " - 0s - loss: 157.4847 - val_loss: 156.1114\n",
      "Epoch 24/50\n",
      " - 0s - loss: 153.8659 - val_loss: 143.6140\n",
      "Epoch 25/50\n",
      " - 0s - loss: 146.6128 - val_loss: 134.6489\n",
      "Epoch 26/50\n",
      " - 0s - loss: 143.2599 - val_loss: 127.3527\n",
      "Epoch 27/50\n",
      " - 0s - loss: 142.4445 - val_loss: 120.8024\n",
      "Epoch 28/50\n",
      " - 0s - loss: 138.3171 - val_loss: 115.0240\n",
      "Epoch 29/50\n",
      " - 0s - loss: 138.7920 - val_loss: 111.4043\n",
      "Epoch 30/50\n",
      " - 0s - loss: 134.4576 - val_loss: 106.8310\n",
      "Epoch 31/50\n",
      " - 0s - loss: 132.5592 - val_loss: 104.4958\n",
      "Epoch 32/50\n",
      " - 0s - loss: 130.8073 - val_loss: 103.7394\n",
      "Epoch 33/50\n",
      " - 0s - loss: 129.5757 - val_loss: 100.0598\n",
      "Epoch 34/50\n",
      " - 0s - loss: 129.1180 - val_loss: 103.0217\n",
      "Epoch 35/50\n",
      " - 0s - loss: 129.0840 - val_loss: 96.6080\n",
      "Epoch 36/50\n",
      " - 0s - loss: 125.9041 - val_loss: 95.6911\n",
      "Epoch 37/50\n",
      " - 0s - loss: 125.0378 - val_loss: 94.6706\n",
      "Epoch 38/50\n",
      " - 0s - loss: 123.3105 - val_loss: 90.4973\n",
      "Epoch 39/50\n",
      " - 0s - loss: 124.5247 - val_loss: 89.3684\n",
      "Epoch 40/50\n",
      " - 0s - loss: 122.4498 - val_loss: 93.0855\n",
      "Epoch 41/50\n",
      " - 0s - loss: 120.8230 - val_loss: 90.1007\n",
      "Epoch 42/50\n",
      " - 0s - loss: 118.9545 - val_loss: 89.9141\n",
      "Epoch 43/50\n",
      " - 0s - loss: 118.3095 - val_loss: 93.0513\n",
      "Epoch 44/50\n",
      " - 0s - loss: 119.9486 - val_loss: 85.8613\n",
      "Epoch 45/50\n",
      " - 0s - loss: 118.1652 - val_loss: 87.3176\n",
      "Epoch 46/50\n",
      " - 0s - loss: 116.0706 - val_loss: 85.8038\n",
      "Epoch 47/50\n",
      " - 0s - loss: 114.0680 - val_loss: 88.6238\n",
      "Epoch 48/50\n",
      " - 0s - loss: 113.1575 - val_loss: 85.4165\n",
      "Epoch 49/50\n",
      " - 0s - loss: 112.5760 - val_loss: 85.9692\n",
      "Epoch 50/50\n",
      " - 0s - loss: 112.2530 - val_loss: 87.9951\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 199302.4796 - val_loss: 121884.2551\n",
      "Epoch 2/50\n",
      " - 0s - loss: 80233.7632 - val_loss: 41296.3672\n",
      "Epoch 3/50\n",
      " - 0s - loss: 23093.7054 - val_loss: 10670.0798\n",
      "Epoch 4/50\n",
      " - 0s - loss: 5619.6909 - val_loss: 3617.7031\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2557.6051 - val_loss: 2831.9586\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2355.3651 - val_loss: 2762.9091\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2320.7657 - val_loss: 2728.6442\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2281.4644 - val_loss: 2698.6410\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2243.1097 - val_loss: 2657.0416\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2201.5942 - val_loss: 2623.3397\n",
      "Epoch 11/50\n",
      " - 0s - loss: 2160.7332 - val_loss: 2587.6440\n",
      "Epoch 12/50\n",
      " - 0s - loss: 2119.7771 - val_loss: 2538.9575\n",
      "Epoch 13/50\n",
      " - 0s - loss: 2078.7251 - val_loss: 2502.0684\n",
      "Epoch 14/50\n",
      " - 0s - loss: 2040.7498 - val_loss: 2460.6175\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1999.2042 - val_loss: 2413.1044\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1958.2258 - val_loss: 2376.4371\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1920.3864 - val_loss: 2333.4248\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1882.7121 - val_loss: 2304.8363\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1846.8955 - val_loss: 2254.5634\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1806.1762 - val_loss: 2225.3044\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1771.2440 - val_loss: 2184.4794\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1739.7644 - val_loss: 2127.7781\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1701.0571 - val_loss: 2104.8234\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1665.7282 - val_loss: 2062.8816\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1632.0877 - val_loss: 2019.5212\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1600.7695 - val_loss: 1981.2485\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1572.0869 - val_loss: 1957.8256\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1542.0098 - val_loss: 1911.8513\n",
      "Epoch 29/50\n",
      " - 0s - loss: 1505.3110 - val_loss: 1888.0955\n",
      "Epoch 30/50\n",
      " - 0s - loss: 1479.2751 - val_loss: 1847.2192\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1443.1086 - val_loss: 1811.1381\n",
      "Epoch 32/50\n",
      " - 0s - loss: 1414.7544 - val_loss: 1778.2587\n",
      "Epoch 33/50\n",
      " - 0s - loss: 1387.4898 - val_loss: 1743.3453\n",
      "Epoch 34/50\n",
      " - 0s - loss: 1358.6547 - val_loss: 1704.3893\n",
      "Epoch 35/50\n",
      " - 0s - loss: 1330.3281 - val_loss: 1680.2287\n",
      "Epoch 36/50\n",
      " - 0s - loss: 1304.0509 - val_loss: 1637.8473\n",
      "Epoch 37/50\n",
      " - 0s - loss: 1277.0575 - val_loss: 1616.9688\n",
      "Epoch 38/50\n",
      " - 0s - loss: 1252.0005 - val_loss: 1576.8484\n",
      "Epoch 39/50\n",
      " - 0s - loss: 1225.4284 - val_loss: 1549.6761\n",
      "Epoch 40/50\n",
      " - 0s - loss: 1201.2571 - val_loss: 1520.5930\n",
      "Epoch 41/50\n",
      " - 0s - loss: 1175.6926 - val_loss: 1482.0016\n",
      "Epoch 42/50\n",
      " - 0s - loss: 1151.0755 - val_loss: 1455.5472\n",
      "Epoch 43/50\n",
      " - 0s - loss: 1126.7491 - val_loss: 1419.6032\n",
      "Epoch 44/50\n",
      " - 0s - loss: 1104.0655 - val_loss: 1400.4595\n",
      "Epoch 45/50\n",
      " - 0s - loss: 1081.3629 - val_loss: 1367.6922\n",
      "Epoch 46/50\n",
      " - 0s - loss: 1058.8383 - val_loss: 1329.6870\n",
      "Epoch 47/50\n",
      " - 0s - loss: 1039.4141 - val_loss: 1302.7100\n",
      "Epoch 48/50\n",
      " - 0s - loss: 1012.8172 - val_loss: 1275.4247\n",
      "Epoch 49/50\n",
      " - 0s - loss: 992.7021 - val_loss: 1249.4951\n",
      "Epoch 50/50\n",
      " - 0s - loss: 971.7225 - val_loss: 1216.8444\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 18992.9149 - val_loss: 7230.9620\n",
      "Epoch 2/50\n",
      " - 0s - loss: 5735.2325 - val_loss: 1909.5759\n",
      "Epoch 3/50\n",
      " - 0s - loss: 2082.5306 - val_loss: 1210.1027\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1530.0469 - val_loss: 1229.6547\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1398.8871 - val_loss: 1174.8195\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1297.2744 - val_loss: 1106.2680\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1204.3708 - val_loss: 1056.7487\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1118.0288 - val_loss: 1021.7090\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1039.2646 - val_loss: 997.5701\n",
      "Epoch 10/50\n",
      " - 0s - loss: 965.8792 - val_loss: 968.9238\n",
      "Epoch 11/50\n",
      " - 0s - loss: 902.3724 - val_loss: 934.3107\n",
      "Epoch 12/50\n",
      " - 0s - loss: 845.7641 - val_loss: 920.3744\n",
      "Epoch 13/50\n",
      " - 0s - loss: 795.1992 - val_loss: 893.5995\n",
      "Epoch 14/50\n",
      " - 0s - loss: 751.2282 - val_loss: 866.0650\n",
      "Epoch 15/50\n",
      " - 0s - loss: 712.0396 - val_loss: 836.9164\n",
      "Epoch 16/50\n",
      " - 0s - loss: 675.4796 - val_loss: 819.9392\n",
      "Epoch 17/50\n",
      " - 0s - loss: 640.0521 - val_loss: 776.7132\n",
      "Epoch 18/50\n",
      " - 0s - loss: 611.1587 - val_loss: 761.0361\n",
      "Epoch 19/50\n",
      " - 0s - loss: 577.6199 - val_loss: 713.5658\n",
      "Epoch 20/50\n",
      " - 0s - loss: 547.0347 - val_loss: 686.2451\n",
      "Epoch 21/50\n",
      " - 0s - loss: 514.4741 - val_loss: 634.6080\n",
      "Epoch 22/50\n",
      " - 0s - loss: 482.5936 - val_loss: 597.9234\n",
      "Epoch 23/50\n",
      " - 0s - loss: 452.0908 - val_loss: 560.8852\n",
      "Epoch 24/50\n",
      " - 0s - loss: 418.6809 - val_loss: 525.4840\n",
      "Epoch 25/50\n",
      " - 0s - loss: 391.7633 - val_loss: 489.8028\n",
      "Epoch 26/50\n",
      " - 0s - loss: 350.1651 - val_loss: 410.6737\n",
      "Epoch 27/50\n",
      " - 0s - loss: 314.5868 - val_loss: 348.1318\n",
      "Epoch 28/50\n",
      " - 0s - loss: 277.6993 - val_loss: 292.7183\n",
      "Epoch 29/50\n",
      " - 0s - loss: 248.5531 - val_loss: 250.4078\n",
      "Epoch 30/50\n",
      " - 0s - loss: 225.7154 - val_loss: 223.6743\n",
      "Epoch 31/50\n",
      " - 0s - loss: 204.0367 - val_loss: 203.0303\n",
      "Epoch 32/50\n",
      " - 0s - loss: 182.9714 - val_loss: 188.3603\n",
      "Epoch 33/50\n",
      " - 0s - loss: 167.4104 - val_loss: 165.3320\n",
      "Epoch 34/50\n",
      " - 0s - loss: 156.2803 - val_loss: 155.0311\n",
      "Epoch 35/50\n",
      " - 0s - loss: 143.8539 - val_loss: 141.9860\n",
      "Epoch 36/50\n",
      " - 0s - loss: 135.6500 - val_loss: 137.1691\n",
      "Epoch 37/50\n",
      " - 0s - loss: 127.1542 - val_loss: 123.3558\n",
      "Epoch 38/50\n",
      " - 0s - loss: 122.2219 - val_loss: 126.2086\n",
      "Epoch 39/50\n",
      " - 0s - loss: 116.5075 - val_loss: 111.7241\n",
      "Epoch 40/50\n",
      " - 0s - loss: 111.7557 - val_loss: 106.5670\n",
      "Epoch 41/50\n",
      " - 0s - loss: 108.5155 - val_loss: 101.6049\n",
      "Epoch 42/50\n",
      " - 0s - loss: 105.4077 - val_loss: 99.5631\n",
      "Epoch 43/50\n",
      " - 0s - loss: 102.9190 - val_loss: 95.1084\n",
      "Epoch 44/50\n",
      " - 0s - loss: 102.3675 - val_loss: 92.6146\n",
      "Epoch 45/50\n",
      " - 0s - loss: 101.2812 - val_loss: 93.5805\n",
      "Epoch 46/50\n",
      " - 0s - loss: 100.0089 - val_loss: 87.7023\n",
      "Epoch 47/50\n",
      " - 0s - loss: 99.2961 - val_loss: 89.6118\n",
      "Epoch 48/50\n",
      " - 0s - loss: 98.2981 - val_loss: 82.8769\n",
      "Epoch 49/50\n",
      " - 0s - loss: 94.5743 - val_loss: 81.7852\n",
      "Epoch 50/50\n",
      " - 0s - loss: 93.6795 - val_loss: 82.7323\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 25484.3322 - val_loss: 8854.6145\n",
      "Epoch 2/50\n",
      " - 0s - loss: 4051.4167 - val_loss: 993.9130\n",
      "Epoch 3/50\n",
      " - 0s - loss: 754.0090 - val_loss: 830.4190\n",
      "Epoch 4/50\n",
      " - 0s - loss: 702.6646 - val_loss: 773.0294\n",
      "Epoch 5/50\n",
      " - 0s - loss: 661.2693 - val_loss: 735.8223\n",
      "Epoch 6/50\n",
      " - 0s - loss: 635.5416 - val_loss: 710.3257\n",
      "Epoch 7/50\n",
      " - 0s - loss: 607.5432 - val_loss: 682.8427\n",
      "Epoch 8/50\n",
      " - 0s - loss: 581.8385 - val_loss: 655.6417\n",
      "Epoch 9/50\n",
      " - 0s - loss: 556.1999 - val_loss: 625.5362\n",
      "Epoch 10/50\n",
      " - 0s - loss: 530.2137 - val_loss: 600.2128\n",
      "Epoch 11/50\n",
      " - 0s - loss: 506.3332 - val_loss: 572.0513\n",
      "Epoch 12/50\n",
      " - 0s - loss: 483.3019 - val_loss: 545.1864\n",
      "Epoch 13/50\n",
      " - 0s - loss: 460.7558 - val_loss: 519.7296\n",
      "Epoch 14/50\n",
      " - 0s - loss: 439.0217 - val_loss: 494.3393\n",
      "Epoch 15/50\n",
      " - 0s - loss: 418.5581 - val_loss: 466.5923\n",
      "Epoch 16/50\n",
      " - 0s - loss: 400.4305 - val_loss: 447.0739\n",
      "Epoch 17/50\n",
      " - 0s - loss: 382.7091 - val_loss: 420.9752\n",
      "Epoch 18/50\n",
      " - 0s - loss: 365.0285 - val_loss: 401.0661\n",
      "Epoch 19/50\n",
      " - 0s - loss: 349.4320 - val_loss: 378.3969\n",
      "Epoch 20/50\n",
      " - 0s - loss: 334.4309 - val_loss: 355.8548\n",
      "Epoch 21/50\n",
      " - 0s - loss: 321.2516 - val_loss: 335.7280\n",
      "Epoch 22/50\n",
      " - 0s - loss: 307.7680 - val_loss: 323.1135\n",
      "Epoch 23/50\n",
      " - 0s - loss: 296.7999 - val_loss: 303.0955\n",
      "Epoch 24/50\n",
      " - 0s - loss: 285.2817 - val_loss: 286.8758\n",
      "Epoch 25/50\n",
      " - 0s - loss: 275.5157 - val_loss: 271.9092\n",
      "Epoch 26/50\n",
      " - 0s - loss: 266.6463 - val_loss: 260.9695\n",
      "Epoch 27/50\n",
      " - 0s - loss: 259.2685 - val_loss: 244.7283\n",
      "Epoch 28/50\n",
      " - 0s - loss: 248.8740 - val_loss: 234.8511\n",
      "Epoch 29/50\n",
      " - 0s - loss: 241.3618 - val_loss: 223.0103\n",
      "Epoch 30/50\n",
      " - 0s - loss: 234.5114 - val_loss: 212.9528\n",
      "Epoch 31/50\n",
      " - 0s - loss: 227.5098 - val_loss: 199.9267\n",
      "Epoch 32/50\n",
      " - 0s - loss: 221.1707 - val_loss: 194.3363\n",
      "Epoch 33/50\n",
      " - 0s - loss: 215.3428 - val_loss: 186.5112\n",
      "Epoch 34/50\n",
      " - 0s - loss: 210.8423 - val_loss: 173.7122\n",
      "Epoch 35/50\n",
      " - 0s - loss: 204.6691 - val_loss: 167.6846\n",
      "Epoch 36/50\n",
      " - 0s - loss: 200.2027 - val_loss: 159.7873\n",
      "Epoch 37/50\n",
      " - 0s - loss: 196.5859 - val_loss: 153.0255\n",
      "Epoch 38/50\n",
      " - 0s - loss: 191.9210 - val_loss: 149.5752\n",
      "Epoch 39/50\n",
      " - 0s - loss: 187.8928 - val_loss: 141.4283\n",
      "Epoch 40/50\n",
      " - 0s - loss: 183.4867 - val_loss: 138.6959\n",
      "Epoch 41/50\n",
      " - 0s - loss: 179.8551 - val_loss: 132.4530\n",
      "Epoch 42/50\n",
      " - 0s - loss: 178.3310 - val_loss: 135.3415\n",
      "Epoch 43/50\n",
      " - 0s - loss: 173.0193 - val_loss: 121.5486\n",
      "Epoch 44/50\n",
      " - 0s - loss: 170.9549 - val_loss: 122.0071\n",
      "Epoch 45/50\n",
      " - 0s - loss: 168.2826 - val_loss: 120.6649\n",
      "Epoch 46/50\n",
      " - 0s - loss: 166.0257 - val_loss: 111.0713\n",
      "Epoch 47/50\n",
      " - 0s - loss: 163.4916 - val_loss: 112.3703\n",
      "Epoch 48/50\n",
      " - 0s - loss: 160.4153 - val_loss: 110.2535\n",
      "Epoch 49/50\n",
      " - 0s - loss: 158.2991 - val_loss: 103.7159\n",
      "Epoch 50/50\n",
      " - 0s - loss: 157.0341 - val_loss: 104.7077\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 29370.5370 - val_loss: 11115.9801\n",
      "Epoch 2/50\n",
      " - 0s - loss: 6666.6957 - val_loss: 6541.1660\n",
      "Epoch 3/50\n",
      " - 0s - loss: 5440.6334 - val_loss: 6152.5072\n",
      "Epoch 4/50\n",
      " - 0s - loss: 5009.2558 - val_loss: 5739.3522\n",
      "Epoch 5/50\n",
      " - 0s - loss: 4666.1302 - val_loss: 5351.6664\n",
      "Epoch 6/50\n",
      " - 0s - loss: 4332.5346 - val_loss: 4980.3357\n",
      "Epoch 7/50\n",
      " - 0s - loss: 4016.8281 - val_loss: 4600.2106\n",
      "Epoch 8/50\n",
      " - 0s - loss: 3720.3533 - val_loss: 4240.9151\n",
      "Epoch 9/50\n",
      " - 0s - loss: 3421.0486 - val_loss: 3903.9529\n",
      "Epoch 10/50\n",
      " - 0s - loss: 3145.4249 - val_loss: 3603.7029\n",
      "Epoch 11/50\n",
      " - 0s - loss: 2899.7434 - val_loss: 3300.9917\n",
      "Epoch 12/50\n",
      " - 0s - loss: 2657.0980 - val_loss: 3034.9499\n",
      "Epoch 13/50\n",
      " - 0s - loss: 2440.6510 - val_loss: 2782.9954\n",
      "Epoch 14/50\n",
      " - 0s - loss: 2248.2651 - val_loss: 2543.7819\n",
      "Epoch 15/50\n",
      " - 0s - loss: 2057.6515 - val_loss: 2336.2187\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1900.9915 - val_loss: 2144.3904\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1745.7405 - val_loss: 1965.7483\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1612.9272 - val_loss: 1819.6743\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1494.6729 - val_loss: 1666.7227\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1375.5129 - val_loss: 1539.9924\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1273.0787 - val_loss: 1415.8834\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1181.0176 - val_loss: 1310.4295\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1100.0817 - val_loss: 1211.8880\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1029.6971 - val_loss: 1130.1279\n",
      "Epoch 25/50\n",
      " - 0s - loss: 955.3564 - val_loss: 1046.3486\n",
      "Epoch 26/50\n",
      " - 0s - loss: 887.0785 - val_loss: 970.9416\n",
      "Epoch 27/50\n",
      " - 0s - loss: 829.4861 - val_loss: 901.8503\n",
      "Epoch 28/50\n",
      " - 0s - loss: 776.2032 - val_loss: 844.2062\n",
      "Epoch 29/50\n",
      " - 0s - loss: 727.7696 - val_loss: 782.8150\n",
      "Epoch 30/50\n",
      " - 0s - loss: 679.7474 - val_loss: 731.3434\n",
      "Epoch 31/50\n",
      " - 0s - loss: 639.4704 - val_loss: 681.6654\n",
      "Epoch 32/50\n",
      " - 0s - loss: 605.3065 - val_loss: 645.5947\n",
      "Epoch 33/50\n",
      " - 0s - loss: 570.3603 - val_loss: 600.9875\n",
      "Epoch 34/50\n",
      " - 0s - loss: 534.8187 - val_loss: 565.9014\n",
      "Epoch 35/50\n",
      " - 0s - loss: 505.7819 - val_loss: 528.5681\n",
      "Epoch 36/50\n",
      " - 0s - loss: 481.0975 - val_loss: 500.6405\n",
      "Epoch 37/50\n",
      " - 0s - loss: 452.9186 - val_loss: 467.4713\n",
      "Epoch 38/50\n",
      " - 0s - loss: 428.8326 - val_loss: 441.6838\n",
      "Epoch 39/50\n",
      " - 0s - loss: 410.1216 - val_loss: 417.5445\n",
      "Epoch 40/50\n",
      " - 0s - loss: 388.4191 - val_loss: 391.7308\n",
      "Epoch 41/50\n",
      " - 0s - loss: 369.0114 - val_loss: 375.7031\n",
      "Epoch 42/50\n",
      " - 0s - loss: 351.9703 - val_loss: 351.2871\n",
      "Epoch 43/50\n",
      " - 0s - loss: 337.4436 - val_loss: 333.9839\n",
      "Epoch 44/50\n",
      " - 0s - loss: 321.0697 - val_loss: 317.2067\n",
      "Epoch 45/50\n",
      " - 0s - loss: 307.5694 - val_loss: 301.1463\n",
      "Epoch 46/50\n",
      " - 0s - loss: 296.8174 - val_loss: 289.3027\n",
      "Epoch 47/50\n",
      " - 0s - loss: 282.4458 - val_loss: 272.6459\n",
      "Epoch 48/50\n",
      " - 0s - loss: 273.0607 - val_loss: 262.7448\n",
      "Epoch 49/50\n",
      " - 0s - loss: 263.3941 - val_loss: 246.8070\n",
      "Epoch 50/50\n",
      " - 0s - loss: 253.8335 - val_loss: 235.6715\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 18280.1901 - val_loss: 7245.4643\n",
      "Epoch 2/50\n",
      " - 0s - loss: 4323.1005 - val_loss: 2018.2356\n",
      "Epoch 3/50\n",
      " - 0s - loss: 2086.0650 - val_loss: 2003.1120\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1876.0670 - val_loss: 1708.1453\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1638.7729 - val_loss: 1484.2817\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1433.1101 - val_loss: 1309.9697\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1253.4620 - val_loss: 1163.6697\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1089.1540 - val_loss: 1001.3924\n",
      "Epoch 9/50\n",
      " - 0s - loss: 942.6995 - val_loss: 873.8987\n",
      "Epoch 10/50\n",
      " - 0s - loss: 815.2761 - val_loss: 753.8896\n",
      "Epoch 11/50\n",
      " - 0s - loss: 706.8756 - val_loss: 654.0709\n",
      "Epoch 12/50\n",
      " - 0s - loss: 617.0795 - val_loss: 571.6083\n",
      "Epoch 13/50\n",
      " - 0s - loss: 541.1965 - val_loss: 494.8245\n",
      "Epoch 14/50\n",
      " - 0s - loss: 478.4353 - val_loss: 437.7156\n",
      "Epoch 15/50\n",
      " - 0s - loss: 427.6511 - val_loss: 385.3853\n",
      "Epoch 16/50\n",
      " - 0s - loss: 384.7437 - val_loss: 344.1850\n",
      "Epoch 17/50\n",
      " - 0s - loss: 351.5710 - val_loss: 317.8110\n",
      "Epoch 18/50\n",
      " - 0s - loss: 324.3631 - val_loss: 286.1225\n",
      "Epoch 19/50\n",
      " - 0s - loss: 299.5174 - val_loss: 265.3062\n",
      "Epoch 20/50\n",
      " - 0s - loss: 279.0461 - val_loss: 243.7473\n",
      "Epoch 21/50\n",
      " - 0s - loss: 263.3425 - val_loss: 226.0281\n",
      "Epoch 22/50\n",
      " - 0s - loss: 249.8738 - val_loss: 219.9906\n",
      "Epoch 23/50\n",
      " - 0s - loss: 238.0564 - val_loss: 207.8566\n",
      "Epoch 24/50\n",
      " - 0s - loss: 227.6734 - val_loss: 195.9815\n",
      "Epoch 25/50\n",
      " - 0s - loss: 219.7107 - val_loss: 198.7053\n",
      "Epoch 26/50\n",
      " - 0s - loss: 213.2932 - val_loss: 185.1989\n",
      "Epoch 27/50\n",
      " - 0s - loss: 206.7176 - val_loss: 176.4620\n",
      "Epoch 28/50\n",
      " - 0s - loss: 200.7022 - val_loss: 172.0976\n",
      "Epoch 29/50\n",
      " - 0s - loss: 194.7766 - val_loss: 173.6972\n",
      "Epoch 30/50\n",
      " - 0s - loss: 190.5057 - val_loss: 166.9644\n",
      "Epoch 31/50\n",
      " - 0s - loss: 187.0697 - val_loss: 165.6868\n",
      "Epoch 32/50\n",
      " - 0s - loss: 182.6223 - val_loss: 166.8924\n",
      "Epoch 33/50\n",
      " - 0s - loss: 178.8994 - val_loss: 164.2270\n",
      "Epoch 34/50\n",
      " - 0s - loss: 175.0402 - val_loss: 157.5643\n",
      "Epoch 35/50\n",
      " - 0s - loss: 172.8067 - val_loss: 167.6301\n",
      "Epoch 36/50\n",
      " - 0s - loss: 168.2165 - val_loss: 155.4572\n",
      "Epoch 37/50\n",
      " - 0s - loss: 165.2465 - val_loss: 156.3114\n",
      "Epoch 38/50\n",
      " - 0s - loss: 163.5249 - val_loss: 151.7639\n",
      "Epoch 39/50\n",
      " - 0s - loss: 160.0844 - val_loss: 158.4333\n",
      "Epoch 40/50\n",
      " - 0s - loss: 157.7567 - val_loss: 151.6124\n",
      "Epoch 41/50\n",
      " - 0s - loss: 155.4828 - val_loss: 158.3773\n",
      "Epoch 42/50\n",
      " - 0s - loss: 153.9176 - val_loss: 154.5017\n",
      "Epoch 43/50\n",
      " - 0s - loss: 151.5199 - val_loss: 147.1338\n",
      "Epoch 44/50\n",
      " - 0s - loss: 150.7054 - val_loss: 145.4612\n",
      "Epoch 45/50\n",
      " - 0s - loss: 147.1560 - val_loss: 149.2956\n",
      "Epoch 46/50\n",
      " - 0s - loss: 145.8450 - val_loss: 143.4127\n",
      "Epoch 47/50\n",
      " - 0s - loss: 143.6326 - val_loss: 153.8058\n",
      "Epoch 48/50\n",
      " - 0s - loss: 142.1291 - val_loss: 141.1564\n",
      "Epoch 49/50\n",
      " - 0s - loss: 142.1054 - val_loss: 157.5524\n",
      "Epoch 50/50\n",
      " - 0s - loss: 141.0442 - val_loss: 145.1344\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 31422.9326 - val_loss: 6091.0482\n",
      "Epoch 2/50\n",
      " - 0s - loss: 3562.3654 - val_loss: 4351.8740\n",
      "Epoch 3/50\n",
      " - 0s - loss: 2850.3113 - val_loss: 3562.4139\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2448.7724 - val_loss: 3053.1667\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2228.6147 - val_loss: 2799.6602\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2012.1217 - val_loss: 2477.5983\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1826.9100 - val_loss: 2211.7751\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1649.5141 - val_loss: 1924.1583\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1492.6171 - val_loss: 1703.9377\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1360.1627 - val_loss: 1511.0970\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1235.1084 - val_loss: 1349.6728\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1134.1498 - val_loss: 1212.7128\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1052.0627 - val_loss: 1092.0554\n",
      "Epoch 14/50\n",
      " - 0s - loss: 980.7451 - val_loss: 1008.1349\n",
      "Epoch 15/50\n",
      " - 0s - loss: 920.9344 - val_loss: 897.9781\n",
      "Epoch 16/50\n",
      " - 0s - loss: 879.0659 - val_loss: 824.3820\n",
      "Epoch 17/50\n",
      " - 0s - loss: 833.8899 - val_loss: 784.7631\n",
      "Epoch 18/50\n",
      " - 0s - loss: 796.1915 - val_loss: 741.1039\n",
      "Epoch 19/50\n",
      " - 0s - loss: 767.4626 - val_loss: 707.9724\n",
      "Epoch 20/50\n",
      " - 0s - loss: 738.6770 - val_loss: 669.0510\n",
      "Epoch 21/50\n",
      " - 0s - loss: 716.0922 - val_loss: 681.1432\n",
      "Epoch 22/50\n",
      " - 0s - loss: 700.8540 - val_loss: 631.2074\n",
      "Epoch 23/50\n",
      " - 0s - loss: 672.6466 - val_loss: 585.5471\n",
      "Epoch 24/50\n",
      " - 0s - loss: 653.4327 - val_loss: 616.9931\n",
      "Epoch 25/50\n",
      " - 0s - loss: 639.6364 - val_loss: 562.3287\n",
      "Epoch 26/50\n",
      " - 0s - loss: 622.5367 - val_loss: 571.7204\n",
      "Epoch 27/50\n",
      " - 0s - loss: 607.3794 - val_loss: 549.9978\n",
      "Epoch 28/50\n",
      " - 0s - loss: 595.4796 - val_loss: 557.5594\n",
      "Epoch 29/50\n",
      " - 0s - loss: 580.3289 - val_loss: 543.5037\n",
      "Epoch 30/50\n",
      " - 0s - loss: 567.1148 - val_loss: 521.3740\n",
      "Epoch 31/50\n",
      " - 0s - loss: 558.7084 - val_loss: 491.6773\n",
      "Epoch 32/50\n",
      " - 0s - loss: 540.9751 - val_loss: 512.5809\n",
      "Epoch 33/50\n",
      " - 0s - loss: 531.1691 - val_loss: 476.3373\n",
      "Epoch 34/50\n",
      " - 0s - loss: 518.5156 - val_loss: 518.8873\n",
      "Epoch 35/50\n",
      " - 0s - loss: 506.9339 - val_loss: 481.3006\n",
      "Epoch 36/50\n",
      " - 0s - loss: 497.0722 - val_loss: 456.0984\n",
      "Epoch 37/50\n",
      " - 0s - loss: 488.1276 - val_loss: 495.4953\n",
      "Epoch 38/50\n",
      " - 0s - loss: 473.5825 - val_loss: 446.1076\n",
      "Epoch 39/50\n",
      " - 0s - loss: 470.1155 - val_loss: 515.2838\n",
      "Epoch 40/50\n",
      " - 0s - loss: 457.6294 - val_loss: 454.9126\n",
      "Epoch 41/50\n",
      " - 0s - loss: 445.3614 - val_loss: 439.1736\n",
      "Epoch 42/50\n",
      " - 0s - loss: 435.0170 - val_loss: 441.7937\n",
      "Epoch 43/50\n",
      " - 0s - loss: 427.1431 - val_loss: 442.2120\n",
      "Epoch 44/50\n",
      " - 0s - loss: 417.0024 - val_loss: 424.4720\n",
      "Epoch 45/50\n",
      " - 0s - loss: 408.3189 - val_loss: 407.9508\n",
      "Epoch 46/50\n",
      " - 0s - loss: 402.3175 - val_loss: 403.3812\n",
      "Epoch 47/50\n",
      " - 0s - loss: 392.4062 - val_loss: 418.0593\n",
      "Epoch 48/50\n",
      " - 0s - loss: 380.3197 - val_loss: 405.2285\n",
      "Epoch 49/50\n",
      " - 0s - loss: 373.7401 - val_loss: 433.2896\n",
      "Epoch 50/50\n",
      " - 0s - loss: 366.8464 - val_loss: 394.8688\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 14001.5033 - val_loss: 8538.1345\n",
      "Epoch 2/50\n",
      " - 0s - loss: 8413.2228 - val_loss: 5000.6665\n",
      "Epoch 3/50\n",
      " - 0s - loss: 5483.5097 - val_loss: 3242.2625\n",
      "Epoch 4/50\n",
      " - 0s - loss: 3950.2718 - val_loss: 2360.8986\n",
      "Epoch 5/50\n",
      " - 0s - loss: 3102.8778 - val_loss: 1915.3982\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2631.6921 - val_loss: 1661.3610\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2350.8418 - val_loss: 1515.8311\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2177.3496 - val_loss: 1423.7696\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2057.1182 - val_loss: 1371.5507\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1975.6813 - val_loss: 1333.9290\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1913.5651 - val_loss: 1308.3521\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1868.6407 - val_loss: 1290.3118\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1835.4715 - val_loss: 1276.2114\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1806.3052 - val_loss: 1265.4101\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1784.1939 - val_loss: 1256.8918\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1766.4067 - val_loss: 1249.1612\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1751.3690 - val_loss: 1243.2158\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1740.2032 - val_loss: 1238.8528\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1730.1144 - val_loss: 1235.1915\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1721.6848 - val_loss: 1232.1997\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1715.1053 - val_loss: 1229.5670\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1708.9375 - val_loss: 1226.8793\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1703.2163 - val_loss: 1224.4077\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1698.8012 - val_loss: 1222.1482\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1694.7109 - val_loss: 1220.0741\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1691.2255 - val_loss: 1217.9972\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1688.1307 - val_loss: 1216.0010\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1685.4704 - val_loss: 1214.1035\n",
      "Epoch 29/50\n",
      " - 0s - loss: 1682.9627 - val_loss: 1212.2180\n",
      "Epoch 30/50\n",
      " - 0s - loss: 1680.5411 - val_loss: 1210.3910\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1678.3772 - val_loss: 1208.5553\n",
      "Epoch 32/50\n",
      " - 0s - loss: 1676.0999 - val_loss: 1206.8004\n",
      "Epoch 33/50\n",
      " - 0s - loss: 1673.9086 - val_loss: 1205.0415\n",
      "Epoch 34/50\n",
      " - 0s - loss: 1671.7399 - val_loss: 1203.2327\n",
      "Epoch 35/50\n",
      " - 0s - loss: 1669.5874 - val_loss: 1201.4820\n",
      "Epoch 36/50\n",
      " - 0s - loss: 1667.4927 - val_loss: 1199.7432\n",
      "Epoch 37/50\n",
      " - 0s - loss: 1665.4488 - val_loss: 1198.0088\n",
      "Epoch 38/50\n",
      " - 0s - loss: 1663.3737 - val_loss: 1196.3073\n",
      "Epoch 39/50\n",
      " - 0s - loss: 1661.3171 - val_loss: 1194.6166\n",
      "Epoch 40/50\n",
      " - 0s - loss: 1659.2285 - val_loss: 1192.9834\n",
      "Epoch 41/50\n",
      " - 0s - loss: 1657.2006 - val_loss: 1191.2913\n",
      "Epoch 42/50\n",
      " - 0s - loss: 1655.1703 - val_loss: 1189.6706\n",
      "Epoch 43/50\n",
      " - 0s - loss: 1653.2376 - val_loss: 1188.0033\n",
      "Epoch 44/50\n",
      " - 0s - loss: 1651.2945 - val_loss: 1186.2989\n",
      "Epoch 45/50\n",
      " - 0s - loss: 1649.2121 - val_loss: 1184.7069\n",
      "Epoch 46/50\n",
      " - 0s - loss: 1647.2745 - val_loss: 1183.0216\n",
      "Epoch 47/50\n",
      " - 0s - loss: 1645.4002 - val_loss: 1181.3603\n",
      "Epoch 48/50\n",
      " - 0s - loss: 1643.5654 - val_loss: 1179.7243\n",
      "Epoch 49/50\n",
      " - 0s - loss: 1641.7548 - val_loss: 1178.1623\n",
      "Epoch 50/50\n",
      " - 0s - loss: 1640.0485 - val_loss: 1176.5992\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 5304.7921 - val_loss: 3858.9161\n",
      "Epoch 2/50\n",
      " - 0s - loss: 3904.7850 - val_loss: 3289.4522\n",
      "Epoch 3/50\n",
      " - 0s - loss: 3205.7832 - val_loss: 2854.6344\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2591.8381 - val_loss: 2572.1766\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2082.1762 - val_loss: 2222.0881\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1666.8968 - val_loss: 1945.4018\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1341.6930 - val_loss: 1638.3756\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1072.4469 - val_loss: 1380.4661\n",
      "Epoch 9/50\n",
      " - 0s - loss: 875.8602 - val_loss: 1168.9955\n",
      "Epoch 10/50\n",
      " - 0s - loss: 743.0038 - val_loss: 973.7677\n",
      "Epoch 11/50\n",
      " - 0s - loss: 638.3996 - val_loss: 851.7897\n",
      "Epoch 12/50\n",
      " - 0s - loss: 575.8267 - val_loss: 749.9843\n",
      "Epoch 13/50\n",
      " - 0s - loss: 528.3248 - val_loss: 675.5359\n",
      "Epoch 14/50\n",
      " - 0s - loss: 490.6363 - val_loss: 624.2755\n",
      "Epoch 15/50\n",
      " - 0s - loss: 459.9502 - val_loss: 563.0783\n",
      "Epoch 16/50\n",
      " - 0s - loss: 433.3620 - val_loss: 542.0835\n",
      "Epoch 17/50\n",
      " - 0s - loss: 407.8070 - val_loss: 531.5571\n",
      "Epoch 18/50\n",
      " - 0s - loss: 384.9540 - val_loss: 474.5319\n",
      "Epoch 19/50\n",
      " - 0s - loss: 366.1372 - val_loss: 454.8905\n",
      "Epoch 20/50\n",
      " - 0s - loss: 349.6464 - val_loss: 420.9901\n",
      "Epoch 21/50\n",
      " - 0s - loss: 332.5290 - val_loss: 429.0597\n",
      "Epoch 22/50\n",
      " - 0s - loss: 318.4082 - val_loss: 387.9885\n",
      "Epoch 23/50\n",
      " - 0s - loss: 304.7304 - val_loss: 369.2910\n",
      "Epoch 24/50\n",
      " - 0s - loss: 292.9096 - val_loss: 356.7163\n",
      "Epoch 25/50\n",
      " - 0s - loss: 283.0977 - val_loss: 335.5857\n",
      "Epoch 26/50\n",
      " - 0s - loss: 275.2328 - val_loss: 340.3636\n",
      "Epoch 27/50\n",
      " - 0s - loss: 265.5319 - val_loss: 323.3881\n",
      "Epoch 28/50\n",
      " - 0s - loss: 257.0967 - val_loss: 319.0160\n",
      "Epoch 29/50\n",
      " - 0s - loss: 248.9489 - val_loss: 291.3739\n",
      "Epoch 30/50\n",
      " - 0s - loss: 241.9491 - val_loss: 262.8483\n",
      "Epoch 31/50\n",
      " - 0s - loss: 232.6251 - val_loss: 285.8507\n",
      "Epoch 32/50\n",
      " - 0s - loss: 225.9085 - val_loss: 254.8149\n",
      "Epoch 33/50\n",
      " - 0s - loss: 218.4105 - val_loss: 252.7876\n",
      "Epoch 34/50\n",
      " - 0s - loss: 212.2916 - val_loss: 221.2241\n",
      "Epoch 35/50\n",
      " - 0s - loss: 202.6385 - val_loss: 208.0847\n",
      "Epoch 36/50\n",
      " - 0s - loss: 198.6161 - val_loss: 215.0000\n",
      "Epoch 37/50\n",
      " - 0s - loss: 188.1998 - val_loss: 201.0408\n",
      "Epoch 38/50\n",
      " - 0s - loss: 179.8893 - val_loss: 191.2334\n",
      "Epoch 39/50\n",
      " - 0s - loss: 173.8998 - val_loss: 180.3180\n",
      "Epoch 40/50\n",
      " - 0s - loss: 168.8041 - val_loss: 185.4307\n",
      "Epoch 41/50\n",
      " - 0s - loss: 164.1563 - val_loss: 169.2750\n",
      "Epoch 42/50\n",
      " - 0s - loss: 158.4631 - val_loss: 190.1171\n",
      "Epoch 43/50\n",
      " - 0s - loss: 155.8563 - val_loss: 169.1372\n",
      "Epoch 44/50\n",
      " - 0s - loss: 150.9745 - val_loss: 160.3528\n",
      "Epoch 45/50\n",
      " - 0s - loss: 149.8328 - val_loss: 153.3671\n",
      "Epoch 46/50\n",
      " - 0s - loss: 147.7607 - val_loss: 142.0539\n",
      "Epoch 47/50\n",
      " - 0s - loss: 146.0700 - val_loss: 155.8171\n",
      "Epoch 48/50\n",
      " - 0s - loss: 143.8865 - val_loss: 150.8288\n",
      "Epoch 49/50\n",
      " - 0s - loss: 142.9054 - val_loss: 151.2178\n",
      "Epoch 50/50\n",
      " - 0s - loss: 141.9570 - val_loss: 146.9073\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 180421.1177 - val_loss: 106477.6981\n",
      "Epoch 2/50\n",
      " - 0s - loss: 71472.9120 - val_loss: 39873.6839\n",
      "Epoch 3/50\n",
      " - 0s - loss: 25435.8017 - val_loss: 18076.3820\n",
      "Epoch 4/50\n",
      " - 0s - loss: 11474.8371 - val_loss: 13446.3841\n",
      "Epoch 5/50\n",
      " - 0s - loss: 8003.8339 - val_loss: 10808.4303\n",
      "Epoch 6/50\n",
      " - 0s - loss: 5982.1483 - val_loss: 8229.4026\n",
      "Epoch 7/50\n",
      " - 0s - loss: 4333.6317 - val_loss: 6076.0038\n",
      "Epoch 8/50\n",
      " - 0s - loss: 3298.2805 - val_loss: 4664.3396\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2559.2248 - val_loss: 3696.7136\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2070.2741 - val_loss: 2962.7281\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1707.8927 - val_loss: 2504.6018\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1482.6909 - val_loss: 2158.7683\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1314.4433 - val_loss: 1894.4534\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1184.0184 - val_loss: 1673.4992\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1086.1119 - val_loss: 1509.1728\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1005.7720 - val_loss: 1385.6189\n",
      "Epoch 17/50\n",
      " - 0s - loss: 933.2168 - val_loss: 1275.7874\n",
      "Epoch 18/50\n",
      " - 0s - loss: 872.2240 - val_loss: 1170.4713\n",
      "Epoch 19/50\n",
      " - 0s - loss: 812.4958 - val_loss: 1106.7498\n",
      "Epoch 20/50\n",
      " - 0s - loss: 757.7067 - val_loss: 1020.4114\n",
      "Epoch 21/50\n",
      " - 0s - loss: 710.1768 - val_loss: 964.7747\n",
      "Epoch 22/50\n",
      " - 0s - loss: 668.3336 - val_loss: 897.1391\n",
      "Epoch 23/50\n",
      " - 0s - loss: 634.3594 - val_loss: 850.3441\n",
      "Epoch 24/50\n",
      " - 0s - loss: 598.0119 - val_loss: 826.7539\n",
      "Epoch 25/50\n",
      " - 0s - loss: 569.3221 - val_loss: 777.3759\n",
      "Epoch 26/50\n",
      " - 0s - loss: 540.4893 - val_loss: 744.0681\n",
      "Epoch 27/50\n",
      " - 0s - loss: 513.5547 - val_loss: 724.8939\n",
      "Epoch 28/50\n",
      " - 0s - loss: 489.2983 - val_loss: 680.6449\n",
      "Epoch 29/50\n",
      " - 0s - loss: 468.5529 - val_loss: 677.9584\n",
      "Epoch 30/50\n",
      " - 0s - loss: 452.9308 - val_loss: 618.5441\n",
      "Epoch 31/50\n",
      " - 0s - loss: 431.8106 - val_loss: 619.7000\n",
      "Epoch 32/50\n",
      " - 0s - loss: 417.7583 - val_loss: 580.4138\n",
      "Epoch 33/50\n",
      " - 0s - loss: 404.1321 - val_loss: 578.5768\n",
      "Epoch 34/50\n",
      " - 0s - loss: 391.3179 - val_loss: 546.7202\n",
      "Epoch 35/50\n",
      " - 0s - loss: 378.4495 - val_loss: 544.8898\n",
      "Epoch 36/50\n",
      " - 0s - loss: 366.7056 - val_loss: 540.3636\n",
      "Epoch 37/50\n",
      " - 0s - loss: 356.2143 - val_loss: 525.4896\n",
      "Epoch 38/50\n",
      " - 0s - loss: 345.7898 - val_loss: 511.1273\n",
      "Epoch 39/50\n",
      " - 0s - loss: 337.8013 - val_loss: 497.1901\n",
      "Epoch 40/50\n",
      " - 0s - loss: 328.8094 - val_loss: 509.9881\n",
      "Epoch 41/50\n",
      " - 0s - loss: 326.5346 - val_loss: 454.8755\n",
      "Epoch 42/50\n",
      " - 0s - loss: 316.0614 - val_loss: 458.7127\n",
      "Epoch 43/50\n",
      " - 0s - loss: 306.0214 - val_loss: 452.8773\n",
      "Epoch 44/50\n",
      " - 0s - loss: 300.4424 - val_loss: 465.6011\n",
      "Epoch 45/50\n",
      " - 0s - loss: 292.0440 - val_loss: 457.5168\n",
      "Epoch 46/50\n",
      " - 0s - loss: 286.9298 - val_loss: 435.5572\n",
      "Epoch 47/50\n",
      " - 0s - loss: 281.4265 - val_loss: 442.5319\n",
      "Epoch 48/50\n",
      " - 0s - loss: 271.8884 - val_loss: 428.8893\n",
      "Epoch 49/50\n",
      " - 0s - loss: 266.3069 - val_loss: 436.5153\n",
      "Epoch 50/50\n",
      " - 0s - loss: 263.4572 - val_loss: 388.8626\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 135615.0893 - val_loss: 82228.8054\n",
      "Epoch 2/50\n",
      " - 0s - loss: 61120.4426 - val_loss: 27868.2162\n",
      "Epoch 3/50\n",
      " - 0s - loss: 19280.2345 - val_loss: 5842.7583\n",
      "Epoch 4/50\n",
      " - 0s - loss: 6106.1110 - val_loss: 3458.4436\n",
      "Epoch 5/50\n",
      " - 0s - loss: 4563.7798 - val_loss: 3431.8460\n",
      "Epoch 6/50\n",
      " - 0s - loss: 4137.3468 - val_loss: 3057.3196\n",
      "Epoch 7/50\n",
      " - 0s - loss: 3715.0441 - val_loss: 2762.5739\n",
      "Epoch 8/50\n",
      " - 0s - loss: 3347.5161 - val_loss: 2496.1740\n",
      "Epoch 9/50\n",
      " - 0s - loss: 3014.7046 - val_loss: 2333.3535\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2714.0278 - val_loss: 2093.1724\n",
      "Epoch 11/50\n",
      " - 0s - loss: 2445.3527 - val_loss: 1921.2356\n",
      "Epoch 12/50\n",
      " - 0s - loss: 2210.5626 - val_loss: 1788.6124\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1994.3294 - val_loss: 1605.3354\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1807.9329 - val_loss: 1515.9141\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1650.5910 - val_loss: 1433.0125\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1502.0755 - val_loss: 1311.0446\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1378.6876 - val_loss: 1222.2364\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1270.6909 - val_loss: 1162.1525\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1177.3501 - val_loss: 1089.6088\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1099.3261 - val_loss: 1040.7721\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1028.6911 - val_loss: 983.9848\n",
      "Epoch 22/50\n",
      " - 0s - loss: 976.9125 - val_loss: 937.5754\n",
      "Epoch 23/50\n",
      " - 0s - loss: 916.6001 - val_loss: 928.9548\n",
      "Epoch 24/50\n",
      " - 0s - loss: 874.4737 - val_loss: 866.8885\n",
      "Epoch 25/50\n",
      " - 0s - loss: 835.1697 - val_loss: 828.3319\n",
      "Epoch 26/50\n",
      " - 0s - loss: 799.7405 - val_loss: 826.7182\n",
      "Epoch 27/50\n",
      " - 0s - loss: 770.3265 - val_loss: 788.5307\n",
      "Epoch 28/50\n",
      " - 0s - loss: 744.7210 - val_loss: 787.5767\n",
      "Epoch 29/50\n",
      " - 0s - loss: 719.6068 - val_loss: 755.2539\n",
      "Epoch 30/50\n",
      " - 0s - loss: 698.4121 - val_loss: 751.3320\n",
      "Epoch 31/50\n",
      " - 0s - loss: 679.4456 - val_loss: 733.8664\n",
      "Epoch 32/50\n",
      " - 0s - loss: 662.8314 - val_loss: 694.7348\n",
      "Epoch 33/50\n",
      " - 0s - loss: 644.5990 - val_loss: 716.1458\n",
      "Epoch 34/50\n",
      " - 0s - loss: 629.7071 - val_loss: 693.9778\n",
      "Epoch 35/50\n",
      " - 0s - loss: 616.3975 - val_loss: 681.1065\n",
      "Epoch 36/50\n",
      " - 0s - loss: 604.5203 - val_loss: 674.3787\n",
      "Epoch 37/50\n",
      " - 0s - loss: 589.5623 - val_loss: 674.6664\n",
      "Epoch 38/50\n",
      " - 0s - loss: 576.8670 - val_loss: 652.1153\n",
      "Epoch 39/50\n",
      " - 0s - loss: 566.3378 - val_loss: 647.4134\n",
      "Epoch 40/50\n",
      " - 0s - loss: 555.9805 - val_loss: 642.7785\n",
      "Epoch 41/50\n",
      " - 0s - loss: 544.7691 - val_loss: 648.7152\n",
      "Epoch 42/50\n",
      " - 0s - loss: 533.9044 - val_loss: 629.2914\n",
      "Epoch 43/50\n",
      " - 0s - loss: 525.7071 - val_loss: 649.9344\n",
      "Epoch 44/50\n",
      " - 0s - loss: 516.4827 - val_loss: 620.8440\n",
      "Epoch 45/50\n",
      " - 0s - loss: 510.0140 - val_loss: 619.3818\n",
      "Epoch 46/50\n",
      " - 0s - loss: 498.6890 - val_loss: 624.7271\n",
      "Epoch 47/50\n",
      " - 0s - loss: 488.5394 - val_loss: 618.3460\n",
      "Epoch 48/50\n",
      " - 0s - loss: 479.9070 - val_loss: 628.0836\n",
      "Epoch 49/50\n",
      " - 0s - loss: 473.1124 - val_loss: 612.1371\n",
      "Epoch 50/50\n",
      " - 0s - loss: 464.5743 - val_loss: 617.9293\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 326046.4088 - val_loss: 210380.7722\n",
      "Epoch 2/50\n",
      " - 0s - loss: 173487.2076 - val_loss: 116814.0593\n",
      "Epoch 3/50\n",
      " - 0s - loss: 98866.4127 - val_loss: 70519.6590\n",
      "Epoch 4/50\n",
      " - 0s - loss: 60915.8135 - val_loss: 45538.3002\n",
      "Epoch 5/50\n",
      " - 0s - loss: 39409.7350 - val_loss: 30380.0728\n",
      "Epoch 6/50\n",
      " - 0s - loss: 26259.5728 - val_loss: 20588.0557\n",
      "Epoch 7/50\n",
      " - 0s - loss: 17741.3166 - val_loss: 14141.0942\n",
      "Epoch 8/50\n",
      " - 0s - loss: 12120.2904 - val_loss: 9738.1243\n",
      "Epoch 9/50\n",
      " - 0s - loss: 8331.4464 - val_loss: 6784.7299\n",
      "Epoch 10/50\n",
      " - 0s - loss: 5799.4069 - val_loss: 4749.6732\n",
      "Epoch 11/50\n",
      " - 0s - loss: 4081.4678 - val_loss: 3359.1379\n",
      "Epoch 12/50\n",
      " - 0s - loss: 2927.2025 - val_loss: 2375.9455\n",
      "Epoch 13/50\n",
      " - 0s - loss: 2125.3957 - val_loss: 1711.8153\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1593.1910 - val_loss: 1248.6607\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1239.1204 - val_loss: 927.9115\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1002.6511 - val_loss: 713.6532\n",
      "Epoch 17/50\n",
      " - 0s - loss: 847.2416 - val_loss: 566.5585\n",
      "Epoch 18/50\n",
      " - 0s - loss: 748.3981 - val_loss: 464.9511\n",
      "Epoch 19/50\n",
      " - 0s - loss: 684.3229 - val_loss: 396.0612\n",
      "Epoch 20/50\n",
      " - 0s - loss: 642.8949 - val_loss: 349.0687\n",
      "Epoch 21/50\n",
      " - 0s - loss: 614.7217 - val_loss: 320.5928\n",
      "Epoch 22/50\n",
      " - 0s - loss: 597.4540 - val_loss: 297.8632\n",
      "Epoch 23/50\n",
      " - 0s - loss: 584.4222 - val_loss: 283.3811\n",
      "Epoch 24/50\n",
      " - 0s - loss: 575.2104 - val_loss: 271.5708\n",
      "Epoch 25/50\n",
      " - 0s - loss: 567.6173 - val_loss: 265.0860\n",
      "Epoch 26/50\n",
      " - 0s - loss: 561.3177 - val_loss: 257.0171\n",
      "Epoch 27/50\n",
      " - 0s - loss: 555.3229 - val_loss: 253.8269\n",
      "Epoch 28/50\n",
      " - 0s - loss: 549.9274 - val_loss: 251.7192\n",
      "Epoch 29/50\n",
      " - 0s - loss: 544.7304 - val_loss: 248.0348\n",
      "Epoch 30/50\n",
      " - 0s - loss: 539.7128 - val_loss: 246.1076\n",
      "Epoch 31/50\n",
      " - 0s - loss: 534.7098 - val_loss: 244.6737\n",
      "Epoch 32/50\n",
      " - 0s - loss: 529.4883 - val_loss: 243.5335\n",
      "Epoch 33/50\n",
      " - 0s - loss: 524.0918 - val_loss: 244.4998\n",
      "Epoch 34/50\n",
      " - 0s - loss: 519.0818 - val_loss: 243.5963\n",
      "Epoch 35/50\n",
      " - 0s - loss: 513.7677 - val_loss: 241.3594\n",
      "Epoch 36/50\n",
      " - 0s - loss: 508.8559 - val_loss: 241.4480\n",
      "Epoch 37/50\n",
      " - 0s - loss: 503.8993 - val_loss: 239.1948\n",
      "Epoch 38/50\n",
      " - 0s - loss: 498.9457 - val_loss: 237.2124\n",
      "Epoch 39/50\n",
      " - 0s - loss: 493.8438 - val_loss: 239.0282\n",
      "Epoch 40/50\n",
      " - 0s - loss: 488.3746 - val_loss: 238.4117\n",
      "Epoch 41/50\n",
      " - 0s - loss: 483.0168 - val_loss: 236.3525\n",
      "Epoch 42/50\n",
      " - 0s - loss: 477.7532 - val_loss: 235.9773\n",
      "Epoch 43/50\n",
      " - 0s - loss: 472.2713 - val_loss: 232.9582\n",
      "Epoch 44/50\n",
      " - 0s - loss: 466.5732 - val_loss: 231.5622\n",
      "Epoch 45/50\n",
      " - 0s - loss: 461.1554 - val_loss: 231.1042\n",
      "Epoch 46/50\n",
      " - 0s - loss: 456.1166 - val_loss: 230.4507\n",
      "Epoch 47/50\n",
      " - 0s - loss: 450.8439 - val_loss: 230.1660\n",
      "Epoch 48/50\n",
      " - 0s - loss: 445.9962 - val_loss: 230.7222\n",
      "Epoch 49/50\n",
      " - 0s - loss: 441.1740 - val_loss: 229.7320\n",
      "Epoch 50/50\n",
      " - 0s - loss: 436.9139 - val_loss: 228.0817\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 32081.4516 - val_loss: 18217.7201\n",
      "Epoch 2/50\n",
      " - 0s - loss: 11390.7039 - val_loss: 6536.5340\n",
      "Epoch 3/50\n",
      " - 0s - loss: 4915.6730 - val_loss: 2938.6065\n",
      "Epoch 4/50\n",
      " - 0s - loss: 3060.1183 - val_loss: 1919.1294\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2274.7424 - val_loss: 1403.8801\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1439.5170 - val_loss: 1057.5014\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1056.2993 - val_loss: 789.3037\n",
      "Epoch 8/50\n",
      " - 0s - loss: 866.1745 - val_loss: 667.1258\n",
      "Epoch 9/50\n",
      " - 0s - loss: 754.4130 - val_loss: 581.0381\n",
      "Epoch 10/50\n",
      " - 0s - loss: 672.5868 - val_loss: 497.7297\n",
      "Epoch 11/50\n",
      " - 0s - loss: 605.8206 - val_loss: 448.6682\n",
      "Epoch 12/50\n",
      " - 0s - loss: 544.5520 - val_loss: 410.9918\n",
      "Epoch 13/50\n",
      " - 0s - loss: 493.5382 - val_loss: 378.7315\n",
      "Epoch 14/50\n",
      " - 0s - loss: 447.9996 - val_loss: 358.9244\n",
      "Epoch 15/50\n",
      " - 0s - loss: 412.3855 - val_loss: 318.5132\n",
      "Epoch 16/50\n",
      " - 0s - loss: 389.7707 - val_loss: 319.1150\n",
      "Epoch 17/50\n",
      " - 0s - loss: 367.8047 - val_loss: 296.2821\n",
      "Epoch 18/50\n",
      " - 0s - loss: 353.2423 - val_loss: 271.8376\n",
      "Epoch 19/50\n",
      " - 0s - loss: 337.9621 - val_loss: 265.8553\n",
      "Epoch 20/50\n",
      " - 0s - loss: 330.7755 - val_loss: 246.1024\n",
      "Epoch 21/50\n",
      " - 0s - loss: 319.7742 - val_loss: 245.3040\n",
      "Epoch 22/50\n",
      " - 0s - loss: 309.4231 - val_loss: 236.3002\n",
      "Epoch 23/50\n",
      " - 0s - loss: 300.3703 - val_loss: 240.5826\n",
      "Epoch 24/50\n",
      " - 0s - loss: 294.4942 - val_loss: 224.4396\n",
      "Epoch 25/50\n",
      " - 0s - loss: 289.5672 - val_loss: 220.3329\n",
      "Epoch 26/50\n",
      " - 0s - loss: 283.5475 - val_loss: 212.8031\n",
      "Epoch 27/50\n",
      " - 0s - loss: 280.1165 - val_loss: 228.5876\n",
      "Epoch 28/50\n",
      " - 0s - loss: 275.2374 - val_loss: 219.0224\n",
      "Epoch 29/50\n",
      " - 0s - loss: 267.8684 - val_loss: 209.6250\n",
      "Epoch 30/50\n",
      " - 0s - loss: 259.5376 - val_loss: 197.3152\n",
      "Epoch 31/50\n",
      " - 0s - loss: 256.1674 - val_loss: 196.3660\n",
      "Epoch 32/50\n",
      " - 0s - loss: 250.5440 - val_loss: 195.5645\n",
      "Epoch 33/50\n",
      " - 0s - loss: 245.5397 - val_loss: 185.6778\n",
      "Epoch 34/50\n",
      " - 0s - loss: 242.3137 - val_loss: 181.0044\n",
      "Epoch 35/50\n",
      " - 0s - loss: 235.9547 - val_loss: 178.8889\n",
      "Epoch 36/50\n",
      " - 0s - loss: 231.8584 - val_loss: 174.0505\n",
      "Epoch 37/50\n",
      " - 0s - loss: 226.0165 - val_loss: 174.6026\n",
      "Epoch 38/50\n",
      " - 0s - loss: 222.2492 - val_loss: 166.3479\n",
      "Epoch 39/50\n",
      " - 0s - loss: 218.2937 - val_loss: 163.0883\n",
      "Epoch 40/50\n",
      " - 0s - loss: 212.2487 - val_loss: 157.1892\n",
      "Epoch 41/50\n",
      " - 0s - loss: 208.7916 - val_loss: 155.2345\n",
      "Epoch 42/50\n",
      " - 0s - loss: 204.5537 - val_loss: 150.5422\n",
      "Epoch 43/50\n",
      " - 0s - loss: 198.9351 - val_loss: 142.7312\n",
      "Epoch 44/50\n",
      " - 0s - loss: 196.2182 - val_loss: 139.1906\n",
      "Epoch 45/50\n",
      " - 0s - loss: 192.5019 - val_loss: 142.8950\n",
      "Epoch 46/50\n",
      " - 0s - loss: 189.5398 - val_loss: 138.2590\n",
      "Epoch 47/50\n",
      " - 0s - loss: 186.1247 - val_loss: 131.4985\n",
      "Epoch 48/50\n",
      " - 0s - loss: 184.3228 - val_loss: 126.3401\n",
      "Epoch 49/50\n",
      " - 0s - loss: 180.4953 - val_loss: 123.8456\n",
      "Epoch 50/50\n",
      " - 0s - loss: 176.9823 - val_loss: 121.2669\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 292155.9075 - val_loss: 207242.8588\n",
      "Epoch 2/50\n",
      " - 0s - loss: 161197.4460 - val_loss: 109757.6553\n",
      "Epoch 3/50\n",
      " - 0s - loss: 81502.0938 - val_loss: 52517.0987\n",
      "Epoch 4/50\n",
      " - 0s - loss: 35459.2769 - val_loss: 19645.0730\n",
      "Epoch 5/50\n",
      " - 0s - loss: 11953.9689 - val_loss: 5938.7012\n",
      "Epoch 6/50\n",
      " - 0s - loss: 4322.0833 - val_loss: 3018.6165\n",
      "Epoch 7/50\n",
      " - 0s - loss: 3151.9929 - val_loss: 2722.0536\n",
      "Epoch 8/50\n",
      " - 0s - loss: 3001.0497 - val_loss: 2632.4510\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2855.1867 - val_loss: 2559.1587\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2717.0473 - val_loss: 2484.3018\n",
      "Epoch 11/50\n",
      " - 0s - loss: 2588.3142 - val_loss: 2417.1174\n",
      "Epoch 12/50\n",
      " - 0s - loss: 2464.6598 - val_loss: 2343.4657\n",
      "Epoch 13/50\n",
      " - 0s - loss: 2349.4472 - val_loss: 2276.0267\n",
      "Epoch 14/50\n",
      " - 0s - loss: 2238.9737 - val_loss: 2212.2787\n",
      "Epoch 15/50\n",
      " - 0s - loss: 2131.3137 - val_loss: 2146.9828\n",
      "Epoch 16/50\n",
      " - 0s - loss: 2034.8588 - val_loss: 2085.9946\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1943.3629 - val_loss: 2032.4426\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1849.8981 - val_loss: 1970.9100\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1767.8903 - val_loss: 1915.7443\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1690.6788 - val_loss: 1868.7587\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1610.0774 - val_loss: 1815.7530\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1532.7957 - val_loss: 1773.2878\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1465.7077 - val_loss: 1725.5697\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1397.5732 - val_loss: 1677.7963\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1334.4717 - val_loss: 1632.2710\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1273.2128 - val_loss: 1591.2636\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1216.9205 - val_loss: 1552.4783\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1161.2950 - val_loss: 1513.0922\n",
      "Epoch 29/50\n",
      " - 0s - loss: 1110.1639 - val_loss: 1472.0425\n",
      "Epoch 30/50\n",
      " - 0s - loss: 1058.4890 - val_loss: 1435.0671\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1012.8228 - val_loss: 1400.5200\n",
      "Epoch 32/50\n",
      " - 0s - loss: 967.5603 - val_loss: 1365.4944\n",
      "Epoch 33/50\n",
      " - 0s - loss: 926.0212 - val_loss: 1331.2615\n",
      "Epoch 34/50\n",
      " - 0s - loss: 886.0668 - val_loss: 1298.8590\n",
      "Epoch 35/50\n",
      " - 0s - loss: 848.0683 - val_loss: 1268.3659\n",
      "Epoch 36/50\n",
      " - 0s - loss: 810.3724 - val_loss: 1236.3169\n",
      "Epoch 37/50\n",
      " - 0s - loss: 777.6518 - val_loss: 1205.3233\n",
      "Epoch 38/50\n",
      " - 0s - loss: 743.2937 - val_loss: 1175.5631\n",
      "Epoch 39/50\n",
      " - 0s - loss: 712.6975 - val_loss: 1148.0071\n",
      "Epoch 40/50\n",
      " - 0s - loss: 683.7265 - val_loss: 1121.9404\n",
      "Epoch 41/50\n",
      " - 0s - loss: 656.9388 - val_loss: 1094.8768\n",
      "Epoch 42/50\n",
      " - 0s - loss: 632.9421 - val_loss: 1068.3265\n",
      "Epoch 43/50\n",
      " - 0s - loss: 605.7410 - val_loss: 1042.8427\n",
      "Epoch 44/50\n",
      " - 0s - loss: 582.6394 - val_loss: 1019.2843\n",
      "Epoch 45/50\n",
      " - 0s - loss: 558.9985 - val_loss: 994.5748\n",
      "Epoch 46/50\n",
      " - 0s - loss: 539.4649 - val_loss: 970.4771\n",
      "Epoch 47/50\n",
      " - 0s - loss: 518.7274 - val_loss: 947.5069\n",
      "Epoch 48/50\n",
      " - 0s - loss: 500.3343 - val_loss: 924.3687\n",
      "Epoch 49/50\n",
      " - 0s - loss: 483.4639 - val_loss: 902.4489\n",
      "Epoch 50/50\n",
      " - 0s - loss: 465.1668 - val_loss: 880.2227\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 5612.1929 - val_loss: 2163.8901\n",
      "Epoch 2/50\n",
      " - 0s - loss: 3429.5591 - val_loss: 1721.0969\n",
      "Epoch 3/50\n",
      " - 0s - loss: 2785.4244 - val_loss: 1318.4648\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2278.4819 - val_loss: 1054.0928\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1905.0577 - val_loss: 883.7382\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1600.9513 - val_loss: 790.3467\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1378.0477 - val_loss: 732.5443\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1210.0702 - val_loss: 701.0505\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1076.3476 - val_loss: 693.0943\n",
      "Epoch 10/50\n",
      " - 0s - loss: 976.4225 - val_loss: 674.4577\n",
      "Epoch 11/50\n",
      " - 0s - loss: 898.6974 - val_loss: 670.3795\n",
      "Epoch 12/50\n",
      " - 0s - loss: 828.0615 - val_loss: 647.1259\n",
      "Epoch 13/50\n",
      " - 0s - loss: 770.0126 - val_loss: 631.6704\n",
      "Epoch 14/50\n",
      " - 0s - loss: 720.1680 - val_loss: 601.7583\n",
      "Epoch 15/50\n",
      " - 0s - loss: 675.4112 - val_loss: 582.8352\n",
      "Epoch 16/50\n",
      " - 0s - loss: 632.5192 - val_loss: 550.5031\n",
      "Epoch 17/50\n",
      " - 0s - loss: 594.3629 - val_loss: 537.2111\n",
      "Epoch 18/50\n",
      " - 0s - loss: 558.9035 - val_loss: 507.2987\n",
      "Epoch 19/50\n",
      " - 0s - loss: 526.2062 - val_loss: 479.4158\n",
      "Epoch 20/50\n",
      " - 0s - loss: 494.3968 - val_loss: 459.1392\n",
      "Epoch 21/50\n",
      " - 0s - loss: 467.7323 - val_loss: 443.5581\n",
      "Epoch 22/50\n",
      " - 0s - loss: 445.3332 - val_loss: 442.3851\n",
      "Epoch 23/50\n",
      " - 0s - loss: 424.9731 - val_loss: 417.7734\n",
      "Epoch 24/50\n",
      " - 0s - loss: 406.6341 - val_loss: 407.1416\n",
      "Epoch 25/50\n",
      " - 0s - loss: 391.3452 - val_loss: 389.0451\n",
      "Epoch 26/50\n",
      " - 0s - loss: 373.1900 - val_loss: 375.4513\n",
      "Epoch 27/50\n",
      " - 0s - loss: 359.4382 - val_loss: 370.7489\n",
      "Epoch 28/50\n",
      " - 0s - loss: 349.7909 - val_loss: 358.8490\n",
      "Epoch 29/50\n",
      " - 0s - loss: 333.1116 - val_loss: 338.7957\n",
      "Epoch 30/50\n",
      " - 0s - loss: 321.7543 - val_loss: 336.3353\n",
      "Epoch 31/50\n",
      " - 0s - loss: 311.6080 - val_loss: 318.3976\n",
      "Epoch 32/50\n",
      " - 0s - loss: 300.8169 - val_loss: 299.7481\n",
      "Epoch 33/50\n",
      " - 0s - loss: 290.0073 - val_loss: 298.7370\n",
      "Epoch 34/50\n",
      " - 0s - loss: 282.4181 - val_loss: 283.3818\n",
      "Epoch 35/50\n",
      " - 0s - loss: 271.7978 - val_loss: 270.8341\n",
      "Epoch 36/50\n",
      " - 0s - loss: 264.4141 - val_loss: 266.3076\n",
      "Epoch 37/50\n",
      " - 0s - loss: 255.1356 - val_loss: 247.9224\n",
      "Epoch 38/50\n",
      " - 0s - loss: 249.4128 - val_loss: 251.8637\n",
      "Epoch 39/50\n",
      " - 0s - loss: 240.5911 - val_loss: 229.4358\n",
      "Epoch 40/50\n",
      " - 0s - loss: 234.7500 - val_loss: 239.8392\n",
      "Epoch 41/50\n",
      " - 0s - loss: 228.8669 - val_loss: 214.3971\n",
      "Epoch 42/50\n",
      " - 0s - loss: 224.4652 - val_loss: 212.2559\n",
      "Epoch 43/50\n",
      " - 0s - loss: 217.2178 - val_loss: 215.6180\n",
      "Epoch 44/50\n",
      " - 0s - loss: 211.4390 - val_loss: 195.4606\n",
      "Epoch 45/50\n",
      " - 0s - loss: 205.5344 - val_loss: 191.0635\n",
      "Epoch 46/50\n",
      " - 0s - loss: 200.6160 - val_loss: 192.5555\n",
      "Epoch 47/50\n",
      " - 0s - loss: 199.1710 - val_loss: 177.2760\n",
      "Epoch 48/50\n",
      " - 0s - loss: 194.3431 - val_loss: 170.4516\n",
      "Epoch 49/50\n",
      " - 0s - loss: 189.3094 - val_loss: 173.5735\n",
      "Epoch 50/50\n",
      " - 0s - loss: 185.0873 - val_loss: 170.8949\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 5196.3510 - val_loss: 2788.6224\n",
      "Epoch 2/50\n",
      " - 0s - loss: 3763.8550 - val_loss: 2446.8343\n",
      "Epoch 3/50\n",
      " - 0s - loss: 3078.1599 - val_loss: 2047.5173\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2529.9781 - val_loss: 1698.8264\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2123.3873 - val_loss: 1363.2276\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1817.0942 - val_loss: 1250.5482\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1569.6572 - val_loss: 1012.3831\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1366.3432 - val_loss: 921.0652\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1209.0904 - val_loss: 809.3519\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1082.0994 - val_loss: 730.9688\n",
      "Epoch 11/50\n",
      " - 0s - loss: 973.4957 - val_loss: 659.0104\n",
      "Epoch 12/50\n",
      " - 0s - loss: 885.3503 - val_loss: 579.4564\n",
      "Epoch 13/50\n",
      " - 0s - loss: 804.9644 - val_loss: 538.8150\n",
      "Epoch 14/50\n",
      " - 0s - loss: 732.0923 - val_loss: 514.4776\n",
      "Epoch 15/50\n",
      " - 0s - loss: 670.4391 - val_loss: 477.6777\n",
      "Epoch 16/50\n",
      " - 0s - loss: 612.3174 - val_loss: 414.6027\n",
      "Epoch 17/50\n",
      " - 0s - loss: 563.5318 - val_loss: 386.4314\n",
      "Epoch 18/50\n",
      " - 0s - loss: 523.9686 - val_loss: 357.2848\n",
      "Epoch 19/50\n",
      " - 0s - loss: 497.3799 - val_loss: 338.7843\n",
      "Epoch 20/50\n",
      " - 0s - loss: 470.5694 - val_loss: 302.6715\n",
      "Epoch 21/50\n",
      " - 0s - loss: 448.7845 - val_loss: 287.9544\n",
      "Epoch 22/50\n",
      " - 0s - loss: 428.2513 - val_loss: 280.0257\n",
      "Epoch 23/50\n",
      " - 0s - loss: 413.0294 - val_loss: 261.8436\n",
      "Epoch 24/50\n",
      " - 0s - loss: 402.0569 - val_loss: 256.4332\n",
      "Epoch 25/50\n",
      " - 0s - loss: 394.1109 - val_loss: 248.3311\n",
      "Epoch 26/50\n",
      " - 0s - loss: 388.2522 - val_loss: 248.0107\n",
      "Epoch 27/50\n",
      " - 0s - loss: 385.4008 - val_loss: 236.5339\n",
      "Epoch 28/50\n",
      " - 0s - loss: 380.8621 - val_loss: 241.4901\n",
      "Epoch 29/50\n",
      " - 0s - loss: 379.9661 - val_loss: 224.6300\n",
      "Epoch 30/50\n",
      " - 0s - loss: 373.7898 - val_loss: 230.1548\n",
      "Epoch 31/50\n",
      " - 0s - loss: 370.1500 - val_loss: 222.1820\n",
      "Epoch 32/50\n",
      " - 0s - loss: 367.1545 - val_loss: 230.8017\n",
      "Epoch 33/50\n",
      " - 0s - loss: 364.5912 - val_loss: 225.4388\n",
      "Epoch 34/50\n",
      " - 0s - loss: 361.3882 - val_loss: 224.9628\n",
      "Epoch 35/50\n",
      " - 0s - loss: 359.6815 - val_loss: 214.2251\n",
      "Epoch 36/50\n",
      " - 0s - loss: 355.6836 - val_loss: 227.2619\n",
      "Epoch 37/50\n",
      " - 0s - loss: 354.1998 - val_loss: 218.3195\n",
      "Epoch 38/50\n",
      " - 0s - loss: 351.8448 - val_loss: 213.7269\n",
      "Epoch 39/50\n",
      " - 0s - loss: 349.4211 - val_loss: 211.2736\n",
      "Epoch 40/50\n",
      " - 0s - loss: 347.6004 - val_loss: 207.2570\n",
      "Epoch 41/50\n",
      " - 0s - loss: 343.6205 - val_loss: 217.6095\n",
      "Epoch 42/50\n",
      " - 0s - loss: 341.9269 - val_loss: 210.3904\n",
      "Epoch 43/50\n",
      " - 0s - loss: 340.0293 - val_loss: 200.8801\n",
      "Epoch 44/50\n",
      " - 0s - loss: 337.2217 - val_loss: 211.6200\n",
      "Epoch 45/50\n",
      " - 0s - loss: 334.8059 - val_loss: 206.3337\n",
      "Epoch 46/50\n",
      " - 0s - loss: 330.9454 - val_loss: 196.4545\n",
      "Epoch 47/50\n",
      " - 0s - loss: 327.4106 - val_loss: 210.7644\n",
      "Epoch 48/50\n",
      " - 0s - loss: 329.9266 - val_loss: 214.4536\n",
      "Epoch 49/50\n",
      " - 0s - loss: 323.3517 - val_loss: 190.6288\n",
      "Epoch 50/50\n",
      " - 0s - loss: 320.4604 - val_loss: 188.7246\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 2697.2260 - val_loss: 1224.0049\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1194.7009 - val_loss: 1049.2269\n",
      "Epoch 3/50\n",
      " - 0s - loss: 854.3749 - val_loss: 929.3908\n",
      "Epoch 4/50\n",
      " - 0s - loss: 648.2092 - val_loss: 905.3066\n",
      "Epoch 5/50\n",
      " - 0s - loss: 530.5193 - val_loss: 884.2998\n",
      "Epoch 6/50\n",
      " - 0s - loss: 452.1234 - val_loss: 831.2828\n",
      "Epoch 7/50\n",
      " - 0s - loss: 387.4689 - val_loss: 771.6138\n",
      "Epoch 8/50\n",
      " - 0s - loss: 346.0124 - val_loss: 693.4696\n",
      "Epoch 9/50\n",
      " - 0s - loss: 310.2978 - val_loss: 609.1336\n",
      "Epoch 10/50\n",
      " - 0s - loss: 285.1768 - val_loss: 544.6391\n",
      "Epoch 11/50\n",
      " - 0s - loss: 260.5619 - val_loss: 481.5397\n",
      "Epoch 12/50\n",
      " - 0s - loss: 241.2023 - val_loss: 432.5624\n",
      "Epoch 13/50\n",
      " - 0s - loss: 227.8732 - val_loss: 385.4584\n",
      "Epoch 14/50\n",
      " - 0s - loss: 212.5896 - val_loss: 344.1218\n",
      "Epoch 15/50\n",
      " - 0s - loss: 201.6210 - val_loss: 310.5442\n",
      "Epoch 16/50\n",
      " - 0s - loss: 194.8652 - val_loss: 287.1487\n",
      "Epoch 17/50\n",
      " - 0s - loss: 187.5710 - val_loss: 252.9041\n",
      "Epoch 18/50\n",
      " - 0s - loss: 174.9869 - val_loss: 232.4774\n",
      "Epoch 19/50\n",
      " - 0s - loss: 167.8418 - val_loss: 210.9855\n",
      "Epoch 20/50\n",
      " - 0s - loss: 164.2466 - val_loss: 196.5723\n",
      "Epoch 21/50\n",
      " - 0s - loss: 157.8176 - val_loss: 187.0763\n",
      "Epoch 22/50\n",
      " - 0s - loss: 159.5907 - val_loss: 174.5211\n",
      "Epoch 23/50\n",
      " - 0s - loss: 156.1117 - val_loss: 163.5574\n",
      "Epoch 24/50\n",
      " - 0s - loss: 148.9817 - val_loss: 165.0527\n",
      "Epoch 25/50\n",
      " - 0s - loss: 149.0637 - val_loss: 143.5309\n",
      "Epoch 26/50\n",
      " - 0s - loss: 144.6347 - val_loss: 134.3745\n",
      "Epoch 27/50\n",
      " - 0s - loss: 140.9411 - val_loss: 129.6122\n",
      "Epoch 28/50\n",
      " - 0s - loss: 138.8328 - val_loss: 122.0548\n",
      "Epoch 29/50\n",
      " - 0s - loss: 138.1292 - val_loss: 118.4273\n",
      "Epoch 30/50\n",
      " - 0s - loss: 135.5517 - val_loss: 110.7929\n",
      "Epoch 31/50\n",
      " - 0s - loss: 135.1360 - val_loss: 107.1397\n",
      "Epoch 32/50\n",
      " - 0s - loss: 141.5411 - val_loss: 105.5266\n",
      "Epoch 33/50\n",
      " - 0s - loss: 135.2161 - val_loss: 101.6809\n",
      "Epoch 34/50\n",
      " - 0s - loss: 132.4391 - val_loss: 101.3603\n",
      "Epoch 35/50\n",
      " - 0s - loss: 132.7922 - val_loss: 96.6538\n",
      "Epoch 36/50\n",
      " - 0s - loss: 131.0214 - val_loss: 94.0271\n",
      "Epoch 37/50\n",
      " - 0s - loss: 129.9784 - val_loss: 92.0881\n",
      "Epoch 38/50\n",
      " - 0s - loss: 131.3546 - val_loss: 90.2954\n",
      "Epoch 39/50\n",
      " - 0s - loss: 131.0119 - val_loss: 88.0487\n",
      "Epoch 40/50\n",
      " - 0s - loss: 128.6582 - val_loss: 86.4057\n",
      "Epoch 41/50\n",
      " - 0s - loss: 127.5072 - val_loss: 86.1517\n",
      "Epoch 42/50\n",
      " - 0s - loss: 129.7254 - val_loss: 83.5562\n",
      "Epoch 43/50\n",
      " - 0s - loss: 129.2316 - val_loss: 82.4602\n",
      "Epoch 44/50\n",
      " - 0s - loss: 127.2513 - val_loss: 85.2899\n",
      "Epoch 45/50\n",
      " - 0s - loss: 127.9021 - val_loss: 86.6800\n",
      "Epoch 46/50\n",
      " - 0s - loss: 128.1882 - val_loss: 83.2660\n",
      "Epoch 47/50\n",
      " - 0s - loss: 128.0869 - val_loss: 80.0627\n",
      "Epoch 48/50\n",
      " - 0s - loss: 130.3361 - val_loss: 80.2604\n",
      "Epoch 49/50\n",
      " - 0s - loss: 128.7787 - val_loss: 79.3173\n",
      "Epoch 50/50\n",
      " - 0s - loss: 126.3324 - val_loss: 77.2559\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 106475.3923 - val_loss: 59059.8959\n",
      "Epoch 2/50\n",
      " - 0s - loss: 43465.8778 - val_loss: 21290.8685\n",
      "Epoch 3/50\n",
      " - 0s - loss: 14673.3904 - val_loss: 6035.8080\n",
      "Epoch 4/50\n",
      " - 0s - loss: 4033.1071 - val_loss: 1562.3674\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1107.6996 - val_loss: 822.2219\n",
      "Epoch 6/50\n",
      " - 0s - loss: 609.5367 - val_loss: 802.6788\n",
      "Epoch 7/50\n",
      " - 0s - loss: 554.8201 - val_loss: 800.7563\n",
      "Epoch 8/50\n",
      " - 0s - loss: 537.9962 - val_loss: 769.0746\n",
      "Epoch 9/50\n",
      " - 0s - loss: 520.7175 - val_loss: 747.3534\n",
      "Epoch 10/50\n",
      " - 0s - loss: 503.5162 - val_loss: 709.9679\n",
      "Epoch 11/50\n",
      " - 0s - loss: 487.1086 - val_loss: 685.2560\n",
      "Epoch 12/50\n",
      " - 0s - loss: 470.9537 - val_loss: 656.7239\n",
      "Epoch 13/50\n",
      " - 0s - loss: 455.8187 - val_loss: 634.0847\n",
      "Epoch 14/50\n",
      " - 0s - loss: 440.7468 - val_loss: 602.3256\n",
      "Epoch 15/50\n",
      " - 0s - loss: 425.9854 - val_loss: 575.5580\n",
      "Epoch 16/50\n",
      " - 0s - loss: 412.4153 - val_loss: 553.5165\n",
      "Epoch 17/50\n",
      " - 0s - loss: 398.6891 - val_loss: 530.3729\n",
      "Epoch 18/50\n",
      " - 0s - loss: 385.2735 - val_loss: 506.6009\n",
      "Epoch 19/50\n",
      " - 0s - loss: 373.2861 - val_loss: 483.0209\n",
      "Epoch 20/50\n",
      " - 0s - loss: 360.9890 - val_loss: 457.9001\n",
      "Epoch 21/50\n",
      " - 0s - loss: 349.1956 - val_loss: 443.9560\n",
      "Epoch 22/50\n",
      " - 0s - loss: 338.1350 - val_loss: 419.6868\n",
      "Epoch 23/50\n",
      " - 0s - loss: 327.3379 - val_loss: 399.7703\n",
      "Epoch 24/50\n",
      " - 0s - loss: 317.5056 - val_loss: 383.1379\n",
      "Epoch 25/50\n",
      " - 0s - loss: 308.1286 - val_loss: 363.5236\n",
      "Epoch 26/50\n",
      " - 0s - loss: 299.5598 - val_loss: 346.8292\n",
      "Epoch 27/50\n",
      " - 0s - loss: 289.9205 - val_loss: 330.5593\n",
      "Epoch 28/50\n",
      " - 0s - loss: 281.5373 - val_loss: 316.3425\n",
      "Epoch 29/50\n",
      " - 0s - loss: 274.3141 - val_loss: 301.1826\n",
      "Epoch 30/50\n",
      " - 0s - loss: 266.9250 - val_loss: 293.1461\n",
      "Epoch 31/50\n",
      " - 0s - loss: 260.1355 - val_loss: 272.7135\n",
      "Epoch 32/50\n",
      " - 0s - loss: 253.1937 - val_loss: 263.1002\n",
      "Epoch 33/50\n",
      " - 0s - loss: 247.1702 - val_loss: 251.4970\n",
      "Epoch 34/50\n",
      " - 0s - loss: 241.2718 - val_loss: 241.0995\n",
      "Epoch 35/50\n",
      " - 0s - loss: 236.0308 - val_loss: 231.2344\n",
      "Epoch 36/50\n",
      " - 0s - loss: 231.1478 - val_loss: 219.5186\n",
      "Epoch 37/50\n",
      " - 0s - loss: 226.5823 - val_loss: 209.9052\n",
      "Epoch 38/50\n",
      " - 0s - loss: 221.6478 - val_loss: 202.5664\n",
      "Epoch 39/50\n",
      " - 0s - loss: 218.0275 - val_loss: 195.8134\n",
      "Epoch 40/50\n",
      " - 0s - loss: 213.1964 - val_loss: 183.5269\n",
      "Epoch 41/50\n",
      " - 0s - loss: 209.4358 - val_loss: 176.8488\n",
      "Epoch 42/50\n",
      " - 0s - loss: 206.7231 - val_loss: 173.6433\n",
      "Epoch 43/50\n",
      " - 0s - loss: 203.0362 - val_loss: 162.7406\n",
      "Epoch 44/50\n",
      " - 0s - loss: 199.3935 - val_loss: 162.3828\n",
      "Epoch 45/50\n",
      " - 0s - loss: 195.4340 - val_loss: 152.4231\n",
      "Epoch 46/50\n",
      " - 0s - loss: 192.7404 - val_loss: 148.9178\n",
      "Epoch 47/50\n",
      " - 0s - loss: 189.7974 - val_loss: 146.7896\n",
      "Epoch 48/50\n",
      " - 0s - loss: 186.7726 - val_loss: 138.6315\n",
      "Epoch 49/50\n",
      " - 0s - loss: 184.1962 - val_loss: 136.3632\n",
      "Epoch 50/50\n",
      " - 0s - loss: 182.2375 - val_loss: 134.3118\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 9s - loss: 142794.0574 - val_loss: 73203.8562\n",
      "Epoch 2/50\n",
      " - 0s - loss: 43026.6440 - val_loss: 17211.3003\n",
      "Epoch 3/50\n",
      " - 0s - loss: 9531.1785 - val_loss: 4742.4840\n",
      "Epoch 4/50\n",
      " - 0s - loss: 3791.6559 - val_loss: 3500.6478\n",
      "Epoch 5/50\n",
      " - 0s - loss: 3320.1897 - val_loss: 3362.3060\n",
      "Epoch 6/50\n",
      " - 0s - loss: 3146.6278 - val_loss: 3219.6971\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2962.0989 - val_loss: 3072.4249\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2776.6732 - val_loss: 2927.8918\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2600.7135 - val_loss: 2779.0737\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2419.6841 - val_loss: 2640.9556\n",
      "Epoch 11/50\n",
      " - 0s - loss: 2251.1391 - val_loss: 2488.3381\n",
      "Epoch 12/50\n",
      " - 0s - loss: 2088.5232 - val_loss: 2342.1100\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1929.6915 - val_loss: 2206.2767\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1785.4967 - val_loss: 2072.6539\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1645.1443 - val_loss: 1943.0552\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1513.7045 - val_loss: 1814.8398\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1389.3400 - val_loss: 1694.2531\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1278.7352 - val_loss: 1578.6763\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1167.8963 - val_loss: 1471.2065\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1070.6550 - val_loss: 1368.1695\n",
      "Epoch 21/50\n",
      " - 0s - loss: 979.7236 - val_loss: 1266.6547\n",
      "Epoch 22/50\n",
      " - 0s - loss: 897.2324 - val_loss: 1170.2560\n",
      "Epoch 23/50\n",
      " - 0s - loss: 818.0058 - val_loss: 1086.3607\n",
      "Epoch 24/50\n",
      " - 0s - loss: 749.4559 - val_loss: 1000.6133\n",
      "Epoch 25/50\n",
      " - 0s - loss: 685.1956 - val_loss: 922.0499\n",
      "Epoch 26/50\n",
      " - 0s - loss: 624.2818 - val_loss: 846.6471\n",
      "Epoch 27/50\n",
      " - 0s - loss: 571.4592 - val_loss: 778.2998\n",
      "Epoch 28/50\n",
      " - 0s - loss: 522.2832 - val_loss: 716.0851\n",
      "Epoch 29/50\n",
      " - 0s - loss: 479.0339 - val_loss: 656.7433\n",
      "Epoch 30/50\n",
      " - 0s - loss: 438.1047 - val_loss: 601.2254\n",
      "Epoch 31/50\n",
      " - 0s - loss: 401.1005 - val_loss: 550.8166\n",
      "Epoch 32/50\n",
      " - 0s - loss: 368.6789 - val_loss: 503.7000\n",
      "Epoch 33/50\n",
      " - 0s - loss: 338.2255 - val_loss: 461.0598\n",
      "Epoch 34/50\n",
      " - 0s - loss: 313.3323 - val_loss: 422.4713\n",
      "Epoch 35/50\n",
      " - 0s - loss: 288.9547 - val_loss: 384.8476\n",
      "Epoch 36/50\n",
      " - 0s - loss: 268.1043 - val_loss: 354.3572\n",
      "Epoch 37/50\n",
      " - 0s - loss: 251.5215 - val_loss: 324.1354\n",
      "Epoch 38/50\n",
      " - 0s - loss: 235.0784 - val_loss: 297.4846\n",
      "Epoch 39/50\n",
      " - 0s - loss: 218.1897 - val_loss: 273.8486\n",
      "Epoch 40/50\n",
      " - 0s - loss: 205.2158 - val_loss: 251.7360\n",
      "Epoch 41/50\n",
      " - 0s - loss: 193.8508 - val_loss: 233.3271\n",
      "Epoch 42/50\n",
      " - 0s - loss: 184.0088 - val_loss: 214.3801\n",
      "Epoch 43/50\n",
      " - 0s - loss: 175.3672 - val_loss: 199.2784\n",
      "Epoch 44/50\n",
      " - 0s - loss: 167.7698 - val_loss: 185.6989\n",
      "Epoch 45/50\n",
      " - 0s - loss: 160.8926 - val_loss: 173.5823\n",
      "Epoch 46/50\n",
      " - 0s - loss: 155.4155 - val_loss: 161.7195\n",
      "Epoch 47/50\n",
      " - 0s - loss: 150.6498 - val_loss: 152.1699\n",
      "Epoch 48/50\n",
      " - 0s - loss: 146.5108 - val_loss: 143.1555\n",
      "Epoch 49/50\n",
      " - 0s - loss: 142.7166 - val_loss: 135.5533\n",
      "Epoch 50/50\n",
      " - 0s - loss: 139.4048 - val_loss: 127.9873\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 29903.8275 - val_loss: 14901.9236\n",
      "Epoch 2/50\n",
      " - 0s - loss: 9809.6647 - val_loss: 4032.8651\n",
      "Epoch 3/50\n",
      " - 0s - loss: 3277.1338 - val_loss: 1634.1843\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1840.3117 - val_loss: 1294.7972\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1546.8106 - val_loss: 1217.3553\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1429.6858 - val_loss: 1167.7356\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1322.4064 - val_loss: 1127.9385\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1235.2821 - val_loss: 1089.3849\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1148.0826 - val_loss: 1045.3577\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1070.9169 - val_loss: 1001.5415\n",
      "Epoch 11/50\n",
      " - 0s - loss: 994.9381 - val_loss: 968.8125\n",
      "Epoch 12/50\n",
      " - 0s - loss: 933.3056 - val_loss: 942.8241\n",
      "Epoch 13/50\n",
      " - 0s - loss: 882.7027 - val_loss: 918.6957\n",
      "Epoch 14/50\n",
      " - 0s - loss: 839.8174 - val_loss: 897.6559\n",
      "Epoch 15/50\n",
      " - 0s - loss: 799.8022 - val_loss: 866.9423\n",
      "Epoch 16/50\n",
      " - 0s - loss: 763.8860 - val_loss: 842.3036\n",
      "Epoch 17/50\n",
      " - 0s - loss: 733.7613 - val_loss: 815.6578\n",
      "Epoch 18/50\n",
      " - 0s - loss: 699.0647 - val_loss: 793.1546\n",
      "Epoch 19/50\n",
      " - 0s - loss: 667.4952 - val_loss: 767.4980\n",
      "Epoch 20/50\n",
      " - 0s - loss: 636.1515 - val_loss: 745.9185\n",
      "Epoch 21/50\n",
      " - 0s - loss: 607.0975 - val_loss: 726.2657\n",
      "Epoch 22/50\n",
      " - 0s - loss: 584.1799 - val_loss: 705.1936\n",
      "Epoch 23/50\n",
      " - 0s - loss: 559.6398 - val_loss: 682.2928\n",
      "Epoch 24/50\n",
      " - 0s - loss: 536.8303 - val_loss: 661.9280\n",
      "Epoch 25/50\n",
      " - 0s - loss: 518.3531 - val_loss: 639.7785\n",
      "Epoch 26/50\n",
      " - 0s - loss: 503.4794 - val_loss: 619.7667\n",
      "Epoch 27/50\n",
      " - 0s - loss: 483.5167 - val_loss: 601.9000\n",
      "Epoch 28/50\n",
      " - 0s - loss: 468.1157 - val_loss: 582.7985\n",
      "Epoch 29/50\n",
      " - 0s - loss: 455.0737 - val_loss: 567.9554\n",
      "Epoch 30/50\n",
      " - 0s - loss: 442.0175 - val_loss: 552.0666\n",
      "Epoch 31/50\n",
      " - 0s - loss: 429.1473 - val_loss: 538.5881\n",
      "Epoch 32/50\n",
      " - 0s - loss: 417.8007 - val_loss: 524.6508\n",
      "Epoch 33/50\n",
      " - 0s - loss: 405.9259 - val_loss: 519.3547\n",
      "Epoch 34/50\n",
      " - 0s - loss: 392.9472 - val_loss: 498.3090\n",
      "Epoch 35/50\n",
      " - 0s - loss: 382.2622 - val_loss: 489.5256\n",
      "Epoch 36/50\n",
      " - 0s - loss: 374.4409 - val_loss: 478.5583\n",
      "Epoch 37/50\n",
      " - 0s - loss: 364.5432 - val_loss: 464.1527\n",
      "Epoch 38/50\n",
      " - 0s - loss: 354.0072 - val_loss: 458.7573\n",
      "Epoch 39/50\n",
      " - 0s - loss: 347.8532 - val_loss: 447.9493\n",
      "Epoch 40/50\n",
      " - 0s - loss: 339.2614 - val_loss: 434.1028\n",
      "Epoch 41/50\n",
      " - 0s - loss: 331.3359 - val_loss: 422.7704\n",
      "Epoch 42/50\n",
      " - 0s - loss: 323.8633 - val_loss: 415.8149\n",
      "Epoch 43/50\n",
      " - 0s - loss: 316.6916 - val_loss: 401.2487\n",
      "Epoch 44/50\n",
      " - 0s - loss: 310.7216 - val_loss: 399.0823\n",
      "Epoch 45/50\n",
      " - 0s - loss: 305.6585 - val_loss: 382.7521\n",
      "Epoch 46/50\n",
      " - 0s - loss: 298.1039 - val_loss: 375.0655\n",
      "Epoch 47/50\n",
      " - 0s - loss: 293.1621 - val_loss: 363.8638\n",
      "Epoch 48/50\n",
      " - 0s - loss: 287.7518 - val_loss: 358.6282\n",
      "Epoch 49/50\n",
      " - 0s - loss: 283.0679 - val_loss: 344.3315\n",
      "Epoch 50/50\n",
      " - 0s - loss: 276.8856 - val_loss: 342.9160\n"
     ]
    }
   ],
   "source": [
    "s=[]\n",
    "i=0\n",
    "while i<50:\n",
    "    i=i+1\n",
    "    def regression_model():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "        model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    model = regression_model()\n",
    "\n",
    "    model.fit(predictors, target, validation_split=0.3, epochs=50, verbose=2)\n",
    "    a=model.predict(predictors, batch_size=1000, verbose=0, steps=None)\n",
    "\n",
    "\n",
    "#calucalte mean squared error\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    k=mean_squared_error(target,a)\n",
    "    s.append(k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1656.4145565921992,\n",
       " 168.81173032841124,\n",
       " 739.6332794446937,\n",
       " 391.2162834347998,\n",
       " 121.32507922618599,\n",
       " 347.3702256830681,\n",
       " 110.62024894934183,\n",
       " 372.4598631144448,\n",
       " 825.9485418666964,\n",
       " 131.04952986803787,\n",
       " 163.66091979144895,\n",
       " 106.82097600580236,\n",
       " 192.29479521369657,\n",
       " 225.16417961773064,\n",
       " 149.25362596320932,\n",
       " 555.6642594017052,\n",
       " 146.38992913480845,\n",
       " 197.56393096566006,\n",
       " 650.22233524495,\n",
       " 148.1985227365529,\n",
       " 238.90444534972883,\n",
       " 128.6817104943441,\n",
       " 101.54293272226016,\n",
       " 218.39310976536527,\n",
       " 91.65626479019353,\n",
       " 550.4259789726902,\n",
       " 167.83279654517,\n",
       " 701.129594776456,\n",
       " 1132.8524738854828,\n",
       " 181.54916244607082,\n",
       " 104.7653907964161,\n",
       " 1036.2667329529957,\n",
       " 90.53505470558176,\n",
       " 139.7811984501729,\n",
       " 243.5942739612907,\n",
       " 140.48125892862382,\n",
       " 369.4178968089393,\n",
       " 1500.374492775812,\n",
       " 142.43231807447125,\n",
       " 300.35072401471115,\n",
       " 507.056066517953,\n",
       " 372.26396253765574,\n",
       " 157.28259092822097,\n",
       " 583.2498799094293,\n",
       " 178.94234594157507,\n",
       " 278.9388489951204,\n",
       " 110.96070877760324,\n",
       " 166.25803765240644,\n",
       " 134.71810277775438,\n",
       " 294.5023743551648]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355.3044708438621"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate mean of meansqured errors\n",
    "import statistics\n",
    "statistics.mean(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352.60417481641196"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate standard deviation of mean squared errors\n",
    "statistics.stdev(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
