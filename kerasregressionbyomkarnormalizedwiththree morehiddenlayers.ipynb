{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data=pd.read_csv(\"concrete_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>47.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>43.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>36.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>39.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>90</td>\n",
       "      <td>38.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>28</td>\n",
       "      <td>28.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>427.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>43.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>190.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>42.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>304.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>47.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>52.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>90</td>\n",
       "      <td>39.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>342.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>365</td>\n",
       "      <td>56.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>90</td>\n",
       "      <td>40.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>180</td>\n",
       "      <td>42.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>427.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>180</td>\n",
       "      <td>41.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>28</td>\n",
       "      <td>28.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>3</td>\n",
       "      <td>8.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>180</td>\n",
       "      <td>44.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>365</td>\n",
       "      <td>52.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>270</td>\n",
       "      <td>53.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>41.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>342.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>180</td>\n",
       "      <td>52.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>427.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>37.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>7</td>\n",
       "      <td>38.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>141.9</td>\n",
       "      <td>166.6</td>\n",
       "      <td>129.7</td>\n",
       "      <td>173.5</td>\n",
       "      <td>10.9</td>\n",
       "      <td>882.6</td>\n",
       "      <td>785.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>297.8</td>\n",
       "      <td>137.2</td>\n",
       "      <td>106.9</td>\n",
       "      <td>201.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>878.4</td>\n",
       "      <td>655.3</td>\n",
       "      <td>28</td>\n",
       "      <td>53.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>321.3</td>\n",
       "      <td>164.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>870.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>28</td>\n",
       "      <td>57.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>366.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>824.3</td>\n",
       "      <td>756.9</td>\n",
       "      <td>28</td>\n",
       "      <td>65.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>279.8</td>\n",
       "      <td>128.9</td>\n",
       "      <td>100.4</td>\n",
       "      <td>172.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>825.1</td>\n",
       "      <td>804.9</td>\n",
       "      <td>28</td>\n",
       "      <td>52.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>252.1</td>\n",
       "      <td>97.1</td>\n",
       "      <td>75.6</td>\n",
       "      <td>193.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>835.5</td>\n",
       "      <td>821.4</td>\n",
       "      <td>28</td>\n",
       "      <td>33.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>164.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.4</td>\n",
       "      <td>181.6</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1023.3</td>\n",
       "      <td>728.9</td>\n",
       "      <td>28</td>\n",
       "      <td>18.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>155.6</td>\n",
       "      <td>243.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.3</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>697.7</td>\n",
       "      <td>28</td>\n",
       "      <td>37.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>160.2</td>\n",
       "      <td>188.0</td>\n",
       "      <td>146.4</td>\n",
       "      <td>203.2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>828.7</td>\n",
       "      <td>709.7</td>\n",
       "      <td>28</td>\n",
       "      <td>35.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>298.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>186.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>879.0</td>\n",
       "      <td>815.2</td>\n",
       "      <td>28</td>\n",
       "      <td>42.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>317.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>209.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>860.5</td>\n",
       "      <td>736.6</td>\n",
       "      <td>28</td>\n",
       "      <td>40.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>287.3</td>\n",
       "      <td>120.5</td>\n",
       "      <td>93.9</td>\n",
       "      <td>187.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>904.4</td>\n",
       "      <td>695.9</td>\n",
       "      <td>28</td>\n",
       "      <td>43.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>325.6</td>\n",
       "      <td>166.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>881.6</td>\n",
       "      <td>790.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>355.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.6</td>\n",
       "      <td>193.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>801.4</td>\n",
       "      <td>778.4</td>\n",
       "      <td>28</td>\n",
       "      <td>40.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>132.0</td>\n",
       "      <td>206.5</td>\n",
       "      <td>160.9</td>\n",
       "      <td>178.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>866.9</td>\n",
       "      <td>735.6</td>\n",
       "      <td>28</td>\n",
       "      <td>33.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>322.5</td>\n",
       "      <td>148.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.8</td>\n",
       "      <td>8.5</td>\n",
       "      <td>951.0</td>\n",
       "      <td>709.5</td>\n",
       "      <td>28</td>\n",
       "      <td>52.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>164.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.1</td>\n",
       "      <td>181.2</td>\n",
       "      <td>12.6</td>\n",
       "      <td>849.3</td>\n",
       "      <td>846.0</td>\n",
       "      <td>28</td>\n",
       "      <td>15.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>313.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.6</td>\n",
       "      <td>169.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>925.3</td>\n",
       "      <td>782.9</td>\n",
       "      <td>28</td>\n",
       "      <td>38.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>321.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.9</td>\n",
       "      <td>182.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>870.1</td>\n",
       "      <td>779.7</td>\n",
       "      <td>28</td>\n",
       "      <td>37.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>139.7</td>\n",
       "      <td>163.9</td>\n",
       "      <td>127.7</td>\n",
       "      <td>236.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>868.6</td>\n",
       "      <td>655.6</td>\n",
       "      <td>28</td>\n",
       "      <td>35.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>288.4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>907.9</td>\n",
       "      <td>829.5</td>\n",
       "      <td>28</td>\n",
       "      <td>42.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>298.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>209.7</td>\n",
       "      <td>11.1</td>\n",
       "      <td>879.6</td>\n",
       "      <td>744.2</td>\n",
       "      <td>28</td>\n",
       "      <td>31.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>264.5</td>\n",
       "      <td>111.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>195.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>832.6</td>\n",
       "      <td>790.4</td>\n",
       "      <td>28</td>\n",
       "      <td>41.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>159.8</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1049.3</td>\n",
       "      <td>688.2</td>\n",
       "      <td>28</td>\n",
       "      <td>39.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>166.0</td>\n",
       "      <td>259.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>858.8</td>\n",
       "      <td>826.8</td>\n",
       "      <td>28</td>\n",
       "      <td>37.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0      540.0                 0.0      0.0  162.0               2.5   \n",
       "1      540.0                 0.0      0.0  162.0               2.5   \n",
       "2      332.5               142.5      0.0  228.0               0.0   \n",
       "3      332.5               142.5      0.0  228.0               0.0   \n",
       "4      198.6               132.4      0.0  192.0               0.0   \n",
       "5      266.0               114.0      0.0  228.0               0.0   \n",
       "6      380.0                95.0      0.0  228.0               0.0   \n",
       "7      380.0                95.0      0.0  228.0               0.0   \n",
       "8      266.0               114.0      0.0  228.0               0.0   \n",
       "9      475.0                 0.0      0.0  228.0               0.0   \n",
       "10     198.6               132.4      0.0  192.0               0.0   \n",
       "11     198.6               132.4      0.0  192.0               0.0   \n",
       "12     427.5                47.5      0.0  228.0               0.0   \n",
       "13     190.0               190.0      0.0  228.0               0.0   \n",
       "14     304.0                76.0      0.0  228.0               0.0   \n",
       "15     380.0                 0.0      0.0  228.0               0.0   \n",
       "16     139.6               209.4      0.0  192.0               0.0   \n",
       "17     342.0                38.0      0.0  228.0               0.0   \n",
       "18     380.0                95.0      0.0  228.0               0.0   \n",
       "19     475.0                 0.0      0.0  228.0               0.0   \n",
       "20     427.5                47.5      0.0  228.0               0.0   \n",
       "21     139.6               209.4      0.0  192.0               0.0   \n",
       "22     139.6               209.4      0.0  192.0               0.0   \n",
       "23     139.6               209.4      0.0  192.0               0.0   \n",
       "24     380.0                 0.0      0.0  228.0               0.0   \n",
       "25     380.0                 0.0      0.0  228.0               0.0   \n",
       "26     380.0                95.0      0.0  228.0               0.0   \n",
       "27     342.0                38.0      0.0  228.0               0.0   \n",
       "28     427.5                47.5      0.0  228.0               0.0   \n",
       "29     475.0                 0.0      0.0  228.0               0.0   \n",
       "...      ...                 ...      ...    ...               ...   \n",
       "1000   141.9               166.6    129.7  173.5              10.9   \n",
       "1001   297.8               137.2    106.9  201.3               6.0   \n",
       "1002   321.3               164.2      0.0  190.5               4.6   \n",
       "1003   366.0               187.0      0.0  191.3               6.6   \n",
       "1004   279.8               128.9    100.4  172.4               9.5   \n",
       "1005   252.1                97.1     75.6  193.8               8.3   \n",
       "1006   164.6                 0.0    150.4  181.6              11.7   \n",
       "1007   155.6               243.5      0.0  180.3              10.7   \n",
       "1008   160.2               188.0    146.4  203.2              11.3   \n",
       "1009   298.1                 0.0    107.0  186.4               6.1   \n",
       "1010   317.9                 0.0    126.5  209.7               5.7   \n",
       "1011   287.3               120.5     93.9  187.6               9.2   \n",
       "1012   325.6               166.4      0.0  174.0               8.9   \n",
       "1013   355.9                 0.0    141.6  193.3              11.0   \n",
       "1014   132.0               206.5    160.9  178.9               5.5   \n",
       "1015   322.5               148.6      0.0  185.8               8.5   \n",
       "1016   164.2                 0.0    200.1  181.2              12.6   \n",
       "1017   313.8                 0.0    112.6  169.9              10.1   \n",
       "1018   321.4                 0.0    127.9  182.5              11.5   \n",
       "1019   139.7               163.9    127.7  236.7               5.8   \n",
       "1020   288.4               121.0      0.0  177.4               7.0   \n",
       "1021   298.2                 0.0    107.0  209.7              11.1   \n",
       "1022   264.5               111.0     86.5  195.5               5.9   \n",
       "1023   159.8               250.0      0.0  168.4              12.2   \n",
       "1024   166.0               259.7      0.0  183.2              12.7   \n",
       "1025   276.4               116.0     90.3  179.6               8.9   \n",
       "1026   322.2                 0.0    115.6  196.0              10.4   \n",
       "1027   148.5               139.4    108.6  192.7               6.1   \n",
       "1028   159.1               186.7      0.0  175.6              11.3   \n",
       "1029   260.9               100.5     78.3  200.6               8.6   \n",
       "\n",
       "      Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0               1040.0           676.0   28     79.99  \n",
       "1               1055.0           676.0   28     61.89  \n",
       "2                932.0           594.0  270     40.27  \n",
       "3                932.0           594.0  365     41.05  \n",
       "4                978.4           825.5  360     44.30  \n",
       "5                932.0           670.0   90     47.03  \n",
       "6                932.0           594.0  365     43.70  \n",
       "7                932.0           594.0   28     36.45  \n",
       "8                932.0           670.0   28     45.85  \n",
       "9                932.0           594.0   28     39.29  \n",
       "10               978.4           825.5   90     38.07  \n",
       "11               978.4           825.5   28     28.02  \n",
       "12               932.0           594.0  270     43.01  \n",
       "13               932.0           670.0   90     42.33  \n",
       "14               932.0           670.0   28     47.81  \n",
       "15               932.0           670.0   90     52.91  \n",
       "16              1047.0           806.9   90     39.36  \n",
       "17               932.0           670.0  365     56.14  \n",
       "18               932.0           594.0   90     40.56  \n",
       "19               932.0           594.0  180     42.62  \n",
       "20               932.0           594.0  180     41.84  \n",
       "21              1047.0           806.9   28     28.24  \n",
       "22              1047.0           806.9    3      8.06  \n",
       "23              1047.0           806.9  180     44.21  \n",
       "24               932.0           670.0  365     52.52  \n",
       "25               932.0           670.0  270     53.30  \n",
       "26               932.0           594.0  270     41.15  \n",
       "27               932.0           670.0  180     52.12  \n",
       "28               932.0           594.0   28     37.43  \n",
       "29               932.0           594.0    7     38.60  \n",
       "...                ...             ...  ...       ...  \n",
       "1000             882.6           785.3   28     44.61  \n",
       "1001             878.4           655.3   28     53.52  \n",
       "1002             870.0           774.0   28     57.22  \n",
       "1003             824.3           756.9   28     65.91  \n",
       "1004             825.1           804.9   28     52.83  \n",
       "1005             835.5           821.4   28     33.40  \n",
       "1006            1023.3           728.9   28     18.03  \n",
       "1007            1022.0           697.7   28     37.36  \n",
       "1008             828.7           709.7   28     35.31  \n",
       "1009             879.0           815.2   28     42.64  \n",
       "1010             860.5           736.6   28     40.06  \n",
       "1011             904.4           695.9   28     43.80  \n",
       "1012             881.6           790.0   28     61.24  \n",
       "1013             801.4           778.4   28     40.87  \n",
       "1014             866.9           735.6   28     33.31  \n",
       "1015             951.0           709.5   28     52.43  \n",
       "1016             849.3           846.0   28     15.09  \n",
       "1017             925.3           782.9   28     38.46  \n",
       "1018             870.1           779.7   28     37.27  \n",
       "1019             868.6           655.6   28     35.23  \n",
       "1020             907.9           829.5   28     42.14  \n",
       "1021             879.6           744.2   28     31.88  \n",
       "1022             832.6           790.4   28     41.54  \n",
       "1023            1049.3           688.2   28     39.46  \n",
       "1024             858.8           826.8   28     37.92  \n",
       "1025             870.1           768.3   28     44.28  \n",
       "1026             817.9           813.4   28     31.18  \n",
       "1027             892.4           780.0   28     23.70  \n",
       "1028             989.6           788.9   28     32.77  \n",
       "1029             864.5           761.5   28     32.40  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns\n",
    "\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "predictors_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = predictors_norm.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0410 14:45:38.804567 17396 deprecation_wrapper.py:119] From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0410 14:45:39.365536 17396 deprecation_wrapper.py:119] From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0410 14:45:39.370523 17396 deprecation_wrapper.py:119] From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0410 14:45:39.477239 17396 deprecation_wrapper.py:119] From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0410 14:45:39.652769 17396 deprecation_wrapper.py:119] From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0410 14:45:39.861211 17396 deprecation_wrapper.py:119] From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 47576.2268 - val_loss: 24524.2531\n",
      "Epoch 2/50\n",
      " - 0s - loss: 14916.6945 - val_loss: 8266.1246\n",
      "Epoch 3/50\n",
      " - 0s - loss: 5091.7770 - val_loss: 3174.8009\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1967.4758 - val_loss: 1368.7252\n",
      "Epoch 5/50\n",
      " - 0s - loss: 896.8616 - val_loss: 697.5293\n",
      "Epoch 6/50\n",
      " - 0s - loss: 519.4399 - val_loss: 415.8697\n",
      "Epoch 7/50\n",
      " - 0s - loss: 383.7353 - val_loss: 300.8809\n",
      "Epoch 8/50\n",
      " - 0s - loss: 338.5458 - val_loss: 255.6004\n",
      "Epoch 9/50\n",
      " - 0s - loss: 325.1487 - val_loss: 238.3145\n",
      "Epoch 10/50\n",
      " - 0s - loss: 320.6220 - val_loss: 227.8227\n",
      "Epoch 11/50\n",
      " - 0s - loss: 317.9399 - val_loss: 221.4424\n",
      "Epoch 12/50\n",
      " - 0s - loss: 315.3611 - val_loss: 216.9241\n",
      "Epoch 13/50\n",
      " - 0s - loss: 312.7408 - val_loss: 212.1786\n",
      "Epoch 14/50\n",
      " - 0s - loss: 309.7943 - val_loss: 207.3380\n",
      "Epoch 15/50\n",
      " - 0s - loss: 307.4182 - val_loss: 202.3633\n",
      "Epoch 16/50\n",
      " - 0s - loss: 304.5876 - val_loss: 202.1403\n",
      "Epoch 17/50\n",
      " - 0s - loss: 301.5821 - val_loss: 196.2715\n",
      "Epoch 18/50\n",
      " - 0s - loss: 299.0497 - val_loss: 189.9433\n",
      "Epoch 19/50\n",
      " - 0s - loss: 296.8656 - val_loss: 186.1739\n",
      "Epoch 20/50\n",
      " - 0s - loss: 294.8766 - val_loss: 183.4130\n",
      "Epoch 21/50\n",
      " - 0s - loss: 293.2809 - val_loss: 180.0979\n",
      "Epoch 22/50\n",
      " - 0s - loss: 292.4320 - val_loss: 178.0849\n",
      "Epoch 23/50\n",
      " - 0s - loss: 291.4230 - val_loss: 177.0920\n",
      "Epoch 24/50\n",
      " - 0s - loss: 290.3375 - val_loss: 173.4426\n",
      "Epoch 25/50\n",
      " - 0s - loss: 288.9531 - val_loss: 174.1760\n",
      "Epoch 26/50\n",
      " - 0s - loss: 287.8494 - val_loss: 171.5516\n",
      "Epoch 27/50\n",
      " - 0s - loss: 286.7955 - val_loss: 170.5535\n",
      "Epoch 28/50\n",
      " - 0s - loss: 285.6555 - val_loss: 168.1380\n",
      "Epoch 29/50\n",
      " - 0s - loss: 284.8694 - val_loss: 166.9832\n",
      "Epoch 30/50\n",
      " - 0s - loss: 283.6284 - val_loss: 166.7042\n",
      "Epoch 31/50\n",
      " - 0s - loss: 282.8421 - val_loss: 167.6045\n",
      "Epoch 32/50\n",
      " - 0s - loss: 281.8231 - val_loss: 162.9766\n",
      "Epoch 33/50\n",
      " - 0s - loss: 280.5555 - val_loss: 162.1314\n",
      "Epoch 34/50\n",
      " - 0s - loss: 280.0340 - val_loss: 162.7658\n",
      "Epoch 35/50\n",
      " - 0s - loss: 279.0645 - val_loss: 161.1708\n",
      "Epoch 36/50\n",
      " - 0s - loss: 277.5656 - val_loss: 162.1513\n",
      "Epoch 37/50\n",
      " - 0s - loss: 277.0112 - val_loss: 157.6742\n",
      "Epoch 38/50\n",
      " - 0s - loss: 275.4852 - val_loss: 159.6651\n",
      "Epoch 39/50\n",
      " - 0s - loss: 274.9021 - val_loss: 158.1182\n",
      "Epoch 40/50\n",
      " - 0s - loss: 273.7238 - val_loss: 158.2624\n",
      "Epoch 41/50\n",
      " - 0s - loss: 272.9418 - val_loss: 154.8896\n",
      "Epoch 42/50\n",
      " - 0s - loss: 274.0232 - val_loss: 158.5362\n",
      "Epoch 43/50\n",
      " - 0s - loss: 271.7448 - val_loss: 151.6190\n",
      "Epoch 44/50\n",
      " - 0s - loss: 270.1303 - val_loss: 155.1898\n",
      "Epoch 45/50\n",
      " - 0s - loss: 269.0397 - val_loss: 152.6786\n",
      "Epoch 46/50\n",
      " - 0s - loss: 268.1502 - val_loss: 152.6130\n",
      "Epoch 47/50\n",
      " - 0s - loss: 267.0343 - val_loss: 150.9731\n",
      "Epoch 48/50\n",
      " - 0s - loss: 266.2667 - val_loss: 152.5599\n",
      "Epoch 49/50\n",
      " - 0s - loss: 265.2590 - val_loss: 151.5647\n",
      "Epoch 50/50\n",
      " - 0s - loss: 265.2140 - val_loss: 152.2684\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 25811.8472 - val_loss: 13628.2653\n",
      "Epoch 2/50\n",
      " - 0s - loss: 10630.5917 - val_loss: 5885.8538\n",
      "Epoch 3/50\n",
      " - 0s - loss: 4770.5810 - val_loss: 2160.6906\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1561.2625 - val_loss: 224.0531\n",
      "Epoch 5/50\n",
      " - 0s - loss: 287.3496 - val_loss: 258.3467\n",
      "Epoch 6/50\n",
      " - 0s - loss: 259.3955 - val_loss: 196.7033\n",
      "Epoch 7/50\n",
      " - 0s - loss: 243.2543 - val_loss: 186.8515\n",
      "Epoch 8/50\n",
      " - 0s - loss: 234.8652 - val_loss: 180.0614\n",
      "Epoch 9/50\n",
      " - 0s - loss: 226.2355 - val_loss: 171.5492\n",
      "Epoch 10/50\n",
      " - 0s - loss: 215.1265 - val_loss: 157.8713\n",
      "Epoch 11/50\n",
      " - 0s - loss: 201.2765 - val_loss: 141.9894\n",
      "Epoch 12/50\n",
      " - 0s - loss: 180.1703 - val_loss: 119.9679\n",
      "Epoch 13/50\n",
      " - 0s - loss: 165.0740 - val_loss: 106.1122\n",
      "Epoch 14/50\n",
      " - 0s - loss: 161.2791 - val_loss: 105.6843\n",
      "Epoch 15/50\n",
      " - 0s - loss: 159.9245 - val_loss: 100.4561\n",
      "Epoch 16/50\n",
      " - 0s - loss: 159.3152 - val_loss: 102.2655\n",
      "Epoch 17/50\n",
      " - 0s - loss: 157.0978 - val_loss: 101.9379\n",
      "Epoch 18/50\n",
      " - 0s - loss: 156.9698 - val_loss: 100.4461\n",
      "Epoch 19/50\n",
      " - 0s - loss: 156.3751 - val_loss: 104.0323\n",
      "Epoch 20/50\n",
      " - 0s - loss: 154.3822 - val_loss: 100.5281\n",
      "Epoch 21/50\n",
      " - 0s - loss: 152.9811 - val_loss: 103.0819\n",
      "Epoch 22/50\n",
      " - 0s - loss: 152.2627 - val_loss: 99.5711\n",
      "Epoch 23/50\n",
      " - 0s - loss: 151.3058 - val_loss: 97.9967\n",
      "Epoch 24/50\n",
      " - 0s - loss: 150.5474 - val_loss: 100.2394\n",
      "Epoch 25/50\n",
      " - 0s - loss: 149.5385 - val_loss: 100.4967\n",
      "Epoch 26/50\n",
      " - 0s - loss: 149.8566 - val_loss: 105.3294\n",
      "Epoch 27/50\n",
      " - 0s - loss: 149.9961 - val_loss: 106.7919\n",
      "Epoch 28/50\n",
      " - 0s - loss: 147.2623 - val_loss: 95.1945\n",
      "Epoch 29/50\n",
      " - 0s - loss: 145.8649 - val_loss: 96.2254\n",
      "Epoch 30/50\n",
      " - 0s - loss: 145.9033 - val_loss: 96.6120\n",
      "Epoch 31/50\n",
      " - 0s - loss: 144.3527 - val_loss: 96.3197\n",
      "Epoch 32/50\n",
      " - 0s - loss: 146.0927 - val_loss: 112.0710\n",
      "Epoch 33/50\n",
      " - 0s - loss: 144.4903 - val_loss: 93.9231\n",
      "Epoch 34/50\n",
      " - 0s - loss: 143.4052 - val_loss: 97.0884\n",
      "Epoch 35/50\n",
      " - 0s - loss: 141.6186 - val_loss: 88.3687\n",
      "Epoch 36/50\n",
      " - 0s - loss: 139.6467 - val_loss: 103.5242\n",
      "Epoch 37/50\n",
      " - 0s - loss: 141.3464 - val_loss: 100.5777\n",
      "Epoch 38/50\n",
      " - 0s - loss: 139.2700 - val_loss: 88.7544\n",
      "Epoch 39/50\n",
      " - 0s - loss: 139.3834 - val_loss: 94.6718\n",
      "Epoch 40/50\n",
      " - 0s - loss: 135.9104 - val_loss: 89.7887\n",
      "Epoch 41/50\n",
      " - 0s - loss: 134.9636 - val_loss: 98.5007\n",
      "Epoch 42/50\n",
      " - 0s - loss: 134.4038 - val_loss: 89.9684\n",
      "Epoch 43/50\n",
      " - 0s - loss: 132.3407 - val_loss: 105.2103\n",
      "Epoch 44/50\n",
      " - 0s - loss: 132.6187 - val_loss: 88.4746\n",
      "Epoch 45/50\n",
      " - 0s - loss: 131.0986 - val_loss: 89.2731\n",
      "Epoch 46/50\n",
      " - 0s - loss: 132.2887 - val_loss: 91.6026\n",
      "Epoch 47/50\n",
      " - 0s - loss: 128.4698 - val_loss: 100.5854\n",
      "Epoch 48/50\n",
      " - 0s - loss: 127.0164 - val_loss: 102.6940\n",
      "Epoch 49/50\n",
      " - 0s - loss: 128.3845 - val_loss: 91.2726\n",
      "Epoch 50/50\n",
      " - 0s - loss: 125.0875 - val_loss: 85.0226\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 11877.8877 - val_loss: 2603.8878\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1277.0395 - val_loss: 225.9070\n",
      "Epoch 3/50\n",
      " - 0s - loss: 370.7962 - val_loss: 304.9324\n",
      "Epoch 4/50\n",
      " - 0s - loss: 335.3964 - val_loss: 203.0338\n",
      "Epoch 5/50\n",
      " - 0s - loss: 302.9311 - val_loss: 189.8501\n",
      "Epoch 6/50\n",
      " - 0s - loss: 290.0839 - val_loss: 178.5790\n",
      "Epoch 7/50\n",
      " - 0s - loss: 276.2047 - val_loss: 174.5946\n",
      "Epoch 8/50\n",
      " - 0s - loss: 271.4936 - val_loss: 172.6309\n",
      "Epoch 9/50\n",
      " - 0s - loss: 269.3648 - val_loss: 176.2459\n",
      "Epoch 10/50\n",
      " - 0s - loss: 269.1516 - val_loss: 184.5448\n",
      "Epoch 11/50\n",
      " - 0s - loss: 269.1054 - val_loss: 163.3545\n",
      "Epoch 12/50\n",
      " - 0s - loss: 271.6911 - val_loss: 154.9421\n",
      "Epoch 13/50\n",
      " - 0s - loss: 267.6889 - val_loss: 177.5041\n",
      "Epoch 14/50\n",
      " - 0s - loss: 264.8231 - val_loss: 169.2033\n",
      "Epoch 15/50\n",
      " - 0s - loss: 264.5416 - val_loss: 175.2375\n",
      "Epoch 16/50\n",
      " - 0s - loss: 263.4703 - val_loss: 156.5555\n",
      "Epoch 17/50\n",
      " - 0s - loss: 263.6693 - val_loss: 171.4480\n",
      "Epoch 18/50\n",
      " - 0s - loss: 262.8741 - val_loss: 183.4188\n",
      "Epoch 19/50\n",
      " - 0s - loss: 265.3594 - val_loss: 192.1754\n",
      "Epoch 20/50\n",
      " - 0s - loss: 262.7881 - val_loss: 160.5448\n",
      "Epoch 21/50\n",
      " - 0s - loss: 259.5958 - val_loss: 158.2985\n",
      "Epoch 22/50\n",
      " - 0s - loss: 263.4115 - val_loss: 168.6460\n",
      "Epoch 23/50\n",
      " - 0s - loss: 258.3565 - val_loss: 159.7831\n",
      "Epoch 24/50\n",
      " - 0s - loss: 256.8362 - val_loss: 163.4945\n",
      "Epoch 25/50\n",
      " - 0s - loss: 255.7605 - val_loss: 157.4619\n",
      "Epoch 26/50\n",
      " - 0s - loss: 259.0653 - val_loss: 152.5217\n",
      "Epoch 27/50\n",
      " - 0s - loss: 253.4740 - val_loss: 155.7425\n",
      "Epoch 28/50\n",
      " - 0s - loss: 252.6271 - val_loss: 158.9962\n",
      "Epoch 29/50\n",
      " - 0s - loss: 253.4889 - val_loss: 174.3910\n",
      "Epoch 30/50\n",
      " - 0s - loss: 245.6660 - val_loss: 176.5438\n",
      "Epoch 31/50\n",
      " - 0s - loss: 246.4455 - val_loss: 187.1254\n",
      "Epoch 32/50\n",
      " - 0s - loss: 241.9540 - val_loss: 179.2795\n",
      "Epoch 33/50\n",
      " - 0s - loss: 236.5361 - val_loss: 171.0258\n",
      "Epoch 34/50\n",
      " - 0s - loss: 233.4389 - val_loss: 154.5559\n",
      "Epoch 35/50\n",
      " - 0s - loss: 228.5466 - val_loss: 147.1432\n",
      "Epoch 36/50\n",
      " - 0s - loss: 225.4520 - val_loss: 145.3558\n",
      "Epoch 37/50\n",
      " - 0s - loss: 221.7217 - val_loss: 152.3245\n",
      "Epoch 38/50\n",
      " - 0s - loss: 219.3905 - val_loss: 142.1728\n",
      "Epoch 39/50\n",
      " - 0s - loss: 217.3518 - val_loss: 135.0293\n",
      "Epoch 40/50\n",
      " - 0s - loss: 212.9346 - val_loss: 152.1958\n",
      "Epoch 41/50\n",
      " - 0s - loss: 214.2962 - val_loss: 142.2122\n",
      "Epoch 42/50\n",
      " - 0s - loss: 209.1235 - val_loss: 151.7706\n",
      "Epoch 43/50\n",
      " - 0s - loss: 204.6037 - val_loss: 133.5058\n",
      "Epoch 44/50\n",
      " - 0s - loss: 200.6885 - val_loss: 142.9990\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 199.8286 - val_loss: 143.4146\n",
      "Epoch 46/50\n",
      " - 0s - loss: 194.1015 - val_loss: 149.0157\n",
      "Epoch 47/50\n",
      " - 0s - loss: 189.6423 - val_loss: 128.0629\n",
      "Epoch 48/50\n",
      " - 0s - loss: 186.6646 - val_loss: 134.7869\n",
      "Epoch 49/50\n",
      " - 0s - loss: 180.6091 - val_loss: 126.1204\n",
      "Epoch 50/50\n",
      " - 0s - loss: 177.8048 - val_loss: 118.2512\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 1971.3652 - val_loss: 389.0461\n",
      "Epoch 2/50\n",
      " - 0s - loss: 388.5058 - val_loss: 203.8721\n",
      "Epoch 3/50\n",
      " - 0s - loss: 346.7648 - val_loss: 212.5911\n",
      "Epoch 4/50\n",
      " - 0s - loss: 314.7844 - val_loss: 206.5092\n",
      "Epoch 5/50\n",
      " - 0s - loss: 292.5638 - val_loss: 216.8962\n",
      "Epoch 6/50\n",
      " - 0s - loss: 274.8598 - val_loss: 215.0092\n",
      "Epoch 7/50\n",
      " - 0s - loss: 259.9616 - val_loss: 227.9138\n",
      "Epoch 8/50\n",
      " - 0s - loss: 246.6682 - val_loss: 206.2742\n",
      "Epoch 9/50\n",
      " - 0s - loss: 236.0232 - val_loss: 222.5975\n",
      "Epoch 10/50\n",
      " - 0s - loss: 224.6796 - val_loss: 232.8574\n",
      "Epoch 11/50\n",
      " - 0s - loss: 215.5839 - val_loss: 250.7592\n",
      "Epoch 12/50\n",
      " - 0s - loss: 204.4915 - val_loss: 213.1670\n",
      "Epoch 13/50\n",
      " - 0s - loss: 195.2144 - val_loss: 197.1520\n",
      "Epoch 14/50\n",
      " - 0s - loss: 185.3950 - val_loss: 206.1548\n",
      "Epoch 15/50\n",
      " - 0s - loss: 177.3205 - val_loss: 204.3672\n",
      "Epoch 16/50\n",
      " - 0s - loss: 169.8163 - val_loss: 177.1645\n",
      "Epoch 17/50\n",
      " - 0s - loss: 159.1647 - val_loss: 161.6637\n",
      "Epoch 18/50\n",
      " - 0s - loss: 151.2410 - val_loss: 136.4364\n",
      "Epoch 19/50\n",
      " - 0s - loss: 143.7998 - val_loss: 143.5466\n",
      "Epoch 20/50\n",
      " - 0s - loss: 135.2099 - val_loss: 148.9322\n",
      "Epoch 21/50\n",
      " - 0s - loss: 129.9540 - val_loss: 127.0443\n",
      "Epoch 22/50\n",
      " - 0s - loss: 121.7304 - val_loss: 117.3404\n",
      "Epoch 23/50\n",
      " - 0s - loss: 119.9106 - val_loss: 96.7861\n",
      "Epoch 24/50\n",
      " - 0s - loss: 112.8826 - val_loss: 101.2982\n",
      "Epoch 25/50\n",
      " - 0s - loss: 104.1475 - val_loss: 99.7616\n",
      "Epoch 26/50\n",
      " - 0s - loss: 98.8644 - val_loss: 110.7446\n",
      "Epoch 27/50\n",
      " - 0s - loss: 96.6223 - val_loss: 81.9528\n",
      "Epoch 28/50\n",
      " - 0s - loss: 92.8483 - val_loss: 88.2745\n",
      "Epoch 29/50\n",
      " - 0s - loss: 89.3971 - val_loss: 100.4457\n",
      "Epoch 30/50\n",
      " - 0s - loss: 89.5404 - val_loss: 82.8012\n",
      "Epoch 31/50\n",
      " - 0s - loss: 90.2836 - val_loss: 99.4625\n",
      "Epoch 32/50\n",
      " - 0s - loss: 87.4763 - val_loss: 83.8503\n",
      "Epoch 33/50\n",
      " - 0s - loss: 86.4064 - val_loss: 78.1532\n",
      "Epoch 34/50\n",
      " - 0s - loss: 84.9118 - val_loss: 88.4572\n",
      "Epoch 35/50\n",
      " - 0s - loss: 85.9894 - val_loss: 75.1883\n",
      "Epoch 36/50\n",
      " - 0s - loss: 85.2317 - val_loss: 81.8547\n",
      "Epoch 37/50\n",
      " - 0s - loss: 82.4810 - val_loss: 83.0514\n",
      "Epoch 38/50\n",
      " - 0s - loss: 81.6925 - val_loss: 74.2362\n",
      "Epoch 39/50\n",
      " - 0s - loss: 80.8481 - val_loss: 73.6899\n",
      "Epoch 40/50\n",
      " - 0s - loss: 81.3380 - val_loss: 73.3561\n",
      "Epoch 41/50\n",
      " - 0s - loss: 82.4046 - val_loss: 74.0634\n",
      "Epoch 42/50\n",
      " - 0s - loss: 81.5124 - val_loss: 73.0326\n",
      "Epoch 43/50\n",
      " - 0s - loss: 79.3425 - val_loss: 73.9292\n",
      "Epoch 44/50\n",
      " - 0s - loss: 79.0769 - val_loss: 73.5396\n",
      "Epoch 45/50\n",
      " - 0s - loss: 81.0647 - val_loss: 71.4367\n",
      "Epoch 46/50\n",
      " - 0s - loss: 79.5991 - val_loss: 75.9101\n",
      "Epoch 47/50\n",
      " - 0s - loss: 82.8245 - val_loss: 74.8267\n",
      "Epoch 48/50\n",
      " - 0s - loss: 82.5655 - val_loss: 77.6997\n",
      "Epoch 49/50\n",
      " - 0s - loss: 78.5918 - val_loss: 71.6216\n",
      "Epoch 50/50\n",
      " - 0s - loss: 78.9539 - val_loss: 70.3368\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 3436.5508 - val_loss: 1880.6637\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1795.5288 - val_loss: 692.4578\n",
      "Epoch 3/50\n",
      " - 0s - loss: 912.3983 - val_loss: 360.5666\n",
      "Epoch 4/50\n",
      " - 0s - loss: 607.5813 - val_loss: 288.7582\n",
      "Epoch 5/50\n",
      " - 0s - loss: 444.2498 - val_loss: 246.2354\n",
      "Epoch 6/50\n",
      " - 0s - loss: 383.6095 - val_loss: 305.5804\n",
      "Epoch 7/50\n",
      " - 0s - loss: 334.6325 - val_loss: 207.6593\n",
      "Epoch 8/50\n",
      " - 0s - loss: 305.2264 - val_loss: 247.7260\n",
      "Epoch 9/50\n",
      " - 0s - loss: 273.5261 - val_loss: 234.2136\n",
      "Epoch 10/50\n",
      " - 0s - loss: 258.3361 - val_loss: 163.4796\n",
      "Epoch 11/50\n",
      " - 0s - loss: 246.2092 - val_loss: 230.7485\n",
      "Epoch 12/50\n",
      " - 0s - loss: 228.0008 - val_loss: 165.0804\n",
      "Epoch 13/50\n",
      " - 0s - loss: 217.5429 - val_loss: 182.3720\n",
      "Epoch 14/50\n",
      " - 0s - loss: 221.3160 - val_loss: 138.1266\n",
      "Epoch 15/50\n",
      " - 0s - loss: 195.3647 - val_loss: 172.6209\n",
      "Epoch 16/50\n",
      " - 0s - loss: 194.0372 - val_loss: 146.5394\n",
      "Epoch 17/50\n",
      " - 0s - loss: 187.3727 - val_loss: 173.5486\n",
      "Epoch 18/50\n",
      " - 0s - loss: 180.8948 - val_loss: 125.8206\n",
      "Epoch 19/50\n",
      " - 0s - loss: 186.4515 - val_loss: 168.9951\n",
      "Epoch 20/50\n",
      " - 0s - loss: 177.7852 - val_loss: 166.0914\n",
      "Epoch 21/50\n",
      " - 0s - loss: 172.4361 - val_loss: 143.8308\n",
      "Epoch 22/50\n",
      " - 0s - loss: 166.3987 - val_loss: 124.7335\n",
      "Epoch 23/50\n",
      " - 0s - loss: 165.3279 - val_loss: 196.3201\n",
      "Epoch 24/50\n",
      " - 0s - loss: 172.2993 - val_loss: 121.0597\n",
      "Epoch 25/50\n",
      " - 0s - loss: 161.3325 - val_loss: 167.8945\n",
      "Epoch 26/50\n",
      " - 0s - loss: 158.8210 - val_loss: 132.8657\n",
      "Epoch 27/50\n",
      " - 0s - loss: 152.3439 - val_loss: 148.7213\n",
      "Epoch 28/50\n",
      " - 0s - loss: 152.6925 - val_loss: 131.8297\n",
      "Epoch 29/50\n",
      " - 0s - loss: 163.4078 - val_loss: 112.4795\n",
      "Epoch 30/50\n",
      " - 0s - loss: 155.6387 - val_loss: 129.5047\n",
      "Epoch 31/50\n",
      " - 0s - loss: 143.8718 - val_loss: 124.5044\n",
      "Epoch 32/50\n",
      " - 0s - loss: 144.0842 - val_loss: 139.6166\n",
      "Epoch 33/50\n",
      " - 0s - loss: 139.4886 - val_loss: 109.5809\n",
      "Epoch 34/50\n",
      " - 0s - loss: 138.6591 - val_loss: 128.5151\n",
      "Epoch 35/50\n",
      " - 0s - loss: 143.4925 - val_loss: 187.4351\n",
      "Epoch 36/50\n",
      " - 0s - loss: 135.3641 - val_loss: 116.7294\n",
      "Epoch 37/50\n",
      " - 0s - loss: 131.8005 - val_loss: 124.1580\n",
      "Epoch 38/50\n",
      " - 0s - loss: 128.5981 - val_loss: 109.4894\n",
      "Epoch 39/50\n",
      " - 0s - loss: 128.4269 - val_loss: 110.8766\n",
      "Epoch 40/50\n",
      " - 0s - loss: 131.0943 - val_loss: 132.0711\n",
      "Epoch 41/50\n",
      " - 0s - loss: 130.5790 - val_loss: 95.8080\n",
      "Epoch 42/50\n",
      " - 0s - loss: 127.2112 - val_loss: 98.6592\n",
      "Epoch 43/50\n",
      " - 0s - loss: 121.0223 - val_loss: 107.9656\n",
      "Epoch 44/50\n",
      " - 0s - loss: 117.9402 - val_loss: 98.0063\n",
      "Epoch 45/50\n",
      " - 0s - loss: 115.3628 - val_loss: 147.9691\n",
      "Epoch 46/50\n",
      " - 0s - loss: 121.4397 - val_loss: 111.2392\n",
      "Epoch 47/50\n",
      " - 0s - loss: 110.9267 - val_loss: 113.5363\n",
      "Epoch 48/50\n",
      " - 0s - loss: 110.1195 - val_loss: 90.0791\n",
      "Epoch 49/50\n",
      " - 0s - loss: 107.7036 - val_loss: 105.5712\n",
      "Epoch 50/50\n",
      " - 0s - loss: 109.4928 - val_loss: 88.3897\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 4878.5930 - val_loss: 1901.0969\n",
      "Epoch 2/50\n",
      " - 0s - loss: 2073.0761 - val_loss: 1329.2254\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1755.8426 - val_loss: 1242.4373\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1630.8211 - val_loss: 1087.2305\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1304.0650 - val_loss: 603.4454\n",
      "Epoch 6/50\n",
      " - 0s - loss: 599.1326 - val_loss: 207.1834\n",
      "Epoch 7/50\n",
      " - 0s - loss: 373.3370 - val_loss: 229.3052\n",
      "Epoch 8/50\n",
      " - 0s - loss: 360.0525 - val_loss: 199.6323\n",
      "Epoch 9/50\n",
      " - 0s - loss: 351.5280 - val_loss: 204.2251\n",
      "Epoch 10/50\n",
      " - 0s - loss: 343.7580 - val_loss: 198.4507\n",
      "Epoch 11/50\n",
      " - 0s - loss: 337.3406 - val_loss: 200.5423\n",
      "Epoch 12/50\n",
      " - 0s - loss: 331.7218 - val_loss: 195.2372\n",
      "Epoch 13/50\n",
      " - 0s - loss: 324.7280 - val_loss: 197.5185\n",
      "Epoch 14/50\n",
      " - 0s - loss: 318.5100 - val_loss: 194.5373\n",
      "Epoch 15/50\n",
      " - 0s - loss: 313.0284 - val_loss: 197.8714\n",
      "Epoch 16/50\n",
      " - 0s - loss: 306.1500 - val_loss: 193.9530\n",
      "Epoch 17/50\n",
      " - 0s - loss: 302.5168 - val_loss: 192.7705\n",
      "Epoch 18/50\n",
      " - 0s - loss: 295.7657 - val_loss: 195.2758\n",
      "Epoch 19/50\n",
      " - 0s - loss: 288.8151 - val_loss: 200.2636\n",
      "Epoch 20/50\n",
      " - 0s - loss: 279.5312 - val_loss: 195.5845\n",
      "Epoch 21/50\n",
      " - 0s - loss: 271.8700 - val_loss: 198.2097\n",
      "Epoch 22/50\n",
      " - 0s - loss: 264.0517 - val_loss: 202.3125\n",
      "Epoch 23/50\n",
      " - 0s - loss: 254.3472 - val_loss: 205.4710\n",
      "Epoch 24/50\n",
      " - 0s - loss: 243.9356 - val_loss: 203.0292\n",
      "Epoch 25/50\n",
      " - 0s - loss: 234.0880 - val_loss: 201.4369\n",
      "Epoch 26/50\n",
      " - 0s - loss: 223.3053 - val_loss: 207.3458\n",
      "Epoch 27/50\n",
      " - 0s - loss: 213.0594 - val_loss: 205.3049\n",
      "Epoch 28/50\n",
      " - 0s - loss: 203.8575 - val_loss: 213.5720\n",
      "Epoch 29/50\n",
      " - 0s - loss: 189.5794 - val_loss: 209.2199\n",
      "Epoch 30/50\n",
      " - 0s - loss: 177.3877 - val_loss: 217.2992\n",
      "Epoch 31/50\n",
      " - 0s - loss: 163.1757 - val_loss: 205.7577\n",
      "Epoch 32/50\n",
      " - 0s - loss: 149.1606 - val_loss: 194.0685\n",
      "Epoch 33/50\n",
      " - 0s - loss: 136.3985 - val_loss: 180.4785\n",
      "Epoch 34/50\n",
      " - 0s - loss: 125.8654 - val_loss: 166.8653\n",
      "Epoch 35/50\n",
      " - 0s - loss: 115.8509 - val_loss: 155.3475\n",
      "Epoch 36/50\n",
      " - 0s - loss: 107.2270 - val_loss: 143.1185\n",
      "Epoch 37/50\n",
      " - 0s - loss: 101.4010 - val_loss: 145.2497\n",
      "Epoch 38/50\n",
      " - 0s - loss: 98.0970 - val_loss: 139.0450\n",
      "Epoch 39/50\n",
      " - 0s - loss: 93.9600 - val_loss: 129.3482\n",
      "Epoch 40/50\n",
      " - 0s - loss: 91.6149 - val_loss: 113.5568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      " - 0s - loss: 90.8009 - val_loss: 109.5327\n",
      "Epoch 42/50\n",
      " - 0s - loss: 89.2622 - val_loss: 109.1998\n",
      "Epoch 43/50\n",
      " - 0s - loss: 86.9063 - val_loss: 103.6478\n",
      "Epoch 44/50\n",
      " - 0s - loss: 86.8059 - val_loss: 109.2094\n",
      "Epoch 45/50\n",
      " - 0s - loss: 85.9720 - val_loss: 114.4163\n",
      "Epoch 46/50\n",
      " - 0s - loss: 85.3321 - val_loss: 103.7680\n",
      "Epoch 47/50\n",
      " - 0s - loss: 85.1294 - val_loss: 96.7288\n",
      "Epoch 48/50\n",
      " - 0s - loss: 85.2321 - val_loss: 97.4970\n",
      "Epoch 49/50\n",
      " - 0s - loss: 84.3110 - val_loss: 99.2096\n",
      "Epoch 50/50\n",
      " - 0s - loss: 83.4950 - val_loss: 98.8591\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 683.9528 - val_loss: 247.7736\n",
      "Epoch 2/50\n",
      " - 0s - loss: 247.0007 - val_loss: 164.5013\n",
      "Epoch 3/50\n",
      " - 0s - loss: 228.1382 - val_loss: 163.1568\n",
      "Epoch 4/50\n",
      " - 0s - loss: 209.2962 - val_loss: 145.8694\n",
      "Epoch 5/50\n",
      " - 0s - loss: 200.4747 - val_loss: 164.4570\n",
      "Epoch 6/50\n",
      " - 0s - loss: 190.5919 - val_loss: 137.0092\n",
      "Epoch 7/50\n",
      " - 0s - loss: 183.3655 - val_loss: 117.0638\n",
      "Epoch 8/50\n",
      " - 0s - loss: 167.9078 - val_loss: 124.8880\n",
      "Epoch 9/50\n",
      " - 0s - loss: 160.0568 - val_loss: 113.2458\n",
      "Epoch 10/50\n",
      " - 0s - loss: 152.8878 - val_loss: 116.4668\n",
      "Epoch 11/50\n",
      " - 0s - loss: 145.9499 - val_loss: 135.8136\n",
      "Epoch 12/50\n",
      " - 0s - loss: 136.6303 - val_loss: 125.9150\n",
      "Epoch 13/50\n",
      " - 0s - loss: 137.9870 - val_loss: 116.1925\n",
      "Epoch 14/50\n",
      " - 0s - loss: 129.5180 - val_loss: 131.8187\n",
      "Epoch 15/50\n",
      " - 0s - loss: 120.6129 - val_loss: 121.5156\n",
      "Epoch 16/50\n",
      " - 0s - loss: 118.9143 - val_loss: 116.6606\n",
      "Epoch 17/50\n",
      " - 0s - loss: 112.9325 - val_loss: 128.4924\n",
      "Epoch 18/50\n",
      " - 0s - loss: 113.5429 - val_loss: 130.6666\n",
      "Epoch 19/50\n",
      " - 0s - loss: 107.6758 - val_loss: 115.5095\n",
      "Epoch 20/50\n",
      " - 0s - loss: 105.6051 - val_loss: 112.6342\n",
      "Epoch 21/50\n",
      " - 0s - loss: 103.3342 - val_loss: 116.5135\n",
      "Epoch 22/50\n",
      " - 0s - loss: 104.2171 - val_loss: 119.8515\n",
      "Epoch 23/50\n",
      " - 0s - loss: 105.2926 - val_loss: 110.5283\n",
      "Epoch 24/50\n",
      " - 0s - loss: 97.8261 - val_loss: 123.4474\n",
      "Epoch 25/50\n",
      " - 0s - loss: 94.8783 - val_loss: 101.8663\n",
      "Epoch 26/50\n",
      " - 0s - loss: 96.0874 - val_loss: 100.0837\n",
      "Epoch 27/50\n",
      " - 0s - loss: 100.9819 - val_loss: 119.7952\n",
      "Epoch 28/50\n",
      " - 0s - loss: 92.5794 - val_loss: 126.6431\n",
      "Epoch 29/50\n",
      " - 0s - loss: 93.2731 - val_loss: 108.0918\n",
      "Epoch 30/50\n",
      " - 0s - loss: 89.8731 - val_loss: 96.1086\n",
      "Epoch 31/50\n",
      " - 0s - loss: 91.4258 - val_loss: 142.3317\n",
      "Epoch 32/50\n",
      " - 0s - loss: 94.3404 - val_loss: 93.7165\n",
      "Epoch 33/50\n",
      " - 0s - loss: 91.1751 - val_loss: 89.8775\n",
      "Epoch 34/50\n",
      " - 0s - loss: 86.7174 - val_loss: 87.7606\n",
      "Epoch 35/50\n",
      " - 0s - loss: 85.1641 - val_loss: 89.1021\n",
      "Epoch 36/50\n",
      " - 0s - loss: 84.3589 - val_loss: 132.1598\n",
      "Epoch 37/50\n",
      " - 0s - loss: 92.4502 - val_loss: 82.5886\n",
      "Epoch 38/50\n",
      " - 0s - loss: 87.5191 - val_loss: 85.0171\n",
      "Epoch 39/50\n",
      " - 0s - loss: 86.3303 - val_loss: 79.5535\n",
      "Epoch 40/50\n",
      " - 0s - loss: 84.0910 - val_loss: 80.9806\n",
      "Epoch 41/50\n",
      " - 0s - loss: 84.1598 - val_loss: 81.5349\n",
      "Epoch 42/50\n",
      " - 0s - loss: 81.0216 - val_loss: 79.0882\n",
      "Epoch 43/50\n",
      " - 0s - loss: 80.2063 - val_loss: 83.3433\n",
      "Epoch 44/50\n",
      " - 0s - loss: 79.4765 - val_loss: 76.1595\n",
      "Epoch 45/50\n",
      " - 0s - loss: 78.4114 - val_loss: 86.7042\n",
      "Epoch 46/50\n",
      " - 0s - loss: 82.7626 - val_loss: 83.2463\n",
      "Epoch 47/50\n",
      " - 0s - loss: 79.9204 - val_loss: 90.0626\n",
      "Epoch 48/50\n",
      " - 0s - loss: 78.8925 - val_loss: 91.3371\n",
      "Epoch 49/50\n",
      " - 0s - loss: 80.1063 - val_loss: 73.3971\n",
      "Epoch 50/50\n",
      " - 0s - loss: 82.0499 - val_loss: 70.7194\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 102583.4938 - val_loss: 54612.2651\n",
      "Epoch 2/50\n",
      " - 0s - loss: 42949.7456 - val_loss: 24953.2575\n",
      "Epoch 3/50\n",
      " - 0s - loss: 22460.4603 - val_loss: 14462.2998\n",
      "Epoch 4/50\n",
      " - 0s - loss: 13886.3847 - val_loss: 9357.1509\n",
      "Epoch 5/50\n",
      " - 0s - loss: 9338.0701 - val_loss: 6398.1044\n",
      "Epoch 6/50\n",
      " - 0s - loss: 6667.0814 - val_loss: 4632.1911\n",
      "Epoch 7/50\n",
      " - 0s - loss: 4092.7448 - val_loss: 1901.9350\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1377.5239 - val_loss: 535.3896\n",
      "Epoch 9/50\n",
      " - 0s - loss: 700.1673 - val_loss: 463.1206\n",
      "Epoch 10/50\n",
      " - 0s - loss: 592.0851 - val_loss: 383.7368\n",
      "Epoch 11/50\n",
      " - 0s - loss: 519.0866 - val_loss: 340.2952\n",
      "Epoch 12/50\n",
      " - 0s - loss: 474.9877 - val_loss: 321.2939\n",
      "Epoch 13/50\n",
      " - 0s - loss: 448.6636 - val_loss: 299.9932\n",
      "Epoch 14/50\n",
      " - 0s - loss: 426.6778 - val_loss: 292.0729\n",
      "Epoch 15/50\n",
      " - 0s - loss: 410.7881 - val_loss: 278.5573\n",
      "Epoch 16/50\n",
      " - 0s - loss: 395.8277 - val_loss: 271.7469\n",
      "Epoch 17/50\n",
      " - 0s - loss: 383.1190 - val_loss: 263.2931\n",
      "Epoch 18/50\n",
      " - 0s - loss: 371.7651 - val_loss: 258.6445\n",
      "Epoch 19/50\n",
      " - 0s - loss: 361.2881 - val_loss: 250.9722\n",
      "Epoch 20/50\n",
      " - 0s - loss: 351.1813 - val_loss: 247.1337\n",
      "Epoch 21/50\n",
      " - 0s - loss: 340.8815 - val_loss: 253.0383\n",
      "Epoch 22/50\n",
      " - 0s - loss: 331.3910 - val_loss: 248.7802\n",
      "Epoch 23/50\n",
      " - 0s - loss: 322.6658 - val_loss: 244.6118\n",
      "Epoch 24/50\n",
      " - 0s - loss: 315.3250 - val_loss: 236.7389\n",
      "Epoch 25/50\n",
      " - 0s - loss: 308.6021 - val_loss: 234.6899\n",
      "Epoch 26/50\n",
      " - 0s - loss: 303.1031 - val_loss: 237.2846\n",
      "Epoch 27/50\n",
      " - 0s - loss: 297.9745 - val_loss: 223.5497\n",
      "Epoch 28/50\n",
      " - 0s - loss: 291.3794 - val_loss: 231.7359\n",
      "Epoch 29/50\n",
      " - 0s - loss: 286.5453 - val_loss: 222.2733\n",
      "Epoch 30/50\n",
      " - 0s - loss: 282.3568 - val_loss: 218.3129\n",
      "Epoch 31/50\n",
      " - 0s - loss: 277.6163 - val_loss: 220.0349\n",
      "Epoch 32/50\n",
      " - 0s - loss: 273.1996 - val_loss: 218.9774\n",
      "Epoch 33/50\n",
      " - 0s - loss: 269.4049 - val_loss: 219.8302\n",
      "Epoch 34/50\n",
      " - 0s - loss: 265.8890 - val_loss: 220.5593\n",
      "Epoch 35/50\n",
      " - 0s - loss: 262.2674 - val_loss: 214.6724\n",
      "Epoch 36/50\n",
      " - 0s - loss: 259.0671 - val_loss: 219.4344\n",
      "Epoch 37/50\n",
      " - 0s - loss: 256.8358 - val_loss: 220.0372\n",
      "Epoch 38/50\n",
      " - 0s - loss: 253.8163 - val_loss: 213.0091\n",
      "Epoch 39/50\n",
      " - 0s - loss: 251.1141 - val_loss: 211.4538\n",
      "Epoch 40/50\n",
      " - 0s - loss: 248.1893 - val_loss: 217.1198\n",
      "Epoch 41/50\n",
      " - 0s - loss: 246.1577 - val_loss: 219.6234\n",
      "Epoch 42/50\n",
      " - 0s - loss: 245.0921 - val_loss: 218.5987\n",
      "Epoch 43/50\n",
      " - 0s - loss: 242.9230 - val_loss: 213.0638\n",
      "Epoch 44/50\n",
      " - 0s - loss: 238.8517 - val_loss: 215.4097\n",
      "Epoch 45/50\n",
      " - 0s - loss: 237.5807 - val_loss: 211.0173\n",
      "Epoch 46/50\n",
      " - 0s - loss: 234.6040 - val_loss: 227.5316\n",
      "Epoch 47/50\n",
      " - 0s - loss: 236.2834 - val_loss: 215.5075\n",
      "Epoch 48/50\n",
      " - 0s - loss: 230.9293 - val_loss: 219.3180\n",
      "Epoch 49/50\n",
      " - 0s - loss: 228.9668 - val_loss: 212.3553\n",
      "Epoch 50/50\n",
      " - 0s - loss: 227.3980 - val_loss: 213.6386\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 1558.5626 - val_loss: 556.8972\n",
      "Epoch 2/50\n",
      " - 0s - loss: 650.0874 - val_loss: 414.1156\n",
      "Epoch 3/50\n",
      " - 0s - loss: 403.9726 - val_loss: 298.6027\n",
      "Epoch 4/50\n",
      " - 0s - loss: 345.7057 - val_loss: 229.6575\n",
      "Epoch 5/50\n",
      " - 0s - loss: 319.0946 - val_loss: 223.1561\n",
      "Epoch 6/50\n",
      " - 0s - loss: 302.6366 - val_loss: 191.3562\n",
      "Epoch 7/50\n",
      " - 0s - loss: 286.0795 - val_loss: 197.7374\n",
      "Epoch 8/50\n",
      " - 0s - loss: 273.0242 - val_loss: 166.1874\n",
      "Epoch 9/50\n",
      " - 0s - loss: 262.0569 - val_loss: 159.2958\n",
      "Epoch 10/50\n",
      " - 0s - loss: 252.5071 - val_loss: 171.3910\n",
      "Epoch 11/50\n",
      " - 0s - loss: 244.0055 - val_loss: 150.1746\n",
      "Epoch 12/50\n",
      " - 0s - loss: 238.2915 - val_loss: 155.8311\n",
      "Epoch 13/50\n",
      " - 0s - loss: 231.5968 - val_loss: 158.5923\n",
      "Epoch 14/50\n",
      " - 0s - loss: 225.6009 - val_loss: 137.9229\n",
      "Epoch 15/50\n",
      " - 0s - loss: 222.1832 - val_loss: 122.9756\n",
      "Epoch 16/50\n",
      " - 0s - loss: 218.6983 - val_loss: 133.5085\n",
      "Epoch 17/50\n",
      " - 0s - loss: 213.9144 - val_loss: 134.7153\n",
      "Epoch 18/50\n",
      " - 0s - loss: 209.5733 - val_loss: 120.6284\n",
      "Epoch 19/50\n",
      " - 0s - loss: 205.1399 - val_loss: 137.2705\n",
      "Epoch 20/50\n",
      " - 0s - loss: 201.8807 - val_loss: 138.8362\n",
      "Epoch 21/50\n",
      " - 0s - loss: 197.7357 - val_loss: 126.6642\n",
      "Epoch 22/50\n",
      " - 0s - loss: 195.8912 - val_loss: 140.3358\n",
      "Epoch 23/50\n",
      " - 0s - loss: 192.3107 - val_loss: 130.7389\n",
      "Epoch 24/50\n",
      " - 0s - loss: 188.6313 - val_loss: 133.5867\n",
      "Epoch 25/50\n",
      " - 0s - loss: 185.7977 - val_loss: 150.1238\n",
      "Epoch 26/50\n",
      " - 0s - loss: 182.6837 - val_loss: 112.8225\n",
      "Epoch 27/50\n",
      " - 0s - loss: 181.2577 - val_loss: 121.1702\n",
      "Epoch 28/50\n",
      " - 0s - loss: 178.5128 - val_loss: 130.5183\n",
      "Epoch 29/50\n",
      " - 0s - loss: 175.4446 - val_loss: 164.9813\n",
      "Epoch 30/50\n",
      " - 0s - loss: 175.8283 - val_loss: 127.5421\n",
      "Epoch 31/50\n",
      " - 0s - loss: 170.8892 - val_loss: 150.9265\n",
      "Epoch 32/50\n",
      " - 0s - loss: 171.1227 - val_loss: 129.8678\n",
      "Epoch 33/50\n",
      " - 0s - loss: 165.0669 - val_loss: 136.6289\n",
      "Epoch 34/50\n",
      " - 0s - loss: 161.9430 - val_loss: 126.6210\n",
      "Epoch 35/50\n",
      " - 0s - loss: 158.5901 - val_loss: 120.7522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      " - 0s - loss: 156.3408 - val_loss: 120.2104\n",
      "Epoch 37/50\n",
      " - 0s - loss: 152.5423 - val_loss: 112.6010\n",
      "Epoch 38/50\n",
      " - 0s - loss: 150.0727 - val_loss: 124.0057\n",
      "Epoch 39/50\n",
      " - 0s - loss: 144.8971 - val_loss: 112.1391\n",
      "Epoch 40/50\n",
      " - 0s - loss: 142.3947 - val_loss: 109.4587\n",
      "Epoch 41/50\n",
      " - 0s - loss: 140.8951 - val_loss: 113.8035\n",
      "Epoch 42/50\n",
      " - 0s - loss: 136.7159 - val_loss: 120.8485\n",
      "Epoch 43/50\n",
      " - 0s - loss: 132.9072 - val_loss: 143.0792\n",
      "Epoch 44/50\n",
      " - 0s - loss: 131.2058 - val_loss: 134.8559\n",
      "Epoch 45/50\n",
      " - 0s - loss: 127.7450 - val_loss: 147.0578\n",
      "Epoch 46/50\n",
      " - 0s - loss: 127.1194 - val_loss: 156.3022\n",
      "Epoch 47/50\n",
      " - 0s - loss: 123.4450 - val_loss: 132.7292\n",
      "Epoch 48/50\n",
      " - 0s - loss: 122.2425 - val_loss: 154.2473\n",
      "Epoch 49/50\n",
      " - 0s - loss: 121.4360 - val_loss: 147.0977\n",
      "Epoch 50/50\n",
      " - 0s - loss: 117.8798 - val_loss: 152.3167\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 3814.2949 - val_loss: 1755.2242\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1188.5910 - val_loss: 1023.0720\n",
      "Epoch 3/50\n",
      " - 0s - loss: 713.8663 - val_loss: 565.8400\n",
      "Epoch 4/50\n",
      " - 0s - loss: 496.2330 - val_loss: 373.3180\n",
      "Epoch 5/50\n",
      " - 0s - loss: 385.7638 - val_loss: 268.8787\n",
      "Epoch 6/50\n",
      " - 0s - loss: 328.2137 - val_loss: 205.5814\n",
      "Epoch 7/50\n",
      " - 0s - loss: 296.4732 - val_loss: 199.1724\n",
      "Epoch 8/50\n",
      " - 0s - loss: 278.8647 - val_loss: 182.9815\n",
      "Epoch 9/50\n",
      " - 0s - loss: 270.2215 - val_loss: 200.2749\n",
      "Epoch 10/50\n",
      " - 0s - loss: 270.3109 - val_loss: 160.0260\n",
      "Epoch 11/50\n",
      " - 0s - loss: 265.5001 - val_loss: 190.4066\n",
      "Epoch 12/50\n",
      " - 0s - loss: 262.1489 - val_loss: 177.0303\n",
      "Epoch 13/50\n",
      " - 0s - loss: 261.2250 - val_loss: 186.6553\n",
      "Epoch 14/50\n",
      " - 0s - loss: 259.5409 - val_loss: 167.2429\n",
      "Epoch 15/50\n",
      " - 0s - loss: 257.7625 - val_loss: 181.7399\n",
      "Epoch 16/50\n",
      " - 0s - loss: 258.0843 - val_loss: 177.5375\n",
      "Epoch 17/50\n",
      " - 0s - loss: 256.7779 - val_loss: 201.3499\n",
      "Epoch 18/50\n",
      " - 0s - loss: 258.0155 - val_loss: 189.4904\n",
      "Epoch 19/50\n",
      " - 0s - loss: 253.6558 - val_loss: 176.7057\n",
      "Epoch 20/50\n",
      " - 0s - loss: 253.1997 - val_loss: 161.9203\n",
      "Epoch 21/50\n",
      " - 0s - loss: 251.5577 - val_loss: 162.0907\n",
      "Epoch 22/50\n",
      " - 0s - loss: 250.0892 - val_loss: 163.8434\n",
      "Epoch 23/50\n",
      " - 0s - loss: 249.2346 - val_loss: 152.8719\n",
      "Epoch 24/50\n",
      " - 0s - loss: 247.9314 - val_loss: 200.0223\n",
      "Epoch 25/50\n",
      " - 0s - loss: 247.4403 - val_loss: 196.9105\n",
      "Epoch 26/50\n",
      " - 0s - loss: 247.2018 - val_loss: 150.7420\n",
      "Epoch 27/50\n",
      " - 0s - loss: 244.0968 - val_loss: 185.3730\n",
      "Epoch 28/50\n",
      " - 0s - loss: 245.2818 - val_loss: 183.1189\n",
      "Epoch 29/50\n",
      " - 0s - loss: 243.2369 - val_loss: 145.6221\n",
      "Epoch 30/50\n",
      " - 0s - loss: 244.2752 - val_loss: 157.9135\n",
      "Epoch 31/50\n",
      " - 0s - loss: 240.8332 - val_loss: 180.2176\n",
      "Epoch 32/50\n",
      " - 0s - loss: 238.8816 - val_loss: 154.5672\n",
      "Epoch 33/50\n",
      " - 0s - loss: 237.0087 - val_loss: 188.0609\n",
      "Epoch 34/50\n",
      " - 0s - loss: 238.4351 - val_loss: 181.1291\n",
      "Epoch 35/50\n",
      " - 0s - loss: 235.0658 - val_loss: 159.7754\n",
      "Epoch 36/50\n",
      " - 0s - loss: 233.6557 - val_loss: 145.7054\n",
      "Epoch 37/50\n",
      " - 0s - loss: 237.1192 - val_loss: 136.3634\n",
      "Epoch 38/50\n",
      " - 0s - loss: 229.9450 - val_loss: 162.4254\n",
      "Epoch 39/50\n",
      " - 0s - loss: 229.1397 - val_loss: 155.7779\n",
      "Epoch 40/50\n",
      " - 0s - loss: 227.2959 - val_loss: 150.9979\n",
      "Epoch 41/50\n",
      " - 0s - loss: 225.9714 - val_loss: 154.5162\n",
      "Epoch 42/50\n",
      " - 0s - loss: 225.3271 - val_loss: 139.8771\n",
      "Epoch 43/50\n",
      " - 0s - loss: 224.1333 - val_loss: 139.6482\n",
      "Epoch 44/50\n",
      " - 0s - loss: 223.2255 - val_loss: 144.7074\n",
      "Epoch 45/50\n",
      " - 0s - loss: 221.3597 - val_loss: 157.0881\n",
      "Epoch 46/50\n",
      " - 0s - loss: 219.7463 - val_loss: 146.6054\n",
      "Epoch 47/50\n",
      " - 0s - loss: 217.4383 - val_loss: 119.9849\n",
      "Epoch 48/50\n",
      " - 0s - loss: 224.9456 - val_loss: 132.4539\n",
      "Epoch 49/50\n",
      " - 0s - loss: 217.3550 - val_loss: 133.0078\n",
      "Epoch 50/50\n",
      " - 0s - loss: 214.8369 - val_loss: 118.0248\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 610.4096 - val_loss: 444.5310\n",
      "Epoch 2/50\n",
      " - 0s - loss: 373.9894 - val_loss: 257.5107\n",
      "Epoch 3/50\n",
      " - 0s - loss: 331.6803 - val_loss: 238.3916\n",
      "Epoch 4/50\n",
      " - 0s - loss: 303.3381 - val_loss: 212.6890\n",
      "Epoch 5/50\n",
      " - 0s - loss: 270.9568 - val_loss: 190.3948\n",
      "Epoch 6/50\n",
      " - 0s - loss: 233.1726 - val_loss: 167.8507\n",
      "Epoch 7/50\n",
      " - 0s - loss: 202.8880 - val_loss: 120.7823\n",
      "Epoch 8/50\n",
      " - 0s - loss: 169.0881 - val_loss: 100.9483\n",
      "Epoch 9/50\n",
      " - 0s - loss: 148.9151 - val_loss: 99.1209\n",
      "Epoch 10/50\n",
      " - 0s - loss: 136.7703 - val_loss: 94.0934\n",
      "Epoch 11/50\n",
      " - 0s - loss: 128.7923 - val_loss: 89.8772\n",
      "Epoch 12/50\n",
      " - 0s - loss: 123.2396 - val_loss: 99.5558\n",
      "Epoch 13/50\n",
      " - 0s - loss: 121.7887 - val_loss: 92.9259\n",
      "Epoch 14/50\n",
      " - 0s - loss: 119.7589 - val_loss: 97.1784\n",
      "Epoch 15/50\n",
      " - 0s - loss: 114.4603 - val_loss: 103.4844\n",
      "Epoch 16/50\n",
      " - 0s - loss: 111.5411 - val_loss: 98.6648\n",
      "Epoch 17/50\n",
      " - 0s - loss: 113.7243 - val_loss: 91.4644\n",
      "Epoch 18/50\n",
      " - 0s - loss: 117.1978 - val_loss: 115.3116\n",
      "Epoch 19/50\n",
      " - 0s - loss: 109.3315 - val_loss: 84.0883\n",
      "Epoch 20/50\n",
      " - 0s - loss: 105.7396 - val_loss: 89.2046\n",
      "Epoch 21/50\n",
      " - 0s - loss: 106.1290 - val_loss: 88.2121\n",
      "Epoch 22/50\n",
      " - 0s - loss: 102.6750 - val_loss: 89.8783\n",
      "Epoch 23/50\n",
      " - 0s - loss: 104.3762 - val_loss: 78.5061\n",
      "Epoch 24/50\n",
      " - 0s - loss: 102.9001 - val_loss: 77.8830\n",
      "Epoch 25/50\n",
      " - 0s - loss: 100.7396 - val_loss: 81.3408\n",
      "Epoch 26/50\n",
      " - 0s - loss: 98.5212 - val_loss: 86.8057\n",
      "Epoch 27/50\n",
      " - 0s - loss: 97.3102 - val_loss: 76.1112\n",
      "Epoch 28/50\n",
      " - 0s - loss: 100.3064 - val_loss: 101.7789\n",
      "Epoch 29/50\n",
      " - 0s - loss: 97.1084 - val_loss: 75.2719\n",
      "Epoch 30/50\n",
      " - 0s - loss: 93.7145 - val_loss: 79.0549\n",
      "Epoch 31/50\n",
      " - 0s - loss: 91.6788 - val_loss: 72.0767\n",
      "Epoch 32/50\n",
      " - 0s - loss: 91.6173 - val_loss: 94.6056\n",
      "Epoch 33/50\n",
      " - 0s - loss: 93.6322 - val_loss: 74.6347\n",
      "Epoch 34/50\n",
      " - 0s - loss: 88.8269 - val_loss: 70.9736\n",
      "Epoch 35/50\n",
      " - 0s - loss: 88.8754 - val_loss: 74.2435\n",
      "Epoch 36/50\n",
      " - 0s - loss: 87.8689 - val_loss: 79.5070\n",
      "Epoch 37/50\n",
      " - 0s - loss: 90.1349 - val_loss: 76.0941\n",
      "Epoch 38/50\n",
      " - 0s - loss: 87.6998 - val_loss: 69.5074\n",
      "Epoch 39/50\n",
      " - 0s - loss: 89.7191 - val_loss: 69.9933\n",
      "Epoch 40/50\n",
      " - 0s - loss: 90.4517 - val_loss: 92.5268\n",
      "Epoch 41/50\n",
      " - 0s - loss: 86.8147 - val_loss: 75.0096\n",
      "Epoch 42/50\n",
      " - 0s - loss: 83.0399 - val_loss: 71.4063\n",
      "Epoch 43/50\n",
      " - 0s - loss: 84.2271 - val_loss: 76.7276\n",
      "Epoch 44/50\n",
      " - 0s - loss: 82.9669 - val_loss: 69.7032\n",
      "Epoch 45/50\n",
      " - 0s - loss: 83.5909 - val_loss: 71.8654\n",
      "Epoch 46/50\n",
      " - 0s - loss: 81.6089 - val_loss: 68.8154\n",
      "Epoch 47/50\n",
      " - 0s - loss: 86.3416 - val_loss: 75.1176\n",
      "Epoch 48/50\n",
      " - 0s - loss: 86.5802 - val_loss: 79.7080\n",
      "Epoch 49/50\n",
      " - 0s - loss: 84.6510 - val_loss: 69.2060\n",
      "Epoch 50/50\n",
      " - 0s - loss: 82.0441 - val_loss: 83.3430\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 5699.7069 - val_loss: 760.6482\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1062.5932 - val_loss: 557.5262\n",
      "Epoch 3/50\n",
      " - 0s - loss: 701.8894 - val_loss: 479.7056\n",
      "Epoch 4/50\n",
      " - 0s - loss: 585.2644 - val_loss: 408.4263\n",
      "Epoch 5/50\n",
      " - 0s - loss: 507.4262 - val_loss: 371.0397\n",
      "Epoch 6/50\n",
      " - 0s - loss: 454.7345 - val_loss: 313.8665\n",
      "Epoch 7/50\n",
      " - 0s - loss: 390.7943 - val_loss: 271.2386\n",
      "Epoch 8/50\n",
      " - 0s - loss: 336.0821 - val_loss: 221.4693\n",
      "Epoch 9/50\n",
      " - 0s - loss: 291.8867 - val_loss: 203.7083\n",
      "Epoch 10/50\n",
      " - 0s - loss: 268.0216 - val_loss: 180.2642\n",
      "Epoch 11/50\n",
      " - 0s - loss: 249.1947 - val_loss: 166.8081\n",
      "Epoch 12/50\n",
      " - 0s - loss: 238.0076 - val_loss: 171.4859\n",
      "Epoch 13/50\n",
      " - 0s - loss: 224.3830 - val_loss: 140.5809\n",
      "Epoch 14/50\n",
      " - 0s - loss: 218.5924 - val_loss: 143.4342\n",
      "Epoch 15/50\n",
      " - 0s - loss: 206.9417 - val_loss: 145.5513\n",
      "Epoch 16/50\n",
      " - 0s - loss: 202.0354 - val_loss: 150.6232\n",
      "Epoch 17/50\n",
      " - 0s - loss: 195.1089 - val_loss: 138.7579\n",
      "Epoch 18/50\n",
      " - 0s - loss: 190.2626 - val_loss: 129.9210\n",
      "Epoch 19/50\n",
      " - 0s - loss: 187.5795 - val_loss: 140.7722\n",
      "Epoch 20/50\n",
      " - 0s - loss: 182.0055 - val_loss: 133.6981\n",
      "Epoch 21/50\n",
      " - 0s - loss: 178.8909 - val_loss: 126.0486\n",
      "Epoch 22/50\n",
      " - 0s - loss: 178.3670 - val_loss: 140.1377\n",
      "Epoch 23/50\n",
      " - 0s - loss: 173.9833 - val_loss: 140.7311\n",
      "Epoch 24/50\n",
      " - 0s - loss: 173.1180 - val_loss: 166.3074\n",
      "Epoch 25/50\n",
      " - 0s - loss: 171.5343 - val_loss: 131.0941\n",
      "Epoch 26/50\n",
      " - 0s - loss: 172.2971 - val_loss: 127.9917\n",
      "Epoch 27/50\n",
      " - 0s - loss: 168.7919 - val_loss: 121.2759\n",
      "Epoch 28/50\n",
      " - 0s - loss: 167.0676 - val_loss: 119.3144\n",
      "Epoch 29/50\n",
      " - 0s - loss: 162.9187 - val_loss: 120.9874\n",
      "Epoch 30/50\n",
      " - 0s - loss: 160.7965 - val_loss: 115.6402\n",
      "Epoch 31/50\n",
      " - 0s - loss: 159.8340 - val_loss: 124.7635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      " - 0s - loss: 158.1707 - val_loss: 121.8156\n",
      "Epoch 33/50\n",
      " - 0s - loss: 157.0508 - val_loss: 130.1137\n",
      "Epoch 34/50\n",
      " - 0s - loss: 155.9866 - val_loss: 131.4705\n",
      "Epoch 35/50\n",
      " - 0s - loss: 154.9274 - val_loss: 134.3947\n",
      "Epoch 36/50\n",
      " - 0s - loss: 154.9600 - val_loss: 127.2269\n",
      "Epoch 37/50\n",
      " - 0s - loss: 153.7632 - val_loss: 123.2127\n",
      "Epoch 38/50\n",
      " - 0s - loss: 152.7194 - val_loss: 115.3383\n",
      "Epoch 39/50\n",
      " - 0s - loss: 152.4256 - val_loss: 129.5244\n",
      "Epoch 40/50\n",
      " - 0s - loss: 151.9910 - val_loss: 127.4980\n",
      "Epoch 41/50\n",
      " - 0s - loss: 150.2495 - val_loss: 124.5652\n",
      "Epoch 42/50\n",
      " - 0s - loss: 151.6606 - val_loss: 120.3932\n",
      "Epoch 43/50\n",
      " - 0s - loss: 148.4567 - val_loss: 104.7496\n",
      "Epoch 44/50\n",
      " - 0s - loss: 148.6704 - val_loss: 108.6525\n",
      "Epoch 45/50\n",
      " - 0s - loss: 146.1405 - val_loss: 106.9984\n",
      "Epoch 46/50\n",
      " - 0s - loss: 146.9527 - val_loss: 115.7699\n",
      "Epoch 47/50\n",
      " - 0s - loss: 148.6377 - val_loss: 116.5120\n",
      "Epoch 48/50\n",
      " - 0s - loss: 149.1611 - val_loss: 101.8082\n",
      "Epoch 49/50\n",
      " - 0s - loss: 150.2705 - val_loss: 102.4632\n",
      "Epoch 50/50\n",
      " - 0s - loss: 144.9759 - val_loss: 112.1974\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 9351.4673 - val_loss: 813.7090\n",
      "Epoch 2/50\n",
      " - 0s - loss: 923.2353 - val_loss: 642.1900\n",
      "Epoch 3/50\n",
      " - 0s - loss: 718.1905 - val_loss: 458.0085\n",
      "Epoch 4/50\n",
      " - 0s - loss: 617.1231 - val_loss: 419.0325\n",
      "Epoch 5/50\n",
      " - 0s - loss: 590.1237 - val_loss: 404.8547\n",
      "Epoch 6/50\n",
      " - 0s - loss: 572.0187 - val_loss: 384.1654\n",
      "Epoch 7/50\n",
      " - 0s - loss: 553.7461 - val_loss: 380.4622\n",
      "Epoch 8/50\n",
      " - 0s - loss: 539.2354 - val_loss: 358.4704\n",
      "Epoch 9/50\n",
      " - 0s - loss: 523.1060 - val_loss: 345.0695\n",
      "Epoch 10/50\n",
      " - 0s - loss: 506.2182 - val_loss: 331.7785\n",
      "Epoch 11/50\n",
      " - 0s - loss: 485.6591 - val_loss: 308.3545\n",
      "Epoch 12/50\n",
      " - 0s - loss: 450.4899 - val_loss: 288.5217\n",
      "Epoch 13/50\n",
      " - 0s - loss: 401.2419 - val_loss: 266.7784\n",
      "Epoch 14/50\n",
      " - 0s - loss: 370.4610 - val_loss: 248.4553\n",
      "Epoch 15/50\n",
      " - 0s - loss: 359.1454 - val_loss: 253.7350\n",
      "Epoch 16/50\n",
      " - 0s - loss: 344.2078 - val_loss: 234.5297\n",
      "Epoch 17/50\n",
      " - 0s - loss: 335.0740 - val_loss: 240.3249\n",
      "Epoch 18/50\n",
      " - 0s - loss: 326.7385 - val_loss: 223.4363\n",
      "Epoch 19/50\n",
      " - 0s - loss: 319.5100 - val_loss: 237.6937\n",
      "Epoch 20/50\n",
      " - 0s - loss: 314.5239 - val_loss: 217.0666\n",
      "Epoch 21/50\n",
      " - 0s - loss: 310.0234 - val_loss: 220.8637\n",
      "Epoch 22/50\n",
      " - 0s - loss: 304.2508 - val_loss: 222.4251\n",
      "Epoch 23/50\n",
      " - 0s - loss: 297.7739 - val_loss: 222.3191\n",
      "Epoch 24/50\n",
      " - 0s - loss: 294.9701 - val_loss: 218.5292\n",
      "Epoch 25/50\n",
      " - 0s - loss: 294.7238 - val_loss: 223.9860\n",
      "Epoch 26/50\n",
      " - 0s - loss: 288.3726 - val_loss: 208.6184\n",
      "Epoch 27/50\n",
      " - 0s - loss: 283.8718 - val_loss: 208.4532\n",
      "Epoch 28/50\n",
      " - 0s - loss: 281.0353 - val_loss: 228.2259\n",
      "Epoch 29/50\n",
      " - 0s - loss: 277.3182 - val_loss: 216.4643\n",
      "Epoch 30/50\n",
      " - 0s - loss: 274.0024 - val_loss: 219.4178\n",
      "Epoch 31/50\n",
      " - 0s - loss: 270.9266 - val_loss: 221.0491\n",
      "Epoch 32/50\n",
      " - 0s - loss: 268.4415 - val_loss: 212.6038\n",
      "Epoch 33/50\n",
      " - 0s - loss: 265.0849 - val_loss: 205.2613\n",
      "Epoch 34/50\n",
      " - 0s - loss: 265.1554 - val_loss: 216.9322\n",
      "Epoch 35/50\n",
      " - 0s - loss: 260.6574 - val_loss: 198.5957\n",
      "Epoch 36/50\n",
      " - 0s - loss: 260.1309 - val_loss: 197.4168\n",
      "Epoch 37/50\n",
      " - 0s - loss: 254.4014 - val_loss: 201.0448\n",
      "Epoch 38/50\n",
      " - 0s - loss: 251.5943 - val_loss: 220.4261\n",
      "Epoch 39/50\n",
      " - 0s - loss: 248.8715 - val_loss: 200.0794\n",
      "Epoch 40/50\n",
      " - 0s - loss: 245.3817 - val_loss: 199.6847\n",
      "Epoch 41/50\n",
      " - 0s - loss: 246.3998 - val_loss: 193.8228\n",
      "Epoch 42/50\n",
      " - 0s - loss: 240.2026 - val_loss: 195.4142\n",
      "Epoch 43/50\n",
      " - 0s - loss: 239.9417 - val_loss: 187.2822\n",
      "Epoch 44/50\n",
      " - 0s - loss: 235.4430 - val_loss: 183.5562\n",
      "Epoch 45/50\n",
      " - 0s - loss: 231.0995 - val_loss: 191.5438\n",
      "Epoch 46/50\n",
      " - 0s - loss: 229.8125 - val_loss: 184.1811\n",
      "Epoch 47/50\n",
      " - 0s - loss: 224.7046 - val_loss: 191.6200\n",
      "Epoch 48/50\n",
      " - 0s - loss: 225.6027 - val_loss: 189.3782\n",
      "Epoch 49/50\n",
      " - 0s - loss: 219.4620 - val_loss: 190.3886\n",
      "Epoch 50/50\n",
      " - 0s - loss: 217.6289 - val_loss: 213.3216\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 6317.7090 - val_loss: 399.4678\n",
      "Epoch 2/50\n",
      " - 0s - loss: 506.5026 - val_loss: 390.6199\n",
      "Epoch 3/50\n",
      " - 0s - loss: 351.0306 - val_loss: 222.5074\n",
      "Epoch 4/50\n",
      " - 0s - loss: 304.1120 - val_loss: 215.8745\n",
      "Epoch 5/50\n",
      " - 0s - loss: 281.1852 - val_loss: 208.1186\n",
      "Epoch 6/50\n",
      " - 0s - loss: 269.1614 - val_loss: 201.5190\n",
      "Epoch 7/50\n",
      " - 0s - loss: 260.3936 - val_loss: 193.1644\n",
      "Epoch 8/50\n",
      " - 0s - loss: 250.6300 - val_loss: 191.5693\n",
      "Epoch 9/50\n",
      " - 0s - loss: 244.1354 - val_loss: 185.5902\n",
      "Epoch 10/50\n",
      " - 0s - loss: 238.8515 - val_loss: 180.7551\n",
      "Epoch 11/50\n",
      " - 0s - loss: 234.5746 - val_loss: 174.8261\n",
      "Epoch 12/50\n",
      " - 0s - loss: 231.1465 - val_loss: 175.2613\n",
      "Epoch 13/50\n",
      " - 0s - loss: 228.4637 - val_loss: 167.2844\n",
      "Epoch 14/50\n",
      " - 0s - loss: 226.4176 - val_loss: 163.2665\n",
      "Epoch 15/50\n",
      " - 0s - loss: 224.4043 - val_loss: 162.6124\n",
      "Epoch 16/50\n",
      " - 0s - loss: 223.8107 - val_loss: 161.7602\n",
      "Epoch 17/50\n",
      " - 0s - loss: 220.7164 - val_loss: 158.0386\n",
      "Epoch 18/50\n",
      " - 0s - loss: 219.2526 - val_loss: 153.2769\n",
      "Epoch 19/50\n",
      " - 0s - loss: 218.3810 - val_loss: 150.8816\n",
      "Epoch 20/50\n",
      " - 0s - loss: 216.6269 - val_loss: 148.0764\n",
      "Epoch 21/50\n",
      " - 0s - loss: 214.5316 - val_loss: 150.3833\n",
      "Epoch 22/50\n",
      " - 0s - loss: 215.0920 - val_loss: 147.0308\n",
      "Epoch 23/50\n",
      " - 0s - loss: 213.3184 - val_loss: 144.7232\n",
      "Epoch 24/50\n",
      " - 0s - loss: 210.5202 - val_loss: 141.7093\n",
      "Epoch 25/50\n",
      " - 0s - loss: 210.0832 - val_loss: 144.7477\n",
      "Epoch 26/50\n",
      " - 0s - loss: 208.8029 - val_loss: 139.7796\n",
      "Epoch 27/50\n",
      " - 0s - loss: 207.7811 - val_loss: 137.5566\n",
      "Epoch 28/50\n",
      " - 0s - loss: 206.5049 - val_loss: 136.5592\n",
      "Epoch 29/50\n",
      " - 0s - loss: 206.3769 - val_loss: 136.9984\n",
      "Epoch 30/50\n",
      " - 0s - loss: 205.5817 - val_loss: 135.1171\n",
      "Epoch 31/50\n",
      " - 0s - loss: 205.4822 - val_loss: 137.3029\n",
      "Epoch 32/50\n",
      " - 0s - loss: 203.9796 - val_loss: 132.2587\n",
      "Epoch 33/50\n",
      " - 0s - loss: 203.9818 - val_loss: 138.3055\n",
      "Epoch 34/50\n",
      " - 0s - loss: 203.9990 - val_loss: 130.6731\n",
      "Epoch 35/50\n",
      " - 0s - loss: 202.8168 - val_loss: 128.8711\n",
      "Epoch 36/50\n",
      " - 0s - loss: 201.2517 - val_loss: 133.0493\n",
      "Epoch 37/50\n",
      " - 0s - loss: 200.8621 - val_loss: 128.9120\n",
      "Epoch 38/50\n",
      " - 0s - loss: 200.6791 - val_loss: 129.6386\n",
      "Epoch 39/50\n",
      " - 0s - loss: 199.4083 - val_loss: 128.6151\n",
      "Epoch 40/50\n",
      " - 0s - loss: 198.4200 - val_loss: 127.5976\n",
      "Epoch 41/50\n",
      " - 0s - loss: 198.1591 - val_loss: 129.2843\n",
      "Epoch 42/50\n",
      " - 0s - loss: 196.4533 - val_loss: 125.3049\n",
      "Epoch 43/50\n",
      " - 0s - loss: 196.0215 - val_loss: 129.2871\n",
      "Epoch 44/50\n",
      " - 0s - loss: 196.0040 - val_loss: 126.4582\n",
      "Epoch 45/50\n",
      " - 0s - loss: 196.2247 - val_loss: 129.7534\n",
      "Epoch 46/50\n",
      " - 0s - loss: 194.2784 - val_loss: 127.9533\n",
      "Epoch 47/50\n",
      " - 0s - loss: 193.7959 - val_loss: 125.1890\n",
      "Epoch 48/50\n",
      " - 0s - loss: 194.1680 - val_loss: 126.3803\n",
      "Epoch 49/50\n",
      " - 0s - loss: 193.5544 - val_loss: 133.1265\n",
      "Epoch 50/50\n",
      " - 0s - loss: 192.3052 - val_loss: 123.1333\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 1506.4672 - val_loss: 586.5731\n",
      "Epoch 2/50\n",
      " - 0s - loss: 487.2597 - val_loss: 474.1715\n",
      "Epoch 3/50\n",
      " - 0s - loss: 351.3832 - val_loss: 462.2149\n",
      "Epoch 4/50\n",
      " - 0s - loss: 314.2592 - val_loss: 405.1098\n",
      "Epoch 5/50\n",
      " - 0s - loss: 293.1446 - val_loss: 380.9034\n",
      "Epoch 6/50\n",
      " - 0s - loss: 272.7723 - val_loss: 323.8000\n",
      "Epoch 7/50\n",
      " - 0s - loss: 258.2690 - val_loss: 313.2908\n",
      "Epoch 8/50\n",
      " - 0s - loss: 245.2464 - val_loss: 272.0522\n",
      "Epoch 9/50\n",
      " - 0s - loss: 232.7559 - val_loss: 240.5470\n",
      "Epoch 10/50\n",
      " - 0s - loss: 223.3859 - val_loss: 226.2489\n",
      "Epoch 11/50\n",
      " - 0s - loss: 213.9311 - val_loss: 198.5387\n",
      "Epoch 12/50\n",
      " - 0s - loss: 203.6225 - val_loss: 177.0008\n",
      "Epoch 13/50\n",
      " - 0s - loss: 201.4983 - val_loss: 168.0656\n",
      "Epoch 14/50\n",
      " - 0s - loss: 190.4230 - val_loss: 154.0002\n",
      "Epoch 15/50\n",
      " - 0s - loss: 184.3885 - val_loss: 147.5880\n",
      "Epoch 16/50\n",
      " - 0s - loss: 179.3697 - val_loss: 147.7795\n",
      "Epoch 17/50\n",
      " - 0s - loss: 175.4851 - val_loss: 129.1372\n",
      "Epoch 18/50\n",
      " - 0s - loss: 170.1755 - val_loss: 154.2841\n",
      "Epoch 19/50\n",
      " - 0s - loss: 173.6055 - val_loss: 113.9841\n",
      "Epoch 20/50\n",
      " - 0s - loss: 161.9462 - val_loss: 116.1974\n",
      "Epoch 21/50\n",
      " - 0s - loss: 162.4341 - val_loss: 97.8740\n",
      "Epoch 22/50\n",
      " - 0s - loss: 155.6115 - val_loss: 101.2253\n",
      "Epoch 23/50\n",
      " - 0s - loss: 154.1928 - val_loss: 101.2852\n",
      "Epoch 24/50\n",
      " - 0s - loss: 154.1578 - val_loss: 90.3253\n",
      "Epoch 25/50\n",
      " - 0s - loss: 150.3791 - val_loss: 84.0909\n",
      "Epoch 26/50\n",
      " - 0s - loss: 153.7767 - val_loss: 83.6294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      " - 0s - loss: 145.4312 - val_loss: 83.7319\n",
      "Epoch 28/50\n",
      " - 0s - loss: 142.8761 - val_loss: 78.4830\n",
      "Epoch 29/50\n",
      " - 0s - loss: 142.5144 - val_loss: 78.3592\n",
      "Epoch 30/50\n",
      " - 0s - loss: 139.4965 - val_loss: 75.0745\n",
      "Epoch 31/50\n",
      " - 0s - loss: 138.6533 - val_loss: 76.8578\n",
      "Epoch 32/50\n",
      " - 0s - loss: 139.0107 - val_loss: 80.4600\n",
      "Epoch 33/50\n",
      " - 0s - loss: 140.1986 - val_loss: 72.0852\n",
      "Epoch 34/50\n",
      " - 0s - loss: 136.9392 - val_loss: 80.6387\n",
      "Epoch 35/50\n",
      " - 0s - loss: 135.4253 - val_loss: 70.6579\n",
      "Epoch 36/50\n",
      " - 0s - loss: 133.4754 - val_loss: 74.4590\n",
      "Epoch 37/50\n",
      " - 0s - loss: 133.2457 - val_loss: 74.6958\n",
      "Epoch 38/50\n",
      " - 0s - loss: 135.7629 - val_loss: 69.8169\n",
      "Epoch 39/50\n",
      " - 0s - loss: 131.8317 - val_loss: 73.3439\n",
      "Epoch 40/50\n",
      " - 0s - loss: 141.2758 - val_loss: 87.8840\n",
      "Epoch 41/50\n",
      " - 0s - loss: 138.9027 - val_loss: 74.2763\n",
      "Epoch 42/50\n",
      " - 0s - loss: 128.4907 - val_loss: 72.0634\n",
      "Epoch 43/50\n",
      " - 0s - loss: 129.1195 - val_loss: 69.6140\n",
      "Epoch 44/50\n",
      " - 0s - loss: 130.6841 - val_loss: 78.5733\n",
      "Epoch 45/50\n",
      " - 0s - loss: 128.5990 - val_loss: 69.1209\n",
      "Epoch 46/50\n",
      " - 0s - loss: 129.0914 - val_loss: 71.3006\n",
      "Epoch 47/50\n",
      " - 0s - loss: 126.2847 - val_loss: 73.6272\n",
      "Epoch 48/50\n",
      " - 0s - loss: 125.5502 - val_loss: 69.4777\n",
      "Epoch 49/50\n",
      " - 0s - loss: 123.5444 - val_loss: 69.7220\n",
      "Epoch 50/50\n",
      " - 0s - loss: 124.2376 - val_loss: 70.7573\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 3171.7255 - val_loss: 782.5052\n",
      "Epoch 2/50\n",
      " - 0s - loss: 496.4205 - val_loss: 248.6630\n",
      "Epoch 3/50\n",
      " - 0s - loss: 325.8631 - val_loss: 193.7486\n",
      "Epoch 4/50\n",
      " - 0s - loss: 315.9053 - val_loss: 190.0540\n",
      "Epoch 5/50\n",
      " - 0s - loss: 305.0354 - val_loss: 187.3785\n",
      "Epoch 6/50\n",
      " - 0s - loss: 294.8729 - val_loss: 181.6838\n",
      "Epoch 7/50\n",
      " - 0s - loss: 284.4419 - val_loss: 171.9411\n",
      "Epoch 8/50\n",
      " - 0s - loss: 275.2126 - val_loss: 168.1786\n",
      "Epoch 9/50\n",
      " - 0s - loss: 266.4102 - val_loss: 158.3925\n",
      "Epoch 10/50\n",
      " - 0s - loss: 258.2244 - val_loss: 152.6868\n",
      "Epoch 11/50\n",
      " - 0s - loss: 250.4033 - val_loss: 148.3315\n",
      "Epoch 12/50\n",
      " - 0s - loss: 242.8217 - val_loss: 142.4410\n",
      "Epoch 13/50\n",
      " - 0s - loss: 235.7374 - val_loss: 137.8742\n",
      "Epoch 14/50\n",
      " - 0s - loss: 228.7223 - val_loss: 133.8451\n",
      "Epoch 15/50\n",
      " - 0s - loss: 222.0468 - val_loss: 130.0907\n",
      "Epoch 16/50\n",
      " - 0s - loss: 215.1678 - val_loss: 122.1384\n",
      "Epoch 17/50\n",
      " - 0s - loss: 209.1920 - val_loss: 117.6667\n",
      "Epoch 18/50\n",
      " - 0s - loss: 202.3498 - val_loss: 116.3682\n",
      "Epoch 19/50\n",
      " - 0s - loss: 196.8957 - val_loss: 114.5848\n",
      "Epoch 20/50\n",
      " - 0s - loss: 190.8421 - val_loss: 108.1011\n",
      "Epoch 21/50\n",
      " - 0s - loss: 186.4117 - val_loss: 112.1154\n",
      "Epoch 22/50\n",
      " - 0s - loss: 181.0286 - val_loss: 106.9652\n",
      "Epoch 23/50\n",
      " - 0s - loss: 175.9653 - val_loss: 101.5931\n",
      "Epoch 24/50\n",
      " - 0s - loss: 171.3522 - val_loss: 105.8693\n",
      "Epoch 25/50\n",
      " - 0s - loss: 168.9366 - val_loss: 96.4133\n",
      "Epoch 26/50\n",
      " - 0s - loss: 164.5352 - val_loss: 100.6064\n",
      "Epoch 27/50\n",
      " - 0s - loss: 161.3637 - val_loss: 101.5915\n",
      "Epoch 28/50\n",
      " - 0s - loss: 157.1505 - val_loss: 92.9317\n",
      "Epoch 29/50\n",
      " - 0s - loss: 154.1740 - val_loss: 100.7949\n",
      "Epoch 30/50\n",
      " - 0s - loss: 151.0185 - val_loss: 96.7462\n",
      "Epoch 31/50\n",
      " - 0s - loss: 147.7096 - val_loss: 95.7615\n",
      "Epoch 32/50\n",
      " - 0s - loss: 145.5538 - val_loss: 89.4658\n",
      "Epoch 33/50\n",
      " - 0s - loss: 142.3777 - val_loss: 92.1800\n",
      "Epoch 34/50\n",
      " - 0s - loss: 139.3230 - val_loss: 90.4459\n",
      "Epoch 35/50\n",
      " - 0s - loss: 138.2013 - val_loss: 86.4119\n",
      "Epoch 36/50\n",
      " - 0s - loss: 135.0154 - val_loss: 92.2018\n",
      "Epoch 37/50\n",
      " - 0s - loss: 132.1638 - val_loss: 94.1325\n",
      "Epoch 38/50\n",
      " - 0s - loss: 129.8797 - val_loss: 88.7536\n",
      "Epoch 39/50\n",
      " - 0s - loss: 128.1722 - val_loss: 95.9707\n",
      "Epoch 40/50\n",
      " - 0s - loss: 125.5730 - val_loss: 88.5501\n",
      "Epoch 41/50\n",
      " - 0s - loss: 124.1259 - val_loss: 95.7816\n",
      "Epoch 42/50\n",
      " - 0s - loss: 123.0363 - val_loss: 91.6408\n",
      "Epoch 43/50\n",
      " - 0s - loss: 120.9403 - val_loss: 95.5734\n",
      "Epoch 44/50\n",
      " - 0s - loss: 119.7920 - val_loss: 94.8711\n",
      "Epoch 45/50\n",
      " - 0s - loss: 119.2715 - val_loss: 85.5978\n",
      "Epoch 46/50\n",
      " - 0s - loss: 117.7589 - val_loss: 90.0898\n",
      "Epoch 47/50\n",
      " - 0s - loss: 115.1037 - val_loss: 91.5132\n",
      "Epoch 48/50\n",
      " - 0s - loss: 113.8620 - val_loss: 94.6899\n",
      "Epoch 49/50\n",
      " - 0s - loss: 113.0670 - val_loss: 89.3545\n",
      "Epoch 50/50\n",
      " - 0s - loss: 111.3642 - val_loss: 92.3211\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 554.3728 - val_loss: 232.1155\n",
      "Epoch 2/50\n",
      " - 0s - loss: 404.1996 - val_loss: 218.3737\n",
      "Epoch 3/50\n",
      " - 0s - loss: 370.3466 - val_loss: 212.2257\n",
      "Epoch 4/50\n",
      " - 0s - loss: 327.3619 - val_loss: 202.4983\n",
      "Epoch 5/50\n",
      " - 0s - loss: 292.5250 - val_loss: 195.1086\n",
      "Epoch 6/50\n",
      " - 0s - loss: 270.5448 - val_loss: 184.3819\n",
      "Epoch 7/50\n",
      " - 0s - loss: 252.2736 - val_loss: 184.9069\n",
      "Epoch 8/50\n",
      " - 0s - loss: 238.4206 - val_loss: 183.5719\n",
      "Epoch 9/50\n",
      " - 0s - loss: 229.6641 - val_loss: 191.5486\n",
      "Epoch 10/50\n",
      " - 0s - loss: 216.1548 - val_loss: 185.2408\n",
      "Epoch 11/50\n",
      " - 0s - loss: 206.7579 - val_loss: 183.3715\n",
      "Epoch 12/50\n",
      " - 0s - loss: 197.9257 - val_loss: 185.3992\n",
      "Epoch 13/50\n",
      " - 0s - loss: 192.7030 - val_loss: 179.7223\n",
      "Epoch 14/50\n",
      " - 0s - loss: 186.9953 - val_loss: 177.4205\n",
      "Epoch 15/50\n",
      " - 0s - loss: 179.9511 - val_loss: 172.7716\n",
      "Epoch 16/50\n",
      " - 0s - loss: 174.8924 - val_loss: 169.8833\n",
      "Epoch 17/50\n",
      " - 0s - loss: 169.8597 - val_loss: 163.8159\n",
      "Epoch 18/50\n",
      " - 0s - loss: 163.1825 - val_loss: 159.7178\n",
      "Epoch 19/50\n",
      " - 0s - loss: 159.1817 - val_loss: 162.1031\n",
      "Epoch 20/50\n",
      " - 0s - loss: 157.5848 - val_loss: 150.2833\n",
      "Epoch 21/50\n",
      " - 0s - loss: 153.5976 - val_loss: 144.8331\n",
      "Epoch 22/50\n",
      " - 0s - loss: 150.1239 - val_loss: 141.1760\n",
      "Epoch 23/50\n",
      " - 0s - loss: 147.5806 - val_loss: 136.0287\n",
      "Epoch 24/50\n",
      " - 0s - loss: 146.4528 - val_loss: 132.6092\n",
      "Epoch 25/50\n",
      " - 0s - loss: 141.3171 - val_loss: 128.6300\n",
      "Epoch 26/50\n",
      " - 0s - loss: 137.5734 - val_loss: 126.7193\n",
      "Epoch 27/50\n",
      " - 0s - loss: 137.9922 - val_loss: 126.0992\n",
      "Epoch 28/50\n",
      " - 0s - loss: 134.5375 - val_loss: 118.6398\n",
      "Epoch 29/50\n",
      " - 0s - loss: 132.4151 - val_loss: 115.9736\n",
      "Epoch 30/50\n",
      " - 0s - loss: 128.3928 - val_loss: 115.0009\n",
      "Epoch 31/50\n",
      " - 0s - loss: 126.7751 - val_loss: 111.7225\n",
      "Epoch 32/50\n",
      " - 0s - loss: 123.6344 - val_loss: 112.1803\n",
      "Epoch 33/50\n",
      " - 0s - loss: 124.2195 - val_loss: 118.8570\n",
      "Epoch 34/50\n",
      " - 0s - loss: 122.0242 - val_loss: 106.3457\n",
      "Epoch 35/50\n",
      " - 0s - loss: 119.8123 - val_loss: 105.2191\n",
      "Epoch 36/50\n",
      " - 0s - loss: 119.2056 - val_loss: 104.2370\n",
      "Epoch 37/50\n",
      " - 0s - loss: 117.7950 - val_loss: 101.9755\n",
      "Epoch 38/50\n",
      " - 0s - loss: 115.9332 - val_loss: 100.9093\n",
      "Epoch 39/50\n",
      " - 0s - loss: 114.4013 - val_loss: 99.8012\n",
      "Epoch 40/50\n",
      " - 0s - loss: 112.4546 - val_loss: 98.8570\n",
      "Epoch 41/50\n",
      " - 0s - loss: 112.3667 - val_loss: 97.4614\n",
      "Epoch 42/50\n",
      " - 0s - loss: 110.2502 - val_loss: 96.8797\n",
      "Epoch 43/50\n",
      " - 0s - loss: 109.6038 - val_loss: 96.3213\n",
      "Epoch 44/50\n",
      " - 0s - loss: 109.1067 - val_loss: 96.1129\n",
      "Epoch 45/50\n",
      " - 0s - loss: 108.0090 - val_loss: 95.0955\n",
      "Epoch 46/50\n",
      " - 0s - loss: 108.3481 - val_loss: 98.8894\n",
      "Epoch 47/50\n",
      " - 0s - loss: 110.6369 - val_loss: 98.3195\n",
      "Epoch 48/50\n",
      " - 0s - loss: 108.5780 - val_loss: 95.4628\n",
      "Epoch 49/50\n",
      " - 0s - loss: 105.2466 - val_loss: 94.3707\n",
      "Epoch 50/50\n",
      " - 0s - loss: 104.3863 - val_loss: 92.7813\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 15925.4061 - val_loss: 4035.5847\n",
      "Epoch 2/50\n",
      " - 0s - loss: 2383.2388 - val_loss: 1103.3507\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1332.3119 - val_loss: 766.9875\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1066.2375 - val_loss: 625.9958\n",
      "Epoch 5/50\n",
      " - 0s - loss: 931.6383 - val_loss: 557.3641\n",
      "Epoch 6/50\n",
      " - 0s - loss: 834.4329 - val_loss: 506.9044\n",
      "Epoch 7/50\n",
      " - 0s - loss: 759.4738 - val_loss: 472.7519\n",
      "Epoch 8/50\n",
      " - 0s - loss: 699.1176 - val_loss: 428.2548\n",
      "Epoch 9/50\n",
      " - 0s - loss: 653.0296 - val_loss: 399.6812\n",
      "Epoch 10/50\n",
      " - 0s - loss: 610.2722 - val_loss: 404.0636\n",
      "Epoch 11/50\n",
      " - 0s - loss: 572.5000 - val_loss: 358.6738\n",
      "Epoch 12/50\n",
      " - 0s - loss: 544.7964 - val_loss: 348.7754\n",
      "Epoch 13/50\n",
      " - 0s - loss: 517.3301 - val_loss: 331.2060\n",
      "Epoch 14/50\n",
      " - 0s - loss: 492.2645 - val_loss: 315.3976\n",
      "Epoch 15/50\n",
      " - 0s - loss: 470.6615 - val_loss: 293.0682\n",
      "Epoch 16/50\n",
      " - 0s - loss: 451.5062 - val_loss: 279.3975\n",
      "Epoch 17/50\n",
      " - 0s - loss: 430.3126 - val_loss: 280.1357\n",
      "Epoch 18/50\n",
      " - 0s - loss: 413.6086 - val_loss: 260.0708\n",
      "Epoch 19/50\n",
      " - 0s - loss: 390.9433 - val_loss: 246.7876\n",
      "Epoch 20/50\n",
      " - 0s - loss: 361.8993 - val_loss: 229.7947\n",
      "Epoch 21/50\n",
      " - 0s - loss: 333.9246 - val_loss: 198.5853\n",
      "Epoch 22/50\n",
      " - 0s - loss: 316.4650 - val_loss: 169.1832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      " - 0s - loss: 299.7125 - val_loss: 160.7758\n",
      "Epoch 24/50\n",
      " - 0s - loss: 286.6810 - val_loss: 153.6013\n",
      "Epoch 25/50\n",
      " - 0s - loss: 278.6457 - val_loss: 141.3315\n",
      "Epoch 26/50\n",
      " - 0s - loss: 268.7401 - val_loss: 150.0465\n",
      "Epoch 27/50\n",
      " - 0s - loss: 263.4474 - val_loss: 140.4593\n",
      "Epoch 28/50\n",
      " - 0s - loss: 254.4692 - val_loss: 123.0864\n",
      "Epoch 29/50\n",
      " - 0s - loss: 243.8382 - val_loss: 133.1184\n",
      "Epoch 30/50\n",
      " - 0s - loss: 234.7501 - val_loss: 115.9580\n",
      "Epoch 31/50\n",
      " - 0s - loss: 236.1763 - val_loss: 109.2408\n",
      "Epoch 32/50\n",
      " - 0s - loss: 222.4125 - val_loss: 107.5677\n",
      "Epoch 33/50\n",
      " - 0s - loss: 217.7611 - val_loss: 103.3012\n",
      "Epoch 34/50\n",
      " - 0s - loss: 208.4242 - val_loss: 101.2261\n",
      "Epoch 35/50\n",
      " - 0s - loss: 197.2989 - val_loss: 104.2449\n",
      "Epoch 36/50\n",
      " - 0s - loss: 183.7701 - val_loss: 105.6016\n",
      "Epoch 37/50\n",
      " - 0s - loss: 175.8377 - val_loss: 106.2283\n",
      "Epoch 38/50\n",
      " - 0s - loss: 171.0272 - val_loss: 104.9683\n",
      "Epoch 39/50\n",
      " - 0s - loss: 165.4390 - val_loss: 106.9960\n",
      "Epoch 40/50\n",
      " - 0s - loss: 161.2207 - val_loss: 109.6172\n",
      "Epoch 41/50\n",
      " - 0s - loss: 157.9256 - val_loss: 108.7150\n",
      "Epoch 42/50\n",
      " - 0s - loss: 155.3633 - val_loss: 105.9206\n",
      "Epoch 43/50\n",
      " - 0s - loss: 154.4205 - val_loss: 107.3764\n",
      "Epoch 44/50\n",
      " - 0s - loss: 154.7665 - val_loss: 111.5046\n",
      "Epoch 45/50\n",
      " - 0s - loss: 147.0233 - val_loss: 106.9495\n",
      "Epoch 46/50\n",
      " - 0s - loss: 147.7244 - val_loss: 108.0839\n",
      "Epoch 47/50\n",
      " - 0s - loss: 144.3504 - val_loss: 105.7784\n",
      "Epoch 48/50\n",
      " - 0s - loss: 144.0786 - val_loss: 106.3492\n",
      "Epoch 49/50\n",
      " - 0s - loss: 139.5084 - val_loss: 104.5950\n",
      "Epoch 50/50\n",
      " - 0s - loss: 134.9258 - val_loss: 106.4786\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 25810.6955 - val_loss: 6124.8111\n",
      "Epoch 2/50\n",
      " - 0s - loss: 2352.2977 - val_loss: 699.7711\n",
      "Epoch 3/50\n",
      " - 0s - loss: 730.8137 - val_loss: 673.7215\n",
      "Epoch 4/50\n",
      " - 0s - loss: 604.6493 - val_loss: 557.0054\n",
      "Epoch 5/50\n",
      " - 0s - loss: 507.8533 - val_loss: 506.6425\n",
      "Epoch 6/50\n",
      " - 0s - loss: 424.3055 - val_loss: 441.5908\n",
      "Epoch 7/50\n",
      " - 0s - loss: 349.1515 - val_loss: 357.6027\n",
      "Epoch 8/50\n",
      " - 0s - loss: 288.5066 - val_loss: 296.9033\n",
      "Epoch 9/50\n",
      " - 0s - loss: 249.3769 - val_loss: 252.7391\n",
      "Epoch 10/50\n",
      " - 0s - loss: 222.8012 - val_loss: 220.7770\n",
      "Epoch 11/50\n",
      " - 0s - loss: 202.3801 - val_loss: 195.7227\n",
      "Epoch 12/50\n",
      " - 0s - loss: 184.3719 - val_loss: 175.3763\n",
      "Epoch 13/50\n",
      " - 0s - loss: 171.7583 - val_loss: 157.8931\n",
      "Epoch 14/50\n",
      " - 0s - loss: 159.7951 - val_loss: 144.6599\n",
      "Epoch 15/50\n",
      " - 0s - loss: 149.7674 - val_loss: 133.3213\n",
      "Epoch 16/50\n",
      " - 0s - loss: 141.4881 - val_loss: 124.5921\n",
      "Epoch 17/50\n",
      " - 0s - loss: 135.3142 - val_loss: 112.9695\n",
      "Epoch 18/50\n",
      " - 0s - loss: 132.8790 - val_loss: 106.4994\n",
      "Epoch 19/50\n",
      " - 0s - loss: 122.6746 - val_loss: 102.5185\n",
      "Epoch 20/50\n",
      " - 0s - loss: 117.0589 - val_loss: 95.6355\n",
      "Epoch 21/50\n",
      " - 0s - loss: 115.2683 - val_loss: 92.6762\n",
      "Epoch 22/50\n",
      " - 0s - loss: 111.2782 - val_loss: 89.5565\n",
      "Epoch 23/50\n",
      " - 0s - loss: 105.4347 - val_loss: 82.4655\n",
      "Epoch 24/50\n",
      " - 0s - loss: 101.7927 - val_loss: 84.7042\n",
      "Epoch 25/50\n",
      " - 0s - loss: 100.0982 - val_loss: 79.7294\n",
      "Epoch 26/50\n",
      " - 0s - loss: 98.5249 - val_loss: 77.8045\n",
      "Epoch 27/50\n",
      " - 0s - loss: 96.4462 - val_loss: 76.5018\n",
      "Epoch 28/50\n",
      " - 0s - loss: 96.5001 - val_loss: 73.4786\n",
      "Epoch 29/50\n",
      " - 0s - loss: 94.2085 - val_loss: 79.5681\n",
      "Epoch 30/50\n",
      " - 0s - loss: 89.9982 - val_loss: 88.5774\n",
      "Epoch 31/50\n",
      " - 0s - loss: 90.9394 - val_loss: 70.1686\n",
      "Epoch 32/50\n",
      " - 0s - loss: 88.2325 - val_loss: 70.5523\n",
      "Epoch 33/50\n",
      " - 0s - loss: 87.0528 - val_loss: 70.8559\n",
      "Epoch 34/50\n",
      " - 0s - loss: 85.6947 - val_loss: 70.2437\n",
      "Epoch 35/50\n",
      " - 0s - loss: 85.8405 - val_loss: 72.7633\n",
      "Epoch 36/50\n",
      " - 0s - loss: 86.2422 - val_loss: 69.2792\n",
      "Epoch 37/50\n",
      " - 0s - loss: 84.2338 - val_loss: 66.6062\n",
      "Epoch 38/50\n",
      " - 0s - loss: 83.8023 - val_loss: 66.6624\n",
      "Epoch 39/50\n",
      " - 0s - loss: 81.9311 - val_loss: 65.6829\n",
      "Epoch 40/50\n",
      " - 0s - loss: 81.6758 - val_loss: 68.1858\n",
      "Epoch 41/50\n",
      " - 0s - loss: 80.8950 - val_loss: 67.2184\n",
      "Epoch 42/50\n",
      " - 0s - loss: 81.5617 - val_loss: 68.8710\n",
      "Epoch 43/50\n",
      " - 0s - loss: 80.3752 - val_loss: 63.6393\n",
      "Epoch 44/50\n",
      " - 0s - loss: 80.8612 - val_loss: 70.3389\n",
      "Epoch 45/50\n",
      " - 0s - loss: 82.4356 - val_loss: 69.0064\n",
      "Epoch 46/50\n",
      " - 0s - loss: 78.8804 - val_loss: 62.8389\n",
      "Epoch 47/50\n",
      " - 0s - loss: 78.4676 - val_loss: 64.2191\n",
      "Epoch 48/50\n",
      " - 0s - loss: 78.9651 - val_loss: 62.6370\n",
      "Epoch 49/50\n",
      " - 0s - loss: 79.3154 - val_loss: 65.9182\n",
      "Epoch 50/50\n",
      " - 0s - loss: 78.3766 - val_loss: 61.8144\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 4158.6864 - val_loss: 1932.7022\n",
      "Epoch 2/50\n",
      " - 0s - loss: 2152.9521 - val_loss: 1195.5217\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1485.5384 - val_loss: 775.0423\n",
      "Epoch 4/50\n",
      " - 0s - loss: 914.0215 - val_loss: 394.7036\n",
      "Epoch 5/50\n",
      " - 0s - loss: 594.4011 - val_loss: 293.3119\n",
      "Epoch 6/50\n",
      " - 0s - loss: 466.4663 - val_loss: 250.9045\n",
      "Epoch 7/50\n",
      " - 0s - loss: 395.9243 - val_loss: 246.7901\n",
      "Epoch 8/50\n",
      " - 0s - loss: 356.2302 - val_loss: 211.1127\n",
      "Epoch 9/50\n",
      " - 0s - loss: 327.7646 - val_loss: 205.2797\n",
      "Epoch 10/50\n",
      " - 0s - loss: 304.9524 - val_loss: 180.3052\n",
      "Epoch 11/50\n",
      " - 0s - loss: 282.5219 - val_loss: 176.0512\n",
      "Epoch 12/50\n",
      " - 0s - loss: 262.0942 - val_loss: 166.5376\n",
      "Epoch 13/50\n",
      " - 0s - loss: 245.8429 - val_loss: 136.5570\n",
      "Epoch 14/50\n",
      " - 0s - loss: 232.1862 - val_loss: 155.0462\n",
      "Epoch 15/50\n",
      " - 0s - loss: 218.4946 - val_loss: 122.8215\n",
      "Epoch 16/50\n",
      " - 0s - loss: 207.9154 - val_loss: 117.6997\n",
      "Epoch 17/50\n",
      " - 0s - loss: 203.2773 - val_loss: 117.9889\n",
      "Epoch 18/50\n",
      " - 0s - loss: 194.7724 - val_loss: 115.0629\n",
      "Epoch 19/50\n",
      " - 0s - loss: 185.7945 - val_loss: 104.4952\n",
      "Epoch 20/50\n",
      " - 0s - loss: 181.7155 - val_loss: 116.9154\n",
      "Epoch 21/50\n",
      " - 0s - loss: 177.9394 - val_loss: 117.6310\n",
      "Epoch 22/50\n",
      " - 0s - loss: 171.7729 - val_loss: 117.7816\n",
      "Epoch 23/50\n",
      " - 0s - loss: 168.3599 - val_loss: 110.2023\n",
      "Epoch 24/50\n",
      " - 0s - loss: 166.6325 - val_loss: 88.2957\n",
      "Epoch 25/50\n",
      " - 0s - loss: 163.2296 - val_loss: 86.8667\n",
      "Epoch 26/50\n",
      " - 0s - loss: 159.4026 - val_loss: 83.1226\n",
      "Epoch 27/50\n",
      " - 0s - loss: 160.5676 - val_loss: 93.4204\n",
      "Epoch 28/50\n",
      " - 0s - loss: 156.7901 - val_loss: 107.3035\n",
      "Epoch 29/50\n",
      " - 0s - loss: 155.2172 - val_loss: 97.8952\n",
      "Epoch 30/50\n",
      " - 0s - loss: 150.7244 - val_loss: 103.4179\n",
      "Epoch 31/50\n",
      " - 0s - loss: 150.4909 - val_loss: 88.0893\n",
      "Epoch 32/50\n",
      " - 0s - loss: 148.4475 - val_loss: 89.3887\n",
      "Epoch 33/50\n",
      " - 0s - loss: 147.0528 - val_loss: 89.3922\n",
      "Epoch 34/50\n",
      " - 0s - loss: 147.5819 - val_loss: 82.4284\n",
      "Epoch 35/50\n",
      " - 0s - loss: 149.4035 - val_loss: 134.0233\n",
      "Epoch 36/50\n",
      " - 0s - loss: 150.8954 - val_loss: 83.6115\n",
      "Epoch 37/50\n",
      " - 0s - loss: 144.4839 - val_loss: 83.3152\n",
      "Epoch 38/50\n",
      " - 0s - loss: 144.4402 - val_loss: 80.9560\n",
      "Epoch 39/50\n",
      " - 0s - loss: 144.4626 - val_loss: 92.3010\n",
      "Epoch 40/50\n",
      " - 0s - loss: 144.2757 - val_loss: 104.0310\n",
      "Epoch 41/50\n",
      " - 0s - loss: 143.1824 - val_loss: 87.3958\n",
      "Epoch 42/50\n",
      " - 0s - loss: 140.6324 - val_loss: 98.7149\n",
      "Epoch 43/50\n",
      " - 0s - loss: 138.7501 - val_loss: 92.1231\n",
      "Epoch 44/50\n",
      " - 0s - loss: 140.4102 - val_loss: 117.4363\n",
      "Epoch 45/50\n",
      " - 0s - loss: 140.4166 - val_loss: 84.7570\n",
      "Epoch 46/50\n",
      " - 0s - loss: 138.0168 - val_loss: 95.4146\n",
      "Epoch 47/50\n",
      " - 0s - loss: 138.0803 - val_loss: 85.8032\n",
      "Epoch 48/50\n",
      " - 0s - loss: 139.9549 - val_loss: 98.6985\n",
      "Epoch 49/50\n",
      " - 0s - loss: 138.6534 - val_loss: 83.2277\n",
      "Epoch 50/50\n",
      " - 0s - loss: 136.0528 - val_loss: 91.0741\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 17137.1425 - val_loss: 1477.0937\n",
      "Epoch 2/50\n",
      " - 0s - loss: 750.5899 - val_loss: 749.0984\n",
      "Epoch 3/50\n",
      " - 0s - loss: 527.3056 - val_loss: 343.4129\n",
      "Epoch 4/50\n",
      " - 0s - loss: 428.6614 - val_loss: 333.7036\n",
      "Epoch 5/50\n",
      " - 0s - loss: 405.6620 - val_loss: 328.6071\n",
      "Epoch 6/50\n",
      " - 0s - loss: 389.2998 - val_loss: 312.2121\n",
      "Epoch 7/50\n",
      " - 0s - loss: 373.9974 - val_loss: 301.5430\n",
      "Epoch 8/50\n",
      " - 0s - loss: 357.9867 - val_loss: 287.8994\n",
      "Epoch 9/50\n",
      " - 0s - loss: 343.7039 - val_loss: 276.3083\n",
      "Epoch 10/50\n",
      " - 0s - loss: 331.1166 - val_loss: 265.9940\n",
      "Epoch 11/50\n",
      " - 0s - loss: 317.6029 - val_loss: 258.6948\n",
      "Epoch 12/50\n",
      " - 0s - loss: 304.5587 - val_loss: 243.0290\n",
      "Epoch 13/50\n",
      " - 0s - loss: 291.3933 - val_loss: 236.0448\n",
      "Epoch 14/50\n",
      " - 0s - loss: 280.6523 - val_loss: 224.0027\n",
      "Epoch 15/50\n",
      " - 0s - loss: 271.6120 - val_loss: 212.9643\n",
      "Epoch 16/50\n",
      " - 0s - loss: 261.6436 - val_loss: 217.5094\n",
      "Epoch 17/50\n",
      " - 0s - loss: 249.6615 - val_loss: 203.1933\n",
      "Epoch 18/50\n",
      " - 0s - loss: 238.8346 - val_loss: 194.2557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      " - 0s - loss: 230.2063 - val_loss: 187.6079\n",
      "Epoch 20/50\n",
      " - 0s - loss: 219.8409 - val_loss: 189.5595\n",
      "Epoch 21/50\n",
      " - 0s - loss: 213.6368 - val_loss: 177.2365\n",
      "Epoch 22/50\n",
      " - 0s - loss: 203.7982 - val_loss: 162.4544\n",
      "Epoch 23/50\n",
      " - 0s - loss: 198.0261 - val_loss: 160.6115\n",
      "Epoch 24/50\n",
      " - 0s - loss: 189.2996 - val_loss: 153.3125\n",
      "Epoch 25/50\n",
      " - 0s - loss: 182.5948 - val_loss: 153.7721\n",
      "Epoch 26/50\n",
      " - 0s - loss: 176.1275 - val_loss: 147.5575\n",
      "Epoch 27/50\n",
      " - 0s - loss: 170.9843 - val_loss: 135.8106\n",
      "Epoch 28/50\n",
      " - 0s - loss: 166.9169 - val_loss: 134.2080\n",
      "Epoch 29/50\n",
      " - 0s - loss: 162.1323 - val_loss: 123.9145\n",
      "Epoch 30/50\n",
      " - 0s - loss: 157.6843 - val_loss: 123.8157\n",
      "Epoch 31/50\n",
      " - 0s - loss: 151.7434 - val_loss: 132.4846\n",
      "Epoch 32/50\n",
      " - 0s - loss: 148.6833 - val_loss: 119.0689\n",
      "Epoch 33/50\n",
      " - 0s - loss: 143.8179 - val_loss: 112.1127\n",
      "Epoch 34/50\n",
      " - 0s - loss: 141.6955 - val_loss: 107.1894\n",
      "Epoch 35/50\n",
      " - 0s - loss: 136.7664 - val_loss: 107.9840\n",
      "Epoch 36/50\n",
      " - 0s - loss: 133.9805 - val_loss: 100.9066\n",
      "Epoch 37/50\n",
      " - 0s - loss: 130.1103 - val_loss: 98.6732\n",
      "Epoch 38/50\n",
      " - 0s - loss: 127.5169 - val_loss: 96.8358\n",
      "Epoch 39/50\n",
      " - 0s - loss: 124.9325 - val_loss: 92.5548\n",
      "Epoch 40/50\n",
      " - 0s - loss: 122.1990 - val_loss: 93.2505\n",
      "Epoch 41/50\n",
      " - 0s - loss: 118.1051 - val_loss: 100.3291\n",
      "Epoch 42/50\n",
      " - 0s - loss: 116.1957 - val_loss: 90.5588\n",
      "Epoch 43/50\n",
      " - 0s - loss: 113.4159 - val_loss: 87.0376\n",
      "Epoch 44/50\n",
      " - 0s - loss: 111.7492 - val_loss: 87.5874\n",
      "Epoch 45/50\n",
      " - 0s - loss: 109.0743 - val_loss: 85.0092\n",
      "Epoch 46/50\n",
      " - 0s - loss: 107.9726 - val_loss: 90.0727\n",
      "Epoch 47/50\n",
      " - 0s - loss: 105.1327 - val_loss: 95.5688\n",
      "Epoch 48/50\n",
      " - 0s - loss: 104.3633 - val_loss: 101.7536\n",
      "Epoch 49/50\n",
      " - 0s - loss: 102.7305 - val_loss: 86.6241\n",
      "Epoch 50/50\n",
      " - 0s - loss: 101.3806 - val_loss: 91.1641\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 425.9091 - val_loss: 222.9123\n",
      "Epoch 2/50\n",
      " - 0s - loss: 323.2158 - val_loss: 197.2063\n",
      "Epoch 3/50\n",
      " - 0s - loss: 292.9955 - val_loss: 176.0354\n",
      "Epoch 4/50\n",
      " - 0s - loss: 277.4347 - val_loss: 162.0651\n",
      "Epoch 5/50\n",
      " - 0s - loss: 258.1835 - val_loss: 147.8221\n",
      "Epoch 6/50\n",
      " - 0s - loss: 240.9693 - val_loss: 146.9273\n",
      "Epoch 7/50\n",
      " - 0s - loss: 218.5081 - val_loss: 122.8648\n",
      "Epoch 8/50\n",
      " - 0s - loss: 198.2472 - val_loss: 99.9734\n",
      "Epoch 9/50\n",
      " - 0s - loss: 186.2352 - val_loss: 92.6279\n",
      "Epoch 10/50\n",
      " - 0s - loss: 171.5219 - val_loss: 101.7794\n",
      "Epoch 11/50\n",
      " - 0s - loss: 166.6340 - val_loss: 104.0427\n",
      "Epoch 12/50\n",
      " - 0s - loss: 158.6872 - val_loss: 121.0787\n",
      "Epoch 13/50\n",
      " - 0s - loss: 159.8562 - val_loss: 133.0704\n",
      "Epoch 14/50\n",
      " - 0s - loss: 157.2966 - val_loss: 88.6990\n",
      "Epoch 15/50\n",
      " - 0s - loss: 150.9368 - val_loss: 93.0297\n",
      "Epoch 16/50\n",
      " - 0s - loss: 148.0401 - val_loss: 87.8417\n",
      "Epoch 17/50\n",
      " - 0s - loss: 146.7193 - val_loss: 108.6636\n",
      "Epoch 18/50\n",
      " - 0s - loss: 143.9925 - val_loss: 91.8561\n",
      "Epoch 19/50\n",
      " - 0s - loss: 141.0354 - val_loss: 111.6343\n",
      "Epoch 20/50\n",
      " - 0s - loss: 139.8699 - val_loss: 98.3745\n",
      "Epoch 21/50\n",
      " - 0s - loss: 137.8523 - val_loss: 93.2469\n",
      "Epoch 22/50\n",
      " - 0s - loss: 137.7969 - val_loss: 106.4600\n",
      "Epoch 23/50\n",
      " - 0s - loss: 130.3961 - val_loss: 126.0466\n",
      "Epoch 24/50\n",
      " - 0s - loss: 131.7894 - val_loss: 117.4583\n",
      "Epoch 25/50\n",
      " - 0s - loss: 131.7061 - val_loss: 90.5313\n",
      "Epoch 26/50\n",
      " - 0s - loss: 131.9977 - val_loss: 90.5165\n",
      "Epoch 27/50\n",
      " - 0s - loss: 126.4611 - val_loss: 98.7295\n",
      "Epoch 28/50\n",
      " - 0s - loss: 126.5244 - val_loss: 98.1177\n",
      "Epoch 29/50\n",
      " - 0s - loss: 121.0336 - val_loss: 90.1188\n",
      "Epoch 30/50\n",
      " - 0s - loss: 121.0031 - val_loss: 101.9864\n",
      "Epoch 31/50\n",
      " - 0s - loss: 118.7066 - val_loss: 96.2864\n",
      "Epoch 32/50\n",
      " - 0s - loss: 117.7644 - val_loss: 93.5356\n",
      "Epoch 33/50\n",
      " - 0s - loss: 116.8057 - val_loss: 104.9476\n",
      "Epoch 34/50\n",
      " - 0s - loss: 113.9018 - val_loss: 91.6119\n",
      "Epoch 35/50\n",
      " - 0s - loss: 113.7309 - val_loss: 93.0855\n",
      "Epoch 36/50\n",
      " - 0s - loss: 112.2647 - val_loss: 96.0528\n",
      "Epoch 37/50\n",
      " - 0s - loss: 109.7682 - val_loss: 98.1360\n",
      "Epoch 38/50\n",
      " - 0s - loss: 108.8588 - val_loss: 99.2708\n",
      "Epoch 39/50\n",
      " - 0s - loss: 112.5124 - val_loss: 97.9925\n",
      "Epoch 40/50\n",
      " - 0s - loss: 105.4990 - val_loss: 99.3883\n",
      "Epoch 41/50\n",
      " - 0s - loss: 106.1361 - val_loss: 98.3304\n",
      "Epoch 42/50\n",
      " - 0s - loss: 105.5226 - val_loss: 96.5168\n",
      "Epoch 43/50\n",
      " - 0s - loss: 103.8037 - val_loss: 87.5622\n",
      "Epoch 44/50\n",
      " - 0s - loss: 106.0332 - val_loss: 105.0648\n",
      "Epoch 45/50\n",
      " - 0s - loss: 105.2912 - val_loss: 87.4618\n",
      "Epoch 46/50\n",
      " - 0s - loss: 101.2488 - val_loss: 99.7138\n",
      "Epoch 47/50\n",
      " - 0s - loss: 99.1411 - val_loss: 92.0298\n",
      "Epoch 48/50\n",
      " - 0s - loss: 96.6728 - val_loss: 90.1952\n",
      "Epoch 49/50\n",
      " - 0s - loss: 95.5904 - val_loss: 92.9379\n",
      "Epoch 50/50\n",
      " - 0s - loss: 94.8603 - val_loss: 96.7586\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 7989.9972 - val_loss: 2201.4662\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1277.1055 - val_loss: 316.6499\n",
      "Epoch 3/50\n",
      " - 0s - loss: 393.9566 - val_loss: 348.3907\n",
      "Epoch 4/50\n",
      " - 0s - loss: 353.9221 - val_loss: 271.0504\n",
      "Epoch 5/50\n",
      " - 0s - loss: 335.2423 - val_loss: 251.3869\n",
      "Epoch 6/50\n",
      " - 0s - loss: 321.1098 - val_loss: 242.0706\n",
      "Epoch 7/50\n",
      " - 0s - loss: 310.5294 - val_loss: 228.4237\n",
      "Epoch 8/50\n",
      " - 0s - loss: 301.7802 - val_loss: 218.8006\n",
      "Epoch 9/50\n",
      " - 0s - loss: 295.1963 - val_loss: 206.5023\n",
      "Epoch 10/50\n",
      " - 0s - loss: 291.5643 - val_loss: 199.9649\n",
      "Epoch 11/50\n",
      " - 0s - loss: 284.4254 - val_loss: 196.6984\n",
      "Epoch 12/50\n",
      " - 0s - loss: 280.3412 - val_loss: 194.6554\n",
      "Epoch 13/50\n",
      " - 0s - loss: 276.4893 - val_loss: 186.8288\n",
      "Epoch 14/50\n",
      " - 0s - loss: 275.0494 - val_loss: 187.9183\n",
      "Epoch 15/50\n",
      " - 0s - loss: 270.4091 - val_loss: 179.1760\n",
      "Epoch 16/50\n",
      " - 0s - loss: 267.7681 - val_loss: 175.4230\n",
      "Epoch 17/50\n",
      " - 0s - loss: 264.8202 - val_loss: 178.7480\n",
      "Epoch 18/50\n",
      " - 0s - loss: 262.7171 - val_loss: 166.6766\n",
      "Epoch 19/50\n",
      " - 0s - loss: 261.8892 - val_loss: 165.1846\n",
      "Epoch 20/50\n",
      " - 0s - loss: 256.8255 - val_loss: 171.1820\n",
      "Epoch 21/50\n",
      " - 0s - loss: 254.6104 - val_loss: 166.0050\n",
      "Epoch 22/50\n",
      " - 0s - loss: 252.2247 - val_loss: 162.0880\n",
      "Epoch 23/50\n",
      " - 0s - loss: 248.2048 - val_loss: 162.1298\n",
      "Epoch 24/50\n",
      " - 0s - loss: 245.0384 - val_loss: 149.1932\n",
      "Epoch 25/50\n",
      " - 0s - loss: 241.7395 - val_loss: 153.9911\n",
      "Epoch 26/50\n",
      " - 0s - loss: 237.5968 - val_loss: 141.8344\n",
      "Epoch 27/50\n",
      " - 0s - loss: 232.3347 - val_loss: 131.9589\n",
      "Epoch 28/50\n",
      " - 0s - loss: 220.7278 - val_loss: 123.2208\n",
      "Epoch 29/50\n",
      " - 0s - loss: 196.8590 - val_loss: 124.4677\n",
      "Epoch 30/50\n",
      " - 0s - loss: 172.1648 - val_loss: 111.7579\n",
      "Epoch 31/50\n",
      " - 0s - loss: 152.6051 - val_loss: 109.1344\n",
      "Epoch 32/50\n",
      " - 0s - loss: 138.3333 - val_loss: 102.4258\n",
      "Epoch 33/50\n",
      " - 0s - loss: 128.2661 - val_loss: 97.9647\n",
      "Epoch 34/50\n",
      " - 0s - loss: 120.7860 - val_loss: 109.9250\n",
      "Epoch 35/50\n",
      " - 0s - loss: 119.3989 - val_loss: 88.2036\n",
      "Epoch 36/50\n",
      " - 0s - loss: 107.9518 - val_loss: 104.3459\n",
      "Epoch 37/50\n",
      " - 0s - loss: 103.1335 - val_loss: 85.7747\n",
      "Epoch 38/50\n",
      " - 0s - loss: 99.7499 - val_loss: 88.1380\n",
      "Epoch 39/50\n",
      " - 0s - loss: 96.3908 - val_loss: 90.7114\n",
      "Epoch 40/50\n",
      " - 0s - loss: 93.1014 - val_loss: 81.9256\n",
      "Epoch 41/50\n",
      " - 0s - loss: 94.2329 - val_loss: 87.5020\n",
      "Epoch 42/50\n",
      " - 0s - loss: 94.1154 - val_loss: 82.1430\n",
      "Epoch 43/50\n",
      " - 0s - loss: 94.3413 - val_loss: 83.4062\n",
      "Epoch 44/50\n",
      " - 0s - loss: 91.8765 - val_loss: 82.6993\n",
      "Epoch 45/50\n",
      " - 0s - loss: 88.8667 - val_loss: 80.5170\n",
      "Epoch 46/50\n",
      " - 0s - loss: 90.5073 - val_loss: 85.5617\n",
      "Epoch 47/50\n",
      " - 0s - loss: 86.4886 - val_loss: 81.0408\n",
      "Epoch 48/50\n",
      " - 0s - loss: 87.8776 - val_loss: 79.7994\n",
      "Epoch 49/50\n",
      " - 0s - loss: 84.8795 - val_loss: 80.7308\n",
      "Epoch 50/50\n",
      " - 0s - loss: 86.9634 - val_loss: 79.2854\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 93918.9509 - val_loss: 40155.6688\n",
      "Epoch 2/50\n",
      " - 0s - loss: 20090.2295 - val_loss: 5981.6425\n",
      "Epoch 3/50\n",
      " - 0s - loss: 2228.1279 - val_loss: 457.3885\n",
      "Epoch 4/50\n",
      " - 0s - loss: 603.5873 - val_loss: 414.6856\n",
      "Epoch 5/50\n",
      " - 0s - loss: 532.0771 - val_loss: 365.9199\n",
      "Epoch 6/50\n",
      " - 0s - loss: 479.0799 - val_loss: 340.2315\n",
      "Epoch 7/50\n",
      " - 0s - loss: 444.5927 - val_loss: 315.6643\n",
      "Epoch 8/50\n",
      " - 0s - loss: 413.6556 - val_loss: 293.6047\n",
      "Epoch 9/50\n",
      " - 0s - loss: 385.2801 - val_loss: 277.4221\n",
      "Epoch 10/50\n",
      " - 0s - loss: 361.0621 - val_loss: 263.6327\n",
      "Epoch 11/50\n",
      " - 0s - loss: 338.4724 - val_loss: 248.2456\n",
      "Epoch 12/50\n",
      " - 0s - loss: 318.7493 - val_loss: 238.6024\n",
      "Epoch 13/50\n",
      " - 0s - loss: 304.4976 - val_loss: 227.1965\n",
      "Epoch 14/50\n",
      " - 0s - loss: 291.7470 - val_loss: 217.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      " - 0s - loss: 281.2069 - val_loss: 212.2289\n",
      "Epoch 16/50\n",
      " - 0s - loss: 271.6339 - val_loss: 204.7421\n",
      "Epoch 17/50\n",
      " - 0s - loss: 264.2777 - val_loss: 196.2117\n",
      "Epoch 18/50\n",
      " - 0s - loss: 256.7584 - val_loss: 192.4542\n",
      "Epoch 19/50\n",
      " - 0s - loss: 251.1755 - val_loss: 185.4642\n",
      "Epoch 20/50\n",
      " - 0s - loss: 245.4919 - val_loss: 183.0276\n",
      "Epoch 21/50\n",
      " - 0s - loss: 240.1155 - val_loss: 182.2865\n",
      "Epoch 22/50\n",
      " - 0s - loss: 234.6203 - val_loss: 178.3615\n",
      "Epoch 23/50\n",
      " - 0s - loss: 230.9373 - val_loss: 172.9982\n",
      "Epoch 24/50\n",
      " - 0s - loss: 227.5852 - val_loss: 170.8763\n",
      "Epoch 25/50\n",
      " - 0s - loss: 222.9860 - val_loss: 171.7070\n",
      "Epoch 26/50\n",
      " - 0s - loss: 218.5387 - val_loss: 173.0962\n",
      "Epoch 27/50\n",
      " - 0s - loss: 213.6535 - val_loss: 169.6575\n",
      "Epoch 28/50\n",
      " - 0s - loss: 210.9413 - val_loss: 168.9504\n",
      "Epoch 29/50\n",
      " - 0s - loss: 206.6317 - val_loss: 174.0329\n",
      "Epoch 30/50\n",
      " - 0s - loss: 204.3001 - val_loss: 170.9537\n",
      "Epoch 31/50\n",
      " - 0s - loss: 201.4970 - val_loss: 170.8690\n",
      "Epoch 32/50\n",
      " - 0s - loss: 198.5885 - val_loss: 166.7703\n",
      "Epoch 33/50\n",
      " - 0s - loss: 196.1201 - val_loss: 164.9278\n",
      "Epoch 34/50\n",
      " - 0s - loss: 193.6693 - val_loss: 169.4728\n",
      "Epoch 35/50\n",
      " - 0s - loss: 192.1638 - val_loss: 161.0461\n",
      "Epoch 36/50\n",
      " - 0s - loss: 190.5147 - val_loss: 157.9937\n",
      "Epoch 37/50\n",
      " - 0s - loss: 188.6067 - val_loss: 177.6258\n",
      "Epoch 38/50\n",
      " - 0s - loss: 184.6942 - val_loss: 158.9895\n",
      "Epoch 39/50\n",
      " - 0s - loss: 183.4236 - val_loss: 160.8292\n",
      "Epoch 40/50\n",
      " - 0s - loss: 181.1216 - val_loss: 177.1447\n",
      "Epoch 41/50\n",
      " - 0s - loss: 179.4537 - val_loss: 162.2930\n",
      "Epoch 42/50\n",
      " - 0s - loss: 178.1315 - val_loss: 162.1568\n",
      "Epoch 43/50\n",
      " - 0s - loss: 175.0138 - val_loss: 160.4509\n",
      "Epoch 44/50\n",
      " - 0s - loss: 173.8140 - val_loss: 148.8111\n",
      "Epoch 45/50\n",
      " - 0s - loss: 173.8095 - val_loss: 177.6034\n",
      "Epoch 46/50\n",
      " - 0s - loss: 171.4714 - val_loss: 164.0205\n",
      "Epoch 47/50\n",
      " - 0s - loss: 167.2530 - val_loss: 147.5281\n",
      "Epoch 48/50\n",
      " - 0s - loss: 165.1112 - val_loss: 167.9168\n",
      "Epoch 49/50\n",
      " - 0s - loss: 166.2385 - val_loss: 149.1660\n",
      "Epoch 50/50\n",
      " - 0s - loss: 160.8862 - val_loss: 136.7174\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 19832.2680 - val_loss: 1699.2132\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1332.2796 - val_loss: 995.2144\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1010.4857 - val_loss: 603.6775\n",
      "Epoch 4/50\n",
      " - 0s - loss: 839.3494 - val_loss: 549.5827\n",
      "Epoch 5/50\n",
      " - 0s - loss: 769.8671 - val_loss: 505.2676\n",
      "Epoch 6/50\n",
      " - 0s - loss: 708.7240 - val_loss: 447.4989\n",
      "Epoch 7/50\n",
      " - 0s - loss: 651.8719 - val_loss: 408.2043\n",
      "Epoch 8/50\n",
      " - 0s - loss: 598.8592 - val_loss: 372.5629\n",
      "Epoch 9/50\n",
      " - 0s - loss: 552.6056 - val_loss: 347.1967\n",
      "Epoch 10/50\n",
      " - 0s - loss: 510.2111 - val_loss: 316.5563\n",
      "Epoch 11/50\n",
      " - 0s - loss: 472.8021 - val_loss: 288.5558\n",
      "Epoch 12/50\n",
      " - 0s - loss: 438.0282 - val_loss: 268.0513\n",
      "Epoch 13/50\n",
      " - 0s - loss: 404.7292 - val_loss: 246.0233\n",
      "Epoch 14/50\n",
      " - 0s - loss: 375.5211 - val_loss: 231.9528\n",
      "Epoch 15/50\n",
      " - 0s - loss: 350.2443 - val_loss: 212.1988\n",
      "Epoch 16/50\n",
      " - 0s - loss: 323.3903 - val_loss: 190.3982\n",
      "Epoch 17/50\n",
      " - 0s - loss: 303.0323 - val_loss: 178.8101\n",
      "Epoch 18/50\n",
      " - 0s - loss: 282.3020 - val_loss: 164.1108\n",
      "Epoch 19/50\n",
      " - 0s - loss: 262.8671 - val_loss: 150.5202\n",
      "Epoch 20/50\n",
      " - 0s - loss: 246.7057 - val_loss: 138.5130\n",
      "Epoch 21/50\n",
      " - 0s - loss: 232.5862 - val_loss: 128.3508\n",
      "Epoch 22/50\n",
      " - 0s - loss: 218.5259 - val_loss: 124.3011\n",
      "Epoch 23/50\n",
      " - 0s - loss: 207.1085 - val_loss: 118.5204\n",
      "Epoch 24/50\n",
      " - 0s - loss: 196.2897 - val_loss: 108.8815\n",
      "Epoch 25/50\n",
      " - 0s - loss: 185.8726 - val_loss: 102.9610\n",
      "Epoch 26/50\n",
      " - 0s - loss: 177.5180 - val_loss: 98.6122\n",
      "Epoch 27/50\n",
      " - 0s - loss: 170.2601 - val_loss: 95.2356\n",
      "Epoch 28/50\n",
      " - 0s - loss: 164.0985 - val_loss: 90.7764\n",
      "Epoch 29/50\n",
      " - 0s - loss: 158.1572 - val_loss: 88.0960\n",
      "Epoch 30/50\n",
      " - 0s - loss: 154.6525 - val_loss: 85.1018\n",
      "Epoch 31/50\n",
      " - 0s - loss: 148.2518 - val_loss: 84.5594\n",
      "Epoch 32/50\n",
      " - 0s - loss: 143.9630 - val_loss: 82.2919\n",
      "Epoch 33/50\n",
      " - 0s - loss: 140.8249 - val_loss: 81.7781\n",
      "Epoch 34/50\n",
      " - 0s - loss: 137.0708 - val_loss: 79.0213\n",
      "Epoch 35/50\n",
      " - 0s - loss: 134.4587 - val_loss: 78.1912\n",
      "Epoch 36/50\n",
      " - 0s - loss: 132.5302 - val_loss: 76.9301\n",
      "Epoch 37/50\n",
      " - 0s - loss: 129.8092 - val_loss: 75.8042\n",
      "Epoch 38/50\n",
      " - 0s - loss: 127.6524 - val_loss: 79.0315\n",
      "Epoch 39/50\n",
      " - 0s - loss: 126.8344 - val_loss: 74.9714\n",
      "Epoch 40/50\n",
      " - 0s - loss: 124.7692 - val_loss: 75.4547\n",
      "Epoch 41/50\n",
      " - 0s - loss: 123.4819 - val_loss: 74.1475\n",
      "Epoch 42/50\n",
      " - 0s - loss: 122.3256 - val_loss: 74.2216\n",
      "Epoch 43/50\n",
      " - 0s - loss: 121.0942 - val_loss: 73.8413\n",
      "Epoch 44/50\n",
      " - 0s - loss: 120.0208 - val_loss: 74.1644\n",
      "Epoch 45/50\n",
      " - 0s - loss: 119.7468 - val_loss: 73.9699\n",
      "Epoch 46/50\n",
      " - 0s - loss: 118.8826 - val_loss: 73.2707\n",
      "Epoch 47/50\n",
      " - 0s - loss: 119.1336 - val_loss: 73.4198\n",
      "Epoch 48/50\n",
      " - 0s - loss: 117.6900 - val_loss: 75.9145\n",
      "Epoch 49/50\n",
      " - 0s - loss: 119.6593 - val_loss: 75.2501\n",
      "Epoch 50/50\n",
      " - 0s - loss: 117.9336 - val_loss: 73.9335\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 19857.3631 - val_loss: 2878.3872\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1749.7223 - val_loss: 909.8555\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1128.8383 - val_loss: 570.7502\n",
      "Epoch 4/50\n",
      " - 0s - loss: 777.5478 - val_loss: 466.4131\n",
      "Epoch 5/50\n",
      " - 0s - loss: 574.4886 - val_loss: 383.8565\n",
      "Epoch 6/50\n",
      " - 0s - loss: 449.1982 - val_loss: 323.8728\n",
      "Epoch 7/50\n",
      " - 0s - loss: 356.1945 - val_loss: 274.5162\n",
      "Epoch 8/50\n",
      " - 0s - loss: 281.6968 - val_loss: 241.6539\n",
      "Epoch 9/50\n",
      " - 0s - loss: 224.7615 - val_loss: 228.1718\n",
      "Epoch 10/50\n",
      " - 0s - loss: 193.6581 - val_loss: 220.8648\n",
      "Epoch 11/50\n",
      " - 0s - loss: 177.3162 - val_loss: 211.5463\n",
      "Epoch 12/50\n",
      " - 0s - loss: 167.4486 - val_loss: 205.6424\n",
      "Epoch 13/50\n",
      " - 0s - loss: 158.8688 - val_loss: 192.4624\n",
      "Epoch 14/50\n",
      " - 0s - loss: 152.6909 - val_loss: 183.2454\n",
      "Epoch 15/50\n",
      " - 0s - loss: 148.3277 - val_loss: 183.1781\n",
      "Epoch 16/50\n",
      " - 0s - loss: 144.5950 - val_loss: 168.1005\n",
      "Epoch 17/50\n",
      " - 0s - loss: 140.2002 - val_loss: 163.3094\n",
      "Epoch 18/50\n",
      " - 0s - loss: 136.6874 - val_loss: 156.7699\n",
      "Epoch 19/50\n",
      " - 0s - loss: 133.3585 - val_loss: 150.6133\n",
      "Epoch 20/50\n",
      " - 0s - loss: 130.0774 - val_loss: 149.3988\n",
      "Epoch 21/50\n",
      " - 0s - loss: 127.6258 - val_loss: 139.9853\n",
      "Epoch 22/50\n",
      " - 0s - loss: 125.2075 - val_loss: 128.2369\n",
      "Epoch 23/50\n",
      " - 0s - loss: 121.6011 - val_loss: 121.2100\n",
      "Epoch 24/50\n",
      " - 0s - loss: 117.8428 - val_loss: 115.6173\n",
      "Epoch 25/50\n",
      " - 0s - loss: 114.3312 - val_loss: 115.2875\n",
      "Epoch 26/50\n",
      " - 0s - loss: 111.8928 - val_loss: 113.4471\n",
      "Epoch 27/50\n",
      " - 0s - loss: 111.1058 - val_loss: 109.2692\n",
      "Epoch 28/50\n",
      " - 0s - loss: 108.6836 - val_loss: 104.2659\n",
      "Epoch 29/50\n",
      " - 0s - loss: 107.1366 - val_loss: 102.6275\n",
      "Epoch 30/50\n",
      " - 0s - loss: 105.6377 - val_loss: 100.6570\n",
      "Epoch 31/50\n",
      " - 0s - loss: 104.0473 - val_loss: 99.5396\n",
      "Epoch 32/50\n",
      " - 0s - loss: 103.1086 - val_loss: 96.8918\n",
      "Epoch 33/50\n",
      " - 0s - loss: 102.4328 - val_loss: 94.3864\n",
      "Epoch 34/50\n",
      " - 0s - loss: 100.6598 - val_loss: 96.2691\n",
      "Epoch 35/50\n",
      " - 0s - loss: 100.2444 - val_loss: 97.7722\n",
      "Epoch 36/50\n",
      " - 0s - loss: 100.1747 - val_loss: 91.8106\n",
      "Epoch 37/50\n",
      " - 0s - loss: 97.7402 - val_loss: 98.7163\n",
      "Epoch 38/50\n",
      " - 0s - loss: 97.9337 - val_loss: 93.0487\n",
      "Epoch 39/50\n",
      " - 0s - loss: 96.7795 - val_loss: 90.6816\n",
      "Epoch 40/50\n",
      " - 0s - loss: 95.7530 - val_loss: 88.5199\n",
      "Epoch 41/50\n",
      " - 0s - loss: 96.4037 - val_loss: 87.6457\n",
      "Epoch 42/50\n",
      " - 0s - loss: 95.0244 - val_loss: 86.1817\n",
      "Epoch 43/50\n",
      " - 0s - loss: 93.8512 - val_loss: 86.2182\n",
      "Epoch 44/50\n",
      " - 0s - loss: 93.4253 - val_loss: 86.6895\n",
      "Epoch 45/50\n",
      " - 0s - loss: 93.1620 - val_loss: 86.4928\n",
      "Epoch 46/50\n",
      " - 0s - loss: 92.7938 - val_loss: 87.3497\n",
      "Epoch 47/50\n",
      " - 0s - loss: 92.5472 - val_loss: 85.7038\n",
      "Epoch 48/50\n",
      " - 0s - loss: 91.6140 - val_loss: 81.2704\n",
      "Epoch 49/50\n",
      " - 0s - loss: 91.1975 - val_loss: 82.1052\n",
      "Epoch 50/50\n",
      " - 0s - loss: 90.5723 - val_loss: 82.5659\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 748.4318 - val_loss: 279.9356\n",
      "Epoch 2/50\n",
      " - 0s - loss: 287.2351 - val_loss: 180.7105\n",
      "Epoch 3/50\n",
      " - 0s - loss: 261.3613 - val_loss: 173.4383\n",
      "Epoch 4/50\n",
      " - 0s - loss: 246.8170 - val_loss: 153.8917\n",
      "Epoch 5/50\n",
      " - 0s - loss: 232.5395 - val_loss: 149.5385\n",
      "Epoch 6/50\n",
      " - 0s - loss: 214.7533 - val_loss: 140.7341\n",
      "Epoch 7/50\n",
      " - 0s - loss: 199.0358 - val_loss: 119.0982\n",
      "Epoch 8/50\n",
      " - 0s - loss: 182.6840 - val_loss: 111.8304\n",
      "Epoch 9/50\n",
      " - 0s - loss: 170.8427 - val_loss: 120.7665\n",
      "Epoch 10/50\n",
      " - 0s - loss: 156.6353 - val_loss: 102.4017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      " - 0s - loss: 147.5564 - val_loss: 101.9272\n",
      "Epoch 12/50\n",
      " - 0s - loss: 141.0017 - val_loss: 107.4922\n",
      "Epoch 13/50\n",
      " - 0s - loss: 132.9421 - val_loss: 116.8175\n",
      "Epoch 14/50\n",
      " - 0s - loss: 128.5449 - val_loss: 105.4844\n",
      "Epoch 15/50\n",
      " - 0s - loss: 123.7108 - val_loss: 84.3648\n",
      "Epoch 16/50\n",
      " - 0s - loss: 122.8107 - val_loss: 100.0420\n",
      "Epoch 17/50\n",
      " - 0s - loss: 121.1321 - val_loss: 82.8246\n",
      "Epoch 18/50\n",
      " - 0s - loss: 112.6830 - val_loss: 82.4395\n",
      "Epoch 19/50\n",
      " - 0s - loss: 110.7336 - val_loss: 82.8994\n",
      "Epoch 20/50\n",
      " - 0s - loss: 108.7080 - val_loss: 79.5178\n",
      "Epoch 21/50\n",
      " - 0s - loss: 107.0103 - val_loss: 78.7673\n",
      "Epoch 22/50\n",
      " - 0s - loss: 104.9293 - val_loss: 91.2040\n",
      "Epoch 23/50\n",
      " - 0s - loss: 102.2694 - val_loss: 77.3971\n",
      "Epoch 24/50\n",
      " - 0s - loss: 102.2961 - val_loss: 102.8383\n",
      "Epoch 25/50\n",
      " - 0s - loss: 106.0222 - val_loss: 90.0937\n",
      "Epoch 26/50\n",
      " - 0s - loss: 98.6922 - val_loss: 81.0418\n",
      "Epoch 27/50\n",
      " - 0s - loss: 97.0035 - val_loss: 80.7593\n",
      "Epoch 28/50\n",
      " - 0s - loss: 96.8101 - val_loss: 80.7460\n",
      "Epoch 29/50\n",
      " - 0s - loss: 97.4873 - val_loss: 74.6316\n",
      "Epoch 30/50\n",
      " - 0s - loss: 96.8417 - val_loss: 82.8999\n",
      "Epoch 31/50\n",
      " - 0s - loss: 92.2871 - val_loss: 72.5836\n",
      "Epoch 32/50\n",
      " - 0s - loss: 90.1986 - val_loss: 71.0206\n",
      "Epoch 33/50\n",
      " - 0s - loss: 89.9912 - val_loss: 77.5187\n",
      "Epoch 34/50\n",
      " - 0s - loss: 87.7628 - val_loss: 71.2528\n",
      "Epoch 35/50\n",
      " - 0s - loss: 88.7723 - val_loss: 115.2344\n",
      "Epoch 36/50\n",
      " - 0s - loss: 90.5679 - val_loss: 77.9887\n",
      "Epoch 37/50\n",
      " - 0s - loss: 84.4871 - val_loss: 72.6982\n",
      "Epoch 38/50\n",
      " - 0s - loss: 83.4705 - val_loss: 77.9729\n",
      "Epoch 39/50\n",
      " - 0s - loss: 81.6517 - val_loss: 77.8704\n",
      "Epoch 40/50\n",
      " - 0s - loss: 78.3686 - val_loss: 63.3312\n",
      "Epoch 41/50\n",
      " - 0s - loss: 76.5618 - val_loss: 75.9931\n",
      "Epoch 42/50\n",
      " - 0s - loss: 75.7725 - val_loss: 70.2948\n",
      "Epoch 43/50\n",
      " - 0s - loss: 74.1530 - val_loss: 66.0743\n",
      "Epoch 44/50\n",
      " - 0s - loss: 73.5034 - val_loss: 68.5826\n",
      "Epoch 45/50\n",
      " - 0s - loss: 73.8731 - val_loss: 98.9213\n",
      "Epoch 46/50\n",
      " - 0s - loss: 74.8619 - val_loss: 62.9814\n",
      "Epoch 47/50\n",
      " - 0s - loss: 68.9490 - val_loss: 69.1087\n",
      "Epoch 48/50\n",
      " - 0s - loss: 68.8701 - val_loss: 59.2981\n",
      "Epoch 49/50\n",
      " - 0s - loss: 68.6112 - val_loss: 63.2650\n",
      "Epoch 50/50\n",
      " - 0s - loss: 70.3031 - val_loss: 59.4865\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 2601.1607 - val_loss: 576.9644\n",
      "Epoch 2/50\n",
      " - 0s - loss: 483.8651 - val_loss: 321.7647\n",
      "Epoch 3/50\n",
      " - 0s - loss: 376.9316 - val_loss: 297.2178\n",
      "Epoch 4/50\n",
      " - 0s - loss: 357.0060 - val_loss: 271.2792\n",
      "Epoch 5/50\n",
      " - 0s - loss: 344.5028 - val_loss: 262.6658\n",
      "Epoch 6/50\n",
      " - 0s - loss: 334.3260 - val_loss: 255.0240\n",
      "Epoch 7/50\n",
      " - 0s - loss: 324.3789 - val_loss: 242.9311\n",
      "Epoch 8/50\n",
      " - 0s - loss: 315.0367 - val_loss: 233.5608\n",
      "Epoch 9/50\n",
      " - 0s - loss: 306.5308 - val_loss: 224.9081\n",
      "Epoch 10/50\n",
      " - 0s - loss: 298.5957 - val_loss: 220.5143\n",
      "Epoch 11/50\n",
      " - 0s - loss: 290.8637 - val_loss: 212.5838\n",
      "Epoch 12/50\n",
      " - 0s - loss: 283.2813 - val_loss: 206.3844\n",
      "Epoch 13/50\n",
      " - 0s - loss: 277.0893 - val_loss: 198.8392\n",
      "Epoch 14/50\n",
      " - 0s - loss: 270.3384 - val_loss: 194.5417\n",
      "Epoch 15/50\n",
      " - 0s - loss: 264.0591 - val_loss: 190.6783\n",
      "Epoch 16/50\n",
      " - 0s - loss: 258.5278 - val_loss: 181.7270\n",
      "Epoch 17/50\n",
      " - 0s - loss: 253.8276 - val_loss: 183.3168\n",
      "Epoch 18/50\n",
      " - 0s - loss: 247.6435 - val_loss: 166.9719\n",
      "Epoch 19/50\n",
      " - 0s - loss: 242.7094 - val_loss: 171.1645\n",
      "Epoch 20/50\n",
      " - 0s - loss: 236.5881 - val_loss: 160.3688\n",
      "Epoch 21/50\n",
      " - 0s - loss: 234.2398 - val_loss: 151.8031\n",
      "Epoch 22/50\n",
      " - 0s - loss: 229.4469 - val_loss: 157.6671\n",
      "Epoch 23/50\n",
      " - 0s - loss: 220.7441 - val_loss: 144.7194\n",
      "Epoch 24/50\n",
      " - 0s - loss: 216.2320 - val_loss: 146.8842\n",
      "Epoch 25/50\n",
      " - 0s - loss: 210.7436 - val_loss: 136.7975\n",
      "Epoch 26/50\n",
      " - 0s - loss: 207.3295 - val_loss: 137.8195\n",
      "Epoch 27/50\n",
      " - 0s - loss: 200.2322 - val_loss: 134.8016\n",
      "Epoch 28/50\n",
      " - 0s - loss: 194.9858 - val_loss: 126.5690\n",
      "Epoch 29/50\n",
      " - 0s - loss: 189.0895 - val_loss: 127.0167\n",
      "Epoch 30/50\n",
      " - 0s - loss: 183.6692 - val_loss: 120.0864\n",
      "Epoch 31/50\n",
      " - 0s - loss: 179.0188 - val_loss: 124.3710\n",
      "Epoch 32/50\n",
      " - 0s - loss: 173.5425 - val_loss: 121.7506\n",
      "Epoch 33/50\n",
      " - 0s - loss: 167.4611 - val_loss: 105.9313\n",
      "Epoch 34/50\n",
      " - 0s - loss: 162.3064 - val_loss: 118.2246\n",
      "Epoch 35/50\n",
      " - 0s - loss: 156.6707 - val_loss: 109.2510\n",
      "Epoch 36/50\n",
      " - 0s - loss: 150.6418 - val_loss: 107.6123\n",
      "Epoch 37/50\n",
      " - 0s - loss: 144.8616 - val_loss: 105.7161\n",
      "Epoch 38/50\n",
      " - 0s - loss: 139.9575 - val_loss: 100.6230\n",
      "Epoch 39/50\n",
      " - 0s - loss: 134.0826 - val_loss: 90.6927\n",
      "Epoch 40/50\n",
      " - 0s - loss: 132.1113 - val_loss: 89.8207\n",
      "Epoch 41/50\n",
      " - 0s - loss: 125.7668 - val_loss: 92.6043\n",
      "Epoch 42/50\n",
      " - 0s - loss: 120.6395 - val_loss: 103.9698\n",
      "Epoch 43/50\n",
      " - 0s - loss: 119.1329 - val_loss: 91.0556\n",
      "Epoch 44/50\n",
      " - 0s - loss: 114.6422 - val_loss: 91.7190\n",
      "Epoch 45/50\n",
      " - 0s - loss: 111.8000 - val_loss: 96.7301\n",
      "Epoch 46/50\n",
      " - 0s - loss: 111.6116 - val_loss: 88.7689\n",
      "Epoch 47/50\n",
      " - 0s - loss: 107.5141 - val_loss: 89.6626\n",
      "Epoch 48/50\n",
      " - 0s - loss: 105.3863 - val_loss: 89.0395\n",
      "Epoch 49/50\n",
      " - 0s - loss: 103.8409 - val_loss: 91.5787\n",
      "Epoch 50/50\n",
      " - 0s - loss: 102.2211 - val_loss: 95.5920\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 311.1794 - val_loss: 157.8228\n",
      "Epoch 2/50\n",
      " - 0s - loss: 245.2913 - val_loss: 143.5935\n",
      "Epoch 3/50\n",
      " - 0s - loss: 228.6605 - val_loss: 138.0656\n",
      "Epoch 4/50\n",
      " - 0s - loss: 216.8467 - val_loss: 117.2129\n",
      "Epoch 5/50\n",
      " - 0s - loss: 206.1274 - val_loss: 106.2004\n",
      "Epoch 6/50\n",
      " - 0s - loss: 197.0557 - val_loss: 107.3284\n",
      "Epoch 7/50\n",
      " - 0s - loss: 191.0727 - val_loss: 104.5265\n",
      "Epoch 8/50\n",
      " - 0s - loss: 183.7808 - val_loss: 101.3795\n",
      "Epoch 9/50\n",
      " - 0s - loss: 179.2717 - val_loss: 90.7393\n",
      "Epoch 10/50\n",
      " - 0s - loss: 175.2272 - val_loss: 96.7496\n",
      "Epoch 11/50\n",
      " - 0s - loss: 170.7476 - val_loss: 87.6492\n",
      "Epoch 12/50\n",
      " - 0s - loss: 168.1895 - val_loss: 87.7075\n",
      "Epoch 13/50\n",
      " - 0s - loss: 168.4111 - val_loss: 84.3672\n",
      "Epoch 14/50\n",
      " - 0s - loss: 162.9641 - val_loss: 76.7871\n",
      "Epoch 15/50\n",
      " - 0s - loss: 158.1326 - val_loss: 80.7576\n",
      "Epoch 16/50\n",
      " - 0s - loss: 154.9591 - val_loss: 74.6279\n",
      "Epoch 17/50\n",
      " - 0s - loss: 151.9453 - val_loss: 79.7490\n",
      "Epoch 18/50\n",
      " - 0s - loss: 147.6391 - val_loss: 78.4010\n",
      "Epoch 19/50\n",
      " - 0s - loss: 144.2875 - val_loss: 75.5149\n",
      "Epoch 20/50\n",
      " - 0s - loss: 141.9225 - val_loss: 74.1664\n",
      "Epoch 21/50\n",
      " - 0s - loss: 140.4512 - val_loss: 75.5153\n",
      "Epoch 22/50\n",
      " - 0s - loss: 138.1656 - val_loss: 78.0317\n",
      "Epoch 23/50\n",
      " - 0s - loss: 137.2487 - val_loss: 74.2620\n",
      "Epoch 24/50\n",
      " - 0s - loss: 135.4183 - val_loss: 79.6664\n",
      "Epoch 25/50\n",
      " - 0s - loss: 135.8557 - val_loss: 77.1432\n",
      "Epoch 26/50\n",
      " - 0s - loss: 133.0743 - val_loss: 77.0157\n",
      "Epoch 27/50\n",
      " - 0s - loss: 132.9425 - val_loss: 74.6097\n",
      "Epoch 28/50\n",
      " - 0s - loss: 131.4629 - val_loss: 74.3656\n",
      "Epoch 29/50\n",
      " - 0s - loss: 130.5571 - val_loss: 80.6434\n",
      "Epoch 30/50\n",
      " - 0s - loss: 129.6913 - val_loss: 74.8983\n",
      "Epoch 31/50\n",
      " - 0s - loss: 131.1283 - val_loss: 78.4828\n",
      "Epoch 32/50\n",
      " - 0s - loss: 128.0037 - val_loss: 79.8497\n",
      "Epoch 33/50\n",
      " - 0s - loss: 127.3611 - val_loss: 80.4696\n",
      "Epoch 34/50\n",
      " - 0s - loss: 126.8647 - val_loss: 82.8547\n",
      "Epoch 35/50\n",
      " - 0s - loss: 126.4047 - val_loss: 84.9935\n",
      "Epoch 36/50\n",
      " - 0s - loss: 126.5271 - val_loss: 83.4916\n",
      "Epoch 37/50\n",
      " - 0s - loss: 124.8222 - val_loss: 80.3713\n",
      "Epoch 38/50\n",
      " - 0s - loss: 127.1341 - val_loss: 80.3125\n",
      "Epoch 39/50\n",
      " - 0s - loss: 123.6837 - val_loss: 85.9276\n",
      "Epoch 40/50\n",
      " - 0s - loss: 123.3861 - val_loss: 83.0509\n",
      "Epoch 41/50\n",
      " - 0s - loss: 123.6509 - val_loss: 85.9159\n",
      "Epoch 42/50\n",
      " - 0s - loss: 129.2982 - val_loss: 91.6218\n",
      "Epoch 43/50\n",
      " - 0s - loss: 121.6355 - val_loss: 80.1514\n",
      "Epoch 44/50\n",
      " - 0s - loss: 127.1593 - val_loss: 82.1490\n",
      "Epoch 45/50\n",
      " - 0s - loss: 124.0543 - val_loss: 85.1270\n",
      "Epoch 46/50\n",
      " - 0s - loss: 125.0384 - val_loss: 91.9376\n",
      "Epoch 47/50\n",
      " - 0s - loss: 120.6508 - val_loss: 84.3749\n",
      "Epoch 48/50\n",
      " - 0s - loss: 121.3662 - val_loss: 82.9964\n",
      "Epoch 49/50\n",
      " - 0s - loss: 122.5500 - val_loss: 87.8623\n",
      "Epoch 50/50\n",
      " - 0s - loss: 121.7918 - val_loss: 88.1141\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 2460.4275 - val_loss: 846.0007\n",
      "Epoch 2/50\n",
      " - 0s - loss: 812.4846 - val_loss: 389.5519\n",
      "Epoch 3/50\n",
      " - 0s - loss: 559.0556 - val_loss: 337.2243\n",
      "Epoch 4/50\n",
      " - 0s - loss: 473.1173 - val_loss: 312.0551\n",
      "Epoch 5/50\n",
      " - 0s - loss: 438.4393 - val_loss: 306.6837\n",
      "Epoch 6/50\n",
      " - 0s - loss: 391.6231 - val_loss: 269.0304\n",
      "Epoch 7/50\n",
      " - 0s - loss: 364.9559 - val_loss: 331.2794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      " - 0s - loss: 338.5477 - val_loss: 236.1070\n",
      "Epoch 9/50\n",
      " - 0s - loss: 319.8514 - val_loss: 264.9726\n",
      "Epoch 10/50\n",
      " - 0s - loss: 299.2054 - val_loss: 309.3677\n",
      "Epoch 11/50\n",
      " - 0s - loss: 296.2321 - val_loss: 226.3173\n",
      "Epoch 12/50\n",
      " - 0s - loss: 266.3870 - val_loss: 271.9627\n",
      "Epoch 13/50\n",
      " - 0s - loss: 262.5685 - val_loss: 222.8623\n",
      "Epoch 14/50\n",
      " - 0s - loss: 245.0382 - val_loss: 231.0314\n",
      "Epoch 15/50\n",
      " - 0s - loss: 242.6054 - val_loss: 194.3721\n",
      "Epoch 16/50\n",
      " - 0s - loss: 223.1891 - val_loss: 167.7452\n",
      "Epoch 17/50\n",
      " - 0s - loss: 218.9416 - val_loss: 167.3025\n",
      "Epoch 18/50\n",
      " - 0s - loss: 231.6949 - val_loss: 147.7024\n",
      "Epoch 19/50\n",
      " - 0s - loss: 230.2257 - val_loss: 150.7309\n",
      "Epoch 20/50\n",
      " - 0s - loss: 200.1100 - val_loss: 195.2078\n",
      "Epoch 21/50\n",
      " - 0s - loss: 188.0318 - val_loss: 159.5214\n",
      "Epoch 22/50\n",
      " - 0s - loss: 194.4433 - val_loss: 188.1205\n",
      "Epoch 23/50\n",
      " - 0s - loss: 176.9419 - val_loss: 227.5042\n",
      "Epoch 24/50\n",
      " - 0s - loss: 176.5023 - val_loss: 143.5717\n",
      "Epoch 25/50\n",
      " - 0s - loss: 168.0490 - val_loss: 148.1097\n",
      "Epoch 26/50\n",
      " - 0s - loss: 182.0370 - val_loss: 133.0598\n",
      "Epoch 27/50\n",
      " - 0s - loss: 171.7048 - val_loss: 157.0887\n",
      "Epoch 28/50\n",
      " - 0s - loss: 158.5676 - val_loss: 155.0170\n",
      "Epoch 29/50\n",
      " - 0s - loss: 155.1543 - val_loss: 166.1508\n",
      "Epoch 30/50\n",
      " - 0s - loss: 158.5133 - val_loss: 124.1244\n",
      "Epoch 31/50\n",
      " - 0s - loss: 160.0683 - val_loss: 148.2897\n",
      "Epoch 32/50\n",
      " - 0s - loss: 151.2275 - val_loss: 161.9172\n",
      "Epoch 33/50\n",
      " - 0s - loss: 143.9808 - val_loss: 133.3249\n",
      "Epoch 34/50\n",
      " - 0s - loss: 148.0892 - val_loss: 146.2222\n",
      "Epoch 35/50\n",
      " - 0s - loss: 151.8058 - val_loss: 127.2043\n",
      "Epoch 36/50\n",
      " - 0s - loss: 136.9716 - val_loss: 130.9863\n",
      "Epoch 37/50\n",
      " - 0s - loss: 142.4251 - val_loss: 124.4968\n",
      "Epoch 38/50\n",
      " - 0s - loss: 137.1239 - val_loss: 166.6907\n",
      "Epoch 39/50\n",
      " - 0s - loss: 128.6948 - val_loss: 173.3904\n",
      "Epoch 40/50\n",
      " - 0s - loss: 133.6577 - val_loss: 140.9218\n",
      "Epoch 41/50\n",
      " - 0s - loss: 125.0575 - val_loss: 153.5015\n",
      "Epoch 42/50\n",
      " - 0s - loss: 131.8337 - val_loss: 108.5799\n",
      "Epoch 43/50\n",
      " - 0s - loss: 121.7507 - val_loss: 129.7980\n",
      "Epoch 44/50\n",
      " - 0s - loss: 120.3631 - val_loss: 117.9995\n",
      "Epoch 45/50\n",
      " - 0s - loss: 133.8830 - val_loss: 160.2789\n",
      "Epoch 46/50\n",
      " - 0s - loss: 134.4303 - val_loss: 106.2400\n",
      "Epoch 47/50\n",
      " - 0s - loss: 121.8562 - val_loss: 124.2686\n",
      "Epoch 48/50\n",
      " - 0s - loss: 114.5241 - val_loss: 102.4648\n",
      "Epoch 49/50\n",
      " - 0s - loss: 128.7163 - val_loss: 110.4580\n",
      "Epoch 50/50\n",
      " - 0s - loss: 128.9732 - val_loss: 130.6160\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 6936.9394 - val_loss: 3621.0418\n",
      "Epoch 2/50\n",
      " - 0s - loss: 2569.8082 - val_loss: 1218.1754\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1146.5071 - val_loss: 604.2751\n",
      "Epoch 4/50\n",
      " - 0s - loss: 718.7069 - val_loss: 344.9787\n",
      "Epoch 5/50\n",
      " - 0s - loss: 503.0242 - val_loss: 255.8303\n",
      "Epoch 6/50\n",
      " - 0s - loss: 418.6815 - val_loss: 255.5782\n",
      "Epoch 7/50\n",
      " - 0s - loss: 404.5272 - val_loss: 257.3474\n",
      "Epoch 8/50\n",
      " - 0s - loss: 397.4774 - val_loss: 247.7319\n",
      "Epoch 9/50\n",
      " - 0s - loss: 390.7349 - val_loss: 244.6648\n",
      "Epoch 10/50\n",
      " - 0s - loss: 385.6484 - val_loss: 243.0455\n",
      "Epoch 11/50\n",
      " - 0s - loss: 381.1474 - val_loss: 239.2677\n",
      "Epoch 12/50\n",
      " - 0s - loss: 376.2343 - val_loss: 234.1044\n",
      "Epoch 13/50\n",
      " - 0s - loss: 370.6596 - val_loss: 236.6802\n",
      "Epoch 14/50\n",
      " - 0s - loss: 367.5266 - val_loss: 228.6914\n",
      "Epoch 15/50\n",
      " - 0s - loss: 360.9538 - val_loss: 223.5430\n",
      "Epoch 16/50\n",
      " - 0s - loss: 356.2594 - val_loss: 220.1014\n",
      "Epoch 17/50\n",
      " - 0s - loss: 351.1556 - val_loss: 221.0883\n",
      "Epoch 18/50\n",
      " - 0s - loss: 346.2481 - val_loss: 216.6393\n",
      "Epoch 19/50\n",
      " - 0s - loss: 341.0271 - val_loss: 211.7822\n",
      "Epoch 20/50\n",
      " - 0s - loss: 335.8946 - val_loss: 212.6215\n",
      "Epoch 21/50\n",
      " - 0s - loss: 328.8099 - val_loss: 206.4701\n",
      "Epoch 22/50\n",
      " - 0s - loss: 319.2522 - val_loss: 203.4104\n",
      "Epoch 23/50\n",
      " - 0s - loss: 311.7054 - val_loss: 199.1826\n",
      "Epoch 24/50\n",
      " - 0s - loss: 306.5009 - val_loss: 190.3525\n",
      "Epoch 25/50\n",
      " - 0s - loss: 298.2301 - val_loss: 191.1566\n",
      "Epoch 26/50\n",
      " - 0s - loss: 291.9382 - val_loss: 186.9776\n",
      "Epoch 27/50\n",
      " - 0s - loss: 285.4008 - val_loss: 179.4173\n",
      "Epoch 28/50\n",
      " - 0s - loss: 279.4611 - val_loss: 179.6889\n",
      "Epoch 29/50\n",
      " - 0s - loss: 273.2943 - val_loss: 179.0301\n",
      "Epoch 30/50\n",
      " - 0s - loss: 267.7123 - val_loss: 163.8286\n",
      "Epoch 31/50\n",
      " - 0s - loss: 261.5236 - val_loss: 168.1050\n",
      "Epoch 32/50\n",
      " - 0s - loss: 254.9087 - val_loss: 155.7205\n",
      "Epoch 33/50\n",
      " - 0s - loss: 252.8579 - val_loss: 167.0492\n",
      "Epoch 34/50\n",
      " - 0s - loss: 244.6827 - val_loss: 150.1206\n",
      "Epoch 35/50\n",
      " - 0s - loss: 238.9664 - val_loss: 151.0759\n",
      "Epoch 36/50\n",
      " - 0s - loss: 233.5869 - val_loss: 145.7480\n",
      "Epoch 37/50\n",
      " - 0s - loss: 229.1259 - val_loss: 136.9364\n",
      "Epoch 38/50\n",
      " - 0s - loss: 224.1060 - val_loss: 148.9221\n",
      "Epoch 39/50\n",
      " - 0s - loss: 219.8546 - val_loss: 134.4617\n",
      "Epoch 40/50\n",
      " - 0s - loss: 214.4442 - val_loss: 132.7125\n",
      "Epoch 41/50\n",
      " - 0s - loss: 208.8570 - val_loss: 124.8235\n",
      "Epoch 42/50\n",
      " - 0s - loss: 203.9996 - val_loss: 114.3170\n",
      "Epoch 43/50\n",
      " - 0s - loss: 195.4492 - val_loss: 127.9820\n",
      "Epoch 44/50\n",
      " - 0s - loss: 187.2029 - val_loss: 109.3843\n",
      "Epoch 45/50\n",
      " - 0s - loss: 181.1184 - val_loss: 107.3710\n",
      "Epoch 46/50\n",
      " - 0s - loss: 173.3360 - val_loss: 120.8536\n",
      "Epoch 47/50\n",
      " - 0s - loss: 168.6775 - val_loss: 103.1261\n",
      "Epoch 48/50\n",
      " - 0s - loss: 161.8124 - val_loss: 99.2272\n",
      "Epoch 49/50\n",
      " - 0s - loss: 157.6920 - val_loss: 102.4600\n",
      "Epoch 50/50\n",
      " - 0s - loss: 153.6519 - val_loss: 102.6432\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 18486.0153 - val_loss: 3740.0126\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1845.4416 - val_loss: 429.2239\n",
      "Epoch 3/50\n",
      " - 0s - loss: 683.5620 - val_loss: 343.5878\n",
      "Epoch 4/50\n",
      " - 0s - loss: 587.7531 - val_loss: 310.2719\n",
      "Epoch 5/50\n",
      " - 0s - loss: 524.1074 - val_loss: 278.7908\n",
      "Epoch 6/50\n",
      " - 0s - loss: 471.2930 - val_loss: 251.1332\n",
      "Epoch 7/50\n",
      " - 0s - loss: 432.0020 - val_loss: 231.3157\n",
      "Epoch 8/50\n",
      " - 0s - loss: 403.0476 - val_loss: 219.3390\n",
      "Epoch 9/50\n",
      " - 0s - loss: 384.4690 - val_loss: 212.6665\n",
      "Epoch 10/50\n",
      " - 0s - loss: 373.1079 - val_loss: 198.2637\n",
      "Epoch 11/50\n",
      " - 0s - loss: 361.6702 - val_loss: 198.5400\n",
      "Epoch 12/50\n",
      " - 0s - loss: 354.2057 - val_loss: 189.2168\n",
      "Epoch 13/50\n",
      " - 0s - loss: 347.0636 - val_loss: 183.9370\n",
      "Epoch 14/50\n",
      " - 0s - loss: 342.4612 - val_loss: 191.0016\n",
      "Epoch 15/50\n",
      " - 0s - loss: 337.7901 - val_loss: 182.0963\n",
      "Epoch 16/50\n",
      " - 0s - loss: 334.6718 - val_loss: 184.5183\n",
      "Epoch 17/50\n",
      " - 0s - loss: 331.8224 - val_loss: 180.9709\n",
      "Epoch 18/50\n",
      " - 0s - loss: 329.7182 - val_loss: 178.9361\n",
      "Epoch 19/50\n",
      " - 0s - loss: 328.0613 - val_loss: 178.5072\n",
      "Epoch 20/50\n",
      " - 0s - loss: 326.9217 - val_loss: 177.8511\n",
      "Epoch 21/50\n",
      " - 0s - loss: 325.3203 - val_loss: 180.9772\n",
      "Epoch 22/50\n",
      " - 0s - loss: 324.5232 - val_loss: 177.4955\n",
      "Epoch 23/50\n",
      " - 0s - loss: 323.0810 - val_loss: 176.7016\n",
      "Epoch 24/50\n",
      " - 0s - loss: 321.7045 - val_loss: 175.3381\n",
      "Epoch 25/50\n",
      " - 0s - loss: 322.8744 - val_loss: 175.9317\n",
      "Epoch 26/50\n",
      " - 0s - loss: 321.9496 - val_loss: 167.9273\n",
      "Epoch 27/50\n",
      " - 0s - loss: 319.4403 - val_loss: 177.4604\n",
      "Epoch 28/50\n",
      " - 0s - loss: 318.1171 - val_loss: 172.4699\n",
      "Epoch 29/50\n",
      " - 0s - loss: 317.5658 - val_loss: 168.8002\n",
      "Epoch 30/50\n",
      " - 0s - loss: 316.3401 - val_loss: 183.8958\n",
      "Epoch 31/50\n",
      " - 0s - loss: 316.4328 - val_loss: 174.9703\n",
      "Epoch 32/50\n",
      " - 0s - loss: 313.9006 - val_loss: 170.6623\n",
      "Epoch 33/50\n",
      " - 0s - loss: 314.5034 - val_loss: 167.0446\n",
      "Epoch 34/50\n",
      " - 0s - loss: 313.0278 - val_loss: 166.0349\n",
      "Epoch 35/50\n",
      " - 0s - loss: 312.2075 - val_loss: 170.4678\n",
      "Epoch 36/50\n",
      " - 0s - loss: 311.0578 - val_loss: 173.6095\n",
      "Epoch 37/50\n",
      " - 0s - loss: 311.4043 - val_loss: 176.4337\n",
      "Epoch 38/50\n",
      " - 0s - loss: 310.0510 - val_loss: 169.2947\n",
      "Epoch 39/50\n",
      " - 0s - loss: 308.7477 - val_loss: 168.7723\n",
      "Epoch 40/50\n",
      " - 0s - loss: 308.8781 - val_loss: 165.9382\n",
      "Epoch 41/50\n",
      " - 0s - loss: 309.1649 - val_loss: 164.9475\n",
      "Epoch 42/50\n",
      " - 0s - loss: 308.2969 - val_loss: 169.1496\n",
      "Epoch 43/50\n",
      " - 0s - loss: 307.7279 - val_loss: 172.8317\n",
      "Epoch 44/50\n",
      " - 0s - loss: 306.9802 - val_loss: 161.8179\n",
      "Epoch 45/50\n",
      " - 0s - loss: 306.3931 - val_loss: 170.2179\n",
      "Epoch 46/50\n",
      " - 0s - loss: 305.6422 - val_loss: 174.3332\n",
      "Epoch 47/50\n",
      " - 0s - loss: 304.2530 - val_loss: 166.9774\n",
      "Epoch 48/50\n",
      " - 0s - loss: 303.8551 - val_loss: 171.5707\n",
      "Epoch 49/50\n",
      " - 0s - loss: 302.6596 - val_loss: 164.0922\n",
      "Epoch 50/50\n",
      " - 0s - loss: 302.4915 - val_loss: 172.4346\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 75577.5610 - val_loss: 19733.1898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      " - 0s - loss: 7082.5500 - val_loss: 1289.8672\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1174.8776 - val_loss: 791.8461\n",
      "Epoch 4/50\n",
      " - 0s - loss: 484.4102 - val_loss: 337.4045\n",
      "Epoch 5/50\n",
      " - 0s - loss: 356.5132 - val_loss: 298.0551\n",
      "Epoch 6/50\n",
      " - 0s - loss: 305.4532 - val_loss: 217.5857\n",
      "Epoch 7/50\n",
      " - 0s - loss: 280.2997 - val_loss: 202.0595\n",
      "Epoch 8/50\n",
      " - 0s - loss: 268.3441 - val_loss: 172.5798\n",
      "Epoch 9/50\n",
      " - 0s - loss: 262.4539 - val_loss: 167.5966\n",
      "Epoch 10/50\n",
      " - 0s - loss: 257.2656 - val_loss: 165.2846\n",
      "Epoch 11/50\n",
      " - 0s - loss: 257.9399 - val_loss: 189.1077\n",
      "Epoch 12/50\n",
      " - 0s - loss: 255.4057 - val_loss: 154.3543\n",
      "Epoch 13/50\n",
      " - 0s - loss: 253.0212 - val_loss: 164.0358\n",
      "Epoch 14/50\n",
      " - 0s - loss: 251.1964 - val_loss: 153.7901\n",
      "Epoch 15/50\n",
      " - 0s - loss: 252.8174 - val_loss: 145.8197\n",
      "Epoch 16/50\n",
      " - 0s - loss: 251.6447 - val_loss: 170.3629\n",
      "Epoch 17/50\n",
      " - 0s - loss: 252.8493 - val_loss: 173.1564\n",
      "Epoch 18/50\n",
      " - 0s - loss: 248.2891 - val_loss: 152.5809\n",
      "Epoch 19/50\n",
      " - 0s - loss: 245.9179 - val_loss: 172.9323\n",
      "Epoch 20/50\n",
      " - 0s - loss: 248.6553 - val_loss: 144.8177\n",
      "Epoch 21/50\n",
      " - 0s - loss: 244.5108 - val_loss: 148.6428\n",
      "Epoch 22/50\n",
      " - 0s - loss: 244.2729 - val_loss: 166.7576\n",
      "Epoch 23/50\n",
      " - 0s - loss: 241.5094 - val_loss: 149.5019\n",
      "Epoch 24/50\n",
      " - 0s - loss: 241.0530 - val_loss: 157.1973\n",
      "Epoch 25/50\n",
      " - 0s - loss: 239.7387 - val_loss: 154.9765\n",
      "Epoch 26/50\n",
      " - 0s - loss: 239.6537 - val_loss: 161.9133\n",
      "Epoch 27/50\n",
      " - 0s - loss: 236.5821 - val_loss: 157.9432\n",
      "Epoch 28/50\n",
      " - 0s - loss: 238.9271 - val_loss: 146.8335\n",
      "Epoch 29/50\n",
      " - 0s - loss: 237.2576 - val_loss: 164.0455\n",
      "Epoch 30/50\n",
      " - 0s - loss: 231.5400 - val_loss: 139.8711\n",
      "Epoch 31/50\n",
      " - 0s - loss: 229.9003 - val_loss: 139.2235\n",
      "Epoch 32/50\n",
      " - 0s - loss: 228.5750 - val_loss: 159.5052\n",
      "Epoch 33/50\n",
      " - 0s - loss: 229.5062 - val_loss: 161.4723\n",
      "Epoch 34/50\n",
      " - 0s - loss: 227.0682 - val_loss: 157.2556\n",
      "Epoch 35/50\n",
      " - 0s - loss: 225.1868 - val_loss: 145.5114\n",
      "Epoch 36/50\n",
      " - 0s - loss: 220.7127 - val_loss: 134.4868\n",
      "Epoch 37/50\n",
      " - 0s - loss: 220.1165 - val_loss: 142.6197\n",
      "Epoch 38/50\n",
      " - 0s - loss: 215.8559 - val_loss: 129.9560\n",
      "Epoch 39/50\n",
      " - 0s - loss: 220.8837 - val_loss: 132.4368\n",
      "Epoch 40/50\n",
      " - 0s - loss: 217.0818 - val_loss: 151.0364\n",
      "Epoch 41/50\n",
      " - 0s - loss: 212.1584 - val_loss: 130.0586\n",
      "Epoch 42/50\n",
      " - 0s - loss: 219.5863 - val_loss: 132.2931\n",
      "Epoch 43/50\n",
      " - 0s - loss: 211.6962 - val_loss: 134.2101\n",
      "Epoch 44/50\n",
      " - 0s - loss: 207.5010 - val_loss: 138.3991\n",
      "Epoch 45/50\n",
      " - 0s - loss: 205.6403 - val_loss: 129.6831\n",
      "Epoch 46/50\n",
      " - 0s - loss: 202.8152 - val_loss: 149.6467\n",
      "Epoch 47/50\n",
      " - 0s - loss: 202.7150 - val_loss: 130.4072\n",
      "Epoch 48/50\n",
      " - 0s - loss: 202.3224 - val_loss: 163.4821\n",
      "Epoch 49/50\n",
      " - 0s - loss: 200.4566 - val_loss: 138.8680\n",
      "Epoch 50/50\n",
      " - 0s - loss: 196.3230 - val_loss: 134.5136\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 7368.3464 - val_loss: 1862.1246\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1430.9850 - val_loss: 916.2309\n",
      "Epoch 3/50\n",
      " - 0s - loss: 985.7220 - val_loss: 848.4666\n",
      "Epoch 4/50\n",
      " - 0s - loss: 793.3010 - val_loss: 687.7038\n",
      "Epoch 5/50\n",
      " - 0s - loss: 621.2399 - val_loss: 538.0780\n",
      "Epoch 6/50\n",
      " - 0s - loss: 489.2379 - val_loss: 435.0891\n",
      "Epoch 7/50\n",
      " - 0s - loss: 406.6408 - val_loss: 399.9523\n",
      "Epoch 8/50\n",
      " - 0s - loss: 351.7282 - val_loss: 318.9098\n",
      "Epoch 9/50\n",
      " - 0s - loss: 317.7206 - val_loss: 295.6738\n",
      "Epoch 10/50\n",
      " - 0s - loss: 281.9579 - val_loss: 252.4227\n",
      "Epoch 11/50\n",
      " - 0s - loss: 249.4910 - val_loss: 198.5475\n",
      "Epoch 12/50\n",
      " - 0s - loss: 235.4888 - val_loss: 202.1322\n",
      "Epoch 13/50\n",
      " - 0s - loss: 227.7257 - val_loss: 184.0572\n",
      "Epoch 14/50\n",
      " - 0s - loss: 222.2224 - val_loss: 199.1319\n",
      "Epoch 15/50\n",
      " - 0s - loss: 218.7210 - val_loss: 167.6361\n",
      "Epoch 16/50\n",
      " - 0s - loss: 212.2960 - val_loss: 187.0200\n",
      "Epoch 17/50\n",
      " - 0s - loss: 207.9336 - val_loss: 175.9947\n",
      "Epoch 18/50\n",
      " - 0s - loss: 204.2430 - val_loss: 172.1938\n",
      "Epoch 19/50\n",
      " - 0s - loss: 200.3450 - val_loss: 175.8944\n",
      "Epoch 20/50\n",
      " - 0s - loss: 196.9021 - val_loss: 154.1093\n",
      "Epoch 21/50\n",
      " - 0s - loss: 193.9238 - val_loss: 166.7447\n",
      "Epoch 22/50\n",
      " - 0s - loss: 189.7284 - val_loss: 152.2465\n",
      "Epoch 23/50\n",
      " - 0s - loss: 186.1754 - val_loss: 174.1255\n",
      "Epoch 24/50\n",
      " - 0s - loss: 184.3097 - val_loss: 152.7720\n",
      "Epoch 25/50\n",
      " - 0s - loss: 178.7013 - val_loss: 164.2643\n",
      "Epoch 26/50\n",
      " - 0s - loss: 174.9555 - val_loss: 140.4189\n",
      "Epoch 27/50\n",
      " - 0s - loss: 172.7892 - val_loss: 148.1031\n",
      "Epoch 28/50\n",
      " - 0s - loss: 171.3826 - val_loss: 150.6066\n",
      "Epoch 29/50\n",
      " - 0s - loss: 165.5731 - val_loss: 136.8150\n",
      "Epoch 30/50\n",
      " - 0s - loss: 162.8785 - val_loss: 138.0237\n",
      "Epoch 31/50\n",
      " - 0s - loss: 159.1816 - val_loss: 143.9403\n",
      "Epoch 32/50\n",
      " - 0s - loss: 155.1392 - val_loss: 140.9281\n",
      "Epoch 33/50\n",
      " - 0s - loss: 151.6447 - val_loss: 139.8576\n",
      "Epoch 34/50\n",
      " - 0s - loss: 148.8861 - val_loss: 131.4005\n",
      "Epoch 35/50\n",
      " - 0s - loss: 146.6051 - val_loss: 137.7428\n",
      "Epoch 36/50\n",
      " - 0s - loss: 145.2392 - val_loss: 133.5347\n",
      "Epoch 37/50\n",
      " - 0s - loss: 142.4400 - val_loss: 128.4174\n",
      "Epoch 38/50\n",
      " - 0s - loss: 138.9367 - val_loss: 113.3390\n",
      "Epoch 39/50\n",
      " - 0s - loss: 134.7096 - val_loss: 113.7455\n",
      "Epoch 40/50\n",
      " - 0s - loss: 131.7194 - val_loss: 108.9077\n",
      "Epoch 41/50\n",
      " - 0s - loss: 129.5491 - val_loss: 108.4561\n",
      "Epoch 42/50\n",
      " - 0s - loss: 126.4638 - val_loss: 107.2365\n",
      "Epoch 43/50\n",
      " - 0s - loss: 123.5597 - val_loss: 100.3406\n",
      "Epoch 44/50\n",
      " - 0s - loss: 121.5321 - val_loss: 99.5636\n",
      "Epoch 45/50\n",
      " - 0s - loss: 118.8059 - val_loss: 94.2404\n",
      "Epoch 46/50\n",
      " - 0s - loss: 116.0684 - val_loss: 100.2556\n",
      "Epoch 47/50\n",
      " - 0s - loss: 117.8658 - val_loss: 93.3118\n",
      "Epoch 48/50\n",
      " - 0s - loss: 114.7016 - val_loss: 87.9751\n",
      "Epoch 49/50\n",
      " - 0s - loss: 110.5617 - val_loss: 91.0099\n",
      "Epoch 50/50\n",
      " - 0s - loss: 108.7394 - val_loss: 85.4476\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 762.4331 - val_loss: 336.4961\n",
      "Epoch 2/50\n",
      " - 0s - loss: 443.6803 - val_loss: 291.9190\n",
      "Epoch 3/50\n",
      " - 0s - loss: 370.3745 - val_loss: 249.9315\n",
      "Epoch 4/50\n",
      " - 0s - loss: 330.3666 - val_loss: 236.8721\n",
      "Epoch 5/50\n",
      " - 0s - loss: 322.1024 - val_loss: 240.9493\n",
      "Epoch 6/50\n",
      " - 0s - loss: 317.1189 - val_loss: 240.0199\n",
      "Epoch 7/50\n",
      " - 0s - loss: 308.8361 - val_loss: 223.6296\n",
      "Epoch 8/50\n",
      " - 0s - loss: 303.0685 - val_loss: 219.3540\n",
      "Epoch 9/50\n",
      " - 0s - loss: 294.8360 - val_loss: 208.4299\n",
      "Epoch 10/50\n",
      " - 0s - loss: 289.1918 - val_loss: 200.1049\n",
      "Epoch 11/50\n",
      " - 0s - loss: 284.0993 - val_loss: 197.7034\n",
      "Epoch 12/50\n",
      " - 0s - loss: 279.8360 - val_loss: 192.3693\n",
      "Epoch 13/50\n",
      " - 0s - loss: 273.3353 - val_loss: 189.3345\n",
      "Epoch 14/50\n",
      " - 0s - loss: 271.9344 - val_loss: 186.2243\n",
      "Epoch 15/50\n",
      " - 0s - loss: 265.8966 - val_loss: 181.5638\n",
      "Epoch 16/50\n",
      " - 0s - loss: 257.7569 - val_loss: 183.1075\n",
      "Epoch 17/50\n",
      " - 0s - loss: 252.3678 - val_loss: 167.1864\n",
      "Epoch 18/50\n",
      " - 0s - loss: 252.0724 - val_loss: 167.8323\n",
      "Epoch 19/50\n",
      " - 0s - loss: 244.6780 - val_loss: 163.4783\n",
      "Epoch 20/50\n",
      " - 0s - loss: 240.2037 - val_loss: 159.0063\n",
      "Epoch 21/50\n",
      " - 0s - loss: 233.0150 - val_loss: 162.4379\n",
      "Epoch 22/50\n",
      " - 0s - loss: 228.9781 - val_loss: 147.6136\n",
      "Epoch 23/50\n",
      " - 0s - loss: 221.5732 - val_loss: 160.4728\n",
      "Epoch 24/50\n",
      " - 0s - loss: 218.8867 - val_loss: 146.9343\n",
      "Epoch 25/50\n",
      " - 0s - loss: 209.0604 - val_loss: 145.4623\n",
      "Epoch 26/50\n",
      " - 0s - loss: 208.2983 - val_loss: 147.4677\n",
      "Epoch 27/50\n",
      " - 0s - loss: 202.5708 - val_loss: 136.0460\n",
      "Epoch 28/50\n",
      " - 0s - loss: 197.9616 - val_loss: 136.6465\n",
      "Epoch 29/50\n",
      " - 0s - loss: 189.3015 - val_loss: 125.7296\n",
      "Epoch 30/50\n",
      " - 0s - loss: 183.8398 - val_loss: 132.6384\n",
      "Epoch 31/50\n",
      " - 0s - loss: 175.3637 - val_loss: 113.0325\n",
      "Epoch 32/50\n",
      " - 0s - loss: 159.3488 - val_loss: 139.1693\n",
      "Epoch 33/50\n",
      " - 0s - loss: 139.6171 - val_loss: 101.8501\n",
      "Epoch 34/50\n",
      " - 0s - loss: 126.3890 - val_loss: 97.2114\n",
      "Epoch 35/50\n",
      " - 0s - loss: 125.9868 - val_loss: 98.7963\n",
      "Epoch 36/50\n",
      " - 0s - loss: 108.8500 - val_loss: 103.2069\n",
      "Epoch 37/50\n",
      " - 0s - loss: 100.0038 - val_loss: 118.7864\n",
      "Epoch 38/50\n",
      " - 0s - loss: 96.0507 - val_loss: 96.8970\n",
      "Epoch 39/50\n",
      " - 0s - loss: 99.4320 - val_loss: 92.4510\n",
      "Epoch 40/50\n",
      " - 0s - loss: 90.9574 - val_loss: 96.1866\n",
      "Epoch 41/50\n",
      " - 0s - loss: 88.5465 - val_loss: 91.8530\n",
      "Epoch 42/50\n",
      " - 0s - loss: 84.6808 - val_loss: 103.1691\n",
      "Epoch 43/50\n",
      " - 0s - loss: 84.3856 - val_loss: 104.1241\n",
      "Epoch 44/50\n",
      " - 0s - loss: 78.1074 - val_loss: 99.1046\n",
      "Epoch 45/50\n",
      " - 0s - loss: 80.2123 - val_loss: 102.4951\n",
      "Epoch 46/50\n",
      " - 0s - loss: 80.3959 - val_loss: 90.7962\n",
      "Epoch 47/50\n",
      " - 0s - loss: 77.4767 - val_loss: 100.9171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      " - 0s - loss: 76.3054 - val_loss: 97.7089\n",
      "Epoch 49/50\n",
      " - 0s - loss: 74.3058 - val_loss: 99.7812\n",
      "Epoch 50/50\n",
      " - 0s - loss: 73.4156 - val_loss: 90.8957\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 54284.2012 - val_loss: 10725.8329\n",
      "Epoch 2/50\n",
      " - 0s - loss: 4343.5233 - val_loss: 405.5689\n",
      "Epoch 3/50\n",
      " - 0s - loss: 496.2436 - val_loss: 346.8927\n",
      "Epoch 4/50\n",
      " - 0s - loss: 419.3708 - val_loss: 225.1665\n",
      "Epoch 5/50\n",
      " - 0s - loss: 356.6288 - val_loss: 200.1429\n",
      "Epoch 6/50\n",
      " - 0s - loss: 323.4078 - val_loss: 189.4989\n",
      "Epoch 7/50\n",
      " - 0s - loss: 293.7164 - val_loss: 180.2186\n",
      "Epoch 8/50\n",
      " - 0s - loss: 265.4111 - val_loss: 161.3375\n",
      "Epoch 9/50\n",
      " - 0s - loss: 242.6464 - val_loss: 153.7382\n",
      "Epoch 10/50\n",
      " - 0s - loss: 223.7525 - val_loss: 145.9058\n",
      "Epoch 11/50\n",
      " - 0s - loss: 207.4097 - val_loss: 137.6461\n",
      "Epoch 12/50\n",
      " - 0s - loss: 192.0008 - val_loss: 133.5383\n",
      "Epoch 13/50\n",
      " - 0s - loss: 178.6403 - val_loss: 131.2588\n",
      "Epoch 14/50\n",
      " - 0s - loss: 167.5703 - val_loss: 122.8094\n",
      "Epoch 15/50\n",
      " - 0s - loss: 159.0907 - val_loss: 114.6736\n",
      "Epoch 16/50\n",
      " - 0s - loss: 151.9487 - val_loss: 110.4085\n",
      "Epoch 17/50\n",
      " - 0s - loss: 147.1803 - val_loss: 117.2366\n",
      "Epoch 18/50\n",
      " - 0s - loss: 142.2372 - val_loss: 106.6705\n",
      "Epoch 19/50\n",
      " - 0s - loss: 138.7560 - val_loss: 104.2068\n",
      "Epoch 20/50\n",
      " - 0s - loss: 135.8591 - val_loss: 106.0175\n",
      "Epoch 21/50\n",
      " - 0s - loss: 132.6773 - val_loss: 102.4340\n",
      "Epoch 22/50\n",
      " - 0s - loss: 129.8529 - val_loss: 108.3006\n",
      "Epoch 23/50\n",
      " - 0s - loss: 128.1862 - val_loss: 98.8078\n",
      "Epoch 24/50\n",
      " - 0s - loss: 125.8173 - val_loss: 97.2054\n",
      "Epoch 25/50\n",
      " - 0s - loss: 124.8047 - val_loss: 96.8856\n",
      "Epoch 26/50\n",
      " - 0s - loss: 123.0770 - val_loss: 95.9390\n",
      "Epoch 27/50\n",
      " - 0s - loss: 121.7349 - val_loss: 96.1797\n",
      "Epoch 28/50\n",
      " - 0s - loss: 121.3709 - val_loss: 93.2339\n",
      "Epoch 29/50\n",
      " - 0s - loss: 119.1962 - val_loss: 91.0113\n",
      "Epoch 30/50\n",
      " - 0s - loss: 118.9776 - val_loss: 90.8921\n",
      "Epoch 31/50\n",
      " - 0s - loss: 118.8444 - val_loss: 89.4071\n",
      "Epoch 32/50\n",
      " - 0s - loss: 116.0996 - val_loss: 89.2837\n",
      "Epoch 33/50\n",
      " - 0s - loss: 115.8746 - val_loss: 88.6756\n",
      "Epoch 34/50\n",
      " - 0s - loss: 114.3848 - val_loss: 90.9763\n",
      "Epoch 35/50\n",
      " - 0s - loss: 111.8936 - val_loss: 88.8968\n",
      "Epoch 36/50\n",
      " - 0s - loss: 110.7914 - val_loss: 88.2979\n",
      "Epoch 37/50\n",
      " - 0s - loss: 109.4645 - val_loss: 91.8144\n",
      "Epoch 38/50\n",
      " - 0s - loss: 108.5784 - val_loss: 93.1562\n",
      "Epoch 39/50\n",
      " - 0s - loss: 107.4616 - val_loss: 88.9441\n",
      "Epoch 40/50\n",
      " - 0s - loss: 108.2818 - val_loss: 90.4564\n",
      "Epoch 41/50\n",
      " - 0s - loss: 106.1279 - val_loss: 89.2758\n",
      "Epoch 42/50\n",
      " - 0s - loss: 104.3917 - val_loss: 91.8769\n",
      "Epoch 43/50\n",
      " - 0s - loss: 103.6468 - val_loss: 86.4831\n",
      "Epoch 44/50\n",
      " - 0s - loss: 104.7953 - val_loss: 91.9705\n",
      "Epoch 45/50\n",
      " - 0s - loss: 102.0684 - val_loss: 88.9581\n",
      "Epoch 46/50\n",
      " - 0s - loss: 100.8428 - val_loss: 87.0885\n",
      "Epoch 47/50\n",
      " - 0s - loss: 101.0344 - val_loss: 85.3764\n",
      "Epoch 48/50\n",
      " - 0s - loss: 100.1134 - val_loss: 84.3453\n",
      "Epoch 49/50\n",
      " - 0s - loss: 98.4837 - val_loss: 84.6236\n",
      "Epoch 50/50\n",
      " - 0s - loss: 100.0346 - val_loss: 83.2374\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 14728.2998 - val_loss: 1833.7295\n",
      "Epoch 2/50\n",
      " - 0s - loss: 714.4625 - val_loss: 402.6109\n",
      "Epoch 3/50\n",
      " - 0s - loss: 365.0231 - val_loss: 224.3349\n",
      "Epoch 4/50\n",
      " - 0s - loss: 272.9288 - val_loss: 201.9008\n",
      "Epoch 5/50\n",
      " - 0s - loss: 257.1913 - val_loss: 202.3812\n",
      "Epoch 6/50\n",
      " - 0s - loss: 248.0343 - val_loss: 195.4738\n",
      "Epoch 7/50\n",
      " - 0s - loss: 240.9740 - val_loss: 189.8104\n",
      "Epoch 8/50\n",
      " - 0s - loss: 234.1342 - val_loss: 184.7085\n",
      "Epoch 9/50\n",
      " - 0s - loss: 229.4361 - val_loss: 177.7949\n",
      "Epoch 10/50\n",
      " - 0s - loss: 221.9922 - val_loss: 174.4564\n",
      "Epoch 11/50\n",
      " - 0s - loss: 215.8800 - val_loss: 163.8671\n",
      "Epoch 12/50\n",
      " - 0s - loss: 210.0137 - val_loss: 163.0238\n",
      "Epoch 13/50\n",
      " - 0s - loss: 204.2425 - val_loss: 154.2425\n",
      "Epoch 14/50\n",
      " - 0s - loss: 198.6050 - val_loss: 149.2969\n",
      "Epoch 15/50\n",
      " - 0s - loss: 194.6211 - val_loss: 141.8344\n",
      "Epoch 16/50\n",
      " - 0s - loss: 190.1037 - val_loss: 136.8963\n",
      "Epoch 17/50\n",
      " - 0s - loss: 183.5061 - val_loss: 134.8511\n",
      "Epoch 18/50\n",
      " - 0s - loss: 177.8101 - val_loss: 129.0509\n",
      "Epoch 19/50\n",
      " - 0s - loss: 173.1126 - val_loss: 124.9744\n",
      "Epoch 20/50\n",
      " - 0s - loss: 169.4100 - val_loss: 118.1977\n",
      "Epoch 21/50\n",
      " - 0s - loss: 164.6010 - val_loss: 118.1966\n",
      "Epoch 22/50\n",
      " - 0s - loss: 159.9927 - val_loss: 109.9844\n",
      "Epoch 23/50\n",
      " - 0s - loss: 155.5798 - val_loss: 108.0551\n",
      "Epoch 24/50\n",
      " - 0s - loss: 151.4229 - val_loss: 103.5180\n",
      "Epoch 25/50\n",
      " - 0s - loss: 147.6139 - val_loss: 99.8350\n",
      "Epoch 26/50\n",
      " - 0s - loss: 144.4488 - val_loss: 96.5297\n",
      "Epoch 27/50\n",
      " - 0s - loss: 142.1411 - val_loss: 93.1584\n",
      "Epoch 28/50\n",
      " - 0s - loss: 140.3401 - val_loss: 91.9052\n",
      "Epoch 29/50\n",
      " - 0s - loss: 133.8166 - val_loss: 90.3540\n",
      "Epoch 30/50\n",
      " - 0s - loss: 131.0990 - val_loss: 88.6554\n",
      "Epoch 31/50\n",
      " - 0s - loss: 128.4571 - val_loss: 85.0999\n",
      "Epoch 32/50\n",
      " - 0s - loss: 124.5967 - val_loss: 83.0584\n",
      "Epoch 33/50\n",
      " - 0s - loss: 121.3132 - val_loss: 81.9962\n",
      "Epoch 34/50\n",
      " - 0s - loss: 117.4124 - val_loss: 89.3347\n",
      "Epoch 35/50\n",
      " - 0s - loss: 118.5484 - val_loss: 78.3582\n",
      "Epoch 36/50\n",
      " - 0s - loss: 111.6781 - val_loss: 76.6375\n",
      "Epoch 37/50\n",
      " - 0s - loss: 110.0505 - val_loss: 77.4790\n",
      "Epoch 38/50\n",
      " - 0s - loss: 110.4168 - val_loss: 77.6918\n",
      "Epoch 39/50\n",
      " - 0s - loss: 104.3359 - val_loss: 76.8845\n",
      "Epoch 40/50\n",
      " - 0s - loss: 101.3717 - val_loss: 74.2760\n",
      "Epoch 41/50\n",
      " - 0s - loss: 98.9083 - val_loss: 71.8814\n",
      "Epoch 42/50\n",
      " - 0s - loss: 96.6159 - val_loss: 70.8208\n",
      "Epoch 43/50\n",
      " - 0s - loss: 95.5233 - val_loss: 72.7570\n",
      "Epoch 44/50\n",
      " - 0s - loss: 93.4156 - val_loss: 70.3096\n",
      "Epoch 45/50\n",
      " - 0s - loss: 91.1508 - val_loss: 71.9051\n",
      "Epoch 46/50\n",
      " - 0s - loss: 89.7159 - val_loss: 70.4951\n",
      "Epoch 47/50\n",
      " - 0s - loss: 87.6144 - val_loss: 66.7480\n",
      "Epoch 48/50\n",
      " - 0s - loss: 86.2879 - val_loss: 68.9211\n",
      "Epoch 49/50\n",
      " - 0s - loss: 85.3381 - val_loss: 70.2691\n",
      "Epoch 50/50\n",
      " - 0s - loss: 84.4593 - val_loss: 64.7506\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 25746.8998 - val_loss: 12791.0951\n",
      "Epoch 2/50\n",
      " - 0s - loss: 10305.9959 - val_loss: 4887.2164\n",
      "Epoch 3/50\n",
      " - 0s - loss: 3985.6974 - val_loss: 1468.5274\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1006.3559 - val_loss: 381.5222\n",
      "Epoch 5/50\n",
      " - 0s - loss: 377.5720 - val_loss: 279.8239\n",
      "Epoch 6/50\n",
      " - 0s - loss: 317.1587 - val_loss: 265.4367\n",
      "Epoch 7/50\n",
      " - 0s - loss: 309.9249 - val_loss: 263.8300\n",
      "Epoch 8/50\n",
      " - 0s - loss: 304.9814 - val_loss: 262.9930\n",
      "Epoch 9/50\n",
      " - 0s - loss: 300.3743 - val_loss: 254.8679\n",
      "Epoch 10/50\n",
      " - 0s - loss: 294.4360 - val_loss: 254.1653\n",
      "Epoch 11/50\n",
      " - 0s - loss: 290.9522 - val_loss: 236.3104\n",
      "Epoch 12/50\n",
      " - 0s - loss: 284.7545 - val_loss: 235.4571\n",
      "Epoch 13/50\n",
      " - 0s - loss: 279.2469 - val_loss: 229.1227\n",
      "Epoch 14/50\n",
      " - 0s - loss: 274.8024 - val_loss: 225.8094\n",
      "Epoch 15/50\n",
      " - 0s - loss: 269.1671 - val_loss: 216.9734\n",
      "Epoch 16/50\n",
      " - 0s - loss: 260.7937 - val_loss: 202.1124\n",
      "Epoch 17/50\n",
      " - 0s - loss: 250.7406 - val_loss: 197.0329\n",
      "Epoch 18/50\n",
      " - 0s - loss: 241.8837 - val_loss: 185.9622\n",
      "Epoch 19/50\n",
      " - 0s - loss: 234.4569 - val_loss: 181.0634\n",
      "Epoch 20/50\n",
      " - 0s - loss: 228.2072 - val_loss: 169.7968\n",
      "Epoch 21/50\n",
      " - 0s - loss: 222.2452 - val_loss: 167.0837\n",
      "Epoch 22/50\n",
      " - 0s - loss: 215.8329 - val_loss: 164.2953\n",
      "Epoch 23/50\n",
      " - 0s - loss: 209.7627 - val_loss: 165.2963\n",
      "Epoch 24/50\n",
      " - 0s - loss: 204.2559 - val_loss: 156.3687\n",
      "Epoch 25/50\n",
      " - 0s - loss: 196.0722 - val_loss: 161.9701\n",
      "Epoch 26/50\n",
      " - 0s - loss: 192.6514 - val_loss: 157.7086\n",
      "Epoch 27/50\n",
      " - 0s - loss: 187.7450 - val_loss: 147.3839\n",
      "Epoch 28/50\n",
      " - 0s - loss: 184.9249 - val_loss: 151.8492\n",
      "Epoch 29/50\n",
      " - 0s - loss: 182.4537 - val_loss: 157.6248\n",
      "Epoch 30/50\n",
      " - 0s - loss: 179.5574 - val_loss: 142.7876\n",
      "Epoch 31/50\n",
      " - 0s - loss: 178.4938 - val_loss: 142.5994\n",
      "Epoch 32/50\n",
      " - 0s - loss: 175.8957 - val_loss: 140.1883\n",
      "Epoch 33/50\n",
      " - 0s - loss: 174.1850 - val_loss: 138.0494\n",
      "Epoch 34/50\n",
      " - 0s - loss: 172.9170 - val_loss: 150.1307\n",
      "Epoch 35/50\n",
      " - 0s - loss: 171.9707 - val_loss: 146.1994\n",
      "Epoch 36/50\n",
      " - 0s - loss: 168.7095 - val_loss: 140.5821\n",
      "Epoch 37/50\n",
      " - 0s - loss: 166.8294 - val_loss: 123.5965\n",
      "Epoch 38/50\n",
      " - 0s - loss: 170.9566 - val_loss: 135.6944\n",
      "Epoch 39/50\n",
      " - 0s - loss: 165.7491 - val_loss: 153.3746\n",
      "Epoch 40/50\n",
      " - 0s - loss: 164.5068 - val_loss: 141.8783\n",
      "Epoch 41/50\n",
      " - 0s - loss: 162.8164 - val_loss: 133.8840\n",
      "Epoch 42/50\n",
      " - 0s - loss: 160.3972 - val_loss: 138.8600\n",
      "Epoch 43/50\n",
      " - 0s - loss: 160.8724 - val_loss: 128.8498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      " - 0s - loss: 157.8241 - val_loss: 127.9163\n",
      "Epoch 45/50\n",
      " - 0s - loss: 157.0784 - val_loss: 120.6654\n",
      "Epoch 46/50\n",
      " - 0s - loss: 155.7712 - val_loss: 134.9532\n",
      "Epoch 47/50\n",
      " - 0s - loss: 156.4766 - val_loss: 127.7617\n",
      "Epoch 48/50\n",
      " - 0s - loss: 154.1975 - val_loss: 117.3901\n",
      "Epoch 49/50\n",
      " - 0s - loss: 156.3637 - val_loss: 114.7155\n",
      "Epoch 50/50\n",
      " - 0s - loss: 153.9587 - val_loss: 127.1082\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 3461.0343 - val_loss: 445.4697\n",
      "Epoch 2/50\n",
      " - 0s - loss: 557.7197 - val_loss: 293.2906\n",
      "Epoch 3/50\n",
      " - 0s - loss: 496.2899 - val_loss: 268.0458\n",
      "Epoch 4/50\n",
      " - 0s - loss: 454.7811 - val_loss: 257.5657\n",
      "Epoch 5/50\n",
      " - 0s - loss: 428.8209 - val_loss: 248.9467\n",
      "Epoch 6/50\n",
      " - 0s - loss: 411.9273 - val_loss: 244.1590\n",
      "Epoch 7/50\n",
      " - 0s - loss: 396.7337 - val_loss: 230.6588\n",
      "Epoch 8/50\n",
      " - 0s - loss: 384.6265 - val_loss: 223.6171\n",
      "Epoch 9/50\n",
      " - 0s - loss: 375.4617 - val_loss: 222.5744\n",
      "Epoch 10/50\n",
      " - 0s - loss: 368.1336 - val_loss: 217.2529\n",
      "Epoch 11/50\n",
      " - 0s - loss: 362.0109 - val_loss: 210.9828\n",
      "Epoch 12/50\n",
      " - 0s - loss: 356.9708 - val_loss: 207.6292\n",
      "Epoch 13/50\n",
      " - 0s - loss: 351.6334 - val_loss: 207.8512\n",
      "Epoch 14/50\n",
      " - 0s - loss: 347.2114 - val_loss: 201.1045\n",
      "Epoch 15/50\n",
      " - 0s - loss: 343.0378 - val_loss: 202.1344\n",
      "Epoch 16/50\n",
      " - 0s - loss: 338.2473 - val_loss: 194.1862\n",
      "Epoch 17/50\n",
      " - 0s - loss: 334.1310 - val_loss: 193.1500\n",
      "Epoch 18/50\n",
      " - 0s - loss: 330.5979 - val_loss: 192.9127\n",
      "Epoch 19/50\n",
      " - 0s - loss: 326.4780 - val_loss: 185.5960\n",
      "Epoch 20/50\n",
      " - 0s - loss: 323.1707 - val_loss: 186.2997\n",
      "Epoch 21/50\n",
      " - 0s - loss: 320.9959 - val_loss: 183.5017\n",
      "Epoch 22/50\n",
      " - 0s - loss: 316.7209 - val_loss: 183.5559\n",
      "Epoch 23/50\n",
      " - 0s - loss: 313.9185 - val_loss: 181.9589\n",
      "Epoch 24/50\n",
      " - 0s - loss: 310.9584 - val_loss: 176.5039\n",
      "Epoch 25/50\n",
      " - 0s - loss: 307.9816 - val_loss: 176.8689\n",
      "Epoch 26/50\n",
      " - 0s - loss: 305.4640 - val_loss: 177.4948\n",
      "Epoch 27/50\n",
      " - 0s - loss: 303.4230 - val_loss: 172.8268\n",
      "Epoch 28/50\n",
      " - 0s - loss: 300.5257 - val_loss: 173.3365\n",
      "Epoch 29/50\n",
      " - 0s - loss: 297.9774 - val_loss: 172.3142\n",
      "Epoch 30/50\n",
      " - 0s - loss: 296.0075 - val_loss: 172.9717\n",
      "Epoch 31/50\n",
      " - 0s - loss: 293.7199 - val_loss: 167.4859\n",
      "Epoch 32/50\n",
      " - 0s - loss: 291.5477 - val_loss: 169.1736\n",
      "Epoch 33/50\n",
      " - 0s - loss: 289.8185 - val_loss: 165.1552\n",
      "Epoch 34/50\n",
      " - 0s - loss: 288.2371 - val_loss: 165.8146\n",
      "Epoch 35/50\n",
      " - 0s - loss: 286.4862 - val_loss: 166.0482\n",
      "Epoch 36/50\n",
      " - 0s - loss: 284.4759 - val_loss: 164.7362\n",
      "Epoch 37/50\n",
      " - 0s - loss: 282.7737 - val_loss: 161.6223\n",
      "Epoch 38/50\n",
      " - 0s - loss: 280.9554 - val_loss: 163.7671\n",
      "Epoch 39/50\n",
      " - 0s - loss: 279.1473 - val_loss: 161.0104\n",
      "Epoch 40/50\n",
      " - 0s - loss: 277.8896 - val_loss: 160.3142\n",
      "Epoch 41/50\n",
      " - 0s - loss: 276.2901 - val_loss: 156.7482\n",
      "Epoch 42/50\n",
      " - 0s - loss: 275.2252 - val_loss: 161.9727\n",
      "Epoch 43/50\n",
      " - 0s - loss: 273.6029 - val_loss: 158.2005\n",
      "Epoch 44/50\n",
      " - 0s - loss: 273.3302 - val_loss: 156.4191\n",
      "Epoch 45/50\n",
      " - 0s - loss: 270.8622 - val_loss: 159.1766\n",
      "Epoch 46/50\n",
      " - 0s - loss: 270.6266 - val_loss: 156.9203\n",
      "Epoch 47/50\n",
      " - 0s - loss: 268.8105 - val_loss: 158.2621\n",
      "Epoch 48/50\n",
      " - 0s - loss: 267.9868 - val_loss: 158.1728\n",
      "Epoch 49/50\n",
      " - 0s - loss: 266.7669 - val_loss: 153.0291\n",
      "Epoch 50/50\n",
      " - 0s - loss: 266.5043 - val_loss: 157.0057\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 3634.5366 - val_loss: 972.0955\n",
      "Epoch 2/50\n",
      " - 0s - loss: 724.3029 - val_loss: 261.6311\n",
      "Epoch 3/50\n",
      " - 0s - loss: 428.2581 - val_loss: 280.8581\n",
      "Epoch 4/50\n",
      " - 0s - loss: 415.4924 - val_loss: 249.0813\n",
      "Epoch 5/50\n",
      " - 0s - loss: 402.8792 - val_loss: 249.9140\n",
      "Epoch 6/50\n",
      " - 0s - loss: 392.0172 - val_loss: 237.7738\n",
      "Epoch 7/50\n",
      " - 0s - loss: 380.5328 - val_loss: 233.5931\n",
      "Epoch 8/50\n",
      " - 0s - loss: 368.7893 - val_loss: 226.0024\n",
      "Epoch 9/50\n",
      " - 0s - loss: 355.2848 - val_loss: 213.5837\n",
      "Epoch 10/50\n",
      " - 0s - loss: 337.1779 - val_loss: 197.9018\n",
      "Epoch 11/50\n",
      " - 0s - loss: 313.0607 - val_loss: 185.1413\n",
      "Epoch 12/50\n",
      " - 0s - loss: 288.6623 - val_loss: 172.6107\n",
      "Epoch 13/50\n",
      " - 0s - loss: 263.9837 - val_loss: 163.4736\n",
      "Epoch 14/50\n",
      " - 0s - loss: 241.0882 - val_loss: 151.0384\n",
      "Epoch 15/50\n",
      " - 0s - loss: 219.7183 - val_loss: 134.3024\n",
      "Epoch 16/50\n",
      " - 0s - loss: 203.2387 - val_loss: 122.8621\n",
      "Epoch 17/50\n",
      " - 0s - loss: 187.2894 - val_loss: 126.5745\n",
      "Epoch 18/50\n",
      " - 0s - loss: 178.1751 - val_loss: 114.1112\n",
      "Epoch 19/50\n",
      " - 0s - loss: 165.6883 - val_loss: 105.1169\n",
      "Epoch 20/50\n",
      " - 0s - loss: 157.1303 - val_loss: 103.8745\n",
      "Epoch 21/50\n",
      " - 0s - loss: 150.6812 - val_loss: 99.7603\n",
      "Epoch 22/50\n",
      " - 0s - loss: 143.3533 - val_loss: 89.6927\n",
      "Epoch 23/50\n",
      " - 0s - loss: 135.6953 - val_loss: 91.5139\n",
      "Epoch 24/50\n",
      " - 0s - loss: 132.0225 - val_loss: 84.5631\n",
      "Epoch 25/50\n",
      " - 0s - loss: 126.0291 - val_loss: 83.9162\n",
      "Epoch 26/50\n",
      " - 0s - loss: 121.8610 - val_loss: 82.6564\n",
      "Epoch 27/50\n",
      " - 0s - loss: 120.4970 - val_loss: 77.9131\n",
      "Epoch 28/50\n",
      " - 0s - loss: 115.1763 - val_loss: 80.7685\n",
      "Epoch 29/50\n",
      " - 0s - loss: 114.2641 - val_loss: 76.3918\n",
      "Epoch 30/50\n",
      " - 0s - loss: 110.3775 - val_loss: 79.0095\n",
      "Epoch 31/50\n",
      " - 0s - loss: 111.5156 - val_loss: 75.8224\n",
      "Epoch 32/50\n",
      " - 0s - loss: 108.5208 - val_loss: 74.7992\n",
      "Epoch 33/50\n",
      " - 0s - loss: 104.3750 - val_loss: 74.9039\n",
      "Epoch 34/50\n",
      " - 0s - loss: 102.4376 - val_loss: 77.1478\n",
      "Epoch 35/50\n",
      " - 0s - loss: 101.7745 - val_loss: 79.4716\n",
      "Epoch 36/50\n",
      " - 0s - loss: 100.0539 - val_loss: 72.5612\n",
      "Epoch 37/50\n",
      " - 0s - loss: 97.9280 - val_loss: 72.7468\n",
      "Epoch 38/50\n",
      " - 0s - loss: 96.2438 - val_loss: 72.7481\n",
      "Epoch 39/50\n",
      " - 0s - loss: 95.1979 - val_loss: 72.5513\n",
      "Epoch 40/50\n",
      " - 0s - loss: 94.7151 - val_loss: 74.5357\n",
      "Epoch 41/50\n",
      " - 0s - loss: 95.3314 - val_loss: 72.8714\n",
      "Epoch 42/50\n",
      " - 0s - loss: 94.6780 - val_loss: 72.6603\n",
      "Epoch 43/50\n",
      " - 0s - loss: 94.0186 - val_loss: 72.7673\n",
      "Epoch 44/50\n",
      " - 0s - loss: 90.1382 - val_loss: 70.9254\n",
      "Epoch 45/50\n",
      " - 0s - loss: 89.8585 - val_loss: 75.9496\n",
      "Epoch 46/50\n",
      " - 0s - loss: 87.6199 - val_loss: 73.1651\n",
      "Epoch 47/50\n",
      " - 0s - loss: 87.4546 - val_loss: 73.0930\n",
      "Epoch 48/50\n",
      " - 0s - loss: 85.8367 - val_loss: 71.6877\n",
      "Epoch 49/50\n",
      " - 0s - loss: 84.8207 - val_loss: 70.8595\n",
      "Epoch 50/50\n",
      " - 0s - loss: 85.6262 - val_loss: 69.8628\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 1480.4985 - val_loss: 903.5327\n",
      "Epoch 2/50\n",
      " - 0s - loss: 630.2707 - val_loss: 430.5862\n",
      "Epoch 3/50\n",
      " - 0s - loss: 412.5775 - val_loss: 318.7794\n",
      "Epoch 4/50\n",
      " - 0s - loss: 314.7551 - val_loss: 248.1573\n",
      "Epoch 5/50\n",
      " - 0s - loss: 287.4636 - val_loss: 209.9942\n",
      "Epoch 6/50\n",
      " - 0s - loss: 271.8782 - val_loss: 154.9798\n",
      "Epoch 7/50\n",
      " - 0s - loss: 261.1913 - val_loss: 162.5324\n",
      "Epoch 8/50\n",
      " - 0s - loss: 247.2311 - val_loss: 199.1003\n",
      "Epoch 9/50\n",
      " - 0s - loss: 235.4457 - val_loss: 164.3615\n",
      "Epoch 10/50\n",
      " - 0s - loss: 222.3853 - val_loss: 148.1057\n",
      "Epoch 11/50\n",
      " - 0s - loss: 211.6977 - val_loss: 135.6683\n",
      "Epoch 12/50\n",
      " - 0s - loss: 203.4547 - val_loss: 155.6713\n",
      "Epoch 13/50\n",
      " - 0s - loss: 184.8899 - val_loss: 162.4814\n",
      "Epoch 14/50\n",
      " - 0s - loss: 174.1837 - val_loss: 140.1171\n",
      "Epoch 15/50\n",
      " - 0s - loss: 162.9334 - val_loss: 146.3320\n",
      "Epoch 16/50\n",
      " - 0s - loss: 154.6174 - val_loss: 139.5735\n",
      "Epoch 17/50\n",
      " - 0s - loss: 148.1958 - val_loss: 144.1934\n",
      "Epoch 18/50\n",
      " - 0s - loss: 142.6655 - val_loss: 212.1198\n",
      "Epoch 19/50\n",
      " - 0s - loss: 131.8790 - val_loss: 153.8675\n",
      "Epoch 20/50\n",
      " - 0s - loss: 126.3785 - val_loss: 143.5227\n",
      "Epoch 21/50\n",
      " - 0s - loss: 120.4911 - val_loss: 142.3266\n",
      "Epoch 22/50\n",
      " - 0s - loss: 116.0624 - val_loss: 145.9691\n",
      "Epoch 23/50\n",
      " - 0s - loss: 116.3364 - val_loss: 147.8168\n",
      "Epoch 24/50\n",
      " - 0s - loss: 107.5722 - val_loss: 131.2606\n",
      "Epoch 25/50\n",
      " - 0s - loss: 103.5663 - val_loss: 158.3005\n",
      "Epoch 26/50\n",
      " - 0s - loss: 103.8697 - val_loss: 130.0594\n",
      "Epoch 27/50\n",
      " - 0s - loss: 99.2271 - val_loss: 125.6233\n",
      "Epoch 28/50\n",
      " - 0s - loss: 95.5618 - val_loss: 108.2693\n",
      "Epoch 29/50\n",
      " - 0s - loss: 96.2644 - val_loss: 106.8725\n",
      "Epoch 30/50\n",
      " - 0s - loss: 93.5958 - val_loss: 101.5916\n",
      "Epoch 31/50\n",
      " - 0s - loss: 93.2903 - val_loss: 106.9741\n",
      "Epoch 32/50\n",
      " - 0s - loss: 89.3493 - val_loss: 98.9922\n",
      "Epoch 33/50\n",
      " - 0s - loss: 87.5827 - val_loss: 99.8559\n",
      "Epoch 34/50\n",
      " - 0s - loss: 85.7772 - val_loss: 93.8023\n",
      "Epoch 35/50\n",
      " - 0s - loss: 87.5074 - val_loss: 87.7777\n",
      "Epoch 36/50\n",
      " - 0s - loss: 85.0361 - val_loss: 87.9096\n",
      "Epoch 37/50\n",
      " - 0s - loss: 86.1136 - val_loss: 93.2267\n",
      "Epoch 38/50\n",
      " - 0s - loss: 80.7825 - val_loss: 91.7401\n",
      "Epoch 39/50\n",
      " - 0s - loss: 82.5209 - val_loss: 86.7404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      " - 0s - loss: 77.4961 - val_loss: 82.8785\n",
      "Epoch 41/50\n",
      " - 0s - loss: 78.9614 - val_loss: 99.6212\n",
      "Epoch 42/50\n",
      " - 0s - loss: 76.5897 - val_loss: 106.0509\n",
      "Epoch 43/50\n",
      " - 0s - loss: 79.1381 - val_loss: 87.8128\n",
      "Epoch 44/50\n",
      " - 0s - loss: 77.5865 - val_loss: 82.7145\n",
      "Epoch 45/50\n",
      " - 0s - loss: 73.8273 - val_loss: 88.0374\n",
      "Epoch 46/50\n",
      " - 0s - loss: 72.3735 - val_loss: 93.0921\n",
      "Epoch 47/50\n",
      " - 0s - loss: 71.3965 - val_loss: 88.8854\n",
      "Epoch 48/50\n",
      " - 0s - loss: 73.6088 - val_loss: 100.5313\n",
      "Epoch 49/50\n",
      " - 0s - loss: 73.7951 - val_loss: 88.2191\n",
      "Epoch 50/50\n",
      " - 0s - loss: 71.8089 - val_loss: 87.3648\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 1343.5168 - val_loss: 685.8427\n",
      "Epoch 2/50\n",
      " - 0s - loss: 698.9039 - val_loss: 349.8776\n",
      "Epoch 3/50\n",
      " - 0s - loss: 439.3289 - val_loss: 237.1273\n",
      "Epoch 4/50\n",
      " - 0s - loss: 295.6924 - val_loss: 185.5998\n",
      "Epoch 5/50\n",
      " - 0s - loss: 228.7103 - val_loss: 194.6262\n",
      "Epoch 6/50\n",
      " - 0s - loss: 183.0340 - val_loss: 148.7361\n",
      "Epoch 7/50\n",
      " - 0s - loss: 170.7434 - val_loss: 138.6213\n",
      "Epoch 8/50\n",
      " - 0s - loss: 156.0226 - val_loss: 181.8438\n",
      "Epoch 9/50\n",
      " - 0s - loss: 152.5110 - val_loss: 133.8487\n",
      "Epoch 10/50\n",
      " - 0s - loss: 141.5487 - val_loss: 128.0378\n",
      "Epoch 11/50\n",
      " - 0s - loss: 142.6023 - val_loss: 116.2654\n",
      "Epoch 12/50\n",
      " - 0s - loss: 133.9863 - val_loss: 134.8402\n",
      "Epoch 13/50\n",
      " - 0s - loss: 140.0170 - val_loss: 131.3446\n",
      "Epoch 14/50\n",
      " - 0s - loss: 131.6541 - val_loss: 105.6083\n",
      "Epoch 15/50\n",
      " - 0s - loss: 126.4311 - val_loss: 102.6983\n",
      "Epoch 16/50\n",
      " - 0s - loss: 126.4516 - val_loss: 104.1519\n",
      "Epoch 17/50\n",
      " - 0s - loss: 134.8164 - val_loss: 98.3954\n",
      "Epoch 18/50\n",
      " - 0s - loss: 133.3957 - val_loss: 126.9051\n",
      "Epoch 19/50\n",
      " - 0s - loss: 121.4350 - val_loss: 100.4641\n",
      "Epoch 20/50\n",
      " - 0s - loss: 120.9947 - val_loss: 94.9001\n",
      "Epoch 21/50\n",
      " - 0s - loss: 124.0721 - val_loss: 95.2766\n",
      "Epoch 22/50\n",
      " - 0s - loss: 121.6179 - val_loss: 96.4690\n",
      "Epoch 23/50\n",
      " - 0s - loss: 122.9699 - val_loss: 97.4339\n",
      "Epoch 24/50\n",
      " - 0s - loss: 127.1418 - val_loss: 95.4109\n",
      "Epoch 25/50\n",
      " - 0s - loss: 118.0237 - val_loss: 95.4694\n",
      "Epoch 26/50\n",
      " - 0s - loss: 118.2977 - val_loss: 91.3108\n",
      "Epoch 27/50\n",
      " - 0s - loss: 120.1349 - val_loss: 91.8939\n",
      "Epoch 28/50\n",
      " - 0s - loss: 123.6733 - val_loss: 90.7393\n",
      "Epoch 29/50\n",
      " - 0s - loss: 121.1614 - val_loss: 101.8352\n",
      "Epoch 30/50\n",
      " - 0s - loss: 119.6949 - val_loss: 105.1345\n",
      "Epoch 31/50\n",
      " - 0s - loss: 126.0294 - val_loss: 89.6785\n",
      "Epoch 32/50\n",
      " - 0s - loss: 116.9622 - val_loss: 101.0718\n",
      "Epoch 33/50\n",
      " - 0s - loss: 118.3402 - val_loss: 92.0617\n",
      "Epoch 34/50\n",
      " - 0s - loss: 116.4183 - val_loss: 88.2296\n",
      "Epoch 35/50\n",
      " - 0s - loss: 115.5217 - val_loss: 94.3641\n",
      "Epoch 36/50\n",
      " - 0s - loss: 118.4394 - val_loss: 90.0073\n",
      "Epoch 37/50\n",
      " - 0s - loss: 114.9000 - val_loss: 92.5995\n",
      "Epoch 38/50\n",
      " - 0s - loss: 115.2987 - val_loss: 87.3105\n",
      "Epoch 39/50\n",
      " - 0s - loss: 114.3424 - val_loss: 88.3776\n",
      "Epoch 40/50\n",
      " - 0s - loss: 115.6321 - val_loss: 97.5902\n",
      "Epoch 41/50\n",
      " - 0s - loss: 116.2867 - val_loss: 86.2146\n",
      "Epoch 42/50\n",
      " - 0s - loss: 113.7742 - val_loss: 92.5638\n",
      "Epoch 43/50\n",
      " - 0s - loss: 121.0164 - val_loss: 87.3102\n",
      "Epoch 44/50\n",
      " - 0s - loss: 114.3235 - val_loss: 89.1534\n",
      "Epoch 45/50\n",
      " - 0s - loss: 113.5707 - val_loss: 89.9961\n",
      "Epoch 46/50\n",
      " - 0s - loss: 120.8043 - val_loss: 93.7531\n",
      "Epoch 47/50\n",
      " - 0s - loss: 115.8239 - val_loss: 84.2334\n",
      "Epoch 48/50\n",
      " - 0s - loss: 119.8451 - val_loss: 87.8016\n",
      "Epoch 49/50\n",
      " - 0s - loss: 121.0749 - val_loss: 82.5897\n",
      "Epoch 50/50\n",
      " - 0s - loss: 112.2918 - val_loss: 89.4220\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 4956.1992 - val_loss: 2699.7401\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1422.5152 - val_loss: 1345.6347\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1089.7587 - val_loss: 1272.2746\n",
      "Epoch 4/50\n",
      " - 0s - loss: 998.6501 - val_loss: 1200.5304\n",
      "Epoch 5/50\n",
      " - 0s - loss: 928.5649 - val_loss: 1155.5150\n",
      "Epoch 6/50\n",
      " - 0s - loss: 867.4091 - val_loss: 1066.9745\n",
      "Epoch 7/50\n",
      " - 0s - loss: 820.3877 - val_loss: 1000.3959\n",
      "Epoch 8/50\n",
      " - 0s - loss: 765.1384 - val_loss: 952.2085\n",
      "Epoch 9/50\n",
      " - 0s - loss: 723.2934 - val_loss: 938.1653\n",
      "Epoch 10/50\n",
      " - 0s - loss: 682.7184 - val_loss: 847.9628\n",
      "Epoch 11/50\n",
      " - 0s - loss: 650.9460 - val_loss: 808.9160\n",
      "Epoch 12/50\n",
      " - 0s - loss: 615.9333 - val_loss: 765.4438\n",
      "Epoch 13/50\n",
      " - 0s - loss: 589.1698 - val_loss: 718.5030\n",
      "Epoch 14/50\n",
      " - 0s - loss: 560.1911 - val_loss: 769.4047\n",
      "Epoch 15/50\n",
      " - 0s - loss: 542.6658 - val_loss: 724.6672\n",
      "Epoch 16/50\n",
      " - 0s - loss: 514.4312 - val_loss: 664.5498\n",
      "Epoch 17/50\n",
      " - 0s - loss: 490.8070 - val_loss: 620.8415\n",
      "Epoch 18/50\n",
      " - 0s - loss: 472.4073 - val_loss: 603.4032\n",
      "Epoch 19/50\n",
      " - 0s - loss: 461.3890 - val_loss: 567.0662\n",
      "Epoch 20/50\n",
      " - 0s - loss: 444.4372 - val_loss: 540.1885\n",
      "Epoch 21/50\n",
      " - 0s - loss: 422.8626 - val_loss: 551.4332\n",
      "Epoch 22/50\n",
      " - 0s - loss: 404.5130 - val_loss: 581.9760\n",
      "Epoch 23/50\n",
      " - 0s - loss: 398.0637 - val_loss: 535.5987\n",
      "Epoch 24/50\n",
      " - 0s - loss: 379.2848 - val_loss: 487.7774\n",
      "Epoch 25/50\n",
      " - 0s - loss: 369.4427 - val_loss: 499.4494\n",
      "Epoch 26/50\n",
      " - 0s - loss: 354.2352 - val_loss: 440.1771\n",
      "Epoch 27/50\n",
      " - 0s - loss: 347.2331 - val_loss: 414.9775\n",
      "Epoch 28/50\n",
      " - 0s - loss: 337.3100 - val_loss: 452.1792\n",
      "Epoch 29/50\n",
      " - 0s - loss: 325.6304 - val_loss: 411.0043\n",
      "Epoch 30/50\n",
      " - 0s - loss: 318.0887 - val_loss: 373.2461\n",
      "Epoch 31/50\n",
      " - 0s - loss: 304.7426 - val_loss: 374.6113\n",
      "Epoch 32/50\n",
      " - 0s - loss: 298.7387 - val_loss: 359.7002\n",
      "Epoch 33/50\n",
      " - 0s - loss: 285.4553 - val_loss: 344.4316\n",
      "Epoch 34/50\n",
      " - 0s - loss: 281.5004 - val_loss: 363.9482\n",
      "Epoch 35/50\n",
      " - 0s - loss: 282.4530 - val_loss: 377.3753\n",
      "Epoch 36/50\n",
      " - 0s - loss: 272.7762 - val_loss: 321.7342\n",
      "Epoch 37/50\n",
      " - 0s - loss: 263.5146 - val_loss: 412.4182\n",
      "Epoch 38/50\n",
      " - 0s - loss: 256.3143 - val_loss: 316.3348\n",
      "Epoch 39/50\n",
      " - 0s - loss: 252.3614 - val_loss: 313.9668\n",
      "Epoch 40/50\n",
      " - 0s - loss: 256.2846 - val_loss: 307.1567\n",
      "Epoch 41/50\n",
      " - 0s - loss: 239.1675 - val_loss: 286.3328\n",
      "Epoch 42/50\n",
      " - 0s - loss: 228.9331 - val_loss: 292.4180\n",
      "Epoch 43/50\n",
      " - 0s - loss: 223.4354 - val_loss: 271.9658\n",
      "Epoch 44/50\n",
      " - 0s - loss: 222.6309 - val_loss: 282.5504\n",
      "Epoch 45/50\n",
      " - 0s - loss: 213.2317 - val_loss: 260.6580\n",
      "Epoch 46/50\n",
      " - 0s - loss: 221.5617 - val_loss: 264.1830\n",
      "Epoch 47/50\n",
      " - 0s - loss: 210.2272 - val_loss: 344.9668\n",
      "Epoch 48/50\n",
      " - 0s - loss: 205.4616 - val_loss: 263.0442\n",
      "Epoch 49/50\n",
      " - 0s - loss: 203.1035 - val_loss: 250.8297\n",
      "Epoch 50/50\n",
      " - 0s - loss: 200.8648 - val_loss: 258.1271\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 1594.9080 - val_loss: 338.6186\n",
      "Epoch 2/50\n",
      " - 0s - loss: 385.4528 - val_loss: 199.3707\n",
      "Epoch 3/50\n",
      " - 0s - loss: 303.1846 - val_loss: 222.9442\n",
      "Epoch 4/50\n",
      " - 0s - loss: 278.2763 - val_loss: 228.7629\n",
      "Epoch 5/50\n",
      " - 0s - loss: 262.8896 - val_loss: 219.0186\n",
      "Epoch 6/50\n",
      " - 0s - loss: 244.1507 - val_loss: 199.0867\n",
      "Epoch 7/50\n",
      " - 0s - loss: 220.4056 - val_loss: 148.1561\n",
      "Epoch 8/50\n",
      " - 0s - loss: 195.2513 - val_loss: 134.6240\n",
      "Epoch 9/50\n",
      " - 0s - loss: 179.7852 - val_loss: 114.6638\n",
      "Epoch 10/50\n",
      " - 0s - loss: 168.9465 - val_loss: 106.2450\n",
      "Epoch 11/50\n",
      " - 0s - loss: 157.6313 - val_loss: 100.7473\n",
      "Epoch 12/50\n",
      " - 0s - loss: 150.9670 - val_loss: 92.8627\n",
      "Epoch 13/50\n",
      " - 0s - loss: 146.6046 - val_loss: 92.2019\n",
      "Epoch 14/50\n",
      " - 0s - loss: 137.2393 - val_loss: 81.1874\n",
      "Epoch 15/50\n",
      " - 0s - loss: 127.7619 - val_loss: 82.6033\n",
      "Epoch 16/50\n",
      " - 0s - loss: 125.4439 - val_loss: 79.2321\n",
      "Epoch 17/50\n",
      " - 0s - loss: 119.7940 - val_loss: 87.6302\n",
      "Epoch 18/50\n",
      " - 0s - loss: 116.9683 - val_loss: 95.8287\n",
      "Epoch 19/50\n",
      " - 0s - loss: 120.6910 - val_loss: 81.4915\n",
      "Epoch 20/50\n",
      " - 0s - loss: 115.6092 - val_loss: 84.0928\n",
      "Epoch 21/50\n",
      " - 0s - loss: 111.4715 - val_loss: 89.3707\n",
      "Epoch 22/50\n",
      " - 0s - loss: 113.4215 - val_loss: 89.2090\n",
      "Epoch 23/50\n",
      " - 0s - loss: 110.9347 - val_loss: 86.0132\n",
      "Epoch 24/50\n",
      " - 0s - loss: 109.0387 - val_loss: 87.1157\n",
      "Epoch 25/50\n",
      " - 0s - loss: 108.7006 - val_loss: 89.5084\n",
      "Epoch 26/50\n",
      " - 0s - loss: 108.5950 - val_loss: 86.8854\n",
      "Epoch 27/50\n",
      " - 0s - loss: 105.7906 - val_loss: 85.7335\n",
      "Epoch 28/50\n",
      " - 0s - loss: 104.4074 - val_loss: 84.7907\n",
      "Epoch 29/50\n",
      " - 0s - loss: 106.1424 - val_loss: 86.0773\n",
      "Epoch 30/50\n",
      " - 0s - loss: 104.1293 - val_loss: 83.2755\n",
      "Epoch 31/50\n",
      " - 0s - loss: 103.2039 - val_loss: 87.3051\n",
      "Epoch 32/50\n",
      " - 0s - loss: 102.2662 - val_loss: 87.2524\n",
      "Epoch 33/50\n",
      " - 0s - loss: 101.1392 - val_loss: 92.6585\n",
      "Epoch 34/50\n",
      " - 0s - loss: 101.2400 - val_loss: 88.5662\n",
      "Epoch 35/50\n",
      " - 0s - loss: 103.7321 - val_loss: 90.4601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      " - 0s - loss: 99.1470 - val_loss: 91.7502\n",
      "Epoch 37/50\n",
      " - 0s - loss: 100.2966 - val_loss: 86.8912\n",
      "Epoch 38/50\n",
      " - 0s - loss: 99.3661 - val_loss: 91.4305\n",
      "Epoch 39/50\n",
      " - 0s - loss: 99.3726 - val_loss: 85.3870\n",
      "Epoch 40/50\n",
      " - 0s - loss: 96.5238 - val_loss: 84.1157\n",
      "Epoch 41/50\n",
      " - 0s - loss: 97.0993 - val_loss: 83.7453\n",
      "Epoch 42/50\n",
      " - 0s - loss: 95.9821 - val_loss: 88.7647\n",
      "Epoch 43/50\n",
      " - 0s - loss: 95.6733 - val_loss: 86.5970\n",
      "Epoch 44/50\n",
      " - 0s - loss: 95.1490 - val_loss: 83.1257\n",
      "Epoch 45/50\n",
      " - 0s - loss: 93.4689 - val_loss: 87.5497\n",
      "Epoch 46/50\n",
      " - 0s - loss: 93.3357 - val_loss: 88.7995\n",
      "Epoch 47/50\n",
      " - 0s - loss: 95.6875 - val_loss: 88.4690\n",
      "Epoch 48/50\n",
      " - 0s - loss: 93.5987 - val_loss: 80.7873\n",
      "Epoch 49/50\n",
      " - 0s - loss: 91.0097 - val_loss: 90.4169\n",
      "Epoch 50/50\n",
      " - 0s - loss: 91.4540 - val_loss: 80.2685\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 260536.5203 - val_loss: 138937.4251\n",
      "Epoch 2/50\n",
      " - 0s - loss: 107913.3334 - val_loss: 66144.9219\n",
      "Epoch 3/50\n",
      " - 0s - loss: 56768.6639 - val_loss: 36410.6953\n",
      "Epoch 4/50\n",
      " - 0s - loss: 31716.6284 - val_loss: 19059.0960\n",
      "Epoch 5/50\n",
      " - 0s - loss: 16019.1236 - val_loss: 8434.3797\n",
      "Epoch 6/50\n",
      " - 0s - loss: 6865.2774 - val_loss: 2999.2523\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2454.7285 - val_loss: 945.7367\n",
      "Epoch 8/50\n",
      " - 0s - loss: 938.7334 - val_loss: 440.0694\n",
      "Epoch 9/50\n",
      " - 0s - loss: 593.4560 - val_loss: 368.1779\n",
      "Epoch 10/50\n",
      " - 0s - loss: 527.4690 - val_loss: 359.7610\n",
      "Epoch 11/50\n",
      " - 0s - loss: 507.0039 - val_loss: 346.3004\n",
      "Epoch 12/50\n",
      " - 0s - loss: 493.0716 - val_loss: 332.7306\n",
      "Epoch 13/50\n",
      " - 0s - loss: 480.3675 - val_loss: 320.9497\n",
      "Epoch 14/50\n",
      " - 0s - loss: 468.0788 - val_loss: 306.2951\n",
      "Epoch 15/50\n",
      " - 0s - loss: 455.7925 - val_loss: 291.4038\n",
      "Epoch 16/50\n",
      " - 0s - loss: 444.7813 - val_loss: 278.0248\n",
      "Epoch 17/50\n",
      " - 0s - loss: 432.5403 - val_loss: 271.0534\n",
      "Epoch 18/50\n",
      " - 0s - loss: 416.7668 - val_loss: 254.7174\n",
      "Epoch 19/50\n",
      " - 0s - loss: 393.0937 - val_loss: 236.9861\n",
      "Epoch 20/50\n",
      " - 0s - loss: 364.9002 - val_loss: 220.1682\n",
      "Epoch 21/50\n",
      " - 0s - loss: 334.5527 - val_loss: 206.9262\n",
      "Epoch 22/50\n",
      " - 0s - loss: 308.6212 - val_loss: 195.8517\n",
      "Epoch 23/50\n",
      " - 0s - loss: 289.4046 - val_loss: 187.2340\n",
      "Epoch 24/50\n",
      " - 0s - loss: 273.9398 - val_loss: 174.5253\n",
      "Epoch 25/50\n",
      " - 0s - loss: 260.9275 - val_loss: 167.6408\n",
      "Epoch 26/50\n",
      " - 0s - loss: 250.5092 - val_loss: 158.1264\n",
      "Epoch 27/50\n",
      " - 0s - loss: 240.1412 - val_loss: 148.4806\n",
      "Epoch 28/50\n",
      " - 0s - loss: 230.7176 - val_loss: 141.4417\n",
      "Epoch 29/50\n",
      " - 0s - loss: 222.9398 - val_loss: 133.7343\n",
      "Epoch 30/50\n",
      " - 0s - loss: 214.4583 - val_loss: 132.3681\n",
      "Epoch 31/50\n",
      " - 0s - loss: 208.5336 - val_loss: 125.4266\n",
      "Epoch 32/50\n",
      " - 0s - loss: 202.1423 - val_loss: 121.9621\n",
      "Epoch 33/50\n",
      " - 0s - loss: 196.2732 - val_loss: 116.3886\n",
      "Epoch 34/50\n",
      " - 0s - loss: 190.1360 - val_loss: 115.2386\n",
      "Epoch 35/50\n",
      " - 0s - loss: 184.4853 - val_loss: 110.1756\n",
      "Epoch 36/50\n",
      " - 0s - loss: 179.0810 - val_loss: 107.7841\n",
      "Epoch 37/50\n",
      " - 0s - loss: 174.5250 - val_loss: 105.6291\n",
      "Epoch 38/50\n",
      " - 0s - loss: 170.2173 - val_loss: 104.6982\n",
      "Epoch 39/50\n",
      " - 0s - loss: 166.2651 - val_loss: 102.6381\n",
      "Epoch 40/50\n",
      " - 0s - loss: 163.2205 - val_loss: 100.4729\n",
      "Epoch 41/50\n",
      " - 0s - loss: 158.9409 - val_loss: 98.7892\n",
      "Epoch 42/50\n",
      " - 0s - loss: 156.4952 - val_loss: 97.3940\n",
      "Epoch 43/50\n",
      " - 0s - loss: 153.2720 - val_loss: 96.6758\n",
      "Epoch 44/50\n",
      " - 0s - loss: 150.1377 - val_loss: 95.3331\n",
      "Epoch 45/50\n",
      " - 0s - loss: 147.6211 - val_loss: 95.8598\n",
      "Epoch 46/50\n",
      " - 0s - loss: 145.2339 - val_loss: 93.4667\n",
      "Epoch 47/50\n",
      " - 0s - loss: 143.0268 - val_loss: 92.4714\n",
      "Epoch 48/50\n",
      " - 0s - loss: 140.8155 - val_loss: 92.1016\n",
      "Epoch 49/50\n",
      " - 0s - loss: 138.6550 - val_loss: 91.2266\n",
      "Epoch 50/50\n",
      " - 0s - loss: 137.1052 - val_loss: 90.9767\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 2021.8951 - val_loss: 1611.1265\n",
      "Epoch 2/50\n",
      " - 0s - loss: 790.9991 - val_loss: 1174.7213\n",
      "Epoch 3/50\n",
      " - 0s - loss: 635.3966 - val_loss: 957.6478\n",
      "Epoch 4/50\n",
      " - 0s - loss: 516.4723 - val_loss: 802.7273\n",
      "Epoch 5/50\n",
      " - 0s - loss: 438.7879 - val_loss: 620.2949\n",
      "Epoch 6/50\n",
      " - 0s - loss: 383.6887 - val_loss: 536.9219\n",
      "Epoch 7/50\n",
      " - 0s - loss: 350.8547 - val_loss: 453.5276\n",
      "Epoch 8/50\n",
      " - 0s - loss: 323.9779 - val_loss: 419.7058\n",
      "Epoch 9/50\n",
      " - 0s - loss: 303.9234 - val_loss: 374.1008\n",
      "Epoch 10/50\n",
      " - 0s - loss: 289.0876 - val_loss: 334.6152\n",
      "Epoch 11/50\n",
      " - 0s - loss: 274.0832 - val_loss: 351.9215\n",
      "Epoch 12/50\n",
      " - 0s - loss: 268.0386 - val_loss: 290.2477\n",
      "Epoch 13/50\n",
      " - 0s - loss: 257.7888 - val_loss: 269.6199\n",
      "Epoch 14/50\n",
      " - 0s - loss: 245.5465 - val_loss: 244.7514\n",
      "Epoch 15/50\n",
      " - 0s - loss: 240.7155 - val_loss: 235.8758\n",
      "Epoch 16/50\n",
      " - 0s - loss: 232.7864 - val_loss: 221.4395\n",
      "Epoch 17/50\n",
      " - 0s - loss: 226.4078 - val_loss: 221.6123\n",
      "Epoch 18/50\n",
      " - 0s - loss: 224.9092 - val_loss: 219.0114\n",
      "Epoch 19/50\n",
      " - 0s - loss: 219.6257 - val_loss: 200.7524\n",
      "Epoch 20/50\n",
      " - 0s - loss: 213.5080 - val_loss: 181.9573\n",
      "Epoch 21/50\n",
      " - 0s - loss: 209.4893 - val_loss: 172.3598\n",
      "Epoch 22/50\n",
      " - 0s - loss: 205.5349 - val_loss: 161.9267\n",
      "Epoch 23/50\n",
      " - 0s - loss: 200.9264 - val_loss: 159.2793\n",
      "Epoch 24/50\n",
      " - 0s - loss: 201.4981 - val_loss: 149.2539\n",
      "Epoch 25/50\n",
      " - 0s - loss: 193.8551 - val_loss: 150.7118\n",
      "Epoch 26/50\n",
      " - 0s - loss: 189.6461 - val_loss: 143.1610\n",
      "Epoch 27/50\n",
      " - 0s - loss: 187.3376 - val_loss: 135.2606\n",
      "Epoch 28/50\n",
      " - 0s - loss: 183.3590 - val_loss: 124.2173\n",
      "Epoch 29/50\n",
      " - 0s - loss: 182.1602 - val_loss: 123.6598\n",
      "Epoch 30/50\n",
      " - 0s - loss: 176.8852 - val_loss: 115.8223\n",
      "Epoch 31/50\n",
      " - 0s - loss: 174.3571 - val_loss: 109.5508\n",
      "Epoch 32/50\n",
      " - 0s - loss: 171.1531 - val_loss: 106.2445\n",
      "Epoch 33/50\n",
      " - 0s - loss: 167.4235 - val_loss: 104.6077\n",
      "Epoch 34/50\n",
      " - 0s - loss: 169.8548 - val_loss: 104.1765\n",
      "Epoch 35/50\n",
      " - 0s - loss: 168.0463 - val_loss: 111.8754\n",
      "Epoch 36/50\n",
      " - 0s - loss: 161.5541 - val_loss: 92.9436\n",
      "Epoch 37/50\n",
      " - 0s - loss: 157.6717 - val_loss: 90.6657\n",
      "Epoch 38/50\n",
      " - 0s - loss: 156.2706 - val_loss: 91.6912\n",
      "Epoch 39/50\n",
      " - 0s - loss: 152.6629 - val_loss: 87.3990\n",
      "Epoch 40/50\n",
      " - 0s - loss: 150.8515 - val_loss: 82.8680\n",
      "Epoch 41/50\n",
      " - 0s - loss: 150.8538 - val_loss: 97.3370\n",
      "Epoch 42/50\n",
      " - 0s - loss: 147.7480 - val_loss: 79.1186\n",
      "Epoch 43/50\n",
      " - 0s - loss: 149.1311 - val_loss: 85.2430\n",
      "Epoch 44/50\n",
      " - 0s - loss: 145.9527 - val_loss: 82.2599\n",
      "Epoch 45/50\n",
      " - 0s - loss: 141.7130 - val_loss: 79.0651\n",
      "Epoch 46/50\n",
      " - 0s - loss: 144.1942 - val_loss: 73.6861\n",
      "Epoch 47/50\n",
      " - 0s - loss: 138.8929 - val_loss: 72.5783\n",
      "Epoch 48/50\n",
      " - 0s - loss: 137.6431 - val_loss: 77.1738\n",
      "Epoch 49/50\n",
      " - 0s - loss: 137.8025 - val_loss: 70.3982\n",
      "Epoch 50/50\n",
      " - 0s - loss: 135.8274 - val_loss: 69.4743\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 536.9660 - val_loss: 262.5211\n",
      "Epoch 2/50\n",
      " - 0s - loss: 378.9629 - val_loss: 249.4820\n",
      "Epoch 3/50\n",
      " - 0s - loss: 336.8184 - val_loss: 203.9033\n",
      "Epoch 4/50\n",
      " - 0s - loss: 317.9024 - val_loss: 186.9141\n",
      "Epoch 5/50\n",
      " - 0s - loss: 294.9494 - val_loss: 170.5888\n",
      "Epoch 6/50\n",
      " - 0s - loss: 269.5078 - val_loss: 160.2502\n",
      "Epoch 7/50\n",
      " - 0s - loss: 249.1274 - val_loss: 140.8783\n",
      "Epoch 8/50\n",
      " - 0s - loss: 229.9792 - val_loss: 134.9919\n",
      "Epoch 9/50\n",
      " - 0s - loss: 210.8217 - val_loss: 115.5653\n",
      "Epoch 10/50\n",
      " - 0s - loss: 195.5349 - val_loss: 112.8376\n",
      "Epoch 11/50\n",
      " - 0s - loss: 179.7295 - val_loss: 121.2954\n",
      "Epoch 12/50\n",
      " - 0s - loss: 170.8300 - val_loss: 107.5027\n",
      "Epoch 13/50\n",
      " - 0s - loss: 158.9712 - val_loss: 95.7059\n",
      "Epoch 14/50\n",
      " - 0s - loss: 148.5162 - val_loss: 90.0152\n",
      "Epoch 15/50\n",
      " - 0s - loss: 138.9998 - val_loss: 80.5107\n",
      "Epoch 16/50\n",
      " - 0s - loss: 130.3117 - val_loss: 80.8198\n",
      "Epoch 17/50\n",
      " - 0s - loss: 122.1686 - val_loss: 79.0979\n",
      "Epoch 18/50\n",
      " - 0s - loss: 114.8233 - val_loss: 75.5964\n",
      "Epoch 19/50\n",
      " - 0s - loss: 114.0852 - val_loss: 79.0088\n",
      "Epoch 20/50\n",
      " - 0s - loss: 103.7194 - val_loss: 69.5960\n",
      "Epoch 21/50\n",
      " - 0s - loss: 97.8663 - val_loss: 72.6982\n",
      "Epoch 22/50\n",
      " - 0s - loss: 92.9319 - val_loss: 68.1271\n",
      "Epoch 23/50\n",
      " - 0s - loss: 90.4862 - val_loss: 68.4714\n",
      "Epoch 24/50\n",
      " - 0s - loss: 87.2876 - val_loss: 65.6886\n",
      "Epoch 25/50\n",
      " - 0s - loss: 87.2763 - val_loss: 71.3373\n",
      "Epoch 26/50\n",
      " - 0s - loss: 84.8206 - val_loss: 65.3452\n",
      "Epoch 27/50\n",
      " - 0s - loss: 81.1796 - val_loss: 63.2353\n",
      "Epoch 28/50\n",
      " - 0s - loss: 79.1666 - val_loss: 62.8831\n",
      "Epoch 29/50\n",
      " - 0s - loss: 77.1685 - val_loss: 74.2931\n",
      "Epoch 30/50\n",
      " - 0s - loss: 78.7425 - val_loss: 63.9899\n",
      "Epoch 31/50\n",
      " - 0s - loss: 76.1529 - val_loss: 61.7318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      " - 0s - loss: 74.9334 - val_loss: 60.7138\n",
      "Epoch 33/50\n",
      " - 0s - loss: 74.9987 - val_loss: 59.1451\n",
      "Epoch 34/50\n",
      " - 0s - loss: 73.5999 - val_loss: 62.2920\n",
      "Epoch 35/50\n",
      " - 0s - loss: 72.8387 - val_loss: 62.6506\n",
      "Epoch 36/50\n",
      " - 0s - loss: 72.6513 - val_loss: 58.8545\n",
      "Epoch 37/50\n",
      " - 0s - loss: 70.7117 - val_loss: 58.3943\n",
      "Epoch 38/50\n",
      " - 0s - loss: 72.6495 - val_loss: 57.5259\n",
      "Epoch 39/50\n",
      " - 0s - loss: 71.5860 - val_loss: 62.3504\n",
      "Epoch 40/50\n",
      " - 0s - loss: 73.8997 - val_loss: 54.9382\n",
      "Epoch 41/50\n",
      " - 0s - loss: 68.7682 - val_loss: 56.7365\n",
      "Epoch 42/50\n",
      " - 0s - loss: 70.4003 - val_loss: 57.6323\n",
      "Epoch 43/50\n",
      " - 0s - loss: 68.1592 - val_loss: 55.6131\n",
      "Epoch 44/50\n",
      " - 0s - loss: 67.7239 - val_loss: 55.7884\n",
      "Epoch 45/50\n",
      " - 0s - loss: 70.4584 - val_loss: 55.7994\n",
      "Epoch 46/50\n",
      " - 0s - loss: 65.9515 - val_loss: 54.3420\n",
      "Epoch 47/50\n",
      " - 0s - loss: 66.7028 - val_loss: 58.3074\n",
      "Epoch 48/50\n",
      " - 0s - loss: 65.5876 - val_loss: 57.6202\n",
      "Epoch 49/50\n",
      " - 0s - loss: 66.2344 - val_loss: 53.9720\n",
      "Epoch 50/50\n",
      " - 0s - loss: 63.7298 - val_loss: 54.9425\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 32908.0968 - val_loss: 11886.2235\n",
      "Epoch 2/50\n",
      " - 0s - loss: 7699.6767 - val_loss: 2216.9726\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1779.7018 - val_loss: 574.5720\n",
      "Epoch 4/50\n",
      " - 0s - loss: 757.5752 - val_loss: 641.2301\n",
      "Epoch 5/50\n",
      " - 0s - loss: 704.8334 - val_loss: 584.8184\n",
      "Epoch 6/50\n",
      " - 0s - loss: 669.1889 - val_loss: 490.0491\n",
      "Epoch 7/50\n",
      " - 0s - loss: 595.3791 - val_loss: 355.1100\n",
      "Epoch 8/50\n",
      " - 0s - loss: 521.3017 - val_loss: 328.4129\n",
      "Epoch 9/50\n",
      " - 0s - loss: 481.1041 - val_loss: 301.1034\n",
      "Epoch 10/50\n",
      " - 0s - loss: 450.5887 - val_loss: 282.0968\n",
      "Epoch 11/50\n",
      " - 0s - loss: 426.7068 - val_loss: 260.2138\n",
      "Epoch 12/50\n",
      " - 0s - loss: 398.5187 - val_loss: 228.6980\n",
      "Epoch 13/50\n",
      " - 0s - loss: 374.7924 - val_loss: 184.3051\n",
      "Epoch 14/50\n",
      " - 0s - loss: 353.2239 - val_loss: 197.4928\n",
      "Epoch 15/50\n",
      " - 0s - loss: 326.9496 - val_loss: 163.5046\n",
      "Epoch 16/50\n",
      " - 0s - loss: 309.4491 - val_loss: 151.8346\n",
      "Epoch 17/50\n",
      " - 0s - loss: 294.5483 - val_loss: 140.6037\n",
      "Epoch 18/50\n",
      " - 0s - loss: 277.2034 - val_loss: 141.7575\n",
      "Epoch 19/50\n",
      " - 0s - loss: 263.7763 - val_loss: 145.2930\n",
      "Epoch 20/50\n",
      " - 0s - loss: 248.5611 - val_loss: 168.4827\n",
      "Epoch 21/50\n",
      " - 0s - loss: 227.1724 - val_loss: 129.1408\n",
      "Epoch 22/50\n",
      " - 0s - loss: 198.8325 - val_loss: 104.4926\n",
      "Epoch 23/50\n",
      " - 0s - loss: 177.7742 - val_loss: 92.3606\n",
      "Epoch 24/50\n",
      " - 0s - loss: 165.9386 - val_loss: 89.4285\n",
      "Epoch 25/50\n",
      " - 0s - loss: 151.7102 - val_loss: 88.5517\n",
      "Epoch 26/50\n",
      " - 0s - loss: 142.3405 - val_loss: 83.8596\n",
      "Epoch 27/50\n",
      " - 0s - loss: 135.5865 - val_loss: 78.0114\n",
      "Epoch 28/50\n",
      " - 0s - loss: 130.8835 - val_loss: 75.6811\n",
      "Epoch 29/50\n",
      " - 0s - loss: 125.7750 - val_loss: 80.3411\n",
      "Epoch 30/50\n",
      " - 0s - loss: 121.4083 - val_loss: 77.1564\n",
      "Epoch 31/50\n",
      " - 0s - loss: 119.2849 - val_loss: 78.0914\n",
      "Epoch 32/50\n",
      " - 0s - loss: 117.3510 - val_loss: 79.1662\n",
      "Epoch 33/50\n",
      " - 0s - loss: 113.4156 - val_loss: 80.7658\n",
      "Epoch 34/50\n",
      " - 0s - loss: 115.0028 - val_loss: 82.4684\n",
      "Epoch 35/50\n",
      " - 0s - loss: 110.5047 - val_loss: 78.0735\n",
      "Epoch 36/50\n",
      " - 0s - loss: 109.9101 - val_loss: 75.3356\n",
      "Epoch 37/50\n",
      " - 0s - loss: 109.8155 - val_loss: 86.2495\n",
      "Epoch 38/50\n",
      " - 0s - loss: 109.5337 - val_loss: 82.5840\n",
      "Epoch 39/50\n",
      " - 0s - loss: 106.7277 - val_loss: 81.9356\n",
      "Epoch 40/50\n",
      " - 0s - loss: 105.2297 - val_loss: 73.5176\n",
      "Epoch 41/50\n",
      " - 0s - loss: 107.4465 - val_loss: 84.1495\n",
      "Epoch 42/50\n",
      " - 0s - loss: 104.5212 - val_loss: 89.0941\n",
      "Epoch 43/50\n",
      " - 0s - loss: 102.3474 - val_loss: 75.0400\n",
      "Epoch 44/50\n",
      " - 0s - loss: 100.6857 - val_loss: 74.7168\n",
      "Epoch 45/50\n",
      " - 0s - loss: 102.4264 - val_loss: 76.3816\n",
      "Epoch 46/50\n",
      " - 0s - loss: 102.4034 - val_loss: 76.7882\n",
      "Epoch 47/50\n",
      " - 0s - loss: 100.8049 - val_loss: 71.4667\n",
      "Epoch 48/50\n",
      " - 0s - loss: 101.8508 - val_loss: 71.8379\n",
      "Epoch 49/50\n",
      " - 0s - loss: 102.8330 - val_loss: 84.7913\n",
      "Epoch 50/50\n",
      " - 0s - loss: 98.4685 - val_loss: 74.6196\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 16288.7549 - val_loss: 8677.4213\n",
      "Epoch 2/50\n",
      " - 0s - loss: 6967.8601 - val_loss: 3880.9364\n",
      "Epoch 3/50\n",
      " - 0s - loss: 3573.2520 - val_loss: 2031.7689\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2102.5078 - val_loss: 1135.4060\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1301.7380 - val_loss: 627.6604\n",
      "Epoch 6/50\n",
      " - 0s - loss: 815.4123 - val_loss: 357.5013\n",
      "Epoch 7/50\n",
      " - 0s - loss: 542.9088 - val_loss: 240.7350\n",
      "Epoch 8/50\n",
      " - 0s - loss: 416.0733 - val_loss: 219.6466\n",
      "Epoch 9/50\n",
      " - 0s - loss: 374.9530 - val_loss: 228.8748\n",
      "Epoch 10/50\n",
      " - 0s - loss: 364.9496 - val_loss: 235.9846\n",
      "Epoch 11/50\n",
      " - 0s - loss: 361.6855 - val_loss: 237.8910\n",
      "Epoch 12/50\n",
      " - 0s - loss: 359.2425 - val_loss: 237.8122\n",
      "Epoch 13/50\n",
      " - 0s - loss: 357.1857 - val_loss: 236.4554\n",
      "Epoch 14/50\n",
      " - 0s - loss: 354.6377 - val_loss: 233.9247\n",
      "Epoch 15/50\n",
      " - 0s - loss: 352.1084 - val_loss: 231.7922\n",
      "Epoch 16/50\n",
      " - 0s - loss: 349.6921 - val_loss: 232.6480\n",
      "Epoch 17/50\n",
      " - 0s - loss: 346.7716 - val_loss: 231.6262\n",
      "Epoch 18/50\n",
      " - 0s - loss: 343.4426 - val_loss: 229.5483\n",
      "Epoch 19/50\n",
      " - 0s - loss: 335.6176 - val_loss: 231.6654\n",
      "Epoch 20/50\n",
      " - 0s - loss: 329.7917 - val_loss: 222.9228\n",
      "Epoch 21/50\n",
      " - 0s - loss: 325.9673 - val_loss: 221.3050\n",
      "Epoch 22/50\n",
      " - 0s - loss: 322.4600 - val_loss: 220.6780\n",
      "Epoch 23/50\n",
      " - 0s - loss: 319.8794 - val_loss: 212.7246\n",
      "Epoch 24/50\n",
      " - 0s - loss: 316.9353 - val_loss: 213.9642\n",
      "Epoch 25/50\n",
      " - 0s - loss: 314.1462 - val_loss: 211.7175\n",
      "Epoch 26/50\n",
      " - 0s - loss: 311.5490 - val_loss: 207.2079\n",
      "Epoch 27/50\n",
      " - 0s - loss: 308.8691 - val_loss: 204.4723\n",
      "Epoch 28/50\n",
      " - 0s - loss: 306.4745 - val_loss: 206.1305\n",
      "Epoch 29/50\n",
      " - 0s - loss: 303.2835 - val_loss: 203.2944\n",
      "Epoch 30/50\n",
      " - 0s - loss: 301.5212 - val_loss: 201.6043\n",
      "Epoch 31/50\n",
      " - 0s - loss: 298.7880 - val_loss: 198.3565\n",
      "Epoch 32/50\n",
      " - 0s - loss: 296.4018 - val_loss: 198.4039\n",
      "Epoch 33/50\n",
      " - 0s - loss: 294.7364 - val_loss: 195.0750\n",
      "Epoch 34/50\n",
      " - 0s - loss: 292.8976 - val_loss: 190.5934\n",
      "Epoch 35/50\n",
      " - 0s - loss: 289.4608 - val_loss: 194.6056\n",
      "Epoch 36/50\n",
      " - 0s - loss: 287.2713 - val_loss: 189.5475\n",
      "Epoch 37/50\n",
      " - 0s - loss: 284.9137 - val_loss: 189.9993\n",
      "Epoch 38/50\n",
      " - 0s - loss: 283.7950 - val_loss: 181.8408\n",
      "Epoch 39/50\n",
      " - 0s - loss: 280.3382 - val_loss: 183.7143\n",
      "Epoch 40/50\n",
      " - 0s - loss: 277.9099 - val_loss: 184.3347\n",
      "Epoch 41/50\n",
      " - 0s - loss: 276.2880 - val_loss: 183.9820\n",
      "Epoch 42/50\n",
      " - 0s - loss: 273.5870 - val_loss: 174.8885\n",
      "Epoch 43/50\n",
      " - 0s - loss: 270.1659 - val_loss: 175.8090\n",
      "Epoch 44/50\n",
      " - 0s - loss: 268.1434 - val_loss: 173.5163\n",
      "Epoch 45/50\n",
      " - 0s - loss: 265.4502 - val_loss: 168.6549\n",
      "Epoch 46/50\n",
      " - 0s - loss: 263.5082 - val_loss: 167.8309\n",
      "Epoch 47/50\n",
      " - 0s - loss: 260.6011 - val_loss: 171.3247\n",
      "Epoch 48/50\n",
      " - 0s - loss: 254.2147 - val_loss: 168.6128\n",
      "Epoch 49/50\n",
      " - 0s - loss: 243.2462 - val_loss: 153.8280\n",
      "Epoch 50/50\n",
      " - 0s - loss: 236.3421 - val_loss: 160.4781\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 29927.3177 - val_loss: 13826.5708\n",
      "Epoch 2/50\n",
      " - 0s - loss: 8747.4412 - val_loss: 2751.0645\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1364.8339 - val_loss: 147.6878\n",
      "Epoch 4/50\n",
      " - 0s - loss: 287.2958 - val_loss: 245.1379\n",
      "Epoch 5/50\n",
      " - 0s - loss: 278.4190 - val_loss: 168.5584\n",
      "Epoch 6/50\n",
      " - 0s - loss: 269.9655 - val_loss: 166.8307\n",
      "Epoch 7/50\n",
      " - 0s - loss: 266.4150 - val_loss: 166.5262\n",
      "Epoch 8/50\n",
      " - 0s - loss: 263.2290 - val_loss: 163.3084\n",
      "Epoch 9/50\n",
      " - 0s - loss: 260.2445 - val_loss: 162.0892\n",
      "Epoch 10/50\n",
      " - 0s - loss: 257.5016 - val_loss: 159.5632\n",
      "Epoch 11/50\n",
      " - 0s - loss: 254.8373 - val_loss: 157.1396\n",
      "Epoch 12/50\n",
      " - 0s - loss: 251.5117 - val_loss: 152.9651\n",
      "Epoch 13/50\n",
      " - 0s - loss: 248.8860 - val_loss: 153.7858\n",
      "Epoch 14/50\n",
      " - 0s - loss: 245.2733 - val_loss: 151.4034\n",
      "Epoch 15/50\n",
      " - 0s - loss: 242.4230 - val_loss: 149.8898\n",
      "Epoch 16/50\n",
      " - 0s - loss: 240.2501 - val_loss: 144.2008\n",
      "Epoch 17/50\n",
      " - 0s - loss: 237.5207 - val_loss: 145.8669\n",
      "Epoch 18/50\n",
      " - 0s - loss: 234.1311 - val_loss: 148.9029\n",
      "Epoch 19/50\n",
      " - 0s - loss: 230.5427 - val_loss: 143.9452\n",
      "Epoch 20/50\n",
      " - 0s - loss: 227.0824 - val_loss: 136.0803\n",
      "Epoch 21/50\n",
      " - 0s - loss: 225.2337 - val_loss: 143.0343\n",
      "Epoch 22/50\n",
      " - 0s - loss: 221.8497 - val_loss: 137.8045\n",
      "Epoch 23/50\n",
      " - 0s - loss: 219.0887 - val_loss: 137.0788\n",
      "Epoch 24/50\n",
      " - 0s - loss: 217.5007 - val_loss: 136.9504\n",
      "Epoch 25/50\n",
      " - 0s - loss: 214.0920 - val_loss: 138.9791\n",
      "Epoch 26/50\n",
      " - 0s - loss: 212.0654 - val_loss: 144.0509\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 209.1163 - val_loss: 131.8982\n",
      "Epoch 28/50\n",
      " - 0s - loss: 207.5573 - val_loss: 141.1085\n",
      "Epoch 29/50\n",
      " - 0s - loss: 202.6820 - val_loss: 123.9646\n",
      "Epoch 30/50\n",
      " - 0s - loss: 200.2475 - val_loss: 140.4495\n",
      "Epoch 31/50\n",
      " - 0s - loss: 198.4371 - val_loss: 145.2289\n",
      "Epoch 32/50\n",
      " - 0s - loss: 195.5132 - val_loss: 129.4993\n",
      "Epoch 33/50\n",
      " - 0s - loss: 191.5275 - val_loss: 130.6010\n",
      "Epoch 34/50\n",
      " - 0s - loss: 189.4693 - val_loss: 141.3439\n",
      "Epoch 35/50\n",
      " - 0s - loss: 188.6534 - val_loss: 126.2727\n",
      "Epoch 36/50\n",
      " - 0s - loss: 183.9868 - val_loss: 127.9746\n",
      "Epoch 37/50\n",
      " - 0s - loss: 180.5577 - val_loss: 143.2788\n",
      "Epoch 38/50\n",
      " - 0s - loss: 179.0876 - val_loss: 136.0909\n",
      "Epoch 39/50\n",
      " - 0s - loss: 175.3771 - val_loss: 128.1144\n",
      "Epoch 40/50\n",
      " - 0s - loss: 173.8901 - val_loss: 136.1061\n",
      "Epoch 41/50\n",
      " - 0s - loss: 171.4082 - val_loss: 127.0464\n",
      "Epoch 42/50\n",
      " - 0s - loss: 168.0432 - val_loss: 149.7752\n",
      "Epoch 43/50\n",
      " - 0s - loss: 168.0533 - val_loss: 133.7460\n",
      "Epoch 44/50\n",
      " - 0s - loss: 163.4467 - val_loss: 137.2164\n",
      "Epoch 45/50\n",
      " - 0s - loss: 161.4449 - val_loss: 126.1195\n",
      "Epoch 46/50\n",
      " - 0s - loss: 162.4989 - val_loss: 140.3451\n",
      "Epoch 47/50\n",
      " - 0s - loss: 161.2519 - val_loss: 131.8499\n",
      "Epoch 48/50\n",
      " - 0s - loss: 156.3900 - val_loss: 135.1370\n",
      "Epoch 49/50\n",
      " - 0s - loss: 153.4489 - val_loss: 140.7857\n",
      "Epoch 50/50\n",
      " - 0s - loss: 150.5863 - val_loss: 137.9058\n"
     ]
    }
   ],
   "source": [
    "s=[]\n",
    "i=0\n",
    "while i<50:\n",
    "    i=i+1\n",
    "    def regression_model():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    model = regression_model()\n",
    "\n",
    "    model.fit(predictors, target, validation_split=0.3, epochs=50, verbose=2)\n",
    "    a=model.predict(predictors, batch_size=1000, verbose=0, steps=None)\n",
    "\n",
    "\n",
    "#calucalte mean squared error\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    k=mean_squared_error(target,a)\n",
    "    s.append(k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[230.09636400576767,\n",
       " 114.66137222249792,\n",
       " 158.0701276051254,\n",
       " 76.90309232787632,\n",
       " 101.76879788852081,\n",
       " 87.56963541141566,\n",
       " 74.49047097933702,\n",
       " 222.2590470422713,\n",
       " 128.58328194095708,\n",
       " 191.07254222797167,\n",
       " 84.83229062595932,\n",
       " 132.6490351070525,\n",
       " 220.067921109028,\n",
       " 170.48671593050514,\n",
       " 105.97153161086814,\n",
       " 104.86051481927043,\n",
       " 100.3755651452077,\n",
       " 126.25797445600828,\n",
       " 72.45887176420682,\n",
       " 121.34525723485362,\n",
       " 96.89077170757592,\n",
       " 94.51641462213705,\n",
       " 83.95383119122953,\n",
       " 153.39578717127142,\n",
       " 103.51904358803161,\n",
       " 87.9820026089436,\n",
       " 62.736191402347664,\n",
       " 98.90197285475207,\n",
       " 110.3907315955753,\n",
       " 120.05975226834266,\n",
       " 136.60049582340082,\n",
       " 263.1020639956861,\n",
       " 175.94212006473765,\n",
       " 100.39615715368274,\n",
       " 77.34431276498337,\n",
       " 95.97193666198923,\n",
       " 77.19399449613134,\n",
       " 144.21406426312117,\n",
       " 232.59064381519948,\n",
       " 78.9204133055058,\n",
       " 74.83203283317278,\n",
       " 109.94806577824811,\n",
       " 212.42790983294623,\n",
       " 86.01568703016426,\n",
       " 122.37634667928998,\n",
       " 116.6276285407164,\n",
       " 60.67147826529775,\n",
       " 89.67061688646649,\n",
       " 209.4285736131805,\n",
       " 145.46414040315625]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124.93731181343968"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate mean of meansqured errors\n",
    "import statistics\n",
    "statistics.mean(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.99952494543396"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate standard deviation of mean squared errors\n",
    "statistics.stdev(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
