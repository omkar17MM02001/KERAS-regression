{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data=pd.read_csv(\"concrete_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>47.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>43.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>36.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>39.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>90</td>\n",
       "      <td>38.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>28</td>\n",
       "      <td>28.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>427.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>43.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>190.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>42.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>304.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>47.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>52.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>90</td>\n",
       "      <td>39.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>342.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>365</td>\n",
       "      <td>56.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>90</td>\n",
       "      <td>40.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>180</td>\n",
       "      <td>42.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>427.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>180</td>\n",
       "      <td>41.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>28</td>\n",
       "      <td>28.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>3</td>\n",
       "      <td>8.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>180</td>\n",
       "      <td>44.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>365</td>\n",
       "      <td>52.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>270</td>\n",
       "      <td>53.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>41.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>342.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>180</td>\n",
       "      <td>52.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>427.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>37.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>7</td>\n",
       "      <td>38.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>141.9</td>\n",
       "      <td>166.6</td>\n",
       "      <td>129.7</td>\n",
       "      <td>173.5</td>\n",
       "      <td>10.9</td>\n",
       "      <td>882.6</td>\n",
       "      <td>785.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>297.8</td>\n",
       "      <td>137.2</td>\n",
       "      <td>106.9</td>\n",
       "      <td>201.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>878.4</td>\n",
       "      <td>655.3</td>\n",
       "      <td>28</td>\n",
       "      <td>53.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>321.3</td>\n",
       "      <td>164.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>870.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>28</td>\n",
       "      <td>57.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>366.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>824.3</td>\n",
       "      <td>756.9</td>\n",
       "      <td>28</td>\n",
       "      <td>65.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>279.8</td>\n",
       "      <td>128.9</td>\n",
       "      <td>100.4</td>\n",
       "      <td>172.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>825.1</td>\n",
       "      <td>804.9</td>\n",
       "      <td>28</td>\n",
       "      <td>52.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>252.1</td>\n",
       "      <td>97.1</td>\n",
       "      <td>75.6</td>\n",
       "      <td>193.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>835.5</td>\n",
       "      <td>821.4</td>\n",
       "      <td>28</td>\n",
       "      <td>33.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>164.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.4</td>\n",
       "      <td>181.6</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1023.3</td>\n",
       "      <td>728.9</td>\n",
       "      <td>28</td>\n",
       "      <td>18.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>155.6</td>\n",
       "      <td>243.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.3</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>697.7</td>\n",
       "      <td>28</td>\n",
       "      <td>37.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>160.2</td>\n",
       "      <td>188.0</td>\n",
       "      <td>146.4</td>\n",
       "      <td>203.2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>828.7</td>\n",
       "      <td>709.7</td>\n",
       "      <td>28</td>\n",
       "      <td>35.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>298.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>186.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>879.0</td>\n",
       "      <td>815.2</td>\n",
       "      <td>28</td>\n",
       "      <td>42.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>317.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>209.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>860.5</td>\n",
       "      <td>736.6</td>\n",
       "      <td>28</td>\n",
       "      <td>40.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>287.3</td>\n",
       "      <td>120.5</td>\n",
       "      <td>93.9</td>\n",
       "      <td>187.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>904.4</td>\n",
       "      <td>695.9</td>\n",
       "      <td>28</td>\n",
       "      <td>43.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>325.6</td>\n",
       "      <td>166.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>881.6</td>\n",
       "      <td>790.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>355.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.6</td>\n",
       "      <td>193.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>801.4</td>\n",
       "      <td>778.4</td>\n",
       "      <td>28</td>\n",
       "      <td>40.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>132.0</td>\n",
       "      <td>206.5</td>\n",
       "      <td>160.9</td>\n",
       "      <td>178.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>866.9</td>\n",
       "      <td>735.6</td>\n",
       "      <td>28</td>\n",
       "      <td>33.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>322.5</td>\n",
       "      <td>148.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.8</td>\n",
       "      <td>8.5</td>\n",
       "      <td>951.0</td>\n",
       "      <td>709.5</td>\n",
       "      <td>28</td>\n",
       "      <td>52.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>164.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.1</td>\n",
       "      <td>181.2</td>\n",
       "      <td>12.6</td>\n",
       "      <td>849.3</td>\n",
       "      <td>846.0</td>\n",
       "      <td>28</td>\n",
       "      <td>15.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>313.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.6</td>\n",
       "      <td>169.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>925.3</td>\n",
       "      <td>782.9</td>\n",
       "      <td>28</td>\n",
       "      <td>38.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>321.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.9</td>\n",
       "      <td>182.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>870.1</td>\n",
       "      <td>779.7</td>\n",
       "      <td>28</td>\n",
       "      <td>37.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>139.7</td>\n",
       "      <td>163.9</td>\n",
       "      <td>127.7</td>\n",
       "      <td>236.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>868.6</td>\n",
       "      <td>655.6</td>\n",
       "      <td>28</td>\n",
       "      <td>35.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>288.4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>907.9</td>\n",
       "      <td>829.5</td>\n",
       "      <td>28</td>\n",
       "      <td>42.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>298.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>209.7</td>\n",
       "      <td>11.1</td>\n",
       "      <td>879.6</td>\n",
       "      <td>744.2</td>\n",
       "      <td>28</td>\n",
       "      <td>31.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>264.5</td>\n",
       "      <td>111.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>195.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>832.6</td>\n",
       "      <td>790.4</td>\n",
       "      <td>28</td>\n",
       "      <td>41.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>159.8</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1049.3</td>\n",
       "      <td>688.2</td>\n",
       "      <td>28</td>\n",
       "      <td>39.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>166.0</td>\n",
       "      <td>259.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>858.8</td>\n",
       "      <td>826.8</td>\n",
       "      <td>28</td>\n",
       "      <td>37.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0      540.0                 0.0      0.0  162.0               2.5   \n",
       "1      540.0                 0.0      0.0  162.0               2.5   \n",
       "2      332.5               142.5      0.0  228.0               0.0   \n",
       "3      332.5               142.5      0.0  228.0               0.0   \n",
       "4      198.6               132.4      0.0  192.0               0.0   \n",
       "5      266.0               114.0      0.0  228.0               0.0   \n",
       "6      380.0                95.0      0.0  228.0               0.0   \n",
       "7      380.0                95.0      0.0  228.0               0.0   \n",
       "8      266.0               114.0      0.0  228.0               0.0   \n",
       "9      475.0                 0.0      0.0  228.0               0.0   \n",
       "10     198.6               132.4      0.0  192.0               0.0   \n",
       "11     198.6               132.4      0.0  192.0               0.0   \n",
       "12     427.5                47.5      0.0  228.0               0.0   \n",
       "13     190.0               190.0      0.0  228.0               0.0   \n",
       "14     304.0                76.0      0.0  228.0               0.0   \n",
       "15     380.0                 0.0      0.0  228.0               0.0   \n",
       "16     139.6               209.4      0.0  192.0               0.0   \n",
       "17     342.0                38.0      0.0  228.0               0.0   \n",
       "18     380.0                95.0      0.0  228.0               0.0   \n",
       "19     475.0                 0.0      0.0  228.0               0.0   \n",
       "20     427.5                47.5      0.0  228.0               0.0   \n",
       "21     139.6               209.4      0.0  192.0               0.0   \n",
       "22     139.6               209.4      0.0  192.0               0.0   \n",
       "23     139.6               209.4      0.0  192.0               0.0   \n",
       "24     380.0                 0.0      0.0  228.0               0.0   \n",
       "25     380.0                 0.0      0.0  228.0               0.0   \n",
       "26     380.0                95.0      0.0  228.0               0.0   \n",
       "27     342.0                38.0      0.0  228.0               0.0   \n",
       "28     427.5                47.5      0.0  228.0               0.0   \n",
       "29     475.0                 0.0      0.0  228.0               0.0   \n",
       "...      ...                 ...      ...    ...               ...   \n",
       "1000   141.9               166.6    129.7  173.5              10.9   \n",
       "1001   297.8               137.2    106.9  201.3               6.0   \n",
       "1002   321.3               164.2      0.0  190.5               4.6   \n",
       "1003   366.0               187.0      0.0  191.3               6.6   \n",
       "1004   279.8               128.9    100.4  172.4               9.5   \n",
       "1005   252.1                97.1     75.6  193.8               8.3   \n",
       "1006   164.6                 0.0    150.4  181.6              11.7   \n",
       "1007   155.6               243.5      0.0  180.3              10.7   \n",
       "1008   160.2               188.0    146.4  203.2              11.3   \n",
       "1009   298.1                 0.0    107.0  186.4               6.1   \n",
       "1010   317.9                 0.0    126.5  209.7               5.7   \n",
       "1011   287.3               120.5     93.9  187.6               9.2   \n",
       "1012   325.6               166.4      0.0  174.0               8.9   \n",
       "1013   355.9                 0.0    141.6  193.3              11.0   \n",
       "1014   132.0               206.5    160.9  178.9               5.5   \n",
       "1015   322.5               148.6      0.0  185.8               8.5   \n",
       "1016   164.2                 0.0    200.1  181.2              12.6   \n",
       "1017   313.8                 0.0    112.6  169.9              10.1   \n",
       "1018   321.4                 0.0    127.9  182.5              11.5   \n",
       "1019   139.7               163.9    127.7  236.7               5.8   \n",
       "1020   288.4               121.0      0.0  177.4               7.0   \n",
       "1021   298.2                 0.0    107.0  209.7              11.1   \n",
       "1022   264.5               111.0     86.5  195.5               5.9   \n",
       "1023   159.8               250.0      0.0  168.4              12.2   \n",
       "1024   166.0               259.7      0.0  183.2              12.7   \n",
       "1025   276.4               116.0     90.3  179.6               8.9   \n",
       "1026   322.2                 0.0    115.6  196.0              10.4   \n",
       "1027   148.5               139.4    108.6  192.7               6.1   \n",
       "1028   159.1               186.7      0.0  175.6              11.3   \n",
       "1029   260.9               100.5     78.3  200.6               8.6   \n",
       "\n",
       "      Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0               1040.0           676.0   28     79.99  \n",
       "1               1055.0           676.0   28     61.89  \n",
       "2                932.0           594.0  270     40.27  \n",
       "3                932.0           594.0  365     41.05  \n",
       "4                978.4           825.5  360     44.30  \n",
       "5                932.0           670.0   90     47.03  \n",
       "6                932.0           594.0  365     43.70  \n",
       "7                932.0           594.0   28     36.45  \n",
       "8                932.0           670.0   28     45.85  \n",
       "9                932.0           594.0   28     39.29  \n",
       "10               978.4           825.5   90     38.07  \n",
       "11               978.4           825.5   28     28.02  \n",
       "12               932.0           594.0  270     43.01  \n",
       "13               932.0           670.0   90     42.33  \n",
       "14               932.0           670.0   28     47.81  \n",
       "15               932.0           670.0   90     52.91  \n",
       "16              1047.0           806.9   90     39.36  \n",
       "17               932.0           670.0  365     56.14  \n",
       "18               932.0           594.0   90     40.56  \n",
       "19               932.0           594.0  180     42.62  \n",
       "20               932.0           594.0  180     41.84  \n",
       "21              1047.0           806.9   28     28.24  \n",
       "22              1047.0           806.9    3      8.06  \n",
       "23              1047.0           806.9  180     44.21  \n",
       "24               932.0           670.0  365     52.52  \n",
       "25               932.0           670.0  270     53.30  \n",
       "26               932.0           594.0  270     41.15  \n",
       "27               932.0           670.0  180     52.12  \n",
       "28               932.0           594.0   28     37.43  \n",
       "29               932.0           594.0    7     38.60  \n",
       "...                ...             ...  ...       ...  \n",
       "1000             882.6           785.3   28     44.61  \n",
       "1001             878.4           655.3   28     53.52  \n",
       "1002             870.0           774.0   28     57.22  \n",
       "1003             824.3           756.9   28     65.91  \n",
       "1004             825.1           804.9   28     52.83  \n",
       "1005             835.5           821.4   28     33.40  \n",
       "1006            1023.3           728.9   28     18.03  \n",
       "1007            1022.0           697.7   28     37.36  \n",
       "1008             828.7           709.7   28     35.31  \n",
       "1009             879.0           815.2   28     42.64  \n",
       "1010             860.5           736.6   28     40.06  \n",
       "1011             904.4           695.9   28     43.80  \n",
       "1012             881.6           790.0   28     61.24  \n",
       "1013             801.4           778.4   28     40.87  \n",
       "1014             866.9           735.6   28     33.31  \n",
       "1015             951.0           709.5   28     52.43  \n",
       "1016             849.3           846.0   28     15.09  \n",
       "1017             925.3           782.9   28     38.46  \n",
       "1018             870.1           779.7   28     37.27  \n",
       "1019             868.6           655.6   28     35.23  \n",
       "1020             907.9           829.5   28     42.14  \n",
       "1021             879.6           744.2   28     31.88  \n",
       "1022             832.6           790.4   28     41.54  \n",
       "1023            1049.3           688.2   28     39.46  \n",
       "1024             858.8           826.8   28     37.92  \n",
       "1025             870.1           768.3   28     44.28  \n",
       "1026             817.9           813.4   28     31.18  \n",
       "1027             892.4           780.0   28     23.70  \n",
       "1028             989.6           788.9   28     32.77  \n",
       "1029             864.5           761.5   28     32.40  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns\n",
    "\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = predictors.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 51536.6364 - val_loss: 30437.7131\n",
      "Epoch 2/50\n",
      " - 0s - loss: 19587.2453 - val_loss: 11094.8592\n",
      "Epoch 3/50\n",
      " - 0s - loss: 6541.1296 - val_loss: 5244.0049\n",
      "Epoch 4/50\n",
      " - 0s - loss: 3318.5628 - val_loss: 4269.9861\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2815.5894 - val_loss: 4041.4614\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2661.6459 - val_loss: 3816.9810\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2516.3836 - val_loss: 3587.5776\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2373.6235 - val_loss: 3366.3637\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2235.2270 - val_loss: 3148.9587\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2097.8444 - val_loss: 2950.0523\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1971.4018 - val_loss: 2756.2335\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1845.2465 - val_loss: 2563.1781\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1726.8038 - val_loss: 2387.9701\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1616.2541 - val_loss: 2218.0587\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1507.6047 - val_loss: 2071.2202\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1408.9973 - val_loss: 1926.3032\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1317.9345 - val_loss: 1785.9727\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1227.8336 - val_loss: 1666.4747\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1145.4059 - val_loss: 1541.9410\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1069.5361 - val_loss: 1436.4495\n",
      "Epoch 21/50\n",
      " - 0s - loss: 999.6685 - val_loss: 1334.7200\n",
      "Epoch 22/50\n",
      " - 0s - loss: 934.4633 - val_loss: 1241.6120\n",
      "Epoch 23/50\n",
      " - 0s - loss: 869.4970 - val_loss: 1147.7825\n",
      "Epoch 24/50\n",
      " - 0s - loss: 813.7483 - val_loss: 1061.2187\n",
      "Epoch 25/50\n",
      " - 0s - loss: 760.2320 - val_loss: 989.2942\n",
      "Epoch 26/50\n",
      " - 0s - loss: 710.8828 - val_loss: 919.6799\n",
      "Epoch 27/50\n",
      " - 0s - loss: 665.1993 - val_loss: 852.9262\n",
      "Epoch 28/50\n",
      " - 0s - loss: 623.2630 - val_loss: 790.1959\n",
      "Epoch 29/50\n",
      " - 0s - loss: 586.0660 - val_loss: 730.5429\n",
      "Epoch 30/50\n",
      " - 0s - loss: 546.1271 - val_loss: 684.0307\n",
      "Epoch 31/50\n",
      " - 0s - loss: 513.5268 - val_loss: 630.7597\n",
      "Epoch 32/50\n",
      " - 0s - loss: 480.8336 - val_loss: 585.8566\n",
      "Epoch 33/50\n",
      " - 0s - loss: 451.2841 - val_loss: 545.0833\n",
      "Epoch 34/50\n",
      " - 0s - loss: 425.3220 - val_loss: 505.8035\n",
      "Epoch 35/50\n",
      " - 0s - loss: 400.5581 - val_loss: 469.9588\n",
      "Epoch 36/50\n",
      " - 0s - loss: 378.8571 - val_loss: 435.2917\n",
      "Epoch 37/50\n",
      " - 0s - loss: 356.4277 - val_loss: 407.5589\n",
      "Epoch 38/50\n",
      " - 0s - loss: 338.7170 - val_loss: 378.6884\n",
      "Epoch 39/50\n",
      " - 0s - loss: 319.4739 - val_loss: 354.0590\n",
      "Epoch 40/50\n",
      " - 0s - loss: 303.4910 - val_loss: 330.0808\n",
      "Epoch 41/50\n",
      " - 0s - loss: 288.9480 - val_loss: 309.3038\n",
      "Epoch 42/50\n",
      " - 0s - loss: 275.0450 - val_loss: 289.3854\n",
      "Epoch 43/50\n",
      " - 0s - loss: 263.1298 - val_loss: 270.4531\n",
      "Epoch 44/50\n",
      " - 0s - loss: 251.6996 - val_loss: 253.8809\n",
      "Epoch 45/50\n",
      " - 0s - loss: 241.7390 - val_loss: 239.3628\n",
      "Epoch 46/50\n",
      " - 0s - loss: 232.0404 - val_loss: 225.9109\n",
      "Epoch 47/50\n",
      " - 0s - loss: 223.7152 - val_loss: 214.0681\n",
      "Epoch 48/50\n",
      " - 0s - loss: 216.4354 - val_loss: 202.1898\n",
      "Epoch 49/50\n",
      " - 0s - loss: 209.8125 - val_loss: 191.6258\n",
      "Epoch 50/50\n",
      " - 0s - loss: 202.7269 - val_loss: 182.6070\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 259303.2919 - val_loss: 156411.8513\n",
      "Epoch 2/50\n",
      " - 0s - loss: 116132.5372 - val_loss: 64574.6601\n",
      "Epoch 3/50\n",
      " - 0s - loss: 44942.7887 - val_loss: 22926.1376\n",
      "Epoch 4/50\n",
      " - 0s - loss: 15263.4334 - val_loss: 7214.4414\n",
      "Epoch 5/50\n",
      " - 0s - loss: 5297.7363 - val_loss: 2931.5397\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2890.5150 - val_loss: 2201.8937\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2514.3483 - val_loss: 2113.1002\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2456.2981 - val_loss: 2084.0189\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2403.7661 - val_loss: 2048.2726\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2351.7180 - val_loss: 2016.1089\n",
      "Epoch 11/50\n",
      " - 0s - loss: 2299.4835 - val_loss: 1981.5059\n",
      "Epoch 12/50\n",
      " - 0s - loss: 2249.5286 - val_loss: 1945.4714\n",
      "Epoch 13/50\n",
      " - 0s - loss: 2197.2994 - val_loss: 1912.0596\n",
      "Epoch 14/50\n",
      " - 0s - loss: 2147.5443 - val_loss: 1876.1967\n",
      "Epoch 15/50\n",
      " - 0s - loss: 2097.1211 - val_loss: 1840.0014\n",
      "Epoch 16/50\n",
      " - 0s - loss: 2048.4350 - val_loss: 1806.6902\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1999.6964 - val_loss: 1772.7010\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1954.9124 - val_loss: 1738.5023\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1909.3334 - val_loss: 1707.8460\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1866.0378 - val_loss: 1673.1165\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1822.6932 - val_loss: 1640.7397\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1781.8347 - val_loss: 1610.7371\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1736.3288 - val_loss: 1578.2337\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1694.9382 - val_loss: 1548.0198\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1655.3320 - val_loss: 1519.4618\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1621.0956 - val_loss: 1490.9035\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1577.0860 - val_loss: 1458.9570\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1536.9465 - val_loss: 1432.2130\n",
      "Epoch 29/50\n",
      " - 0s - loss: 1496.0071 - val_loss: 1409.9497\n",
      "Epoch 30/50\n",
      " - 0s - loss: 1453.0794 - val_loss: 1379.2161\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1415.4820 - val_loss: 1351.4719\n",
      "Epoch 32/50\n",
      " - 0s - loss: 1380.4934 - val_loss: 1325.1505\n",
      "Epoch 33/50\n",
      " - 0s - loss: 1344.0748 - val_loss: 1301.9870\n",
      "Epoch 34/50\n",
      " - 0s - loss: 1310.6885 - val_loss: 1271.3240\n",
      "Epoch 35/50\n",
      " - 0s - loss: 1276.7448 - val_loss: 1247.5825\n",
      "Epoch 36/50\n",
      " - 0s - loss: 1243.2213 - val_loss: 1221.0541\n",
      "Epoch 37/50\n",
      " - 0s - loss: 1211.7148 - val_loss: 1194.3935\n",
      "Epoch 38/50\n",
      " - 0s - loss: 1178.3288 - val_loss: 1164.0265\n",
      "Epoch 39/50\n",
      " - 0s - loss: 1142.7588 - val_loss: 1126.1105\n",
      "Epoch 40/50\n",
      " - 0s - loss: 1104.3317 - val_loss: 1096.7139\n",
      "Epoch 41/50\n",
      " - 0s - loss: 1059.4506 - val_loss: 1053.8736\n",
      "Epoch 42/50\n",
      " - 0s - loss: 1013.4698 - val_loss: 1001.9199\n",
      "Epoch 43/50\n",
      " - 0s - loss: 945.8014 - val_loss: 914.0522\n",
      "Epoch 44/50\n",
      " - 0s - loss: 844.5565 - val_loss: 829.4926\n",
      "Epoch 45/50\n",
      " - 0s - loss: 773.4308 - val_loss: 765.8652\n",
      "Epoch 46/50\n",
      " - 0s - loss: 718.8161 - val_loss: 703.2754\n",
      "Epoch 47/50\n",
      " - 0s - loss: 675.5543 - val_loss: 643.8967\n",
      "Epoch 48/50\n",
      " - 0s - loss: 636.4763 - val_loss: 603.0102\n",
      "Epoch 49/50\n",
      " - 0s - loss: 600.6666 - val_loss: 555.4585\n",
      "Epoch 50/50\n",
      " - 0s - loss: 565.8172 - val_loss: 528.4300\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 98381.1911 - val_loss: 53975.5791\n",
      "Epoch 2/50\n",
      " - 0s - loss: 40788.0841 - val_loss: 21845.8634\n",
      "Epoch 3/50\n",
      " - 0s - loss: 18010.8151 - val_loss: 10112.2648\n",
      "Epoch 4/50\n",
      " - 0s - loss: 9333.6243 - val_loss: 5515.5074\n",
      "Epoch 5/50\n",
      " - 0s - loss: 5580.1609 - val_loss: 3470.9710\n",
      "Epoch 6/50\n",
      " - 0s - loss: 3666.7433 - val_loss: 2445.0643\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2568.3017 - val_loss: 1878.3542\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1890.2156 - val_loss: 1567.0104\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1468.0324 - val_loss: 1386.2042\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1204.9351 - val_loss: 1275.8526\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1036.4871 - val_loss: 1200.5924\n",
      "Epoch 12/50\n",
      " - 0s - loss: 918.7199 - val_loss: 1149.3653\n",
      "Epoch 13/50\n",
      " - 0s - loss: 834.2478 - val_loss: 1110.7915\n",
      "Epoch 14/50\n",
      " - 0s - loss: 771.7789 - val_loss: 1080.4086\n",
      "Epoch 15/50\n",
      " - 0s - loss: 722.8560 - val_loss: 1052.9418\n",
      "Epoch 16/50\n",
      " - 0s - loss: 684.1148 - val_loss: 1028.1591\n",
      "Epoch 17/50\n",
      " - 0s - loss: 653.3632 - val_loss: 1004.2048\n",
      "Epoch 18/50\n",
      " - 0s - loss: 628.3274 - val_loss: 983.5496\n",
      "Epoch 19/50\n",
      " - 0s - loss: 607.2471 - val_loss: 967.2827\n",
      "Epoch 20/50\n",
      " - 0s - loss: 589.8565 - val_loss: 949.4471\n",
      "Epoch 21/50\n",
      " - 0s - loss: 574.8163 - val_loss: 933.9376\n",
      "Epoch 22/50\n",
      " - 0s - loss: 562.3366 - val_loss: 918.4187\n",
      "Epoch 23/50\n",
      " - 0s - loss: 551.6700 - val_loss: 905.5205\n",
      "Epoch 24/50\n",
      " - 0s - loss: 542.3927 - val_loss: 892.7119\n",
      "Epoch 25/50\n",
      " - 0s - loss: 534.3249 - val_loss: 879.5033\n",
      "Epoch 26/50\n",
      " - 0s - loss: 526.3426 - val_loss: 868.2115\n",
      "Epoch 27/50\n",
      " - 0s - loss: 519.2376 - val_loss: 856.4523\n",
      "Epoch 28/50\n",
      " - 0s - loss: 512.3540 - val_loss: 845.9250\n",
      "Epoch 29/50\n",
      " - 0s - loss: 506.1859 - val_loss: 834.7626\n",
      "Epoch 30/50\n",
      " - 0s - loss: 500.1440 - val_loss: 824.0939\n",
      "Epoch 31/50\n",
      " - 0s - loss: 493.9833 - val_loss: 813.7021\n",
      "Epoch 32/50\n",
      " - 0s - loss: 487.9858 - val_loss: 803.6197\n",
      "Epoch 33/50\n",
      " - 0s - loss: 481.8636 - val_loss: 792.2912\n",
      "Epoch 34/50\n",
      " - 0s - loss: 475.5951 - val_loss: 781.3258\n",
      "Epoch 35/50\n",
      " - 0s - loss: 469.5627 - val_loss: 772.7041\n",
      "Epoch 36/50\n",
      " - 0s - loss: 463.2625 - val_loss: 762.9662\n",
      "Epoch 37/50\n",
      " - 0s - loss: 457.0875 - val_loss: 752.4736\n",
      "Epoch 38/50\n",
      " - 0s - loss: 451.2094 - val_loss: 742.8712\n",
      "Epoch 39/50\n",
      " - 0s - loss: 444.4483 - val_loss: 733.6506\n",
      "Epoch 40/50\n",
      " - 0s - loss: 438.2331 - val_loss: 723.0256\n",
      "Epoch 41/50\n",
      " - 0s - loss: 432.1316 - val_loss: 714.7790\n",
      "Epoch 42/50\n",
      " - 0s - loss: 425.3120 - val_loss: 704.8551\n",
      "Epoch 43/50\n",
      " - 0s - loss: 419.4085 - val_loss: 694.7236\n",
      "Epoch 44/50\n",
      " - 0s - loss: 412.5364 - val_loss: 686.3783\n",
      "Epoch 45/50\n",
      " - 0s - loss: 406.3129 - val_loss: 676.9058\n",
      "Epoch 46/50\n",
      " - 0s - loss: 400.1446 - val_loss: 667.2954\n",
      "Epoch 47/50\n",
      " - 0s - loss: 394.1214 - val_loss: 658.0066\n",
      "Epoch 48/50\n",
      " - 0s - loss: 388.4137 - val_loss: 649.0547\n",
      "Epoch 49/50\n",
      " - 0s - loss: 382.3124 - val_loss: 638.7981\n",
      "Epoch 50/50\n",
      " - 0s - loss: 376.9399 - val_loss: 630.4929\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 41410.1249 - val_loss: 10459.1012\n",
      "Epoch 2/50\n",
      " - 0s - loss: 3935.0063 - val_loss: 717.7761\n",
      "Epoch 3/50\n",
      " - 0s - loss: 663.9941 - val_loss: 902.7962\n",
      "Epoch 4/50\n",
      " - 0s - loss: 578.2474 - val_loss: 669.7860\n",
      "Epoch 5/50\n",
      " - 0s - loss: 540.0435 - val_loss: 643.3210\n",
      "Epoch 6/50\n",
      " - 0s - loss: 521.3353 - val_loss: 622.9114\n",
      "Epoch 7/50\n",
      " - 0s - loss: 503.9942 - val_loss: 597.9026\n",
      "Epoch 8/50\n",
      " - 0s - loss: 486.0989 - val_loss: 567.5966\n",
      "Epoch 9/50\n",
      " - 0s - loss: 468.1589 - val_loss: 542.6431\n",
      "Epoch 10/50\n",
      " - 0s - loss: 450.6029 - val_loss: 515.2702\n",
      "Epoch 11/50\n",
      " - 0s - loss: 435.4201 - val_loss: 484.7618\n",
      "Epoch 12/50\n",
      " - 0s - loss: 418.7287 - val_loss: 470.1719\n",
      "Epoch 13/50\n",
      " - 0s - loss: 403.5597 - val_loss: 435.0298\n",
      "Epoch 14/50\n",
      " - 0s - loss: 388.6855 - val_loss: 419.5577\n",
      "Epoch 15/50\n",
      " - 0s - loss: 374.2879 - val_loss: 384.7999\n",
      "Epoch 16/50\n",
      " - 0s - loss: 361.3030 - val_loss: 368.2294\n",
      "Epoch 17/50\n",
      " - 0s - loss: 347.7762 - val_loss: 351.7053\n",
      "Epoch 18/50\n",
      " - 0s - loss: 336.2480 - val_loss: 327.3016\n",
      "Epoch 19/50\n",
      " - 0s - loss: 325.8485 - val_loss: 305.8184\n",
      "Epoch 20/50\n",
      " - 0s - loss: 314.7312 - val_loss: 290.9925\n",
      "Epoch 21/50\n",
      " - 0s - loss: 304.9129 - val_loss: 273.0848\n",
      "Epoch 22/50\n",
      " - 0s - loss: 294.4021 - val_loss: 280.1146\n",
      "Epoch 23/50\n",
      " - 0s - loss: 288.0055 - val_loss: 239.2457\n",
      "Epoch 24/50\n",
      " - 0s - loss: 276.6036 - val_loss: 233.9478\n",
      "Epoch 25/50\n",
      " - 0s - loss: 265.9843 - val_loss: 226.0924\n",
      "Epoch 26/50\n",
      " - 0s - loss: 258.2665 - val_loss: 210.5710\n",
      "Epoch 27/50\n",
      " - 0s - loss: 250.3627 - val_loss: 202.7925\n",
      "Epoch 28/50\n",
      " - 0s - loss: 242.4649 - val_loss: 191.3437\n",
      "Epoch 29/50\n",
      " - 0s - loss: 235.4268 - val_loss: 185.8102\n",
      "Epoch 30/50\n",
      " - 0s - loss: 229.0046 - val_loss: 174.0341\n",
      "Epoch 31/50\n",
      " - 0s - loss: 222.4816 - val_loss: 166.4857\n",
      "Epoch 32/50\n",
      " - 0s - loss: 217.2285 - val_loss: 158.1728\n",
      "Epoch 33/50\n",
      " - 0s - loss: 211.7849 - val_loss: 158.3258\n",
      "Epoch 34/50\n",
      " - 0s - loss: 206.3885 - val_loss: 151.8053\n",
      "Epoch 35/50\n",
      " - 0s - loss: 200.8362 - val_loss: 136.8635\n",
      "Epoch 36/50\n",
      " - 0s - loss: 197.3713 - val_loss: 134.2870\n",
      "Epoch 37/50\n",
      " - 0s - loss: 191.6920 - val_loss: 132.0981\n",
      "Epoch 38/50\n",
      " - 0s - loss: 188.4587 - val_loss: 121.9969\n",
      "Epoch 39/50\n",
      " - 0s - loss: 184.3956 - val_loss: 118.7188\n",
      "Epoch 40/50\n",
      " - 0s - loss: 179.9661 - val_loss: 126.0168\n",
      "Epoch 41/50\n",
      " - 0s - loss: 178.0292 - val_loss: 124.0590\n",
      "Epoch 42/50\n",
      " - 0s - loss: 174.6631 - val_loss: 110.3124\n",
      "Epoch 43/50\n",
      " - 0s - loss: 172.6289 - val_loss: 121.9128\n",
      "Epoch 44/50\n",
      " - 0s - loss: 167.6635 - val_loss: 101.9849\n",
      "Epoch 45/50\n",
      " - 0s - loss: 166.0784 - val_loss: 96.9878\n",
      "Epoch 46/50\n",
      " - 0s - loss: 163.4932 - val_loss: 96.8643\n",
      "Epoch 47/50\n",
      " - 0s - loss: 160.5635 - val_loss: 107.3271\n",
      "Epoch 48/50\n",
      " - 0s - loss: 158.8120 - val_loss: 95.4101\n",
      "Epoch 49/50\n",
      " - 0s - loss: 156.2419 - val_loss: 103.7961\n",
      "Epoch 50/50\n",
      " - 0s - loss: 154.8876 - val_loss: 88.6669\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 2456.3984 - val_loss: 2680.8800\n",
      "Epoch 2/50\n",
      " - 0s - loss: 2183.7382 - val_loss: 2527.2897\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1964.6052 - val_loss: 2134.0322\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1800.2723 - val_loss: 1912.8844\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1647.7187 - val_loss: 1859.4874\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1493.1961 - val_loss: 1691.6705\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1371.9699 - val_loss: 1454.8498\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1268.6888 - val_loss: 1394.5717\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1170.8686 - val_loss: 1213.2585\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1085.8977 - val_loss: 1189.3866\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1008.9306 - val_loss: 1046.0993\n",
      "Epoch 12/50\n",
      " - 0s - loss: 936.5734 - val_loss: 956.4506\n",
      "Epoch 13/50\n",
      " - 0s - loss: 879.4700 - val_loss: 890.4972\n",
      "Epoch 14/50\n",
      " - 0s - loss: 822.4708 - val_loss: 815.2124\n",
      "Epoch 15/50\n",
      " - 0s - loss: 768.1275 - val_loss: 806.2277\n",
      "Epoch 16/50\n",
      " - 0s - loss: 717.3647 - val_loss: 691.7356\n",
      "Epoch 17/50\n",
      " - 0s - loss: 691.9659 - val_loss: 722.6501\n",
      "Epoch 18/50\n",
      " - 0s - loss: 647.9377 - val_loss: 657.1289\n",
      "Epoch 19/50\n",
      " - 0s - loss: 608.9361 - val_loss: 630.3212\n",
      "Epoch 20/50\n",
      " - 0s - loss: 576.3008 - val_loss: 538.7255\n",
      "Epoch 21/50\n",
      " - 0s - loss: 542.1275 - val_loss: 537.8108\n",
      "Epoch 22/50\n",
      " - 0s - loss: 514.3527 - val_loss: 479.2226\n",
      "Epoch 23/50\n",
      " - 0s - loss: 497.8593 - val_loss: 529.3201\n",
      "Epoch 24/50\n",
      " - 0s - loss: 460.4923 - val_loss: 429.8809\n",
      "Epoch 25/50\n",
      " - 0s - loss: 445.7002 - val_loss: 399.6132\n",
      "Epoch 26/50\n",
      " - 0s - loss: 423.9672 - val_loss: 378.1765\n",
      "Epoch 27/50\n",
      " - 0s - loss: 402.5263 - val_loss: 373.7389\n",
      "Epoch 28/50\n",
      " - 0s - loss: 382.0040 - val_loss: 381.2960\n",
      "Epoch 29/50\n",
      " - 0s - loss: 365.7326 - val_loss: 336.3692\n",
      "Epoch 30/50\n",
      " - 0s - loss: 350.8397 - val_loss: 319.3317\n",
      "Epoch 31/50\n",
      " - 0s - loss: 332.8988 - val_loss: 329.7635\n",
      "Epoch 32/50\n",
      " - 0s - loss: 319.6727 - val_loss: 290.0256\n",
      "Epoch 33/50\n",
      " - 0s - loss: 307.3386 - val_loss: 293.5354\n",
      "Epoch 34/50\n",
      " - 0s - loss: 294.9881 - val_loss: 265.4169\n",
      "Epoch 35/50\n",
      " - 0s - loss: 284.4073 - val_loss: 277.4744\n",
      "Epoch 36/50\n",
      " - 0s - loss: 273.1438 - val_loss: 245.7276\n",
      "Epoch 37/50\n",
      " - 0s - loss: 263.7943 - val_loss: 241.9016\n",
      "Epoch 38/50\n",
      " - 0s - loss: 255.0290 - val_loss: 212.4445\n",
      "Epoch 39/50\n",
      " - 0s - loss: 245.4794 - val_loss: 196.8232\n",
      "Epoch 40/50\n",
      " - 0s - loss: 239.5458 - val_loss: 191.8170\n",
      "Epoch 41/50\n",
      " - 0s - loss: 234.3915 - val_loss: 179.6109\n",
      "Epoch 42/50\n",
      " - 0s - loss: 231.1169 - val_loss: 204.3310\n",
      "Epoch 43/50\n",
      " - 0s - loss: 216.9406 - val_loss: 191.4071\n",
      "Epoch 44/50\n",
      " - 0s - loss: 209.2039 - val_loss: 169.8845\n",
      "Epoch 45/50\n",
      " - 0s - loss: 203.4380 - val_loss: 178.6429\n",
      "Epoch 46/50\n",
      " - 0s - loss: 197.1825 - val_loss: 175.2997\n",
      "Epoch 47/50\n",
      " - 0s - loss: 194.3273 - val_loss: 182.6354\n",
      "Epoch 48/50\n",
      " - 0s - loss: 191.7354 - val_loss: 161.8529\n",
      "Epoch 49/50\n",
      " - 0s - loss: 183.2658 - val_loss: 155.7566\n",
      "Epoch 50/50\n",
      " - 0s - loss: 178.7115 - val_loss: 134.6230\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 84356.8832 - val_loss: 46797.7311\n",
      "Epoch 2/50\n",
      " - 0s - loss: 28779.1841 - val_loss: 12024.4588\n",
      "Epoch 3/50\n",
      " - 0s - loss: 7385.0015 - val_loss: 2168.6683\n",
      "Epoch 4/50\n",
      " - 0s - loss: 3011.9055 - val_loss: 1738.2588\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2686.1696 - val_loss: 1501.1486\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2421.5345 - val_loss: 1351.7834\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2165.7637 - val_loss: 1247.8487\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1965.3741 - val_loss: 1129.8430\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1783.6124 - val_loss: 1035.4996\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1619.9589 - val_loss: 948.0376\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1475.5195 - val_loss: 873.2473\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1342.3212 - val_loss: 810.2874\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1220.5912 - val_loss: 746.7308\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1115.5650 - val_loss: 697.6275\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1017.6129 - val_loss: 647.6127\n",
      "Epoch 16/50\n",
      " - 0s - loss: 929.4213 - val_loss: 604.9737\n",
      "Epoch 17/50\n",
      " - 0s - loss: 850.0911 - val_loss: 567.5522\n",
      "Epoch 18/50\n",
      " - 0s - loss: 783.0294 - val_loss: 537.5747\n",
      "Epoch 19/50\n",
      " - 0s - loss: 721.4935 - val_loss: 500.8427\n",
      "Epoch 20/50\n",
      " - 0s - loss: 660.1192 - val_loss: 477.7523\n",
      "Epoch 21/50\n",
      " - 0s - loss: 608.8597 - val_loss: 444.5104\n",
      "Epoch 22/50\n",
      " - 0s - loss: 563.9484 - val_loss: 428.6069\n",
      "Epoch 23/50\n",
      " - 0s - loss: 521.3543 - val_loss: 403.0181\n",
      "Epoch 24/50\n",
      " - 0s - loss: 484.7324 - val_loss: 380.4606\n",
      "Epoch 25/50\n",
      " - 0s - loss: 452.6295 - val_loss: 361.7997\n",
      "Epoch 26/50\n",
      " - 0s - loss: 423.5944 - val_loss: 344.2809\n",
      "Epoch 27/50\n",
      " - 0s - loss: 399.5574 - val_loss: 329.5494\n",
      "Epoch 28/50\n",
      " - 0s - loss: 375.8663 - val_loss: 307.0799\n",
      "Epoch 29/50\n",
      " - 0s - loss: 353.3603 - val_loss: 298.2458\n",
      "Epoch 30/50\n",
      " - 0s - loss: 334.9532 - val_loss: 280.2873\n",
      "Epoch 31/50\n",
      " - 0s - loss: 318.7693 - val_loss: 267.6411\n",
      "Epoch 32/50\n",
      " - 0s - loss: 303.1113 - val_loss: 261.3350\n",
      "Epoch 33/50\n",
      " - 0s - loss: 288.4112 - val_loss: 245.8447\n",
      "Epoch 34/50\n",
      " - 0s - loss: 276.9808 - val_loss: 238.5636\n",
      "Epoch 35/50\n",
      " - 0s - loss: 265.3162 - val_loss: 226.1570\n",
      "Epoch 36/50\n",
      " - 0s - loss: 255.4620 - val_loss: 217.2371\n",
      "Epoch 37/50\n",
      " - 0s - loss: 246.0913 - val_loss: 207.1384\n",
      "Epoch 38/50\n",
      " - 0s - loss: 237.9785 - val_loss: 198.3247\n",
      "Epoch 39/50\n",
      " - 0s - loss: 231.0235 - val_loss: 191.9677\n",
      "Epoch 40/50\n",
      " - 0s - loss: 224.7249 - val_loss: 182.9070\n",
      "Epoch 41/50\n",
      " - 0s - loss: 218.1760 - val_loss: 176.6163\n",
      "Epoch 42/50\n",
      " - 0s - loss: 212.2551 - val_loss: 169.9582\n",
      "Epoch 43/50\n",
      " - 0s - loss: 207.6791 - val_loss: 162.8331\n",
      "Epoch 44/50\n",
      " - 0s - loss: 202.3702 - val_loss: 158.3588\n",
      "Epoch 45/50\n",
      " - 0s - loss: 198.0867 - val_loss: 153.7834\n",
      "Epoch 46/50\n",
      " - 0s - loss: 193.5197 - val_loss: 147.6263\n",
      "Epoch 47/50\n",
      " - 0s - loss: 189.9226 - val_loss: 142.3324\n",
      "Epoch 48/50\n",
      " - 0s - loss: 186.8850 - val_loss: 140.0084\n",
      "Epoch 49/50\n",
      " - 0s - loss: 182.8144 - val_loss: 133.0238\n",
      "Epoch 50/50\n",
      " - 0s - loss: 179.2059 - val_loss: 130.3412\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 153633.1668 - val_loss: 112251.5253\n",
      "Epoch 2/50\n",
      " - 0s - loss: 97222.9628 - val_loss: 71674.5436\n",
      "Epoch 3/50\n",
      " - 0s - loss: 63237.8339 - val_loss: 47302.4199\n",
      "Epoch 4/50\n",
      " - 0s - loss: 42159.4859 - val_loss: 31922.1851\n",
      "Epoch 5/50\n",
      " - 0s - loss: 28473.0083 - val_loss: 21798.0454\n",
      "Epoch 6/50\n",
      " - 0s - loss: 19536.8504 - val_loss: 15046.4396\n",
      "Epoch 7/50\n",
      " - 0s - loss: 13667.0527 - val_loss: 10405.3916\n",
      "Epoch 8/50\n",
      " - 0s - loss: 9553.0389 - val_loss: 7080.7967\n",
      "Epoch 9/50\n",
      " - 0s - loss: 6560.9129 - val_loss: 4761.0032\n",
      "Epoch 10/50\n",
      " - 0s - loss: 4499.3533 - val_loss: 3172.7336\n",
      "Epoch 11/50\n",
      " - 0s - loss: 3134.2395 - val_loss: 2210.1008\n",
      "Epoch 12/50\n",
      " - 0s - loss: 2316.1694 - val_loss: 1670.5496\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1882.3390 - val_loss: 1382.6773\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1666.5718 - val_loss: 1246.7991\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1551.3919 - val_loss: 1188.9334\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1496.2871 - val_loss: 1155.4476\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1454.7943 - val_loss: 1133.7602\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1421.4381 - val_loss: 1110.9484\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1390.8044 - val_loss: 1089.9541\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1362.5460 - val_loss: 1067.7411\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1331.1217 - val_loss: 1047.2886\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1303.0220 - val_loss: 1025.7944\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1275.3497 - val_loss: 1002.4657\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1247.7062 - val_loss: 980.9510\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1219.8839 - val_loss: 959.3919\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1192.5117 - val_loss: 938.7750\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1166.1983 - val_loss: 916.7790\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1140.5221 - val_loss: 895.5937\n",
      "Epoch 29/50\n",
      " - 0s - loss: 1116.6965 - val_loss: 874.7792\n",
      "Epoch 30/50\n",
      " - 0s - loss: 1093.0363 - val_loss: 854.0825\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1068.6108 - val_loss: 834.9693\n",
      "Epoch 32/50\n",
      " - 0s - loss: 1045.7800 - val_loss: 814.6596\n",
      "Epoch 33/50\n",
      " - 0s - loss: 1023.9766 - val_loss: 795.9345\n",
      "Epoch 34/50\n",
      " - 0s - loss: 1003.7977 - val_loss: 778.1357\n",
      "Epoch 35/50\n",
      " - 0s - loss: 984.1212 - val_loss: 760.2734\n",
      "Epoch 36/50\n",
      " - 0s - loss: 965.2296 - val_loss: 743.2354\n",
      "Epoch 37/50\n",
      " - 0s - loss: 946.6862 - val_loss: 726.4083\n",
      "Epoch 38/50\n",
      " - 0s - loss: 929.3946 - val_loss: 709.1142\n",
      "Epoch 39/50\n",
      " - 0s - loss: 909.5432 - val_loss: 692.8500\n",
      "Epoch 40/50\n",
      " - 0s - loss: 891.5805 - val_loss: 676.1600\n",
      "Epoch 41/50\n",
      " - 0s - loss: 874.7179 - val_loss: 659.7610\n",
      "Epoch 42/50\n",
      " - 0s - loss: 857.9284 - val_loss: 646.0876\n",
      "Epoch 43/50\n",
      " - 0s - loss: 841.5995 - val_loss: 630.6769\n",
      "Epoch 44/50\n",
      " - 0s - loss: 825.1144 - val_loss: 615.7910\n",
      "Epoch 45/50\n",
      " - 0s - loss: 809.6262 - val_loss: 603.1344\n",
      "Epoch 46/50\n",
      " - 0s - loss: 794.3310 - val_loss: 589.7025\n",
      "Epoch 47/50\n",
      " - 0s - loss: 780.0235 - val_loss: 577.2117\n",
      "Epoch 48/50\n",
      " - 0s - loss: 766.5482 - val_loss: 564.5732\n",
      "Epoch 49/50\n",
      " - 0s - loss: 751.3839 - val_loss: 553.3114\n",
      "Epoch 50/50\n",
      " - 0s - loss: 738.7799 - val_loss: 542.4006\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 627224.9862 - val_loss: 452067.0814\n",
      "Epoch 2/50\n",
      " - 0s - loss: 356259.2803 - val_loss: 231877.8148\n",
      "Epoch 3/50\n",
      " - 0s - loss: 174156.6056 - val_loss: 97474.2205\n",
      "Epoch 4/50\n",
      " - 0s - loss: 70996.0558 - val_loss: 34436.6249\n",
      "Epoch 5/50\n",
      " - 0s - loss: 25975.0117 - val_loss: 13285.2474\n",
      "Epoch 6/50\n",
      " - 0s - loss: 11933.9609 - val_loss: 8541.7534\n",
      "Epoch 7/50\n",
      " - 0s - loss: 8510.3165 - val_loss: 7982.1525\n",
      "Epoch 8/50\n",
      " - 0s - loss: 7585.5773 - val_loss: 7656.7820\n",
      "Epoch 9/50\n",
      " - 0s - loss: 7001.3783 - val_loss: 7321.0363\n",
      "Epoch 10/50\n",
      " - 0s - loss: 6433.7264 - val_loss: 6877.1158\n",
      "Epoch 11/50\n",
      " - 0s - loss: 5856.7617 - val_loss: 6358.6152\n",
      "Epoch 12/50\n",
      " - 0s - loss: 5303.4326 - val_loss: 5824.6233\n",
      "Epoch 13/50\n",
      " - 0s - loss: 4766.6973 - val_loss: 5408.2768\n",
      "Epoch 14/50\n",
      " - 0s - loss: 4278.6347 - val_loss: 4972.5047\n",
      "Epoch 15/50\n",
      " - 0s - loss: 3829.9589 - val_loss: 4568.3369\n",
      "Epoch 16/50\n",
      " - 0s - loss: 3426.9318 - val_loss: 4199.0008\n",
      "Epoch 17/50\n",
      " - 0s - loss: 3060.4009 - val_loss: 3889.7786\n",
      "Epoch 18/50\n",
      " - 0s - loss: 2738.2156 - val_loss: 3609.8916\n",
      "Epoch 19/50\n",
      " - 0s - loss: 2456.1051 - val_loss: 3358.8910\n",
      "Epoch 20/50\n",
      " - 0s - loss: 2202.4597 - val_loss: 3112.7716\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1984.9136 - val_loss: 2897.9547\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1798.1475 - val_loss: 2745.2851\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1632.3024 - val_loss: 2553.8910\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1491.3366 - val_loss: 2428.1481\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1365.1009 - val_loss: 2273.4069\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1256.6921 - val_loss: 2165.9609\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1161.2455 - val_loss: 2052.4326\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1077.6480 - val_loss: 1953.7470\n",
      "Epoch 29/50\n",
      " - 0s - loss: 1004.1347 - val_loss: 1863.9956\n",
      "Epoch 30/50\n",
      " - 0s - loss: 937.3579 - val_loss: 1791.9778\n",
      "Epoch 31/50\n",
      " - 0s - loss: 879.9771 - val_loss: 1712.2223\n",
      "Epoch 32/50\n",
      " - 0s - loss: 827.5624 - val_loss: 1660.3108\n",
      "Epoch 33/50\n",
      " - 0s - loss: 782.6893 - val_loss: 1575.5869\n",
      "Epoch 34/50\n",
      " - 0s - loss: 742.4984 - val_loss: 1523.0422\n",
      "Epoch 35/50\n",
      " - 0s - loss: 705.8232 - val_loss: 1458.3255\n",
      "Epoch 36/50\n",
      " - 0s - loss: 675.6916 - val_loss: 1394.5678\n",
      "Epoch 37/50\n",
      " - 0s - loss: 646.9914 - val_loss: 1367.5891\n",
      "Epoch 38/50\n",
      " - 0s - loss: 621.6563 - val_loss: 1318.4859\n",
      "Epoch 39/50\n",
      " - 0s - loss: 599.7458 - val_loss: 1276.4145\n",
      "Epoch 40/50\n",
      " - 0s - loss: 578.9409 - val_loss: 1233.8874\n",
      "Epoch 41/50\n",
      " - 0s - loss: 558.3908 - val_loss: 1220.0957\n",
      "Epoch 42/50\n",
      " - 0s - loss: 539.3076 - val_loss: 1154.0468\n",
      "Epoch 43/50\n",
      " - 0s - loss: 524.4769 - val_loss: 1116.0980\n",
      "Epoch 44/50\n",
      " - 0s - loss: 508.8220 - val_loss: 1096.3423\n",
      "Epoch 45/50\n",
      " - 0s - loss: 495.0659 - val_loss: 1074.2023\n",
      "Epoch 46/50\n",
      " - 0s - loss: 483.4191 - val_loss: 1040.3729\n",
      "Epoch 47/50\n",
      " - 0s - loss: 472.2225 - val_loss: 1019.7576\n",
      "Epoch 48/50\n",
      " - 0s - loss: 462.1102 - val_loss: 981.9064\n",
      "Epoch 49/50\n",
      " - 0s - loss: 451.6102 - val_loss: 956.2740\n",
      "Epoch 50/50\n",
      " - 0s - loss: 442.8841 - val_loss: 929.1707\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 135736.2892 - val_loss: 81720.9711\n",
      "Epoch 2/50\n",
      " - 0s - loss: 57312.6108 - val_loss: 33726.1838\n",
      "Epoch 3/50\n",
      " - 0s - loss: 22722.4276 - val_loss: 13128.3182\n",
      "Epoch 4/50\n",
      " - 0s - loss: 8313.7413 - val_loss: 4694.2542\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2798.4111 - val_loss: 1733.8686\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1100.4022 - val_loss: 935.1087\n",
      "Epoch 7/50\n",
      " - 0s - loss: 709.7093 - val_loss: 767.1216\n",
      "Epoch 8/50\n",
      " - 0s - loss: 639.0969 - val_loss: 730.3985\n",
      "Epoch 9/50\n",
      " - 0s - loss: 620.9803 - val_loss: 710.7554\n",
      "Epoch 10/50\n",
      " - 0s - loss: 603.3848 - val_loss: 698.7309\n",
      "Epoch 11/50\n",
      " - 0s - loss: 585.2876 - val_loss: 685.9528\n",
      "Epoch 12/50\n",
      " - 0s - loss: 568.1146 - val_loss: 671.2669\n",
      "Epoch 13/50\n",
      " - 0s - loss: 550.2283 - val_loss: 654.0170\n",
      "Epoch 14/50\n",
      " - 0s - loss: 532.8190 - val_loss: 638.4689\n",
      "Epoch 15/50\n",
      " - 0s - loss: 516.6473 - val_loss: 620.4113\n",
      "Epoch 16/50\n",
      " - 0s - loss: 500.4339 - val_loss: 604.7589\n",
      "Epoch 17/50\n",
      " - 0s - loss: 486.5685 - val_loss: 588.5562\n",
      "Epoch 18/50\n",
      " - 0s - loss: 471.1933 - val_loss: 569.1438\n",
      "Epoch 19/50\n",
      " - 0s - loss: 457.3590 - val_loss: 555.5748\n",
      "Epoch 20/50\n",
      " - 0s - loss: 445.2206 - val_loss: 538.7464\n",
      "Epoch 21/50\n",
      " - 0s - loss: 433.4855 - val_loss: 524.9274\n",
      "Epoch 22/50\n",
      " - 0s - loss: 422.7551 - val_loss: 512.7833\n",
      "Epoch 23/50\n",
      " - 0s - loss: 411.6873 - val_loss: 495.0837\n",
      "Epoch 24/50\n",
      " - 0s - loss: 402.8422 - val_loss: 481.2686\n",
      "Epoch 25/50\n",
      " - 0s - loss: 393.1207 - val_loss: 466.6726\n",
      "Epoch 26/50\n",
      " - 0s - loss: 384.1386 - val_loss: 454.6510\n",
      "Epoch 27/50\n",
      " - 0s - loss: 376.1740 - val_loss: 440.7902\n",
      "Epoch 28/50\n",
      " - 0s - loss: 367.8995 - val_loss: 428.2818\n",
      "Epoch 29/50\n",
      " - 0s - loss: 361.8526 - val_loss: 416.3272\n",
      "Epoch 30/50\n",
      " - 0s - loss: 351.8287 - val_loss: 401.4528\n",
      "Epoch 31/50\n",
      " - 0s - loss: 344.1758 - val_loss: 390.1076\n",
      "Epoch 32/50\n",
      " - 0s - loss: 336.6103 - val_loss: 379.0931\n",
      "Epoch 33/50\n",
      " - 0s - loss: 328.6769 - val_loss: 369.3190\n",
      "Epoch 34/50\n",
      " - 0s - loss: 321.8465 - val_loss: 356.1557\n",
      "Epoch 35/50\n",
      " - 0s - loss: 315.0901 - val_loss: 344.6577\n",
      "Epoch 36/50\n",
      " - 0s - loss: 308.8882 - val_loss: 335.8978\n",
      "Epoch 37/50\n",
      " - 0s - loss: 303.4587 - val_loss: 326.3799\n",
      "Epoch 38/50\n",
      " - 0s - loss: 297.6317 - val_loss: 314.0829\n",
      "Epoch 39/50\n",
      " - 0s - loss: 292.9503 - val_loss: 308.7033\n",
      "Epoch 40/50\n",
      " - 0s - loss: 287.3960 - val_loss: 299.0501\n",
      "Epoch 41/50\n",
      " - 0s - loss: 282.4320 - val_loss: 291.5157\n",
      "Epoch 42/50\n",
      " - 0s - loss: 278.1738 - val_loss: 282.6441\n",
      "Epoch 43/50\n",
      " - 0s - loss: 274.2485 - val_loss: 277.1057\n",
      "Epoch 44/50\n",
      " - 0s - loss: 270.5471 - val_loss: 270.5612\n",
      "Epoch 45/50\n",
      " - 0s - loss: 266.8796 - val_loss: 264.9302\n",
      "Epoch 46/50\n",
      " - 0s - loss: 263.4357 - val_loss: 259.0823\n",
      "Epoch 47/50\n",
      " - 0s - loss: 260.5545 - val_loss: 252.2159\n",
      "Epoch 48/50\n",
      " - 0s - loss: 257.0059 - val_loss: 247.1122\n",
      "Epoch 49/50\n",
      " - 0s - loss: 254.3087 - val_loss: 243.7406\n",
      "Epoch 50/50\n",
      " - 0s - loss: 250.9653 - val_loss: 235.8709\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 2290.8135 - val_loss: 1796.0320\n",
      "Epoch 2/50\n",
      " - 0s - loss: 937.2953 - val_loss: 1452.4262\n",
      "Epoch 3/50\n",
      " - 0s - loss: 619.3625 - val_loss: 860.5551\n",
      "Epoch 4/50\n",
      " - 0s - loss: 461.7703 - val_loss: 663.9548\n",
      "Epoch 5/50\n",
      " - 0s - loss: 367.1376 - val_loss: 491.6742\n",
      "Epoch 6/50\n",
      " - 0s - loss: 308.5471 - val_loss: 410.9490\n",
      "Epoch 7/50\n",
      " - 0s - loss: 265.2060 - val_loss: 356.4120\n",
      "Epoch 8/50\n",
      " - 0s - loss: 231.8848 - val_loss: 294.8505\n",
      "Epoch 9/50\n",
      " - 0s - loss: 205.0206 - val_loss: 250.1157\n",
      "Epoch 10/50\n",
      " - 0s - loss: 185.9385 - val_loss: 223.2835\n",
      "Epoch 11/50\n",
      " - 0s - loss: 172.2594 - val_loss: 197.4474\n",
      "Epoch 12/50\n",
      " - 0s - loss: 160.8087 - val_loss: 182.1892\n",
      "Epoch 13/50\n",
      " - 0s - loss: 153.9804 - val_loss: 167.5664\n",
      "Epoch 14/50\n",
      " - 0s - loss: 148.6339 - val_loss: 161.1750\n",
      "Epoch 15/50\n",
      " - 0s - loss: 146.4494 - val_loss: 151.9104\n",
      "Epoch 16/50\n",
      " - 0s - loss: 141.7309 - val_loss: 144.5464\n",
      "Epoch 17/50\n",
      " - 0s - loss: 139.4142 - val_loss: 140.8452\n",
      "Epoch 18/50\n",
      " - 0s - loss: 137.3947 - val_loss: 136.9025\n",
      "Epoch 19/50\n",
      " - 0s - loss: 135.1612 - val_loss: 132.6642\n",
      "Epoch 20/50\n",
      " - 0s - loss: 135.1898 - val_loss: 131.0318\n",
      "Epoch 21/50\n",
      " - 0s - loss: 132.8732 - val_loss: 128.1662\n",
      "Epoch 22/50\n",
      " - 0s - loss: 131.1653 - val_loss: 126.2920\n",
      "Epoch 23/50\n",
      " - 0s - loss: 130.3069 - val_loss: 123.7527\n",
      "Epoch 24/50\n",
      " - 0s - loss: 128.8853 - val_loss: 121.7675\n",
      "Epoch 25/50\n",
      " - 0s - loss: 126.9405 - val_loss: 124.0840\n",
      "Epoch 26/50\n",
      " - 0s - loss: 129.2047 - val_loss: 119.3079\n",
      "Epoch 27/50\n",
      " - 0s - loss: 124.7536 - val_loss: 117.7448\n",
      "Epoch 28/50\n",
      " - 0s - loss: 124.6217 - val_loss: 114.8348\n",
      "Epoch 29/50\n",
      " - 0s - loss: 125.1107 - val_loss: 118.2582\n",
      "Epoch 30/50\n",
      " - 0s - loss: 124.7730 - val_loss: 113.8614\n",
      "Epoch 31/50\n",
      " - 0s - loss: 122.7664 - val_loss: 107.8096\n",
      "Epoch 32/50\n",
      " - 0s - loss: 121.0602 - val_loss: 113.5044\n",
      "Epoch 33/50\n",
      " - 0s - loss: 122.1898 - val_loss: 104.2710\n",
      "Epoch 34/50\n",
      " - 0s - loss: 118.2512 - val_loss: 102.5322\n",
      "Epoch 35/50\n",
      " - 0s - loss: 116.8816 - val_loss: 102.1350\n",
      "Epoch 36/50\n",
      " - 0s - loss: 118.4744 - val_loss: 98.1531\n",
      "Epoch 37/50\n",
      " - 0s - loss: 116.1117 - val_loss: 97.1368\n",
      "Epoch 38/50\n",
      " - 0s - loss: 115.7001 - val_loss: 94.9448\n",
      "Epoch 39/50\n",
      " - 0s - loss: 115.3809 - val_loss: 94.1440\n",
      "Epoch 40/50\n",
      " - 0s - loss: 112.3646 - val_loss: 91.1371\n",
      "Epoch 41/50\n",
      " - 0s - loss: 110.0465 - val_loss: 92.7781\n",
      "Epoch 42/50\n",
      " - 0s - loss: 111.0688 - val_loss: 92.4467\n",
      "Epoch 43/50\n",
      " - 0s - loss: 107.8921 - val_loss: 95.0346\n",
      "Epoch 44/50\n",
      " - 0s - loss: 106.6665 - val_loss: 87.4954\n",
      "Epoch 45/50\n",
      " - 0s - loss: 105.4688 - val_loss: 87.7464\n",
      "Epoch 46/50\n",
      " - 0s - loss: 104.0339 - val_loss: 85.9487\n",
      "Epoch 47/50\n",
      " - 0s - loss: 103.2666 - val_loss: 85.9115\n",
      "Epoch 48/50\n",
      " - 0s - loss: 102.8926 - val_loss: 85.9066\n",
      "Epoch 49/50\n",
      " - 0s - loss: 100.5088 - val_loss: 86.0637\n",
      "Epoch 50/50\n",
      " - 0s - loss: 100.4966 - val_loss: 82.5745\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 1864.4211 - val_loss: 2428.2260\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1481.0500 - val_loss: 1932.0786\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1188.2949 - val_loss: 1549.6256\n",
      "Epoch 4/50\n",
      " - 0s - loss: 944.8778 - val_loss: 1270.6176\n",
      "Epoch 5/50\n",
      " - 0s - loss: 762.2589 - val_loss: 988.5235\n",
      "Epoch 6/50\n",
      " - 0s - loss: 612.5160 - val_loss: 772.5251\n",
      "Epoch 7/50\n",
      " - 0s - loss: 490.6086 - val_loss: 615.8120\n",
      "Epoch 8/50\n",
      " - 0s - loss: 399.8405 - val_loss: 487.3439\n",
      "Epoch 9/50\n",
      " - 0s - loss: 325.0985 - val_loss: 404.0169\n",
      "Epoch 10/50\n",
      " - 0s - loss: 278.6969 - val_loss: 327.9651\n",
      "Epoch 11/50\n",
      " - 0s - loss: 234.7886 - val_loss: 269.8134\n",
      "Epoch 12/50\n",
      " - 0s - loss: 215.8290 - val_loss: 239.9559\n",
      "Epoch 13/50\n",
      " - 0s - loss: 188.8599 - val_loss: 198.7502\n",
      "Epoch 14/50\n",
      " - 0s - loss: 173.1414 - val_loss: 168.3773\n",
      "Epoch 15/50\n",
      " - 0s - loss: 163.8142 - val_loss: 149.4546\n",
      "Epoch 16/50\n",
      " - 0s - loss: 157.9191 - val_loss: 142.0644\n",
      "Epoch 17/50\n",
      " - 0s - loss: 149.8224 - val_loss: 122.6178\n",
      "Epoch 18/50\n",
      " - 0s - loss: 147.8666 - val_loss: 115.4468\n",
      "Epoch 19/50\n",
      " - 0s - loss: 144.0824 - val_loss: 124.4136\n",
      "Epoch 20/50\n",
      " - 0s - loss: 144.6117 - val_loss: 120.0073\n",
      "Epoch 21/50\n",
      " - 0s - loss: 142.9017 - val_loss: 107.9821\n",
      "Epoch 22/50\n",
      " - 0s - loss: 143.0595 - val_loss: 105.6329\n",
      "Epoch 23/50\n",
      " - 0s - loss: 138.5171 - val_loss: 104.2639\n",
      "Epoch 24/50\n",
      " - 0s - loss: 138.1343 - val_loss: 96.4552\n",
      "Epoch 25/50\n",
      " - 0s - loss: 140.6958 - val_loss: 103.4701\n",
      "Epoch 26/50\n",
      " - 0s - loss: 137.1932 - val_loss: 99.5408\n",
      "Epoch 27/50\n",
      " - 0s - loss: 136.9440 - val_loss: 95.2929\n",
      "Epoch 28/50\n",
      " - 0s - loss: 150.2589 - val_loss: 92.9131\n",
      "Epoch 29/50\n",
      " - 0s - loss: 139.1610 - val_loss: 93.8772\n",
      "Epoch 30/50\n",
      " - 0s - loss: 134.0179 - val_loss: 90.7153\n",
      "Epoch 31/50\n",
      " - 0s - loss: 133.3902 - val_loss: 91.4503\n",
      "Epoch 32/50\n",
      " - 0s - loss: 134.6854 - val_loss: 88.2718\n",
      "Epoch 33/50\n",
      " - 0s - loss: 136.4926 - val_loss: 92.2333\n",
      "Epoch 34/50\n",
      " - 0s - loss: 136.9760 - val_loss: 99.8654\n",
      "Epoch 35/50\n",
      " - 0s - loss: 132.5394 - val_loss: 97.5344\n",
      "Epoch 36/50\n",
      " - 0s - loss: 130.9948 - val_loss: 89.1051\n",
      "Epoch 37/50\n",
      " - 0s - loss: 130.6044 - val_loss: 95.8019\n",
      "Epoch 38/50\n",
      " - 0s - loss: 135.2184 - val_loss: 87.3094\n",
      "Epoch 39/50\n",
      " - 0s - loss: 141.0946 - val_loss: 85.5801\n",
      "Epoch 40/50\n",
      " - 0s - loss: 137.2589 - val_loss: 91.2524\n",
      "Epoch 41/50\n",
      " - 0s - loss: 134.0765 - val_loss: 89.5220\n",
      "Epoch 42/50\n",
      " - 0s - loss: 130.2496 - val_loss: 103.6931\n",
      "Epoch 43/50\n",
      " - 0s - loss: 138.8476 - val_loss: 84.5427\n",
      "Epoch 44/50\n",
      " - 0s - loss: 130.8045 - val_loss: 82.2661\n",
      "Epoch 45/50\n",
      " - 0s - loss: 135.6732 - val_loss: 91.1285\n",
      "Epoch 46/50\n",
      " - 0s - loss: 131.3413 - val_loss: 87.4091\n",
      "Epoch 47/50\n",
      " - 0s - loss: 129.2381 - val_loss: 88.2369\n",
      "Epoch 48/50\n",
      " - 0s - loss: 132.5039 - val_loss: 81.5827\n",
      "Epoch 49/50\n",
      " - 0s - loss: 128.4128 - val_loss: 82.6144\n",
      "Epoch 50/50\n",
      " - 0s - loss: 130.2625 - val_loss: 82.1664\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 281204.5406 - val_loss: 179835.7807\n",
      "Epoch 2/50\n",
      " - 0s - loss: 125355.2694 - val_loss: 75616.2881\n",
      "Epoch 3/50\n",
      " - 0s - loss: 49394.3748 - val_loss: 28956.1065\n",
      "Epoch 4/50\n",
      " - 0s - loss: 17846.0064 - val_loss: 10868.5261\n",
      "Epoch 5/50\n",
      " - 0s - loss: 6392.6374 - val_loss: 4436.1250\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2580.0366 - val_loss: 2300.2326\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1373.0827 - val_loss: 1627.6860\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1022.1764 - val_loss: 1411.2351\n",
      "Epoch 9/50\n",
      " - 0s - loss: 924.3925 - val_loss: 1316.2528\n",
      "Epoch 10/50\n",
      " - 0s - loss: 880.6763 - val_loss: 1264.2286\n",
      "Epoch 11/50\n",
      " - 0s - loss: 853.4531 - val_loss: 1218.2502\n",
      "Epoch 12/50\n",
      " - 0s - loss: 827.8512 - val_loss: 1178.7223\n",
      "Epoch 13/50\n",
      " - 0s - loss: 803.6952 - val_loss: 1142.2240\n",
      "Epoch 14/50\n",
      " - 0s - loss: 781.6258 - val_loss: 1104.4550\n",
      "Epoch 15/50\n",
      " - 0s - loss: 760.5339 - val_loss: 1069.5826\n",
      "Epoch 16/50\n",
      " - 0s - loss: 740.5402 - val_loss: 1036.1286\n",
      "Epoch 17/50\n",
      " - 0s - loss: 722.4553 - val_loss: 1004.8573\n",
      "Epoch 18/50\n",
      " - 0s - loss: 705.2018 - val_loss: 969.9297\n",
      "Epoch 19/50\n",
      " - 0s - loss: 686.0264 - val_loss: 945.4156\n",
      "Epoch 20/50\n",
      " - 0s - loss: 670.3621 - val_loss: 917.4201\n",
      "Epoch 21/50\n",
      " - 0s - loss: 653.8255 - val_loss: 885.3128\n",
      "Epoch 22/50\n",
      " - 0s - loss: 639.3999 - val_loss: 863.3623\n",
      "Epoch 23/50\n",
      " - 0s - loss: 624.8990 - val_loss: 836.3824\n",
      "Epoch 24/50\n",
      " - 0s - loss: 611.1576 - val_loss: 809.7224\n",
      "Epoch 25/50\n",
      " - 0s - loss: 598.8706 - val_loss: 787.8935\n",
      "Epoch 26/50\n",
      " - 0s - loss: 586.3036 - val_loss: 767.6166\n",
      "Epoch 27/50\n",
      " - 0s - loss: 574.6518 - val_loss: 745.4627\n",
      "Epoch 28/50\n",
      " - 0s - loss: 563.4120 - val_loss: 727.8672\n",
      "Epoch 29/50\n",
      " - 0s - loss: 552.7011 - val_loss: 706.8624\n",
      "Epoch 30/50\n",
      " - 0s - loss: 541.7247 - val_loss: 689.0903\n",
      "Epoch 31/50\n",
      " - 0s - loss: 531.4198 - val_loss: 668.9230\n",
      "Epoch 32/50\n",
      " - 0s - loss: 521.1508 - val_loss: 651.1321\n",
      "Epoch 33/50\n",
      " - 0s - loss: 511.4144 - val_loss: 633.1195\n",
      "Epoch 34/50\n",
      " - 0s - loss: 501.7925 - val_loss: 618.8933\n",
      "Epoch 35/50\n",
      " - 0s - loss: 492.9868 - val_loss: 599.5716\n",
      "Epoch 36/50\n",
      " - 0s - loss: 483.5279 - val_loss: 581.5642\n",
      "Epoch 37/50\n",
      " - 0s - loss: 476.3713 - val_loss: 572.1176\n",
      "Epoch 38/50\n",
      " - 0s - loss: 466.2431 - val_loss: 550.2020\n",
      "Epoch 39/50\n",
      " - 0s - loss: 458.2714 - val_loss: 537.9061\n",
      "Epoch 40/50\n",
      " - 0s - loss: 450.0268 - val_loss: 524.1774\n",
      "Epoch 41/50\n",
      " - 0s - loss: 442.0212 - val_loss: 510.3975\n",
      "Epoch 42/50\n",
      " - 0s - loss: 434.3772 - val_loss: 493.7627\n",
      "Epoch 43/50\n",
      " - 0s - loss: 427.5965 - val_loss: 482.7899\n",
      "Epoch 44/50\n",
      " - 0s - loss: 420.3745 - val_loss: 473.6356\n",
      "Epoch 45/50\n",
      " - 0s - loss: 414.0050 - val_loss: 455.5342\n",
      "Epoch 46/50\n",
      " - 0s - loss: 406.9490 - val_loss: 448.5900\n",
      "Epoch 47/50\n",
      " - 0s - loss: 399.3441 - val_loss: 431.6502\n",
      "Epoch 48/50\n",
      " - 0s - loss: 392.4185 - val_loss: 420.2550\n",
      "Epoch 49/50\n",
      " - 0s - loss: 386.4714 - val_loss: 408.0148\n",
      "Epoch 50/50\n",
      " - 0s - loss: 379.5085 - val_loss: 405.2265\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 294668.9376 - val_loss: 202402.5903\n",
      "Epoch 2/50\n",
      " - 0s - loss: 165319.5497 - val_loss: 104727.1903\n",
      "Epoch 3/50\n",
      " - 0s - loss: 84030.3583 - val_loss: 48693.8936\n",
      "Epoch 4/50\n",
      " - 0s - loss: 37886.8856 - val_loss: 18786.8115\n",
      "Epoch 5/50\n",
      " - 0s - loss: 18500.4768 - val_loss: 10473.7771\n",
      "Epoch 6/50\n",
      " - 0s - loss: 14872.7610 - val_loss: 9324.0606\n",
      "Epoch 7/50\n",
      " - 0s - loss: 13394.3009 - val_loss: 8725.8215\n",
      "Epoch 8/50\n",
      " - 0s - loss: 12184.9811 - val_loss: 8139.7701\n",
      "Epoch 9/50\n",
      " - 0s - loss: 11190.0642 - val_loss: 7601.3798\n",
      "Epoch 10/50\n",
      " - 0s - loss: 10255.6143 - val_loss: 7105.6987\n",
      "Epoch 11/50\n",
      " - 0s - loss: 9450.5328 - val_loss: 6618.8748\n",
      "Epoch 12/50\n",
      " - 0s - loss: 8681.3032 - val_loss: 6194.1843\n",
      "Epoch 13/50\n",
      " - 0s - loss: 7994.7560 - val_loss: 5787.1146\n",
      "Epoch 14/50\n",
      " - 0s - loss: 7375.2134 - val_loss: 5402.4954\n",
      "Epoch 15/50\n",
      " - 0s - loss: 6777.0158 - val_loss: 5025.8647\n",
      "Epoch 16/50\n",
      " - 0s - loss: 6229.1853 - val_loss: 4673.8217\n",
      "Epoch 17/50\n",
      " - 0s - loss: 5670.0692 - val_loss: 4306.5188\n",
      "Epoch 18/50\n",
      " - 0s - loss: 5167.9083 - val_loss: 4000.8090\n",
      "Epoch 19/50\n",
      " - 0s - loss: 4716.6040 - val_loss: 3684.9782\n",
      "Epoch 20/50\n",
      " - 0s - loss: 4301.2357 - val_loss: 3415.0494\n",
      "Epoch 21/50\n",
      " - 0s - loss: 3945.5299 - val_loss: 3164.2220\n",
      "Epoch 22/50\n",
      " - 0s - loss: 3618.9310 - val_loss: 2937.7119\n",
      "Epoch 23/50\n",
      " - 0s - loss: 3328.7114 - val_loss: 2694.3702\n",
      "Epoch 24/50\n",
      " - 0s - loss: 3046.4258 - val_loss: 2518.8203\n",
      "Epoch 25/50\n",
      " - 0s - loss: 2806.8013 - val_loss: 2308.6909\n",
      "Epoch 26/50\n",
      " - 0s - loss: 2589.5775 - val_loss: 2151.3219\n",
      "Epoch 27/50\n",
      " - 0s - loss: 2393.7041 - val_loss: 1970.3861\n",
      "Epoch 28/50\n",
      " - 0s - loss: 2212.3042 - val_loss: 1829.9122\n",
      "Epoch 29/50\n",
      " - 0s - loss: 2040.4941 - val_loss: 1683.2782\n",
      "Epoch 30/50\n",
      " - 0s - loss: 1887.6510 - val_loss: 1542.2392\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1749.9972 - val_loss: 1415.0881\n",
      "Epoch 32/50\n",
      " - 0s - loss: 1613.2995 - val_loss: 1302.8359\n",
      "Epoch 33/50\n",
      " - 0s - loss: 1495.7384 - val_loss: 1190.3819\n",
      "Epoch 34/50\n",
      " - 0s - loss: 1385.5153 - val_loss: 1094.5203\n",
      "Epoch 35/50\n",
      " - 0s - loss: 1291.4347 - val_loss: 994.7428\n",
      "Epoch 36/50\n",
      " - 0s - loss: 1179.9694 - val_loss: 919.8969\n",
      "Epoch 37/50\n",
      " - 0s - loss: 1091.7750 - val_loss: 830.4758\n",
      "Epoch 38/50\n",
      " - 0s - loss: 1006.0264 - val_loss: 752.0271\n",
      "Epoch 39/50\n",
      " - 0s - loss: 926.3712 - val_loss: 685.8647\n",
      "Epoch 40/50\n",
      " - 0s - loss: 849.0653 - val_loss: 615.1453\n",
      "Epoch 41/50\n",
      " - 0s - loss: 779.5700 - val_loss: 555.1969\n",
      "Epoch 42/50\n",
      " - 0s - loss: 718.7198 - val_loss: 503.2692\n",
      "Epoch 43/50\n",
      " - 0s - loss: 657.9503 - val_loss: 450.2167\n",
      "Epoch 44/50\n",
      " - 0s - loss: 600.5352 - val_loss: 405.7361\n",
      "Epoch 45/50\n",
      " - 0s - loss: 552.5620 - val_loss: 365.2813\n",
      "Epoch 46/50\n",
      " - 0s - loss: 505.4551 - val_loss: 326.8126\n",
      "Epoch 47/50\n",
      " - 0s - loss: 462.6974 - val_loss: 291.2003\n",
      "Epoch 48/50\n",
      " - 0s - loss: 425.2191 - val_loss: 262.3934\n",
      "Epoch 49/50\n",
      " - 0s - loss: 391.0304 - val_loss: 236.9918\n",
      "Epoch 50/50\n",
      " - 0s - loss: 360.2850 - val_loss: 216.1578\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 11792.7874 - val_loss: 5094.1438\n",
      "Epoch 2/50\n",
      " - 0s - loss: 4917.4754 - val_loss: 4475.6131\n",
      "Epoch 3/50\n",
      " - 0s - loss: 4055.4718 - val_loss: 4151.1976\n",
      "Epoch 4/50\n",
      " - 0s - loss: 3431.7568 - val_loss: 3370.1791\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2881.7236 - val_loss: 2793.1291\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2392.7473 - val_loss: 2154.4834\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1913.0355 - val_loss: 1677.3077\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1455.9658 - val_loss: 1230.1920\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1051.5532 - val_loss: 810.7204\n",
      "Epoch 10/50\n",
      " - 0s - loss: 755.9178 - val_loss: 578.3152\n",
      "Epoch 11/50\n",
      " - 0s - loss: 558.9792 - val_loss: 432.6659\n",
      "Epoch 12/50\n",
      " - 0s - loss: 439.9668 - val_loss: 417.3861\n",
      "Epoch 13/50\n",
      " - 0s - loss: 362.2214 - val_loss: 362.6705\n",
      "Epoch 14/50\n",
      " - 0s - loss: 311.0197 - val_loss: 389.9489\n",
      "Epoch 15/50\n",
      " - 0s - loss: 280.7779 - val_loss: 365.4499\n",
      "Epoch 16/50\n",
      " - 0s - loss: 258.3499 - val_loss: 309.2384\n",
      "Epoch 17/50\n",
      " - 0s - loss: 230.8730 - val_loss: 332.6888\n",
      "Epoch 18/50\n",
      " - 0s - loss: 217.5350 - val_loss: 290.2202\n",
      "Epoch 19/50\n",
      " - 0s - loss: 209.5388 - val_loss: 278.7030\n",
      "Epoch 20/50\n",
      " - 0s - loss: 192.9384 - val_loss: 303.3750\n",
      "Epoch 21/50\n",
      " - 0s - loss: 183.3839 - val_loss: 312.2454\n",
      "Epoch 22/50\n",
      " - 0s - loss: 176.3905 - val_loss: 288.7389\n",
      "Epoch 23/50\n",
      " - 0s - loss: 169.7566 - val_loss: 305.5489\n",
      "Epoch 24/50\n",
      " - 0s - loss: 164.5284 - val_loss: 279.7075\n",
      "Epoch 25/50\n",
      " - 0s - loss: 159.3458 - val_loss: 276.2150\n",
      "Epoch 26/50\n",
      " - 0s - loss: 154.4840 - val_loss: 294.7289\n",
      "Epoch 27/50\n",
      " - 0s - loss: 150.8383 - val_loss: 249.3582\n",
      "Epoch 28/50\n",
      " - 0s - loss: 151.5575 - val_loss: 242.7206\n",
      "Epoch 29/50\n",
      " - 0s - loss: 146.0754 - val_loss: 296.1998\n",
      "Epoch 30/50\n",
      " - 0s - loss: 143.2739 - val_loss: 270.0229\n",
      "Epoch 31/50\n",
      " - 0s - loss: 139.3801 - val_loss: 255.4734\n",
      "Epoch 32/50\n",
      " - 0s - loss: 137.8885 - val_loss: 269.9100\n",
      "Epoch 33/50\n",
      " - 0s - loss: 135.0173 - val_loss: 240.4060\n",
      "Epoch 34/50\n",
      " - 0s - loss: 134.5170 - val_loss: 249.1128\n",
      "Epoch 35/50\n",
      " - 0s - loss: 130.9740 - val_loss: 243.0445\n",
      "Epoch 36/50\n",
      " - 0s - loss: 130.9070 - val_loss: 250.8643\n",
      "Epoch 37/50\n",
      " - 0s - loss: 127.1019 - val_loss: 240.1933\n",
      "Epoch 38/50\n",
      " - 0s - loss: 126.2967 - val_loss: 229.7700\n",
      "Epoch 39/50\n",
      " - 0s - loss: 125.0430 - val_loss: 228.8336\n",
      "Epoch 40/50\n",
      " - 0s - loss: 122.4865 - val_loss: 226.6441\n",
      "Epoch 41/50\n",
      " - 0s - loss: 121.6275 - val_loss: 223.6274\n",
      "Epoch 42/50\n",
      " - 0s - loss: 120.4514 - val_loss: 225.6324\n",
      "Epoch 43/50\n",
      " - 0s - loss: 120.2946 - val_loss: 249.0238\n",
      "Epoch 44/50\n",
      " - 0s - loss: 119.3918 - val_loss: 240.9125\n",
      "Epoch 45/50\n",
      " - 0s - loss: 115.4282 - val_loss: 227.6247\n",
      "Epoch 46/50\n",
      " - 0s - loss: 114.9099 - val_loss: 268.3789\n",
      "Epoch 47/50\n",
      " - 0s - loss: 112.2070 - val_loss: 236.6498\n",
      "Epoch 48/50\n",
      " - 0s - loss: 110.1571 - val_loss: 210.7971\n",
      "Epoch 49/50\n",
      " - 0s - loss: 110.2404 - val_loss: 214.8958\n",
      "Epoch 50/50\n",
      " - 0s - loss: 109.0972 - val_loss: 229.8235\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 21532.8432 - val_loss: 5812.6242\n",
      "Epoch 2/50\n",
      " - 0s - loss: 4128.9345 - val_loss: 5143.8532\n",
      "Epoch 3/50\n",
      " - 0s - loss: 3227.2638 - val_loss: 4465.5760\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2934.6380 - val_loss: 4014.3413\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2774.6178 - val_loss: 3887.4578\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2615.8444 - val_loss: 3702.6053\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2469.4514 - val_loss: 3431.0974\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2325.2830 - val_loss: 3208.2068\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2153.1222 - val_loss: 2700.5019\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1892.5937 - val_loss: 2286.0394\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1659.9145 - val_loss: 1892.3137\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1452.9892 - val_loss: 1592.4765\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1259.8583 - val_loss: 1358.5011\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1088.9950 - val_loss: 1261.0460\n",
      "Epoch 15/50\n",
      " - 0s - loss: 947.6229 - val_loss: 965.0099\n",
      "Epoch 16/50\n",
      " - 0s - loss: 828.9956 - val_loss: 843.3237\n",
      "Epoch 17/50\n",
      " - 0s - loss: 716.9817 - val_loss: 735.7531\n",
      "Epoch 18/50\n",
      " - 0s - loss: 630.0803 - val_loss: 692.6769\n",
      "Epoch 19/50\n",
      " - 0s - loss: 556.3419 - val_loss: 604.7570\n",
      "Epoch 20/50\n",
      " - 0s - loss: 496.5707 - val_loss: 560.8800\n",
      "Epoch 21/50\n",
      " - 0s - loss: 446.0072 - val_loss: 472.2057\n",
      "Epoch 22/50\n",
      " - 0s - loss: 404.8247 - val_loss: 498.7796\n",
      "Epoch 23/50\n",
      " - 0s - loss: 368.2863 - val_loss: 480.4852\n",
      "Epoch 24/50\n",
      " - 0s - loss: 340.1683 - val_loss: 420.0768\n",
      "Epoch 25/50\n",
      " - 0s - loss: 314.8108 - val_loss: 397.5686\n",
      "Epoch 26/50\n",
      " - 0s - loss: 296.7749 - val_loss: 406.2127\n",
      "Epoch 27/50\n",
      " - 0s - loss: 278.1021 - val_loss: 412.4685\n",
      "Epoch 28/50\n",
      " - 0s - loss: 264.7146 - val_loss: 432.6738\n",
      "Epoch 29/50\n",
      " - 0s - loss: 257.3274 - val_loss: 369.8676\n",
      "Epoch 30/50\n",
      " - 0s - loss: 245.7455 - val_loss: 327.0401\n",
      "Epoch 31/50\n",
      " - 0s - loss: 235.1739 - val_loss: 293.5944\n",
      "Epoch 32/50\n",
      " - 0s - loss: 229.8241 - val_loss: 289.6922\n",
      "Epoch 33/50\n",
      " - 0s - loss: 228.0345 - val_loss: 285.6666\n",
      "Epoch 34/50\n",
      " - 0s - loss: 218.4389 - val_loss: 317.2659\n",
      "Epoch 35/50\n",
      " - 0s - loss: 210.1383 - val_loss: 339.7112\n",
      "Epoch 36/50\n",
      " - 0s - loss: 205.5681 - val_loss: 317.9140\n",
      "Epoch 37/50\n",
      " - 0s - loss: 201.7652 - val_loss: 312.9473\n",
      "Epoch 38/50\n",
      " - 0s - loss: 198.3562 - val_loss: 310.4363\n",
      "Epoch 39/50\n",
      " - 0s - loss: 194.3104 - val_loss: 328.2637\n",
      "Epoch 40/50\n",
      " - 0s - loss: 192.5173 - val_loss: 262.6122\n",
      "Epoch 41/50\n",
      " - 0s - loss: 187.6691 - val_loss: 276.6021\n",
      "Epoch 42/50\n",
      " - 0s - loss: 185.7783 - val_loss: 235.8151\n",
      "Epoch 43/50\n",
      " - 0s - loss: 180.9227 - val_loss: 289.4139\n",
      "Epoch 44/50\n",
      " - 0s - loss: 182.6677 - val_loss: 254.5800\n",
      "Epoch 45/50\n",
      " - 0s - loss: 179.4252 - val_loss: 265.7114\n",
      "Epoch 46/50\n",
      " - 0s - loss: 178.5431 - val_loss: 264.6046\n",
      "Epoch 47/50\n",
      " - 0s - loss: 173.0410 - val_loss: 239.6395\n",
      "Epoch 48/50\n",
      " - 0s - loss: 174.2644 - val_loss: 238.8862\n",
      "Epoch 49/50\n",
      " - 0s - loss: 171.0163 - val_loss: 212.3807\n",
      "Epoch 50/50\n",
      " - 0s - loss: 168.6840 - val_loss: 191.1915\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 446733.5161 - val_loss: 316864.1533\n",
      "Epoch 2/50\n",
      " - 0s - loss: 249585.3164 - val_loss: 166166.4024\n",
      "Epoch 3/50\n",
      " - 0s - loss: 126528.9254 - val_loss: 79388.9804\n",
      "Epoch 4/50\n",
      " - 0s - loss: 58323.6104 - val_loss: 34496.9329\n",
      "Epoch 5/50\n",
      " - 0s - loss: 24307.5885 - val_loss: 13879.3949\n",
      "Epoch 6/50\n",
      " - 0s - loss: 9488.4908 - val_loss: 5590.3147\n",
      "Epoch 7/50\n",
      " - 0s - loss: 4070.9226 - val_loss: 2823.1783\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2502.7973 - val_loss: 2028.4551\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2062.4230 - val_loss: 1841.0493\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1942.7741 - val_loss: 1752.7948\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1867.2830 - val_loss: 1696.5385\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1798.3334 - val_loss: 1651.2109\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1731.6335 - val_loss: 1610.9548\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1664.7897 - val_loss: 1566.5497\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1602.7711 - val_loss: 1520.6252\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1545.2318 - val_loss: 1487.6488\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1486.5585 - val_loss: 1439.7240\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1430.9011 - val_loss: 1402.2714\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1379.2815 - val_loss: 1363.7511\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1329.7078 - val_loss: 1325.3926\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1284.3938 - val_loss: 1287.8300\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1239.5439 - val_loss: 1256.8014\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1196.3809 - val_loss: 1223.8264\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1156.8544 - val_loss: 1189.4543\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1118.5108 - val_loss: 1158.5021\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1083.6611 - val_loss: 1133.7670\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1048.6756 - val_loss: 1106.0929\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1018.0837 - val_loss: 1078.8979\n",
      "Epoch 29/50\n",
      " - 0s - loss: 986.2829 - val_loss: 1051.9483\n",
      "Epoch 30/50\n",
      " - 0s - loss: 957.9105 - val_loss: 1031.2148\n",
      "Epoch 31/50\n",
      " - 0s - loss: 930.7259 - val_loss: 1006.5724\n",
      "Epoch 32/50\n",
      " - 0s - loss: 904.9374 - val_loss: 985.4442\n",
      "Epoch 33/50\n",
      " - 0s - loss: 880.4802 - val_loss: 963.0937\n",
      "Epoch 34/50\n",
      " - 0s - loss: 857.7441 - val_loss: 940.0844\n",
      "Epoch 35/50\n",
      " - 0s - loss: 836.6526 - val_loss: 921.3143\n",
      "Epoch 36/50\n",
      " - 0s - loss: 815.1112 - val_loss: 899.3266\n",
      "Epoch 37/50\n",
      " - 0s - loss: 794.8299 - val_loss: 883.7193\n",
      "Epoch 38/50\n",
      " - 0s - loss: 777.4153 - val_loss: 863.8851\n",
      "Epoch 39/50\n",
      " - 0s - loss: 759.6810 - val_loss: 847.5826\n",
      "Epoch 40/50\n",
      " - 0s - loss: 742.0208 - val_loss: 832.0373\n",
      "Epoch 41/50\n",
      " - 0s - loss: 728.2067 - val_loss: 815.7574\n",
      "Epoch 42/50\n",
      " - 0s - loss: 712.9526 - val_loss: 796.4602\n",
      "Epoch 43/50\n",
      " - 0s - loss: 697.4418 - val_loss: 785.8455\n",
      "Epoch 44/50\n",
      " - 0s - loss: 681.7236 - val_loss: 768.2600\n",
      "Epoch 45/50\n",
      " - 0s - loss: 669.8745 - val_loss: 754.2781\n",
      "Epoch 46/50\n",
      " - 0s - loss: 656.6590 - val_loss: 740.8267\n",
      "Epoch 47/50\n",
      " - 0s - loss: 644.2384 - val_loss: 725.7537\n",
      "Epoch 48/50\n",
      " - 0s - loss: 631.5551 - val_loss: 714.6336\n",
      "Epoch 49/50\n",
      " - 0s - loss: 620.1192 - val_loss: 701.7709\n",
      "Epoch 50/50\n",
      " - 0s - loss: 609.2928 - val_loss: 688.2839\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 159324.2788 - val_loss: 108476.1456\n",
      "Epoch 2/50\n",
      " - 0s - loss: 84889.8878 - val_loss: 51003.7954\n",
      "Epoch 3/50\n",
      " - 0s - loss: 38689.2245 - val_loss: 20273.7902\n",
      "Epoch 4/50\n",
      " - 0s - loss: 16170.7078 - val_loss: 7463.2499\n",
      "Epoch 5/50\n",
      " - 0s - loss: 7814.8175 - val_loss: 3720.8902\n",
      "Epoch 6/50\n",
      " - 0s - loss: 5467.5390 - val_loss: 2973.6220\n",
      "Epoch 7/50\n",
      " - 0s - loss: 4899.4537 - val_loss: 2790.0996\n",
      "Epoch 8/50\n",
      " - 0s - loss: 4604.6787 - val_loss: 2653.3194\n",
      "Epoch 9/50\n",
      " - 0s - loss: 4345.9674 - val_loss: 2523.2949\n",
      "Epoch 10/50\n",
      " - 0s - loss: 4100.7344 - val_loss: 2395.2014\n",
      "Epoch 11/50\n",
      " - 0s - loss: 3874.1615 - val_loss: 2270.1618\n",
      "Epoch 12/50\n",
      " - 0s - loss: 3651.4144 - val_loss: 2160.6108\n",
      "Epoch 13/50\n",
      " - 0s - loss: 3450.0839 - val_loss: 2050.2201\n",
      "Epoch 14/50\n",
      " - 0s - loss: 3250.1835 - val_loss: 1956.2202\n",
      "Epoch 15/50\n",
      " - 0s - loss: 3063.4128 - val_loss: 1852.1468\n",
      "Epoch 16/50\n",
      " - 0s - loss: 2894.8786 - val_loss: 1754.9591\n",
      "Epoch 17/50\n",
      " - 0s - loss: 2730.4620 - val_loss: 1672.8040\n",
      "Epoch 18/50\n",
      " - 0s - loss: 2575.8714 - val_loss: 1590.2714\n",
      "Epoch 19/50\n",
      " - 0s - loss: 2433.9774 - val_loss: 1511.3954\n",
      "Epoch 20/50\n",
      " - 0s - loss: 2303.7520 - val_loss: 1441.0902\n",
      "Epoch 21/50\n",
      " - 0s - loss: 2177.1735 - val_loss: 1370.4245\n",
      "Epoch 22/50\n",
      " - 0s - loss: 2062.3177 - val_loss: 1307.1692\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1954.2975 - val_loss: 1245.4048\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1854.1601 - val_loss: 1191.5147\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1762.1154 - val_loss: 1142.1203\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1669.4665 - val_loss: 1085.5381\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1593.7860 - val_loss: 1035.4204\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1512.2125 - val_loss: 994.7446\n",
      "Epoch 29/50\n",
      " - 0s - loss: 1442.0061 - val_loss: 960.2607\n",
      "Epoch 30/50\n",
      " - 0s - loss: 1374.7450 - val_loss: 914.6758\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1309.1534 - val_loss: 875.5641\n",
      "Epoch 32/50\n",
      " - 0s - loss: 1250.5844 - val_loss: 845.0087\n",
      "Epoch 33/50\n",
      " - 0s - loss: 1195.4650 - val_loss: 804.4572\n",
      "Epoch 34/50\n",
      " - 0s - loss: 1144.5021 - val_loss: 775.8637\n",
      "Epoch 35/50\n",
      " - 0s - loss: 1094.7994 - val_loss: 748.8357\n",
      "Epoch 36/50\n",
      " - 0s - loss: 1048.1819 - val_loss: 715.2932\n",
      "Epoch 37/50\n",
      " - 0s - loss: 1003.2547 - val_loss: 691.4617\n",
      "Epoch 38/50\n",
      " - 0s - loss: 963.7765 - val_loss: 663.3730\n",
      "Epoch 39/50\n",
      " - 0s - loss: 924.4325 - val_loss: 639.6516\n",
      "Epoch 40/50\n",
      " - 0s - loss: 888.0475 - val_loss: 616.7990\n",
      "Epoch 41/50\n",
      " - 0s - loss: 854.2633 - val_loss: 593.4301\n",
      "Epoch 42/50\n",
      " - 0s - loss: 820.9441 - val_loss: 571.2488\n",
      "Epoch 43/50\n",
      " - 0s - loss: 789.9012 - val_loss: 551.4759\n",
      "Epoch 44/50\n",
      " - 0s - loss: 760.8550 - val_loss: 533.2283\n",
      "Epoch 45/50\n",
      " - 0s - loss: 732.1740 - val_loss: 513.6152\n",
      "Epoch 46/50\n",
      " - 0s - loss: 706.1080 - val_loss: 498.1164\n",
      "Epoch 47/50\n",
      " - 0s - loss: 681.0806 - val_loss: 478.8855\n",
      "Epoch 48/50\n",
      " - 0s - loss: 657.6984 - val_loss: 460.6365\n",
      "Epoch 49/50\n",
      " - 0s - loss: 633.7936 - val_loss: 446.8857\n",
      "Epoch 50/50\n",
      " - 0s - loss: 612.9621 - val_loss: 433.9133\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 439205.8844 - val_loss: 305461.1865\n",
      "Epoch 2/50\n",
      " - 0s - loss: 248298.4495 - val_loss: 154292.3022\n",
      "Epoch 3/50\n",
      " - 0s - loss: 118117.5213 - val_loss: 64030.1499\n",
      "Epoch 4/50\n",
      " - 0s - loss: 47036.9170 - val_loss: 22373.8415\n",
      "Epoch 5/50\n",
      " - 0s - loss: 16834.2818 - val_loss: 8607.7445\n",
      "Epoch 6/50\n",
      " - 0s - loss: 7443.0120 - val_loss: 5774.6588\n",
      "Epoch 7/50\n",
      " - 0s - loss: 5509.1768 - val_loss: 5509.0543\n",
      "Epoch 8/50\n",
      " - 0s - loss: 5069.2503 - val_loss: 5425.6079\n",
      "Epoch 9/50\n",
      " - 0s - loss: 4909.9758 - val_loss: 5274.2395\n",
      "Epoch 10/50\n",
      " - 0s - loss: 4763.2068 - val_loss: 5105.6545\n",
      "Epoch 11/50\n",
      " - 0s - loss: 4614.5810 - val_loss: 4941.1094\n",
      "Epoch 12/50\n",
      " - 0s - loss: 4465.6216 - val_loss: 4752.3661\n",
      "Epoch 13/50\n",
      " - 0s - loss: 4327.2928 - val_loss: 4587.1151\n",
      "Epoch 14/50\n",
      " - 0s - loss: 4180.3134 - val_loss: 4412.5443\n",
      "Epoch 15/50\n",
      " - 0s - loss: 4048.7444 - val_loss: 4261.3022\n",
      "Epoch 16/50\n",
      " - 0s - loss: 3918.5214 - val_loss: 4087.3370\n",
      "Epoch 17/50\n",
      " - 0s - loss: 3792.0689 - val_loss: 3938.0049\n",
      "Epoch 18/50\n",
      " - 0s - loss: 3679.5007 - val_loss: 3816.9484\n",
      "Epoch 19/50\n",
      " - 0s - loss: 3556.0208 - val_loss: 3677.1496\n",
      "Epoch 20/50\n",
      " - 0s - loss: 3447.0678 - val_loss: 3550.6900\n",
      "Epoch 21/50\n",
      " - 0s - loss: 3344.1892 - val_loss: 3422.3958\n",
      "Epoch 22/50\n",
      " - 0s - loss: 3244.3112 - val_loss: 3325.7435\n",
      "Epoch 23/50\n",
      " - 0s - loss: 3148.2442 - val_loss: 3208.6745\n",
      "Epoch 24/50\n",
      " - 0s - loss: 3059.6106 - val_loss: 3102.6540\n",
      "Epoch 25/50\n",
      " - 0s - loss: 2972.8681 - val_loss: 3014.3587\n",
      "Epoch 26/50\n",
      " - 0s - loss: 2899.6169 - val_loss: 2888.4441\n",
      "Epoch 27/50\n",
      " - 0s - loss: 2817.7970 - val_loss: 2823.8761\n",
      "Epoch 28/50\n",
      " - 0s - loss: 2748.9812 - val_loss: 2749.5455\n",
      "Epoch 29/50\n",
      " - 0s - loss: 2684.6757 - val_loss: 2661.9345\n",
      "Epoch 30/50\n",
      " - 0s - loss: 2617.1013 - val_loss: 2589.2117\n",
      "Epoch 31/50\n",
      " - 0s - loss: 2551.5847 - val_loss: 2519.4956\n",
      "Epoch 32/50\n",
      " - 0s - loss: 2492.0700 - val_loss: 2442.6751\n",
      "Epoch 33/50\n",
      " - 0s - loss: 2430.2499 - val_loss: 2374.1011\n",
      "Epoch 34/50\n",
      " - 0s - loss: 2373.2692 - val_loss: 2320.5421\n",
      "Epoch 35/50\n",
      " - 0s - loss: 2319.1098 - val_loss: 2263.1799\n",
      "Epoch 36/50\n",
      " - 0s - loss: 2262.6130 - val_loss: 2174.1305\n",
      "Epoch 37/50\n",
      " - 0s - loss: 2210.6986 - val_loss: 2129.2184\n",
      "Epoch 38/50\n",
      " - 0s - loss: 2160.9208 - val_loss: 2076.1294\n",
      "Epoch 39/50\n",
      " - 0s - loss: 2110.8201 - val_loss: 2020.3346\n",
      "Epoch 40/50\n",
      " - 0s - loss: 2064.1974 - val_loss: 1952.0325\n",
      "Epoch 41/50\n",
      " - 0s - loss: 2018.2371 - val_loss: 1930.2813\n",
      "Epoch 42/50\n",
      " - 0s - loss: 1974.9888 - val_loss: 1879.1223\n",
      "Epoch 43/50\n",
      " - 0s - loss: 1927.8160 - val_loss: 1819.6944\n",
      "Epoch 44/50\n",
      " - 0s - loss: 1886.1219 - val_loss: 1790.8642\n",
      "Epoch 45/50\n",
      " - 0s - loss: 1843.3647 - val_loss: 1727.0799\n",
      "Epoch 46/50\n",
      " - 0s - loss: 1802.5609 - val_loss: 1701.6303\n",
      "Epoch 47/50\n",
      " - 0s - loss: 1763.8616 - val_loss: 1655.3830\n",
      "Epoch 48/50\n",
      " - 0s - loss: 1728.8105 - val_loss: 1591.3290\n",
      "Epoch 49/50\n",
      " - 0s - loss: 1684.4410 - val_loss: 1584.8605\n",
      "Epoch 50/50\n",
      " - 0s - loss: 1648.3732 - val_loss: 1546.4337\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 77753.5178 - val_loss: 46048.1889\n",
      "Epoch 2/50\n",
      " - 0s - loss: 30781.3659 - val_loss: 15441.1726\n",
      "Epoch 3/50\n",
      " - 0s - loss: 8537.1909 - val_loss: 4165.5121\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2565.8593 - val_loss: 2479.7248\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2066.8569 - val_loss: 2367.0635\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1960.4342 - val_loss: 2280.4751\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1852.5860 - val_loss: 2199.8752\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1755.5808 - val_loss: 2110.1659\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1660.4921 - val_loss: 2021.8725\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1573.2648 - val_loss: 1940.5215\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1491.8613 - val_loss: 1860.2859\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1412.9887 - val_loss: 1792.4733\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1343.5214 - val_loss: 1723.8056\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1276.1309 - val_loss: 1660.3859\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1213.8980 - val_loss: 1602.2686\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1157.9320 - val_loss: 1544.7296\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1101.9762 - val_loss: 1489.9858\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1049.3544 - val_loss: 1444.0962\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1002.1273 - val_loss: 1393.1601\n",
      "Epoch 20/50\n",
      " - 0s - loss: 959.3310 - val_loss: 1346.0651\n",
      "Epoch 21/50\n",
      " - 0s - loss: 915.6049 - val_loss: 1303.5118\n",
      "Epoch 22/50\n",
      " - 0s - loss: 875.8707 - val_loss: 1263.3091\n",
      "Epoch 23/50\n",
      " - 0s - loss: 839.6489 - val_loss: 1223.7995\n",
      "Epoch 24/50\n",
      " - 0s - loss: 805.1866 - val_loss: 1186.4392\n",
      "Epoch 25/50\n",
      " - 0s - loss: 771.9188 - val_loss: 1145.9638\n",
      "Epoch 26/50\n",
      " - 0s - loss: 740.5405 - val_loss: 1110.8000\n",
      "Epoch 27/50\n",
      " - 0s - loss: 711.5977 - val_loss: 1076.0342\n",
      "Epoch 28/50\n",
      " - 0s - loss: 682.3756 - val_loss: 1044.2584\n",
      "Epoch 29/50\n",
      " - 0s - loss: 656.1127 - val_loss: 1014.5116\n",
      "Epoch 30/50\n",
      " - 0s - loss: 632.2041 - val_loss: 985.3579\n",
      "Epoch 31/50\n",
      " - 0s - loss: 607.8193 - val_loss: 954.1137\n",
      "Epoch 32/50\n",
      " - 0s - loss: 585.6594 - val_loss: 926.9706\n",
      "Epoch 33/50\n",
      " - 0s - loss: 565.1994 - val_loss: 900.2936\n",
      "Epoch 34/50\n",
      " - 0s - loss: 545.0636 - val_loss: 876.1611\n",
      "Epoch 35/50\n",
      " - 0s - loss: 526.3176 - val_loss: 850.9099\n",
      "Epoch 36/50\n",
      " - 0s - loss: 508.2709 - val_loss: 828.9146\n",
      "Epoch 37/50\n",
      " - 0s - loss: 491.1530 - val_loss: 807.5734\n",
      "Epoch 38/50\n",
      " - 0s - loss: 474.7936 - val_loss: 785.0711\n",
      "Epoch 39/50\n",
      " - 0s - loss: 460.0886 - val_loss: 763.5839\n",
      "Epoch 40/50\n",
      " - 0s - loss: 444.8152 - val_loss: 744.3881\n",
      "Epoch 41/50\n",
      " - 0s - loss: 430.1569 - val_loss: 721.8414\n",
      "Epoch 42/50\n",
      " - 0s - loss: 416.6856 - val_loss: 705.8841\n",
      "Epoch 43/50\n",
      " - 0s - loss: 404.1102 - val_loss: 690.9404\n",
      "Epoch 44/50\n",
      " - 0s - loss: 391.3647 - val_loss: 666.3781\n",
      "Epoch 45/50\n",
      " - 0s - loss: 379.7277 - val_loss: 652.5713\n",
      "Epoch 46/50\n",
      " - 0s - loss: 370.1999 - val_loss: 633.9295\n",
      "Epoch 47/50\n",
      " - 0s - loss: 358.5384 - val_loss: 621.7255\n",
      "Epoch 48/50\n",
      " - 0s - loss: 349.3597 - val_loss: 599.5921\n",
      "Epoch 49/50\n",
      " - 0s - loss: 340.4830 - val_loss: 589.9025\n",
      "Epoch 50/50\n",
      " - 0s - loss: 329.6240 - val_loss: 575.3094\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 24628.8461 - val_loss: 14099.4449\n",
      "Epoch 2/50\n",
      " - 0s - loss: 6989.8725 - val_loss: 3921.1177\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1958.5192 - val_loss: 1317.5013\n",
      "Epoch 4/50\n",
      " - 0s - loss: 975.7591 - val_loss: 786.5342\n",
      "Epoch 5/50\n",
      " - 0s - loss: 842.8631 - val_loss: 695.7328\n",
      "Epoch 6/50\n",
      " - 0s - loss: 820.0349 - val_loss: 666.5742\n",
      "Epoch 7/50\n",
      " - 0s - loss: 799.9235 - val_loss: 661.5126\n",
      "Epoch 8/50\n",
      " - 0s - loss: 778.7888 - val_loss: 642.6302\n",
      "Epoch 9/50\n",
      " - 0s - loss: 759.6274 - val_loss: 634.7261\n",
      "Epoch 10/50\n",
      " - 0s - loss: 740.7607 - val_loss: 617.9228\n",
      "Epoch 11/50\n",
      " - 0s - loss: 721.9955 - val_loss: 610.3230\n",
      "Epoch 12/50\n",
      " - 0s - loss: 705.2649 - val_loss: 591.0328\n",
      "Epoch 13/50\n",
      " - 0s - loss: 689.1453 - val_loss: 582.9171\n",
      "Epoch 14/50\n",
      " - 0s - loss: 673.5888 - val_loss: 567.4854\n",
      "Epoch 15/50\n",
      " - 0s - loss: 659.0059 - val_loss: 562.0337\n",
      "Epoch 16/50\n",
      " - 0s - loss: 645.4332 - val_loss: 539.2634\n",
      "Epoch 17/50\n",
      " - 0s - loss: 632.1839 - val_loss: 534.5976\n",
      "Epoch 18/50\n",
      " - 0s - loss: 618.8615 - val_loss: 524.6461\n",
      "Epoch 19/50\n",
      " - 0s - loss: 607.0116 - val_loss: 517.8646\n",
      "Epoch 20/50\n",
      " - 0s - loss: 596.5715 - val_loss: 507.4142\n",
      "Epoch 21/50\n",
      " - 0s - loss: 583.7674 - val_loss: 488.9376\n",
      "Epoch 22/50\n",
      " - 0s - loss: 572.5954 - val_loss: 493.5341\n",
      "Epoch 23/50\n",
      " - 0s - loss: 562.6957 - val_loss: 491.3772\n",
      "Epoch 24/50\n",
      " - 0s - loss: 551.1436 - val_loss: 467.2165\n",
      "Epoch 25/50\n",
      " - 0s - loss: 540.0870 - val_loss: 458.6442\n",
      "Epoch 26/50\n",
      " - 0s - loss: 528.9253 - val_loss: 466.3728\n",
      "Epoch 27/50\n",
      " - 0s - loss: 517.3636 - val_loss: 446.5936\n",
      "Epoch 28/50\n",
      " - 0s - loss: 506.4059 - val_loss: 438.3966\n",
      "Epoch 29/50\n",
      " - 0s - loss: 494.5265 - val_loss: 433.7552\n",
      "Epoch 30/50\n",
      " - 0s - loss: 485.0054 - val_loss: 423.4946\n",
      "Epoch 31/50\n",
      " - 0s - loss: 473.1978 - val_loss: 423.7789\n",
      "Epoch 32/50\n",
      " - 0s - loss: 461.8513 - val_loss: 405.2812\n",
      "Epoch 33/50\n",
      " - 0s - loss: 450.2548 - val_loss: 397.9368\n",
      "Epoch 34/50\n",
      " - 0s - loss: 440.1851 - val_loss: 380.2244\n",
      "Epoch 35/50\n",
      " - 0s - loss: 428.2456 - val_loss: 377.8513\n",
      "Epoch 36/50\n",
      " - 0s - loss: 418.0606 - val_loss: 377.9758\n",
      "Epoch 37/50\n",
      " - 0s - loss: 407.8731 - val_loss: 355.1764\n",
      "Epoch 38/50\n",
      " - 0s - loss: 397.0420 - val_loss: 360.8730\n",
      "Epoch 39/50\n",
      " - 0s - loss: 387.8610 - val_loss: 352.8583\n",
      "Epoch 40/50\n",
      " - 0s - loss: 378.2082 - val_loss: 338.5984\n",
      "Epoch 41/50\n",
      " - 0s - loss: 368.3641 - val_loss: 327.6177\n",
      "Epoch 42/50\n",
      " - 0s - loss: 359.2879 - val_loss: 327.9450\n",
      "Epoch 43/50\n",
      " - 0s - loss: 350.5929 - val_loss: 322.4621\n",
      "Epoch 44/50\n",
      " - 0s - loss: 342.8781 - val_loss: 322.4145\n",
      "Epoch 45/50\n",
      " - 0s - loss: 333.9519 - val_loss: 311.6725\n",
      "Epoch 46/50\n",
      " - 0s - loss: 326.0535 - val_loss: 310.4509\n",
      "Epoch 47/50\n",
      " - 0s - loss: 317.8991 - val_loss: 289.6605\n",
      "Epoch 48/50\n",
      " - 0s - loss: 310.2954 - val_loss: 299.8402\n",
      "Epoch 49/50\n",
      " - 0s - loss: 304.5680 - val_loss: 284.3591\n",
      "Epoch 50/50\n",
      " - 0s - loss: 297.8239 - val_loss: 286.8555\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 171431.5389 - val_loss: 105088.8177\n",
      "Epoch 2/50\n",
      " - 0s - loss: 70000.4201 - val_loss: 34944.8639\n",
      "Epoch 3/50\n",
      " - 0s - loss: 21380.2599 - val_loss: 9488.6384\n",
      "Epoch 4/50\n",
      " - 0s - loss: 7042.6582 - val_loss: 3921.3435\n",
      "Epoch 5/50\n",
      " - 0s - loss: 4540.9884 - val_loss: 3414.2766\n",
      "Epoch 6/50\n",
      " - 0s - loss: 4082.4021 - val_loss: 3313.6951\n",
      "Epoch 7/50\n",
      " - 0s - loss: 3755.9381 - val_loss: 3204.2590\n",
      "Epoch 8/50\n",
      " - 0s - loss: 3336.8013 - val_loss: 3067.0765\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2754.7872 - val_loss: 2911.5016\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2051.1786 - val_loss: 2795.9432\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1644.3942 - val_loss: 2765.5543\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1464.3773 - val_loss: 2626.4801\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1328.6372 - val_loss: 2447.1456\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1214.1302 - val_loss: 2284.6630\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1113.6280 - val_loss: 2129.8932\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1023.6495 - val_loss: 1958.2015\n",
      "Epoch 17/50\n",
      " - 0s - loss: 941.9884 - val_loss: 1787.2461\n",
      "Epoch 18/50\n",
      " - 0s - loss: 863.1576 - val_loss: 1622.9048\n",
      "Epoch 19/50\n",
      " - 0s - loss: 791.8346 - val_loss: 1460.9470\n",
      "Epoch 20/50\n",
      " - 0s - loss: 723.5061 - val_loss: 1314.5353\n",
      "Epoch 21/50\n",
      " - 0s - loss: 662.3562 - val_loss: 1173.7172\n",
      "Epoch 22/50\n",
      " - 0s - loss: 604.9480 - val_loss: 1044.9308\n",
      "Epoch 23/50\n",
      " - 0s - loss: 544.7987 - val_loss: 908.0164\n",
      "Epoch 24/50\n",
      " - 0s - loss: 484.2717 - val_loss: 829.9319\n",
      "Epoch 25/50\n",
      " - 0s - loss: 435.4740 - val_loss: 677.3696\n",
      "Epoch 26/50\n",
      " - 0s - loss: 380.2336 - val_loss: 587.0679\n",
      "Epoch 27/50\n",
      " - 0s - loss: 351.3829 - val_loss: 496.5309\n",
      "Epoch 28/50\n",
      " - 0s - loss: 307.7552 - val_loss: 426.4259\n",
      "Epoch 29/50\n",
      " - 0s - loss: 280.1612 - val_loss: 368.9631\n",
      "Epoch 30/50\n",
      " - 0s - loss: 248.5163 - val_loss: 324.2242\n",
      "Epoch 31/50\n",
      " - 0s - loss: 227.4399 - val_loss: 281.0917\n",
      "Epoch 32/50\n",
      " - 0s - loss: 208.1897 - val_loss: 255.5004\n",
      "Epoch 33/50\n",
      " - 0s - loss: 196.0077 - val_loss: 227.8005\n",
      "Epoch 34/50\n",
      " - 0s - loss: 183.9844 - val_loss: 204.5805\n",
      "Epoch 35/50\n",
      " - 0s - loss: 173.6458 - val_loss: 190.2994\n",
      "Epoch 36/50\n",
      " - 0s - loss: 158.4434 - val_loss: 170.4908\n",
      "Epoch 37/50\n",
      " - 0s - loss: 149.6704 - val_loss: 179.6810\n",
      "Epoch 38/50\n",
      " - 0s - loss: 145.6534 - val_loss: 160.9042\n",
      "Epoch 39/50\n",
      " - 0s - loss: 141.4318 - val_loss: 154.8828\n",
      "Epoch 40/50\n",
      " - 0s - loss: 134.9181 - val_loss: 150.6403\n",
      "Epoch 41/50\n",
      " - 0s - loss: 130.8600 - val_loss: 130.4144\n",
      "Epoch 42/50\n",
      " - 0s - loss: 128.8577 - val_loss: 128.3903\n",
      "Epoch 43/50\n",
      " - 0s - loss: 126.1327 - val_loss: 131.6071\n",
      "Epoch 44/50\n",
      " - 0s - loss: 122.1034 - val_loss: 136.1570\n",
      "Epoch 45/50\n",
      " - 0s - loss: 122.3919 - val_loss: 124.0148\n",
      "Epoch 46/50\n",
      " - 0s - loss: 117.6776 - val_loss: 131.8397\n",
      "Epoch 47/50\n",
      " - 0s - loss: 117.6507 - val_loss: 121.0370\n",
      "Epoch 48/50\n",
      " - 0s - loss: 116.1692 - val_loss: 118.9904\n",
      "Epoch 49/50\n",
      " - 0s - loss: 114.0792 - val_loss: 113.8847\n",
      "Epoch 50/50\n",
      " - 0s - loss: 112.7124 - val_loss: 119.8037\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 7325.1850 - val_loss: 1981.8344\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1001.0507 - val_loss: 1364.5642\n",
      "Epoch 3/50\n",
      " - 0s - loss: 799.2143 - val_loss: 1150.7831\n",
      "Epoch 4/50\n",
      " - 0s - loss: 703.9458 - val_loss: 1035.4454\n",
      "Epoch 5/50\n",
      " - 0s - loss: 653.0757 - val_loss: 947.5954\n",
      "Epoch 6/50\n",
      " - 0s - loss: 600.3296 - val_loss: 858.7175\n",
      "Epoch 7/50\n",
      " - 0s - loss: 550.0538 - val_loss: 784.1582\n",
      "Epoch 8/50\n",
      " - 0s - loss: 502.0672 - val_loss: 687.2166\n",
      "Epoch 9/50\n",
      " - 0s - loss: 459.4746 - val_loss: 623.7381\n",
      "Epoch 10/50\n",
      " - 0s - loss: 417.5886 - val_loss: 554.1764\n",
      "Epoch 11/50\n",
      " - 0s - loss: 381.3313 - val_loss: 493.9673\n",
      "Epoch 12/50\n",
      " - 0s - loss: 347.8988 - val_loss: 442.2185\n",
      "Epoch 13/50\n",
      " - 0s - loss: 318.7778 - val_loss: 394.3269\n",
      "Epoch 14/50\n",
      " - 0s - loss: 293.4085 - val_loss: 358.0441\n",
      "Epoch 15/50\n",
      " - 0s - loss: 271.3243 - val_loss: 313.7713\n",
      "Epoch 16/50\n",
      " - 0s - loss: 250.0941 - val_loss: 285.8951\n",
      "Epoch 17/50\n",
      " - 0s - loss: 232.4131 - val_loss: 256.7978\n",
      "Epoch 18/50\n",
      " - 0s - loss: 217.5748 - val_loss: 233.0709\n",
      "Epoch 19/50\n",
      " - 0s - loss: 204.9299 - val_loss: 218.7559\n",
      "Epoch 20/50\n",
      " - 0s - loss: 192.5354 - val_loss: 189.3929\n",
      "Epoch 21/50\n",
      " - 0s - loss: 184.5377 - val_loss: 191.9544\n",
      "Epoch 22/50\n",
      " - 0s - loss: 178.3204 - val_loss: 161.0406\n",
      "Epoch 23/50\n",
      " - 0s - loss: 169.8098 - val_loss: 161.1154\n",
      "Epoch 24/50\n",
      " - 0s - loss: 163.7815 - val_loss: 154.6146\n",
      "Epoch 25/50\n",
      " - 0s - loss: 158.1686 - val_loss: 140.7516\n",
      "Epoch 26/50\n",
      " - 0s - loss: 155.5125 - val_loss: 147.7660\n",
      "Epoch 27/50\n",
      " - 0s - loss: 151.1925 - val_loss: 127.1476\n",
      "Epoch 28/50\n",
      " - 0s - loss: 148.9453 - val_loss: 132.5436\n",
      "Epoch 29/50\n",
      " - 0s - loss: 147.0393 - val_loss: 125.1422\n",
      "Epoch 30/50\n",
      " - 0s - loss: 145.3994 - val_loss: 122.2590\n",
      "Epoch 31/50\n",
      " - 0s - loss: 144.6981 - val_loss: 131.3523\n",
      "Epoch 32/50\n",
      " - 0s - loss: 143.4900 - val_loss: 111.6440\n",
      "Epoch 33/50\n",
      " - 0s - loss: 143.0132 - val_loss: 119.7059\n",
      "Epoch 34/50\n",
      " - 0s - loss: 141.0097 - val_loss: 113.6997\n",
      "Epoch 35/50\n",
      " - 0s - loss: 140.3430 - val_loss: 123.6993\n",
      "Epoch 36/50\n",
      " - 0s - loss: 140.2353 - val_loss: 115.9148\n",
      "Epoch 37/50\n",
      " - 0s - loss: 139.2920 - val_loss: 112.5290\n",
      "Epoch 38/50\n",
      " - 0s - loss: 139.0524 - val_loss: 119.8337\n",
      "Epoch 39/50\n",
      " - 0s - loss: 139.4850 - val_loss: 120.9116\n",
      "Epoch 40/50\n",
      " - 0s - loss: 138.6197 - val_loss: 111.8654\n",
      "Epoch 41/50\n",
      " - 0s - loss: 138.4662 - val_loss: 108.5001\n",
      "Epoch 42/50\n",
      " - 0s - loss: 139.6955 - val_loss: 108.4217\n",
      "Epoch 43/50\n",
      " - 0s - loss: 138.7269 - val_loss: 111.5979\n",
      "Epoch 44/50\n",
      " - 0s - loss: 137.8736 - val_loss: 119.8308\n",
      "Epoch 45/50\n",
      " - 0s - loss: 137.2823 - val_loss: 106.0167\n",
      "Epoch 46/50\n",
      " - 0s - loss: 139.0099 - val_loss: 107.9105\n",
      "Epoch 47/50\n",
      " - 0s - loss: 137.5254 - val_loss: 127.4972\n",
      "Epoch 48/50\n",
      " - 0s - loss: 138.8003 - val_loss: 118.1486\n",
      "Epoch 49/50\n",
      " - 0s - loss: 138.9886 - val_loss: 104.6833\n",
      "Epoch 50/50\n",
      " - 0s - loss: 138.4446 - val_loss: 108.5214\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 45416.7106 - val_loss: 14187.8464\n",
      "Epoch 2/50\n",
      " - 0s - loss: 9467.8495 - val_loss: 8533.2345\n",
      "Epoch 3/50\n",
      " - 0s - loss: 7999.7918 - val_loss: 7901.1642\n",
      "Epoch 4/50\n",
      " - 0s - loss: 7373.1947 - val_loss: 7452.9939\n",
      "Epoch 5/50\n",
      " - 0s - loss: 6851.1046 - val_loss: 6989.6837\n",
      "Epoch 6/50\n",
      " - 0s - loss: 6388.7810 - val_loss: 6550.8651\n",
      "Epoch 7/50\n",
      " - 0s - loss: 5917.7642 - val_loss: 6134.2926\n",
      "Epoch 8/50\n",
      " - 0s - loss: 5473.5629 - val_loss: 5728.9963\n",
      "Epoch 9/50\n",
      " - 0s - loss: 5052.3473 - val_loss: 5321.8317\n",
      "Epoch 10/50\n",
      " - 0s - loss: 4673.6529 - val_loss: 4949.5059\n",
      "Epoch 11/50\n",
      " - 0s - loss: 4315.0149 - val_loss: 4581.3684\n",
      "Epoch 12/50\n",
      " - 0s - loss: 3977.6925 - val_loss: 4239.7298\n",
      "Epoch 13/50\n",
      " - 0s - loss: 3658.2568 - val_loss: 3918.8744\n",
      "Epoch 14/50\n",
      " - 0s - loss: 3357.7206 - val_loss: 3618.6055\n",
      "Epoch 15/50\n",
      " - 0s - loss: 3095.0337 - val_loss: 3324.1018\n",
      "Epoch 16/50\n",
      " - 0s - loss: 2826.0093 - val_loss: 3048.1202\n",
      "Epoch 17/50\n",
      " - 0s - loss: 2579.3870 - val_loss: 2799.1504\n",
      "Epoch 18/50\n",
      " - 0s - loss: 2356.8997 - val_loss: 2557.7623\n",
      "Epoch 19/50\n",
      " - 0s - loss: 2147.2924 - val_loss: 2349.6563\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1952.4524 - val_loss: 2151.1513\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1785.2117 - val_loss: 1971.5345\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1635.0391 - val_loss: 1796.1136\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1479.1273 - val_loss: 1652.3863\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1349.7823 - val_loss: 1504.7985\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1227.5606 - val_loss: 1376.1106\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1117.3640 - val_loss: 1259.0071\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1016.4487 - val_loss: 1151.2446\n",
      "Epoch 28/50\n",
      " - 0s - loss: 926.0365 - val_loss: 1054.3657\n",
      "Epoch 29/50\n",
      " - 0s - loss: 842.2084 - val_loss: 966.9591\n",
      "Epoch 30/50\n",
      " - 0s - loss: 761.5604 - val_loss: 890.8388\n",
      "Epoch 31/50\n",
      " - 0s - loss: 682.4048 - val_loss: 819.7198\n",
      "Epoch 32/50\n",
      " - 0s - loss: 615.1002 - val_loss: 765.9508\n",
      "Epoch 33/50\n",
      " - 0s - loss: 553.6791 - val_loss: 716.7500\n",
      "Epoch 34/50\n",
      " - 0s - loss: 498.9872 - val_loss: 679.3867\n",
      "Epoch 35/50\n",
      " - 0s - loss: 451.4292 - val_loss: 633.2647\n",
      "Epoch 36/50\n",
      " - 0s - loss: 409.1433 - val_loss: 607.9089\n",
      "Epoch 37/50\n",
      " - 0s - loss: 374.7789 - val_loss: 577.4022\n",
      "Epoch 38/50\n",
      " - 0s - loss: 346.2091 - val_loss: 558.2280\n",
      "Epoch 39/50\n",
      " - 0s - loss: 323.6896 - val_loss: 542.2180\n",
      "Epoch 40/50\n",
      " - 0s - loss: 302.1420 - val_loss: 512.1956\n",
      "Epoch 41/50\n",
      " - 0s - loss: 287.1642 - val_loss: 503.6063\n",
      "Epoch 42/50\n",
      " - 0s - loss: 273.8335 - val_loss: 484.5636\n",
      "Epoch 43/50\n",
      " - 0s - loss: 262.6011 - val_loss: 465.7640\n",
      "Epoch 44/50\n",
      " - 0s - loss: 254.1475 - val_loss: 461.9149\n",
      "Epoch 45/50\n",
      " - 0s - loss: 246.4367 - val_loss: 451.2245\n",
      "Epoch 46/50\n",
      " - 0s - loss: 237.4364 - val_loss: 435.1921\n",
      "Epoch 47/50\n",
      " - 0s - loss: 232.8320 - val_loss: 431.5315\n",
      "Epoch 48/50\n",
      " - 0s - loss: 227.5540 - val_loss: 430.3065\n",
      "Epoch 49/50\n",
      " - 0s - loss: 221.2072 - val_loss: 415.4188\n",
      "Epoch 50/50\n",
      " - 0s - loss: 215.7450 - val_loss: 401.0728\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 23864.1771 - val_loss: 11146.7784\n",
      "Epoch 2/50\n",
      " - 0s - loss: 10689.3065 - val_loss: 8908.1100\n",
      "Epoch 3/50\n",
      " - 0s - loss: 8919.9894 - val_loss: 7677.4879\n",
      "Epoch 4/50\n",
      " - 0s - loss: 7730.4492 - val_loss: 6612.0515\n",
      "Epoch 5/50\n",
      " - 0s - loss: 6715.0759 - val_loss: 5776.2058\n",
      "Epoch 6/50\n",
      " - 0s - loss: 5812.9977 - val_loss: 4983.2496\n",
      "Epoch 7/50\n",
      " - 0s - loss: 5021.2906 - val_loss: 4370.7311\n",
      "Epoch 8/50\n",
      " - 0s - loss: 4315.4000 - val_loss: 3822.7354\n",
      "Epoch 9/50\n",
      " - 0s - loss: 3679.9761 - val_loss: 3262.6781\n",
      "Epoch 10/50\n",
      " - 0s - loss: 3112.8322 - val_loss: 2866.7405\n",
      "Epoch 11/50\n",
      " - 0s - loss: 2629.4777 - val_loss: 2464.9736\n",
      "Epoch 12/50\n",
      " - 0s - loss: 2217.4029 - val_loss: 2220.4156\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1846.4219 - val_loss: 1859.0645\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1574.0663 - val_loss: 1673.6146\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1393.6186 - val_loss: 1457.9596\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1256.1268 - val_loss: 1388.1237\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1137.0427 - val_loss: 1224.3832\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1053.2312 - val_loss: 1216.7977\n",
      "Epoch 19/50\n",
      " - 0s - loss: 959.3306 - val_loss: 1080.7415\n",
      "Epoch 20/50\n",
      " - 0s - loss: 886.9561 - val_loss: 1033.2782\n",
      "Epoch 21/50\n",
      " - 0s - loss: 827.6726 - val_loss: 980.8279\n",
      "Epoch 22/50\n",
      " - 0s - loss: 775.8518 - val_loss: 995.6052\n",
      "Epoch 23/50\n",
      " - 0s - loss: 733.8001 - val_loss: 925.7968\n",
      "Epoch 24/50\n",
      " - 0s - loss: 686.7956 - val_loss: 907.6557\n",
      "Epoch 25/50\n",
      " - 0s - loss: 644.2779 - val_loss: 849.5148\n",
      "Epoch 26/50\n",
      " - 0s - loss: 605.4467 - val_loss: 839.3126\n",
      "Epoch 27/50\n",
      " - 0s - loss: 574.7366 - val_loss: 800.5159\n",
      "Epoch 28/50\n",
      " - 0s - loss: 541.4308 - val_loss: 779.1979\n",
      "Epoch 29/50\n",
      " - 0s - loss: 512.7853 - val_loss: 750.3936\n",
      "Epoch 30/50\n",
      " - 0s - loss: 489.6996 - val_loss: 697.5942\n",
      "Epoch 31/50\n",
      " - 0s - loss: 464.9268 - val_loss: 733.0608\n",
      "Epoch 32/50\n",
      " - 0s - loss: 440.3500 - val_loss: 705.3623\n",
      "Epoch 33/50\n",
      " - 0s - loss: 422.8203 - val_loss: 636.8710\n",
      "Epoch 34/50\n",
      " - 0s - loss: 403.4251 - val_loss: 638.9643\n",
      "Epoch 35/50\n",
      " - 0s - loss: 383.9673 - val_loss: 616.4838\n",
      "Epoch 36/50\n",
      " - 0s - loss: 369.1646 - val_loss: 585.0243\n",
      "Epoch 37/50\n",
      " - 0s - loss: 354.8508 - val_loss: 596.0751\n",
      "Epoch 38/50\n",
      " - 0s - loss: 341.7981 - val_loss: 602.4066\n",
      "Epoch 39/50\n",
      " - 0s - loss: 328.3244 - val_loss: 549.2344\n",
      "Epoch 40/50\n",
      " - 0s - loss: 316.7721 - val_loss: 504.6056\n",
      "Epoch 41/50\n",
      " - 0s - loss: 309.8790 - val_loss: 537.7663\n",
      "Epoch 42/50\n",
      " - 0s - loss: 296.7382 - val_loss: 532.7862\n",
      "Epoch 43/50\n",
      " - 0s - loss: 289.1161 - val_loss: 496.1711\n",
      "Epoch 44/50\n",
      " - 0s - loss: 276.6902 - val_loss: 451.8609\n",
      "Epoch 45/50\n",
      " - 0s - loss: 267.4990 - val_loss: 442.1911\n",
      "Epoch 46/50\n",
      " - 0s - loss: 259.2507 - val_loss: 441.7982\n",
      "Epoch 47/50\n",
      " - 0s - loss: 252.8380 - val_loss: 421.2260\n",
      "Epoch 48/50\n",
      " - 0s - loss: 249.3666 - val_loss: 387.3587\n",
      "Epoch 49/50\n",
      " - 0s - loss: 241.4316 - val_loss: 377.2729\n",
      "Epoch 50/50\n",
      " - 0s - loss: 232.8072 - val_loss: 395.5500\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 18357.6232 - val_loss: 10216.2844\n",
      "Epoch 2/50\n",
      " - 0s - loss: 6541.3359 - val_loss: 2617.7870\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1618.4788 - val_loss: 514.1473\n",
      "Epoch 4/50\n",
      " - 0s - loss: 590.7999 - val_loss: 348.8642\n",
      "Epoch 5/50\n",
      " - 0s - loss: 514.5745 - val_loss: 334.1094\n",
      "Epoch 6/50\n",
      " - 0s - loss: 458.9014 - val_loss: 315.9236\n",
      "Epoch 7/50\n",
      " - 0s - loss: 385.6564 - val_loss: 294.0403\n",
      "Epoch 8/50\n",
      " - 0s - loss: 328.0082 - val_loss: 259.5346\n",
      "Epoch 9/50\n",
      " - 0s - loss: 289.0269 - val_loss: 234.6148\n",
      "Epoch 10/50\n",
      " - 0s - loss: 263.5127 - val_loss: 215.1533\n",
      "Epoch 11/50\n",
      " - 0s - loss: 244.9391 - val_loss: 200.1717\n",
      "Epoch 12/50\n",
      " - 0s - loss: 227.1204 - val_loss: 184.7516\n",
      "Epoch 13/50\n",
      " - 0s - loss: 213.5582 - val_loss: 169.6323\n",
      "Epoch 14/50\n",
      " - 0s - loss: 200.4401 - val_loss: 158.1797\n",
      "Epoch 15/50\n",
      " - 0s - loss: 190.7897 - val_loss: 146.8553\n",
      "Epoch 16/50\n",
      " - 0s - loss: 182.5962 - val_loss: 138.4487\n",
      "Epoch 17/50\n",
      " - 0s - loss: 175.2162 - val_loss: 129.3176\n",
      "Epoch 18/50\n",
      " - 0s - loss: 169.0666 - val_loss: 123.7954\n",
      "Epoch 19/50\n",
      " - 0s - loss: 163.9200 - val_loss: 115.1086\n",
      "Epoch 20/50\n",
      " - 0s - loss: 158.6366 - val_loss: 109.4332\n",
      "Epoch 21/50\n",
      " - 0s - loss: 153.5984 - val_loss: 106.8625\n",
      "Epoch 22/50\n",
      " - 0s - loss: 151.4007 - val_loss: 100.0800\n",
      "Epoch 23/50\n",
      " - 0s - loss: 147.4786 - val_loss: 96.7180\n",
      "Epoch 24/50\n",
      " - 0s - loss: 145.0474 - val_loss: 94.5425\n",
      "Epoch 25/50\n",
      " - 0s - loss: 142.4706 - val_loss: 90.0421\n",
      "Epoch 26/50\n",
      " - 0s - loss: 141.2340 - val_loss: 87.0686\n",
      "Epoch 27/50\n",
      " - 0s - loss: 139.1875 - val_loss: 85.2526\n",
      "Epoch 28/50\n",
      " - 0s - loss: 137.4521 - val_loss: 83.1720\n",
      "Epoch 29/50\n",
      " - 0s - loss: 135.9092 - val_loss: 81.4376\n",
      "Epoch 30/50\n",
      " - 0s - loss: 135.0403 - val_loss: 81.5537\n",
      "Epoch 31/50\n",
      " - 0s - loss: 133.8571 - val_loss: 78.4945\n",
      "Epoch 32/50\n",
      " - 0s - loss: 133.2142 - val_loss: 78.4357\n",
      "Epoch 33/50\n",
      " - 0s - loss: 132.4946 - val_loss: 76.4989\n",
      "Epoch 34/50\n",
      " - 0s - loss: 132.2536 - val_loss: 75.4467\n",
      "Epoch 35/50\n",
      " - 0s - loss: 131.9592 - val_loss: 74.7630\n",
      "Epoch 36/50\n",
      " - 0s - loss: 131.3544 - val_loss: 74.5762\n",
      "Epoch 37/50\n",
      " - 0s - loss: 131.1897 - val_loss: 74.0443\n",
      "Epoch 38/50\n",
      " - 0s - loss: 130.6804 - val_loss: 75.6807\n",
      "Epoch 39/50\n",
      " - 0s - loss: 131.5428 - val_loss: 75.3316\n",
      "Epoch 40/50\n",
      " - 0s - loss: 130.7158 - val_loss: 73.4756\n",
      "Epoch 41/50\n",
      " - 0s - loss: 130.6642 - val_loss: 74.9034\n",
      "Epoch 42/50\n",
      " - 0s - loss: 131.6904 - val_loss: 73.1939\n",
      "Epoch 43/50\n",
      " - 0s - loss: 129.6809 - val_loss: 72.5854\n",
      "Epoch 44/50\n",
      " - 0s - loss: 131.0680 - val_loss: 74.9975\n",
      "Epoch 45/50\n",
      " - 0s - loss: 132.3658 - val_loss: 73.6291\n",
      "Epoch 46/50\n",
      " - 0s - loss: 131.5425 - val_loss: 72.4735\n",
      "Epoch 47/50\n",
      " - 0s - loss: 129.8592 - val_loss: 73.0768\n",
      "Epoch 48/50\n",
      " - 0s - loss: 129.7902 - val_loss: 75.6181\n",
      "Epoch 49/50\n",
      " - 0s - loss: 130.0071 - val_loss: 72.1047\n",
      "Epoch 50/50\n",
      " - 0s - loss: 128.7141 - val_loss: 74.1841\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 4572.4303 - val_loss: 2889.0087\n",
      "Epoch 2/50\n",
      " - 0s - loss: 3362.8043 - val_loss: 2345.0210\n",
      "Epoch 3/50\n",
      " - 0s - loss: 2726.1001 - val_loss: 2298.3904\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2290.7560 - val_loss: 2201.4940\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2010.5156 - val_loss: 1983.7605\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1788.9626 - val_loss: 1917.3057\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1597.1507 - val_loss: 1718.7186\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1432.7613 - val_loss: 1579.3418\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1282.3551 - val_loss: 1369.2544\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1163.9396 - val_loss: 1162.5092\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1046.8624 - val_loss: 1028.1490\n",
      "Epoch 12/50\n",
      " - 0s - loss: 945.0895 - val_loss: 955.7084\n",
      "Epoch 13/50\n",
      " - 0s - loss: 851.4425 - val_loss: 1085.0478\n",
      "Epoch 14/50\n",
      " - 0s - loss: 788.3344 - val_loss: 855.0905\n",
      "Epoch 15/50\n",
      " - 0s - loss: 697.6041 - val_loss: 708.4617\n",
      "Epoch 16/50\n",
      " - 0s - loss: 634.6092 - val_loss: 650.5936\n",
      "Epoch 17/50\n",
      " - 0s - loss: 581.8745 - val_loss: 606.3035\n",
      "Epoch 18/50\n",
      " - 0s - loss: 548.7936 - val_loss: 572.4190\n",
      "Epoch 19/50\n",
      " - 0s - loss: 488.7484 - val_loss: 659.4611\n",
      "Epoch 20/50\n",
      " - 0s - loss: 451.3362 - val_loss: 471.9295\n",
      "Epoch 21/50\n",
      " - 0s - loss: 410.3788 - val_loss: 406.6950\n",
      "Epoch 22/50\n",
      " - 0s - loss: 379.3554 - val_loss: 463.0731\n",
      "Epoch 23/50\n",
      " - 0s - loss: 352.1136 - val_loss: 517.1846\n",
      "Epoch 24/50\n",
      " - 0s - loss: 337.5129 - val_loss: 371.1670\n",
      "Epoch 25/50\n",
      " - 0s - loss: 303.9990 - val_loss: 350.7692\n",
      "Epoch 26/50\n",
      " - 0s - loss: 285.3737 - val_loss: 300.7710\n",
      "Epoch 27/50\n",
      " - 0s - loss: 266.1862 - val_loss: 281.3726\n",
      "Epoch 28/50\n",
      " - 0s - loss: 251.6436 - val_loss: 282.4411\n",
      "Epoch 29/50\n",
      " - 0s - loss: 239.2938 - val_loss: 256.5452\n",
      "Epoch 30/50\n",
      " - 0s - loss: 228.6683 - val_loss: 251.2447\n",
      "Epoch 31/50\n",
      " - 0s - loss: 218.4629 - val_loss: 256.9958\n",
      "Epoch 32/50\n",
      " - 0s - loss: 211.0177 - val_loss: 253.6059\n",
      "Epoch 33/50\n",
      " - 0s - loss: 210.4141 - val_loss: 235.5514\n",
      "Epoch 34/50\n",
      " - 0s - loss: 196.8554 - val_loss: 224.8844\n",
      "Epoch 35/50\n",
      " - 0s - loss: 189.3344 - val_loss: 290.9828\n",
      "Epoch 36/50\n",
      " - 0s - loss: 191.7410 - val_loss: 198.4019\n",
      "Epoch 37/50\n",
      " - 0s - loss: 185.4020 - val_loss: 220.0060\n",
      "Epoch 38/50\n",
      " - 0s - loss: 180.2346 - val_loss: 248.2811\n",
      "Epoch 39/50\n",
      " - 0s - loss: 179.0137 - val_loss: 183.9765\n",
      "Epoch 40/50\n",
      " - 0s - loss: 176.4565 - val_loss: 219.7221\n",
      "Epoch 41/50\n",
      " - 0s - loss: 181.8242 - val_loss: 219.6264\n",
      "Epoch 42/50\n",
      " - 0s - loss: 171.5815 - val_loss: 189.7595\n",
      "Epoch 43/50\n",
      " - 0s - loss: 165.5670 - val_loss: 230.6786\n",
      "Epoch 44/50\n",
      " - 0s - loss: 164.7371 - val_loss: 200.9009\n",
      "Epoch 45/50\n",
      " - 0s - loss: 162.7050 - val_loss: 182.9347\n",
      "Epoch 46/50\n",
      " - 0s - loss: 163.2400 - val_loss: 228.4642\n",
      "Epoch 47/50\n",
      " - 0s - loss: 158.6618 - val_loss: 176.3268\n",
      "Epoch 48/50\n",
      " - 0s - loss: 158.0940 - val_loss: 161.7174\n",
      "Epoch 49/50\n",
      " - 0s - loss: 164.6082 - val_loss: 223.7273\n",
      "Epoch 50/50\n",
      " - 0s - loss: 159.3360 - val_loss: 151.7334\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 5752.9788 - val_loss: 2641.1280\n",
      "Epoch 2/50\n",
      " - 0s - loss: 3469.9527 - val_loss: 2218.8456\n",
      "Epoch 3/50\n",
      " - 0s - loss: 2916.6830 - val_loss: 1975.8971\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2538.5158 - val_loss: 1684.9139\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2194.6664 - val_loss: 1414.7481\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1834.2875 - val_loss: 1163.9613\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1403.5877 - val_loss: 844.9849\n",
      "Epoch 8/50\n",
      " - 0s - loss: 887.1784 - val_loss: 716.3065\n",
      "Epoch 9/50\n",
      " - 0s - loss: 628.8020 - val_loss: 769.8056\n",
      "Epoch 10/50\n",
      " - 0s - loss: 557.1564 - val_loss: 642.6303\n",
      "Epoch 11/50\n",
      " - 0s - loss: 511.5780 - val_loss: 650.7661\n",
      "Epoch 12/50\n",
      " - 0s - loss: 453.8806 - val_loss: 705.3147\n",
      "Epoch 13/50\n",
      " - 0s - loss: 420.3296 - val_loss: 664.4283\n",
      "Epoch 14/50\n",
      " - 0s - loss: 374.0285 - val_loss: 606.8900\n",
      "Epoch 15/50\n",
      " - 0s - loss: 341.3788 - val_loss: 575.7337\n",
      "Epoch 16/50\n",
      " - 0s - loss: 300.5521 - val_loss: 535.7995\n",
      "Epoch 17/50\n",
      " - 0s - loss: 279.4158 - val_loss: 502.6968\n",
      "Epoch 18/50\n",
      " - 0s - loss: 260.7483 - val_loss: 478.8704\n",
      "Epoch 19/50\n",
      " - 0s - loss: 255.7343 - val_loss: 457.7172\n",
      "Epoch 20/50\n",
      " - 0s - loss: 240.0836 - val_loss: 435.5438\n",
      "Epoch 21/50\n",
      " - 0s - loss: 232.9286 - val_loss: 444.7635\n",
      "Epoch 22/50\n",
      " - 0s - loss: 227.8912 - val_loss: 414.4930\n",
      "Epoch 23/50\n",
      " - 0s - loss: 222.6315 - val_loss: 402.9723\n",
      "Epoch 24/50\n",
      " - 0s - loss: 215.9621 - val_loss: 387.9141\n",
      "Epoch 25/50\n",
      " - 0s - loss: 208.8483 - val_loss: 414.6425\n",
      "Epoch 26/50\n",
      " - 0s - loss: 212.8342 - val_loss: 363.6721\n",
      "Epoch 27/50\n",
      " - 0s - loss: 203.5622 - val_loss: 355.6741\n",
      "Epoch 28/50\n",
      " - 0s - loss: 197.2085 - val_loss: 334.8836\n",
      "Epoch 29/50\n",
      " - 0s - loss: 192.8249 - val_loss: 326.3936\n",
      "Epoch 30/50\n",
      " - 0s - loss: 188.5124 - val_loss: 313.6220\n",
      "Epoch 31/50\n",
      " - 0s - loss: 181.1327 - val_loss: 305.3174\n",
      "Epoch 32/50\n",
      " - 0s - loss: 179.9732 - val_loss: 288.5685\n",
      "Epoch 33/50\n",
      " - 0s - loss: 174.0793 - val_loss: 284.9643\n",
      "Epoch 34/50\n",
      " - 0s - loss: 172.8106 - val_loss: 272.1487\n",
      "Epoch 35/50\n",
      " - 0s - loss: 178.9838 - val_loss: 267.3423\n",
      "Epoch 36/50\n",
      " - 0s - loss: 166.4744 - val_loss: 277.8375\n",
      "Epoch 37/50\n",
      " - 0s - loss: 165.7950 - val_loss: 252.8904\n",
      "Epoch 38/50\n",
      " - 0s - loss: 160.2149 - val_loss: 245.9913\n",
      "Epoch 39/50\n",
      " - 0s - loss: 158.5691 - val_loss: 244.5580\n",
      "Epoch 40/50\n",
      " - 0s - loss: 155.8252 - val_loss: 232.3061\n",
      "Epoch 41/50\n",
      " - 0s - loss: 152.5519 - val_loss: 235.0402\n",
      "Epoch 42/50\n",
      " - 0s - loss: 153.3448 - val_loss: 229.0913\n",
      "Epoch 43/50\n",
      " - 0s - loss: 152.2877 - val_loss: 214.7095\n",
      "Epoch 44/50\n",
      " - 0s - loss: 147.8864 - val_loss: 214.7748\n",
      "Epoch 45/50\n",
      " - 0s - loss: 145.3329 - val_loss: 219.4946\n",
      "Epoch 46/50\n",
      " - 0s - loss: 143.9269 - val_loss: 205.1293\n",
      "Epoch 47/50\n",
      " - 0s - loss: 143.7424 - val_loss: 208.9694\n",
      "Epoch 48/50\n",
      " - 0s - loss: 142.5931 - val_loss: 199.6859\n",
      "Epoch 49/50\n",
      " - 0s - loss: 139.3269 - val_loss: 206.9078\n",
      "Epoch 50/50\n",
      " - 0s - loss: 138.1256 - val_loss: 200.9052\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 287783.7378 - val_loss: 224986.2205\n",
      "Epoch 2/50\n",
      " - 0s - loss: 177978.3640 - val_loss: 132294.3654\n",
      "Epoch 3/50\n",
      " - 0s - loss: 97651.9691 - val_loss: 69314.7086\n",
      "Epoch 4/50\n",
      " - 0s - loss: 47105.4230 - val_loss: 32594.3810\n",
      "Epoch 5/50\n",
      " - 0s - loss: 20668.1628 - val_loss: 14877.6651\n",
      "Epoch 6/50\n",
      " - 0s - loss: 9587.5872 - val_loss: 8147.6911\n",
      "Epoch 7/50\n",
      " - 0s - loss: 6076.0063 - val_loss: 6059.3842\n",
      "Epoch 8/50\n",
      " - 0s - loss: 5253.6650 - val_loss: 5433.9591\n",
      "Epoch 9/50\n",
      " - 0s - loss: 5052.9752 - val_loss: 5227.9942\n",
      "Epoch 10/50\n",
      " - 0s - loss: 4929.8744 - val_loss: 5126.3125\n",
      "Epoch 11/50\n",
      " - 0s - loss: 4835.1015 - val_loss: 5027.7972\n",
      "Epoch 12/50\n",
      " - 0s - loss: 4722.1774 - val_loss: 4941.4953\n",
      "Epoch 13/50\n",
      " - 0s - loss: 4617.8251 - val_loss: 4859.3385\n",
      "Epoch 14/50\n",
      " - 0s - loss: 4512.9645 - val_loss: 4767.3579\n",
      "Epoch 15/50\n",
      " - 0s - loss: 4418.0918 - val_loss: 4661.0666\n",
      "Epoch 16/50\n",
      " - 0s - loss: 4310.4725 - val_loss: 4567.2233\n",
      "Epoch 17/50\n",
      " - 0s - loss: 4208.7303 - val_loss: 4496.5914\n",
      "Epoch 18/50\n",
      " - 0s - loss: 4117.7129 - val_loss: 4393.6495\n",
      "Epoch 19/50\n",
      " - 0s - loss: 4016.1174 - val_loss: 4347.7129\n",
      "Epoch 20/50\n",
      " - 0s - loss: 3921.7399 - val_loss: 4238.3285\n",
      "Epoch 21/50\n",
      " - 0s - loss: 3843.3246 - val_loss: 4125.5509\n",
      "Epoch 22/50\n",
      " - 0s - loss: 3736.1339 - val_loss: 4087.4771\n",
      "Epoch 23/50\n",
      " - 0s - loss: 3651.8085 - val_loss: 4017.6537\n",
      "Epoch 24/50\n",
      " - 0s - loss: 3565.9729 - val_loss: 3904.0807\n",
      "Epoch 25/50\n",
      " - 0s - loss: 3485.6901 - val_loss: 3850.7849\n",
      "Epoch 26/50\n",
      " - 0s - loss: 3394.3988 - val_loss: 3738.1915\n",
      "Epoch 27/50\n",
      " - 0s - loss: 3318.0673 - val_loss: 3639.8497\n",
      "Epoch 28/50\n",
      " - 0s - loss: 3236.2088 - val_loss: 3594.1724\n",
      "Epoch 29/50\n",
      " - 0s - loss: 3162.7826 - val_loss: 3542.3181\n",
      "Epoch 30/50\n",
      " - 0s - loss: 3088.9357 - val_loss: 3452.2347\n",
      "Epoch 31/50\n",
      " - 0s - loss: 3017.9067 - val_loss: 3373.7859\n",
      "Epoch 32/50\n",
      " - 0s - loss: 2950.4524 - val_loss: 3301.6102\n",
      "Epoch 33/50\n",
      " - 0s - loss: 2877.7342 - val_loss: 3254.2157\n",
      "Epoch 34/50\n",
      " - 0s - loss: 2813.6244 - val_loss: 3178.3230\n",
      "Epoch 35/50\n",
      " - 0s - loss: 2749.2582 - val_loss: 3098.0504\n",
      "Epoch 36/50\n",
      " - 0s - loss: 2687.9895 - val_loss: 3052.6930\n",
      "Epoch 37/50\n",
      " - 0s - loss: 2626.1477 - val_loss: 2969.6281\n",
      "Epoch 38/50\n",
      " - 0s - loss: 2566.7255 - val_loss: 2920.6251\n",
      "Epoch 39/50\n",
      " - 0s - loss: 2505.9639 - val_loss: 2832.3475\n",
      "Epoch 40/50\n",
      " - 0s - loss: 2448.4255 - val_loss: 2777.1157\n",
      "Epoch 41/50\n",
      " - 0s - loss: 2391.9900 - val_loss: 2722.3135\n",
      "Epoch 42/50\n",
      " - 0s - loss: 2335.5799 - val_loss: 2675.6557\n",
      "Epoch 43/50\n",
      " - 0s - loss: 2282.8569 - val_loss: 2609.9364\n",
      "Epoch 44/50\n",
      " - 0s - loss: 2234.9920 - val_loss: 2531.5531\n",
      "Epoch 45/50\n",
      " - 0s - loss: 2175.1726 - val_loss: 2511.4830\n",
      "Epoch 46/50\n",
      " - 0s - loss: 2132.2821 - val_loss: 2451.3228\n",
      "Epoch 47/50\n",
      " - 0s - loss: 2074.9705 - val_loss: 2369.4615\n",
      "Epoch 48/50\n",
      " - 0s - loss: 2027.6725 - val_loss: 2316.0022\n",
      "Epoch 49/50\n",
      " - 0s - loss: 1981.6273 - val_loss: 2250.3447\n",
      "Epoch 50/50\n",
      " - 0s - loss: 1936.6706 - val_loss: 2222.7503\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 352728.4243 - val_loss: 252828.0844\n",
      "Epoch 2/50\n",
      " - 0s - loss: 196338.3141 - val_loss: 123325.0910\n",
      "Epoch 3/50\n",
      " - 0s - loss: 84547.5859 - val_loss: 45933.3729\n",
      "Epoch 4/50\n",
      " - 0s - loss: 27347.4869 - val_loss: 14446.1887\n",
      "Epoch 5/50\n",
      " - 0s - loss: 7777.3479 - val_loss: 10104.9327\n",
      "Epoch 6/50\n",
      " - 0s - loss: 5656.3543 - val_loss: 8670.5186\n",
      "Epoch 7/50\n",
      " - 0s - loss: 4805.4366 - val_loss: 7462.0617\n",
      "Epoch 8/50\n",
      " - 0s - loss: 4228.7623 - val_loss: 6603.2552\n",
      "Epoch 9/50\n",
      " - 0s - loss: 3698.0154 - val_loss: 5778.6083\n",
      "Epoch 10/50\n",
      " - 0s - loss: 3190.6286 - val_loss: 5015.7128\n",
      "Epoch 11/50\n",
      " - 0s - loss: 2663.7897 - val_loss: 4153.9034\n",
      "Epoch 12/50\n",
      " - 0s - loss: 2167.5732 - val_loss: 3450.9127\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1752.8280 - val_loss: 2902.0920\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1457.9880 - val_loss: 2456.7608\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1256.7439 - val_loss: 2126.9111\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1113.2969 - val_loss: 1897.4862\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1009.9281 - val_loss: 1726.4520\n",
      "Epoch 18/50\n",
      " - 0s - loss: 930.9600 - val_loss: 1599.2291\n",
      "Epoch 19/50\n",
      " - 0s - loss: 861.7396 - val_loss: 1481.8579\n",
      "Epoch 20/50\n",
      " - 0s - loss: 802.1570 - val_loss: 1389.2373\n",
      "Epoch 21/50\n",
      " - 0s - loss: 747.1808 - val_loss: 1296.8595\n",
      "Epoch 22/50\n",
      " - 0s - loss: 698.5313 - val_loss: 1214.5634\n",
      "Epoch 23/50\n",
      " - 0s - loss: 652.0484 - val_loss: 1142.0972\n",
      "Epoch 24/50\n",
      " - 0s - loss: 608.2464 - val_loss: 1070.5172\n",
      "Epoch 25/50\n",
      " - 0s - loss: 567.4580 - val_loss: 1006.6154\n",
      "Epoch 26/50\n",
      " - 0s - loss: 531.8799 - val_loss: 953.6905\n",
      "Epoch 27/50\n",
      " - 0s - loss: 498.8743 - val_loss: 896.9595\n",
      "Epoch 28/50\n",
      " - 0s - loss: 468.0686 - val_loss: 851.8765\n",
      "Epoch 29/50\n",
      " - 0s - loss: 441.6909 - val_loss: 808.8344\n",
      "Epoch 30/50\n",
      " - 0s - loss: 415.9778 - val_loss: 768.3428\n",
      "Epoch 31/50\n",
      " - 0s - loss: 394.1553 - val_loss: 731.0531\n",
      "Epoch 32/50\n",
      " - 0s - loss: 373.0282 - val_loss: 699.2277\n",
      "Epoch 33/50\n",
      " - 0s - loss: 354.4724 - val_loss: 665.5754\n",
      "Epoch 34/50\n",
      " - 0s - loss: 336.6236 - val_loss: 633.1959\n",
      "Epoch 35/50\n",
      " - 0s - loss: 322.0862 - val_loss: 603.9250\n",
      "Epoch 36/50\n",
      " - 0s - loss: 307.4059 - val_loss: 577.9646\n",
      "Epoch 37/50\n",
      " - 0s - loss: 295.0325 - val_loss: 553.1823\n",
      "Epoch 38/50\n",
      " - 0s - loss: 282.9126 - val_loss: 536.1623\n",
      "Epoch 39/50\n",
      " - 0s - loss: 271.1416 - val_loss: 513.0783\n",
      "Epoch 40/50\n",
      " - 0s - loss: 259.4026 - val_loss: 498.8191\n",
      "Epoch 41/50\n",
      " - 0s - loss: 248.6098 - val_loss: 478.0427\n",
      "Epoch 42/50\n",
      " - 0s - loss: 239.0231 - val_loss: 463.2355\n",
      "Epoch 43/50\n",
      " - 0s - loss: 230.3683 - val_loss: 441.0430\n",
      "Epoch 44/50\n",
      " - 0s - loss: 223.0699 - val_loss: 428.8233\n",
      "Epoch 45/50\n",
      " - 0s - loss: 216.9810 - val_loss: 415.2912\n",
      "Epoch 46/50\n",
      " - 0s - loss: 210.7347 - val_loss: 405.1768\n",
      "Epoch 47/50\n",
      " - 0s - loss: 205.4965 - val_loss: 397.2482\n",
      "Epoch 48/50\n",
      " - 0s - loss: 201.7354 - val_loss: 386.3996\n",
      "Epoch 49/50\n",
      " - 0s - loss: 197.7415 - val_loss: 379.1519\n",
      "Epoch 50/50\n",
      " - 0s - loss: 193.6766 - val_loss: 371.3151\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 16764.1826 - val_loss: 3645.1917\n",
      "Epoch 2/50\n",
      " - 0s - loss: 6923.5405 - val_loss: 3333.0266\n",
      "Epoch 3/50\n",
      " - 0s - loss: 5710.6151 - val_loss: 3006.5872\n",
      "Epoch 4/50\n",
      " - 0s - loss: 5065.3335 - val_loss: 2768.9255\n",
      "Epoch 5/50\n",
      " - 0s - loss: 4475.0347 - val_loss: 2571.5666\n",
      "Epoch 6/50\n",
      " - 0s - loss: 3987.7570 - val_loss: 2416.1998\n",
      "Epoch 7/50\n",
      " - 0s - loss: 3560.7457 - val_loss: 2265.8078\n",
      "Epoch 8/50\n",
      " - 0s - loss: 3215.3990 - val_loss: 2151.0552\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2903.7185 - val_loss: 2063.4274\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2641.2934 - val_loss: 1935.6734\n",
      "Epoch 11/50\n",
      " - 0s - loss: 2405.5500 - val_loss: 1820.2069\n",
      "Epoch 12/50\n",
      " - 0s - loss: 2188.0731 - val_loss: 1699.0981\n",
      "Epoch 13/50\n",
      " - 0s - loss: 2001.6456 - val_loss: 1599.1118\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1826.0159 - val_loss: 1504.3780\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1665.0438 - val_loss: 1422.4665\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1539.4434 - val_loss: 1342.9000\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1412.6195 - val_loss: 1284.1688\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1299.8353 - val_loss: 1217.1929\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1193.1589 - val_loss: 1159.6960\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1101.0817 - val_loss: 1112.7079\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1018.6800 - val_loss: 1034.6483\n",
      "Epoch 22/50\n",
      " - 0s - loss: 939.1856 - val_loss: 985.8122\n",
      "Epoch 23/50\n",
      " - 0s - loss: 863.9933 - val_loss: 933.3933\n",
      "Epoch 24/50\n",
      " - 0s - loss: 796.9188 - val_loss: 865.2765\n",
      "Epoch 25/50\n",
      " - 0s - loss: 744.5904 - val_loss: 815.7573\n",
      "Epoch 26/50\n",
      " - 0s - loss: 696.0786 - val_loss: 777.4598\n",
      "Epoch 27/50\n",
      " - 0s - loss: 630.1530 - val_loss: 710.9862\n",
      "Epoch 28/50\n",
      " - 0s - loss: 577.9400 - val_loss: 682.7298\n",
      "Epoch 29/50\n",
      " - 0s - loss: 518.5839 - val_loss: 620.3969\n",
      "Epoch 30/50\n",
      " - 0s - loss: 465.8785 - val_loss: 573.1118\n",
      "Epoch 31/50\n",
      " - 0s - loss: 426.2662 - val_loss: 543.9949\n",
      "Epoch 32/50\n",
      " - 0s - loss: 389.5987 - val_loss: 550.5653\n",
      "Epoch 33/50\n",
      " - 0s - loss: 368.3653 - val_loss: 501.6836\n",
      "Epoch 34/50\n",
      " - 0s - loss: 330.7986 - val_loss: 467.7225\n",
      "Epoch 35/50\n",
      " - 0s - loss: 313.0801 - val_loss: 442.7216\n",
      "Epoch 36/50\n",
      " - 0s - loss: 288.2578 - val_loss: 425.5834\n",
      "Epoch 37/50\n",
      " - 0s - loss: 265.2628 - val_loss: 394.4695\n",
      "Epoch 38/50\n",
      " - 0s - loss: 249.2422 - val_loss: 374.5388\n",
      "Epoch 39/50\n",
      " - 0s - loss: 236.9781 - val_loss: 353.1402\n",
      "Epoch 40/50\n",
      " - 0s - loss: 224.8480 - val_loss: 347.8910\n",
      "Epoch 41/50\n",
      " - 0s - loss: 213.6738 - val_loss: 331.2083\n",
      "Epoch 42/50\n",
      " - 0s - loss: 202.9017 - val_loss: 322.8823\n",
      "Epoch 43/50\n",
      " - 0s - loss: 194.6460 - val_loss: 297.8934\n",
      "Epoch 44/50\n",
      " - 0s - loss: 187.6610 - val_loss: 287.4021\n",
      "Epoch 45/50\n",
      " - 0s - loss: 184.2065 - val_loss: 271.9510\n",
      "Epoch 46/50\n",
      " - 0s - loss: 178.8125 - val_loss: 265.5684\n",
      "Epoch 47/50\n",
      " - 0s - loss: 171.8435 - val_loss: 258.9991\n",
      "Epoch 48/50\n",
      " - 0s - loss: 168.9024 - val_loss: 238.5567\n",
      "Epoch 49/50\n",
      " - 0s - loss: 164.0998 - val_loss: 231.5714\n",
      "Epoch 50/50\n",
      " - 0s - loss: 161.4015 - val_loss: 222.4747\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 1677.4838 - val_loss: 1284.9958\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1184.2822 - val_loss: 980.4659\n",
      "Epoch 3/50\n",
      " - 0s - loss: 867.3006 - val_loss: 850.8626\n",
      "Epoch 4/50\n",
      " - 0s - loss: 665.9192 - val_loss: 795.5111\n",
      "Epoch 5/50\n",
      " - 0s - loss: 538.1302 - val_loss: 689.2657\n",
      "Epoch 6/50\n",
      " - 0s - loss: 468.2602 - val_loss: 608.2437\n",
      "Epoch 7/50\n",
      " - 0s - loss: 401.5255 - val_loss: 514.8340\n",
      "Epoch 8/50\n",
      " - 0s - loss: 349.3912 - val_loss: 447.8452\n",
      "Epoch 9/50\n",
      " - 0s - loss: 307.6130 - val_loss: 333.6016\n",
      "Epoch 10/50\n",
      " - 0s - loss: 268.3727 - val_loss: 286.5043\n",
      "Epoch 11/50\n",
      " - 0s - loss: 242.0291 - val_loss: 240.8057\n",
      "Epoch 12/50\n",
      " - 0s - loss: 228.9995 - val_loss: 225.0180\n",
      "Epoch 13/50\n",
      " - 0s - loss: 214.8434 - val_loss: 183.3022\n",
      "Epoch 14/50\n",
      " - 0s - loss: 206.3540 - val_loss: 205.6013\n",
      "Epoch 15/50\n",
      " - 0s - loss: 198.8239 - val_loss: 189.8783\n",
      "Epoch 16/50\n",
      " - 0s - loss: 195.6472 - val_loss: 138.9980\n",
      "Epoch 17/50\n",
      " - 0s - loss: 183.0043 - val_loss: 135.6306\n",
      "Epoch 18/50\n",
      " - 0s - loss: 186.1473 - val_loss: 162.7244\n",
      "Epoch 19/50\n",
      " - 0s - loss: 176.0479 - val_loss: 114.7702\n",
      "Epoch 20/50\n",
      " - 0s - loss: 173.3206 - val_loss: 115.1824\n",
      "Epoch 21/50\n",
      " - 0s - loss: 170.3191 - val_loss: 128.3002\n",
      "Epoch 22/50\n",
      " - 0s - loss: 164.8675 - val_loss: 108.0159\n",
      "Epoch 23/50\n",
      " - 0s - loss: 165.2759 - val_loss: 103.3719\n",
      "Epoch 24/50\n",
      " - 0s - loss: 162.7530 - val_loss: 90.9621\n",
      "Epoch 25/50\n",
      " - 0s - loss: 155.6795 - val_loss: 82.2820\n",
      "Epoch 26/50\n",
      " - 0s - loss: 152.9279 - val_loss: 93.1236\n",
      "Epoch 27/50\n",
      " - 0s - loss: 151.1437 - val_loss: 88.4477\n",
      "Epoch 28/50\n",
      " - 0s - loss: 147.5212 - val_loss: 85.2407\n",
      "Epoch 29/50\n",
      " - 0s - loss: 148.3101 - val_loss: 78.5765\n",
      "Epoch 30/50\n",
      " - 0s - loss: 143.7022 - val_loss: 117.1995\n",
      "Epoch 31/50\n",
      " - 0s - loss: 145.8304 - val_loss: 85.8353\n",
      "Epoch 32/50\n",
      " - 0s - loss: 143.8441 - val_loss: 77.8163\n",
      "Epoch 33/50\n",
      " - 0s - loss: 144.7548 - val_loss: 77.9682\n",
      "Epoch 34/50\n",
      " - 0s - loss: 139.0292 - val_loss: 72.9883\n",
      "Epoch 35/50\n",
      " - 0s - loss: 137.4846 - val_loss: 70.8192\n",
      "Epoch 36/50\n",
      " - 0s - loss: 139.7158 - val_loss: 71.8166\n",
      "Epoch 37/50\n",
      " - 0s - loss: 143.1715 - val_loss: 70.7062\n",
      "Epoch 38/50\n",
      " - 0s - loss: 136.9070 - val_loss: 77.4925\n",
      "Epoch 39/50\n",
      " - 0s - loss: 135.6782 - val_loss: 77.3732\n",
      "Epoch 40/50\n",
      " - 0s - loss: 133.6452 - val_loss: 70.2467\n",
      "Epoch 41/50\n",
      " - 0s - loss: 132.7347 - val_loss: 68.0038\n",
      "Epoch 42/50\n",
      " - 0s - loss: 131.3875 - val_loss: 72.3576\n",
      "Epoch 43/50\n",
      " - 0s - loss: 133.6603 - val_loss: 75.5801\n",
      "Epoch 44/50\n",
      " - 0s - loss: 129.3496 - val_loss: 74.0064\n",
      "Epoch 45/50\n",
      " - 0s - loss: 130.2224 - val_loss: 70.4444\n",
      "Epoch 46/50\n",
      " - 0s - loss: 129.3061 - val_loss: 68.4091\n",
      "Epoch 47/50\n",
      " - 0s - loss: 130.4021 - val_loss: 69.7472\n",
      "Epoch 48/50\n",
      " - 0s - loss: 135.7776 - val_loss: 75.1471\n",
      "Epoch 49/50\n",
      " - 0s - loss: 128.6059 - val_loss: 72.7236\n",
      "Epoch 50/50\n",
      " - 0s - loss: 129.3119 - val_loss: 81.0125\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 1246.4588 - val_loss: 441.4465\n",
      "Epoch 2/50\n",
      " - 0s - loss: 562.2619 - val_loss: 326.0384\n",
      "Epoch 3/50\n",
      " - 0s - loss: 524.2133 - val_loss: 313.5867\n",
      "Epoch 4/50\n",
      " - 0s - loss: 502.2648 - val_loss: 309.6429\n",
      "Epoch 5/50\n",
      " - 0s - loss: 483.7744 - val_loss: 291.8442\n",
      "Epoch 6/50\n",
      " - 0s - loss: 467.3746 - val_loss: 287.5024\n",
      "Epoch 7/50\n",
      " - 0s - loss: 454.6666 - val_loss: 276.9189\n",
      "Epoch 8/50\n",
      " - 0s - loss: 442.8184 - val_loss: 269.7317\n",
      "Epoch 9/50\n",
      " - 0s - loss: 432.6761 - val_loss: 261.8406\n",
      "Epoch 10/50\n",
      " - 0s - loss: 423.5949 - val_loss: 251.9168\n",
      "Epoch 11/50\n",
      " - 0s - loss: 414.8030 - val_loss: 249.0354\n",
      "Epoch 12/50\n",
      " - 0s - loss: 406.2677 - val_loss: 245.2670\n",
      "Epoch 13/50\n",
      " - 0s - loss: 399.9060 - val_loss: 236.9173\n",
      "Epoch 14/50\n",
      " - 0s - loss: 392.2573 - val_loss: 236.5359\n",
      "Epoch 15/50\n",
      " - 0s - loss: 387.9868 - val_loss: 231.9003\n",
      "Epoch 16/50\n",
      " - 0s - loss: 382.0447 - val_loss: 227.5098\n",
      "Epoch 17/50\n",
      " - 0s - loss: 375.5975 - val_loss: 222.5485\n",
      "Epoch 18/50\n",
      " - 0s - loss: 370.5184 - val_loss: 222.9108\n",
      "Epoch 19/50\n",
      " - 0s - loss: 365.9559 - val_loss: 218.1889\n",
      "Epoch 20/50\n",
      " - 0s - loss: 361.6765 - val_loss: 217.5040\n",
      "Epoch 21/50\n",
      " - 0s - loss: 356.5284 - val_loss: 210.5923\n",
      "Epoch 22/50\n",
      " - 0s - loss: 352.4358 - val_loss: 207.1210\n",
      "Epoch 23/50\n",
      " - 0s - loss: 347.5080 - val_loss: 204.7878\n",
      "Epoch 24/50\n",
      " - 0s - loss: 343.1062 - val_loss: 203.8495\n",
      "Epoch 25/50\n",
      " - 0s - loss: 337.8466 - val_loss: 201.0196\n",
      "Epoch 26/50\n",
      " - 0s - loss: 332.8153 - val_loss: 198.4952\n",
      "Epoch 27/50\n",
      " - 0s - loss: 327.0316 - val_loss: 193.6450\n",
      "Epoch 28/50\n",
      " - 0s - loss: 320.4870 - val_loss: 189.3258\n",
      "Epoch 29/50\n",
      " - 0s - loss: 314.2790 - val_loss: 182.8489\n",
      "Epoch 30/50\n",
      " - 0s - loss: 306.1583 - val_loss: 183.1120\n",
      "Epoch 31/50\n",
      " - 0s - loss: 298.7532 - val_loss: 179.4502\n",
      "Epoch 32/50\n",
      " - 0s - loss: 290.9577 - val_loss: 168.5276\n",
      "Epoch 33/50\n",
      " - 0s - loss: 281.1998 - val_loss: 171.6081\n",
      "Epoch 34/50\n",
      " - 0s - loss: 272.4609 - val_loss: 162.4547\n",
      "Epoch 35/50\n",
      " - 0s - loss: 261.8516 - val_loss: 155.9094\n",
      "Epoch 36/50\n",
      " - 0s - loss: 252.4404 - val_loss: 150.8985\n",
      "Epoch 37/50\n",
      " - 0s - loss: 242.8518 - val_loss: 141.9176\n",
      "Epoch 38/50\n",
      " - 0s - loss: 235.0599 - val_loss: 138.4358\n",
      "Epoch 39/50\n",
      " - 0s - loss: 223.9016 - val_loss: 138.1687\n",
      "Epoch 40/50\n",
      " - 0s - loss: 215.5565 - val_loss: 126.0186\n",
      "Epoch 41/50\n",
      " - 0s - loss: 206.2854 - val_loss: 129.0271\n",
      "Epoch 42/50\n",
      " - 0s - loss: 197.8688 - val_loss: 119.9957\n",
      "Epoch 43/50\n",
      " - 0s - loss: 191.2010 - val_loss: 117.4876\n",
      "Epoch 44/50\n",
      " - 0s - loss: 184.0751 - val_loss: 115.5075\n",
      "Epoch 45/50\n",
      " - 0s - loss: 178.2613 - val_loss: 110.7772\n",
      "Epoch 46/50\n",
      " - 0s - loss: 174.4592 - val_loss: 104.8101\n",
      "Epoch 47/50\n",
      " - 0s - loss: 169.9503 - val_loss: 100.3119\n",
      "Epoch 48/50\n",
      " - 0s - loss: 163.6613 - val_loss: 99.8505\n",
      "Epoch 49/50\n",
      " - 0s - loss: 159.0542 - val_loss: 100.7386\n",
      "Epoch 50/50\n",
      " - 0s - loss: 155.3564 - val_loss: 94.4580\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 591041.6826 - val_loss: 452988.2870\n",
      "Epoch 2/50\n",
      " - 0s - loss: 379033.3194 - val_loss: 263648.4576\n",
      "Epoch 3/50\n",
      " - 0s - loss: 207133.9812 - val_loss: 122767.1808\n",
      "Epoch 4/50\n",
      " - 0s - loss: 91383.6231 - val_loss: 45122.4005\n",
      "Epoch 5/50\n",
      " - 0s - loss: 35382.4678 - val_loss: 16191.6977\n",
      "Epoch 6/50\n",
      " - 0s - loss: 17247.5740 - val_loss: 8870.9879\n",
      "Epoch 7/50\n",
      " - 0s - loss: 12977.3375 - val_loss: 7825.3675\n",
      "Epoch 8/50\n",
      " - 0s - loss: 12133.9067 - val_loss: 7644.1826\n",
      "Epoch 9/50\n",
      " - 0s - loss: 11678.3699 - val_loss: 7478.1408\n",
      "Epoch 10/50\n",
      " - 0s - loss: 11262.5994 - val_loss: 7309.9138\n",
      "Epoch 11/50\n",
      " - 0s - loss: 10852.4192 - val_loss: 7159.5119\n",
      "Epoch 12/50\n",
      " - 0s - loss: 10450.5260 - val_loss: 6985.4870\n",
      "Epoch 13/50\n",
      " - 0s - loss: 10072.3943 - val_loss: 6852.3398\n",
      "Epoch 14/50\n",
      " - 0s - loss: 9706.8187 - val_loss: 6673.4852\n",
      "Epoch 15/50\n",
      " - 0s - loss: 9308.4448 - val_loss: 6554.8719\n",
      "Epoch 16/50\n",
      " - 0s - loss: 8957.9227 - val_loss: 6399.5081\n",
      "Epoch 17/50\n",
      " - 0s - loss: 8627.2314 - val_loss: 6305.3504\n",
      "Epoch 18/50\n",
      " - 0s - loss: 8290.3742 - val_loss: 6146.0715\n",
      "Epoch 19/50\n",
      " - 0s - loss: 7988.5366 - val_loss: 6043.8412\n",
      "Epoch 20/50\n",
      " - 0s - loss: 7658.8517 - val_loss: 5924.0602\n",
      "Epoch 21/50\n",
      " - 0s - loss: 7361.6411 - val_loss: 5817.7183\n",
      "Epoch 22/50\n",
      " - 0s - loss: 7087.3279 - val_loss: 5715.8740\n",
      "Epoch 23/50\n",
      " - 0s - loss: 6829.3526 - val_loss: 5608.3922\n",
      "Epoch 24/50\n",
      " - 0s - loss: 6565.5587 - val_loss: 5532.5344\n",
      "Epoch 25/50\n",
      " - 0s - loss: 6328.6191 - val_loss: 5412.5818\n",
      "Epoch 26/50\n",
      " - 0s - loss: 6097.3047 - val_loss: 5334.1383\n",
      "Epoch 27/50\n",
      " - 0s - loss: 5870.5118 - val_loss: 5267.0737\n",
      "Epoch 28/50\n",
      " - 0s - loss: 5667.0663 - val_loss: 5168.1513\n",
      "Epoch 29/50\n",
      " - 0s - loss: 5461.6842 - val_loss: 5115.5249\n",
      "Epoch 30/50\n",
      " - 0s - loss: 5266.2549 - val_loss: 5029.5631\n",
      "Epoch 31/50\n",
      " - 0s - loss: 5081.0118 - val_loss: 4944.7564\n",
      "Epoch 32/50\n",
      " - 0s - loss: 4910.9361 - val_loss: 4907.7002\n",
      "Epoch 33/50\n",
      " - 0s - loss: 4735.8016 - val_loss: 4820.6962\n",
      "Epoch 34/50\n",
      " - 0s - loss: 4573.1170 - val_loss: 4740.8446\n",
      "Epoch 35/50\n",
      " - 0s - loss: 4418.9232 - val_loss: 4681.4703\n",
      "Epoch 36/50\n",
      " - 0s - loss: 4269.8622 - val_loss: 4625.3081\n",
      "Epoch 37/50\n",
      " - 0s - loss: 4122.5891 - val_loss: 4590.0311\n",
      "Epoch 38/50\n",
      " - 0s - loss: 3984.9327 - val_loss: 4489.1198\n",
      "Epoch 39/50\n",
      " - 0s - loss: 3852.3683 - val_loss: 4443.0562\n",
      "Epoch 40/50\n",
      " - 0s - loss: 3725.4740 - val_loss: 4440.6199\n",
      "Epoch 41/50\n",
      " - 0s - loss: 3588.3949 - val_loss: 4332.0523\n",
      "Epoch 42/50\n",
      " - 0s - loss: 3472.0903 - val_loss: 4284.1343\n",
      "Epoch 43/50\n",
      " - 0s - loss: 3353.5361 - val_loss: 4233.4054\n",
      "Epoch 44/50\n",
      " - 0s - loss: 3239.9352 - val_loss: 4202.9726\n",
      "Epoch 45/50\n",
      " - 0s - loss: 3131.7697 - val_loss: 4148.1573\n",
      "Epoch 46/50\n",
      " - 0s - loss: 3020.4771 - val_loss: 4081.5606\n",
      "Epoch 47/50\n",
      " - 0s - loss: 2926.1473 - val_loss: 4036.6334\n",
      "Epoch 48/50\n",
      " - 0s - loss: 2818.0475 - val_loss: 4012.3104\n",
      "Epoch 49/50\n",
      " - 0s - loss: 2724.5298 - val_loss: 3934.4792\n",
      "Epoch 50/50\n",
      " - 0s - loss: 2623.4785 - val_loss: 3890.2234\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 2227.2939 - val_loss: 1103.7489\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1332.9355 - val_loss: 726.5871\n",
      "Epoch 3/50\n",
      " - 0s - loss: 980.4329 - val_loss: 551.4855\n",
      "Epoch 4/50\n",
      " - 0s - loss: 693.2449 - val_loss: 477.9896\n",
      "Epoch 5/50\n",
      " - 0s - loss: 494.0869 - val_loss: 424.7982\n",
      "Epoch 6/50\n",
      " - 0s - loss: 399.2487 - val_loss: 390.4620\n",
      "Epoch 7/50\n",
      " - 0s - loss: 336.2576 - val_loss: 354.1480\n",
      "Epoch 8/50\n",
      " - 0s - loss: 296.1230 - val_loss: 322.8389\n",
      "Epoch 9/50\n",
      " - 0s - loss: 261.4196 - val_loss: 293.8325\n",
      "Epoch 10/50\n",
      " - 0s - loss: 238.9008 - val_loss: 267.5009\n",
      "Epoch 11/50\n",
      " - 0s - loss: 220.1914 - val_loss: 242.4338\n",
      "Epoch 12/50\n",
      " - 0s - loss: 201.1870 - val_loss: 231.8313\n",
      "Epoch 13/50\n",
      " - 0s - loss: 192.9971 - val_loss: 207.8074\n",
      "Epoch 14/50\n",
      " - 0s - loss: 181.4682 - val_loss: 191.4373\n",
      "Epoch 15/50\n",
      " - 0s - loss: 168.8734 - val_loss: 179.6660\n",
      "Epoch 16/50\n",
      " - 0s - loss: 162.8768 - val_loss: 172.5377\n",
      "Epoch 17/50\n",
      " - 0s - loss: 158.6667 - val_loss: 157.2694\n",
      "Epoch 18/50\n",
      " - 0s - loss: 153.7879 - val_loss: 148.3668\n",
      "Epoch 19/50\n",
      " - 0s - loss: 151.1509 - val_loss: 142.3905\n",
      "Epoch 20/50\n",
      " - 0s - loss: 148.2182 - val_loss: 138.2593\n",
      "Epoch 21/50\n",
      " - 0s - loss: 142.5495 - val_loss: 142.6046\n",
      "Epoch 22/50\n",
      " - 0s - loss: 141.8773 - val_loss: 133.1521\n",
      "Epoch 23/50\n",
      " - 0s - loss: 139.4393 - val_loss: 131.7906\n",
      "Epoch 24/50\n",
      " - 0s - loss: 137.7541 - val_loss: 126.3077\n",
      "Epoch 25/50\n",
      " - 0s - loss: 136.9903 - val_loss: 117.2286\n",
      "Epoch 26/50\n",
      " - 0s - loss: 133.3290 - val_loss: 115.4993\n",
      "Epoch 27/50\n",
      " - 0s - loss: 131.7817 - val_loss: 114.6152\n",
      "Epoch 28/50\n",
      " - 0s - loss: 129.5734 - val_loss: 110.9973\n",
      "Epoch 29/50\n",
      " - 0s - loss: 130.0768 - val_loss: 112.1467\n",
      "Epoch 30/50\n",
      " - 0s - loss: 129.2791 - val_loss: 107.8340\n",
      "Epoch 31/50\n",
      " - 0s - loss: 130.1614 - val_loss: 110.6403\n",
      "Epoch 32/50\n",
      " - 0s - loss: 130.8549 - val_loss: 112.1311\n",
      "Epoch 33/50\n",
      " - 0s - loss: 128.0443 - val_loss: 104.5977\n",
      "Epoch 34/50\n",
      " - 0s - loss: 127.3168 - val_loss: 105.1351\n",
      "Epoch 35/50\n",
      " - 0s - loss: 126.0424 - val_loss: 103.8574\n",
      "Epoch 36/50\n",
      " - 0s - loss: 125.5772 - val_loss: 101.8283\n",
      "Epoch 37/50\n",
      " - 0s - loss: 124.6939 - val_loss: 106.9901\n",
      "Epoch 38/50\n",
      " - 0s - loss: 127.1860 - val_loss: 101.9123\n",
      "Epoch 39/50\n",
      " - 0s - loss: 127.2231 - val_loss: 101.0983\n",
      "Epoch 40/50\n",
      " - 0s - loss: 123.4133 - val_loss: 101.1468\n",
      "Epoch 41/50\n",
      " - 0s - loss: 123.3801 - val_loss: 108.3929\n",
      "Epoch 42/50\n",
      " - 0s - loss: 127.1891 - val_loss: 98.3770\n",
      "Epoch 43/50\n",
      " - 0s - loss: 123.9335 - val_loss: 104.3438\n",
      "Epoch 44/50\n",
      " - 0s - loss: 125.2024 - val_loss: 103.9856\n",
      "Epoch 45/50\n",
      " - 0s - loss: 124.0417 - val_loss: 99.9351\n",
      "Epoch 46/50\n",
      " - 0s - loss: 122.6224 - val_loss: 97.6891\n",
      "Epoch 47/50\n",
      " - 0s - loss: 126.4911 - val_loss: 95.6103\n",
      "Epoch 48/50\n",
      " - 0s - loss: 122.2781 - val_loss: 99.0421\n",
      "Epoch 49/50\n",
      " - 0s - loss: 122.1746 - val_loss: 99.9877\n",
      "Epoch 50/50\n",
      " - 0s - loss: 122.1893 - val_loss: 102.5211\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 2392.4050 - val_loss: 655.7851\n",
      "Epoch 2/50\n",
      " - 0s - loss: 939.1689 - val_loss: 481.3650\n",
      "Epoch 3/50\n",
      " - 0s - loss: 694.1623 - val_loss: 467.0845\n",
      "Epoch 4/50\n",
      " - 0s - loss: 617.0416 - val_loss: 439.5922\n",
      "Epoch 5/50\n",
      " - 0s - loss: 563.8719 - val_loss: 417.8079\n",
      "Epoch 6/50\n",
      " - 0s - loss: 520.8651 - val_loss: 396.2228\n",
      "Epoch 7/50\n",
      " - 0s - loss: 476.6251 - val_loss: 381.0325\n",
      "Epoch 8/50\n",
      " - 0s - loss: 444.2914 - val_loss: 371.4231\n",
      "Epoch 9/50\n",
      " - 0s - loss: 413.7518 - val_loss: 370.9047\n",
      "Epoch 10/50\n",
      " - 0s - loss: 392.6820 - val_loss: 348.4097\n",
      "Epoch 11/50\n",
      " - 0s - loss: 357.9060 - val_loss: 333.7879\n",
      "Epoch 12/50\n",
      " - 0s - loss: 335.6060 - val_loss: 318.6965\n",
      "Epoch 13/50\n",
      " - 0s - loss: 312.6688 - val_loss: 299.1340\n",
      "Epoch 14/50\n",
      " - 0s - loss: 291.9068 - val_loss: 280.1561\n",
      "Epoch 15/50\n",
      " - 0s - loss: 274.2130 - val_loss: 266.0864\n",
      "Epoch 16/50\n",
      " - 0s - loss: 259.5518 - val_loss: 250.0772\n",
      "Epoch 17/50\n",
      " - 0s - loss: 245.6121 - val_loss: 223.7744\n",
      "Epoch 18/50\n",
      " - 0s - loss: 232.7680 - val_loss: 212.3682\n",
      "Epoch 19/50\n",
      " - 0s - loss: 223.4322 - val_loss: 196.0223\n",
      "Epoch 20/50\n",
      " - 0s - loss: 214.0508 - val_loss: 178.1349\n",
      "Epoch 21/50\n",
      " - 0s - loss: 204.4044 - val_loss: 182.7698\n",
      "Epoch 22/50\n",
      " - 0s - loss: 199.8379 - val_loss: 177.6505\n",
      "Epoch 23/50\n",
      " - 0s - loss: 192.1220 - val_loss: 149.4544\n",
      "Epoch 24/50\n",
      " - 0s - loss: 185.5136 - val_loss: 142.8129\n",
      "Epoch 25/50\n",
      " - 0s - loss: 181.6330 - val_loss: 136.4813\n",
      "Epoch 26/50\n",
      " - 0s - loss: 176.3517 - val_loss: 133.4559\n",
      "Epoch 27/50\n",
      " - 0s - loss: 172.6551 - val_loss: 123.1267\n",
      "Epoch 28/50\n",
      " - 0s - loss: 171.6090 - val_loss: 115.4768\n",
      "Epoch 29/50\n",
      " - 0s - loss: 167.9448 - val_loss: 107.2052\n",
      "Epoch 30/50\n",
      " - 0s - loss: 161.7410 - val_loss: 99.4929\n",
      "Epoch 31/50\n",
      " - 0s - loss: 153.5684 - val_loss: 94.3598\n",
      "Epoch 32/50\n",
      " - 0s - loss: 145.6708 - val_loss: 96.7857\n",
      "Epoch 33/50\n",
      " - 0s - loss: 140.2691 - val_loss: 93.3815\n",
      "Epoch 34/50\n",
      " - 0s - loss: 140.2604 - val_loss: 91.2151\n",
      "Epoch 35/50\n",
      " - 0s - loss: 138.0854 - val_loss: 92.7673\n",
      "Epoch 36/50\n",
      " - 0s - loss: 134.5840 - val_loss: 93.9640\n",
      "Epoch 37/50\n",
      " - 0s - loss: 137.5468 - val_loss: 84.5668\n",
      "Epoch 38/50\n",
      " - 0s - loss: 132.0087 - val_loss: 86.2157\n",
      "Epoch 39/50\n",
      " - 0s - loss: 129.3546 - val_loss: 86.2419\n",
      "Epoch 40/50\n",
      " - 0s - loss: 124.8761 - val_loss: 97.4354\n",
      "Epoch 41/50\n",
      " - 0s - loss: 130.1528 - val_loss: 89.6933\n",
      "Epoch 42/50\n",
      " - 0s - loss: 128.1584 - val_loss: 83.8968\n",
      "Epoch 43/50\n",
      " - 0s - loss: 124.2179 - val_loss: 84.6837\n",
      "Epoch 44/50\n",
      " - 0s - loss: 122.2147 - val_loss: 87.0962\n",
      "Epoch 45/50\n",
      " - 0s - loss: 119.3411 - val_loss: 88.4967\n",
      "Epoch 46/50\n",
      " - 0s - loss: 120.7664 - val_loss: 85.1783\n",
      "Epoch 47/50\n",
      " - 0s - loss: 117.2501 - val_loss: 86.4429\n",
      "Epoch 48/50\n",
      " - 0s - loss: 117.5483 - val_loss: 92.7022\n",
      "Epoch 49/50\n",
      " - 0s - loss: 115.8088 - val_loss: 87.9871\n",
      "Epoch 50/50\n",
      " - 0s - loss: 114.8046 - val_loss: 91.0776\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 7633.8978 - val_loss: 1682.2786\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1139.1151 - val_loss: 508.5019\n",
      "Epoch 3/50\n",
      " - 0s - loss: 588.5191 - val_loss: 583.3855\n",
      "Epoch 4/50\n",
      " - 0s - loss: 536.1943 - val_loss: 467.5128\n",
      "Epoch 5/50\n",
      " - 0s - loss: 498.1692 - val_loss: 441.3269\n",
      "Epoch 6/50\n",
      " - 0s - loss: 463.4393 - val_loss: 428.3629\n",
      "Epoch 7/50\n",
      " - 0s - loss: 429.0659 - val_loss: 397.9954\n",
      "Epoch 8/50\n",
      " - 0s - loss: 396.9347 - val_loss: 367.5917\n",
      "Epoch 9/50\n",
      " - 0s - loss: 368.2643 - val_loss: 356.5970\n",
      "Epoch 10/50\n",
      " - 0s - loss: 344.7036 - val_loss: 332.0444\n",
      "Epoch 11/50\n",
      " - 0s - loss: 322.4728 - val_loss: 305.1378\n",
      "Epoch 12/50\n",
      " - 0s - loss: 304.2580 - val_loss: 308.2685\n",
      "Epoch 13/50\n",
      " - 0s - loss: 287.6658 - val_loss: 275.2308\n",
      "Epoch 14/50\n",
      " - 0s - loss: 273.4464 - val_loss: 283.0831\n",
      "Epoch 15/50\n",
      " - 0s - loss: 261.2744 - val_loss: 258.7383\n",
      "Epoch 16/50\n",
      " - 0s - loss: 251.1124 - val_loss: 246.1512\n",
      "Epoch 17/50\n",
      " - 0s - loss: 240.2680 - val_loss: 250.7416\n",
      "Epoch 18/50\n",
      " - 0s - loss: 230.2120 - val_loss: 246.3786\n",
      "Epoch 19/50\n",
      " - 0s - loss: 222.4190 - val_loss: 234.6128\n",
      "Epoch 20/50\n",
      " - 0s - loss: 217.7613 - val_loss: 249.8300\n",
      "Epoch 21/50\n",
      " - 0s - loss: 210.1083 - val_loss: 251.8497\n",
      "Epoch 22/50\n",
      " - 0s - loss: 208.3279 - val_loss: 225.8774\n",
      "Epoch 23/50\n",
      " - 0s - loss: 200.2715 - val_loss: 228.3675\n",
      "Epoch 24/50\n",
      " - 0s - loss: 196.2032 - val_loss: 223.4582\n",
      "Epoch 25/50\n",
      " - 0s - loss: 192.7365 - val_loss: 206.8372\n",
      "Epoch 26/50\n",
      " - 0s - loss: 189.3509 - val_loss: 215.3145\n",
      "Epoch 27/50\n",
      " - 0s - loss: 185.1282 - val_loss: 215.7298\n",
      "Epoch 28/50\n",
      " - 0s - loss: 183.1626 - val_loss: 219.0345\n",
      "Epoch 29/50\n",
      " - 0s - loss: 180.7744 - val_loss: 201.5719\n",
      "Epoch 30/50\n",
      " - 0s - loss: 177.9234 - val_loss: 191.0097\n",
      "Epoch 31/50\n",
      " - 0s - loss: 173.9001 - val_loss: 203.8270\n",
      "Epoch 32/50\n",
      " - 0s - loss: 170.5411 - val_loss: 208.5925\n",
      "Epoch 33/50\n",
      " - 0s - loss: 169.2620 - val_loss: 180.9728\n",
      "Epoch 34/50\n",
      " - 0s - loss: 165.3167 - val_loss: 203.8029\n",
      "Epoch 35/50\n",
      " - 0s - loss: 163.5950 - val_loss: 187.8542\n",
      "Epoch 36/50\n",
      " - 0s - loss: 161.1697 - val_loss: 185.0422\n",
      "Epoch 37/50\n",
      " - 0s - loss: 158.0981 - val_loss: 200.1660\n",
      "Epoch 38/50\n",
      " - 0s - loss: 157.8363 - val_loss: 187.6358\n",
      "Epoch 39/50\n",
      " - 0s - loss: 158.5110 - val_loss: 173.6046\n",
      "Epoch 40/50\n",
      " - 0s - loss: 151.9952 - val_loss: 179.0160\n",
      "Epoch 41/50\n",
      " - 0s - loss: 149.4021 - val_loss: 187.6763\n",
      "Epoch 42/50\n",
      " - 0s - loss: 146.4613 - val_loss: 171.3898\n",
      "Epoch 43/50\n",
      " - 0s - loss: 144.5310 - val_loss: 173.7348\n",
      "Epoch 44/50\n",
      " - 0s - loss: 142.7796 - val_loss: 173.3696\n",
      "Epoch 45/50\n",
      " - 0s - loss: 140.7487 - val_loss: 163.4322\n",
      "Epoch 46/50\n",
      " - 0s - loss: 139.6417 - val_loss: 181.7069\n",
      "Epoch 47/50\n",
      " - 0s - loss: 137.1048 - val_loss: 173.6164\n",
      "Epoch 48/50\n",
      " - 0s - loss: 135.0412 - val_loss: 172.3802\n",
      "Epoch 49/50\n",
      " - 0s - loss: 133.7242 - val_loss: 150.5635\n",
      "Epoch 50/50\n",
      " - 0s - loss: 132.3413 - val_loss: 144.1655\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 1050.0114 - val_loss: 419.0390\n",
      "Epoch 2/50\n",
      " - 0s - loss: 430.7570 - val_loss: 333.2462\n",
      "Epoch 3/50\n",
      " - 0s - loss: 341.2908 - val_loss: 295.7599\n",
      "Epoch 4/50\n",
      " - 0s - loss: 294.1671 - val_loss: 286.7011\n",
      "Epoch 5/50\n",
      " - 0s - loss: 260.5783 - val_loss: 302.2612\n",
      "Epoch 6/50\n",
      " - 0s - loss: 239.3756 - val_loss: 334.6526\n",
      "Epoch 7/50\n",
      " - 0s - loss: 227.4919 - val_loss: 319.1142\n",
      "Epoch 8/50\n",
      " - 0s - loss: 214.3112 - val_loss: 326.9162\n",
      "Epoch 9/50\n",
      " - 0s - loss: 206.8758 - val_loss: 338.3809\n",
      "Epoch 10/50\n",
      " - 0s - loss: 198.3933 - val_loss: 299.8052\n",
      "Epoch 11/50\n",
      " - 0s - loss: 192.1352 - val_loss: 274.3891\n",
      "Epoch 12/50\n",
      " - 0s - loss: 196.1887 - val_loss: 269.7315\n",
      "Epoch 13/50\n",
      " - 0s - loss: 188.7422 - val_loss: 284.2663\n",
      "Epoch 14/50\n",
      " - 0s - loss: 185.3051 - val_loss: 306.4812\n",
      "Epoch 15/50\n",
      " - 0s - loss: 179.0089 - val_loss: 298.1911\n",
      "Epoch 16/50\n",
      " - 0s - loss: 177.2044 - val_loss: 280.6527\n",
      "Epoch 17/50\n",
      " - 0s - loss: 175.5016 - val_loss: 278.1227\n",
      "Epoch 18/50\n",
      " - 0s - loss: 172.5821 - val_loss: 319.9558\n",
      "Epoch 19/50\n",
      " - 0s - loss: 179.6498 - val_loss: 268.7749\n",
      "Epoch 20/50\n",
      " - 0s - loss: 169.3510 - val_loss: 261.3828\n",
      "Epoch 21/50\n",
      " - 0s - loss: 166.0403 - val_loss: 292.7826\n",
      "Epoch 22/50\n",
      " - 0s - loss: 165.3792 - val_loss: 265.6864\n",
      "Epoch 23/50\n",
      " - 0s - loss: 163.0885 - val_loss: 260.0048\n",
      "Epoch 24/50\n",
      " - 0s - loss: 162.3364 - val_loss: 263.8545\n",
      "Epoch 25/50\n",
      " - 0s - loss: 163.6506 - val_loss: 236.7587\n",
      "Epoch 26/50\n",
      " - 0s - loss: 165.3454 - val_loss: 290.3624\n",
      "Epoch 27/50\n",
      " - 0s - loss: 157.1569 - val_loss: 229.3482\n",
      "Epoch 28/50\n",
      " - 0s - loss: 154.9803 - val_loss: 229.2947\n",
      "Epoch 29/50\n",
      " - 0s - loss: 154.8684 - val_loss: 223.3675\n",
      "Epoch 30/50\n",
      " - 0s - loss: 152.3508 - val_loss: 218.5599\n",
      "Epoch 31/50\n",
      " - 0s - loss: 151.7045 - val_loss: 215.2035\n",
      "Epoch 32/50\n",
      " - 0s - loss: 150.0774 - val_loss: 223.4856\n",
      "Epoch 33/50\n",
      " - 0s - loss: 148.1787 - val_loss: 233.1781\n",
      "Epoch 34/50\n",
      " - 0s - loss: 150.1627 - val_loss: 205.3991\n",
      "Epoch 35/50\n",
      " - 0s - loss: 146.4204 - val_loss: 197.8848\n",
      "Epoch 36/50\n",
      " - 0s - loss: 146.2732 - val_loss: 220.7528\n",
      "Epoch 37/50\n",
      " - 0s - loss: 144.6013 - val_loss: 190.1710\n",
      "Epoch 38/50\n",
      " - 0s - loss: 145.3355 - val_loss: 202.5546\n",
      "Epoch 39/50\n",
      " - 0s - loss: 141.5732 - val_loss: 204.5936\n",
      "Epoch 40/50\n",
      " - 0s - loss: 145.4338 - val_loss: 176.7785\n",
      "Epoch 41/50\n",
      " - 0s - loss: 140.1748 - val_loss: 180.1738\n",
      "Epoch 42/50\n",
      " - 0s - loss: 141.9146 - val_loss: 171.0199\n",
      "Epoch 43/50\n",
      " - 0s - loss: 138.1141 - val_loss: 194.9933\n",
      "Epoch 44/50\n",
      " - 0s - loss: 136.9873 - val_loss: 183.4369\n",
      "Epoch 45/50\n",
      " - 0s - loss: 135.5615 - val_loss: 164.1647\n",
      "Epoch 46/50\n",
      " - 0s - loss: 133.9172 - val_loss: 159.7171\n",
      "Epoch 47/50\n",
      " - 0s - loss: 131.9682 - val_loss: 152.5412\n",
      "Epoch 48/50\n",
      " - 0s - loss: 136.9270 - val_loss: 166.3867\n",
      "Epoch 49/50\n",
      " - 0s - loss: 130.8672 - val_loss: 151.5661\n",
      "Epoch 50/50\n",
      " - 0s - loss: 133.3831 - val_loss: 167.9234\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 1887.3486 - val_loss: 1271.0455\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1130.6084 - val_loss: 995.7821\n",
      "Epoch 3/50\n",
      " - 0s - loss: 753.3547 - val_loss: 917.1979\n",
      "Epoch 4/50\n",
      " - 0s - loss: 525.0853 - val_loss: 833.5538\n",
      "Epoch 5/50\n",
      " - 0s - loss: 411.7432 - val_loss: 684.6368\n",
      "Epoch 6/50\n",
      " - 0s - loss: 338.6231 - val_loss: 581.9018\n",
      "Epoch 7/50\n",
      " - 0s - loss: 295.5077 - val_loss: 522.7540\n",
      "Epoch 8/50\n",
      " - 0s - loss: 262.7072 - val_loss: 429.9011\n",
      "Epoch 9/50\n",
      " - 0s - loss: 240.6602 - val_loss: 358.5689\n",
      "Epoch 10/50\n",
      " - 0s - loss: 224.5433 - val_loss: 331.5457\n",
      "Epoch 11/50\n",
      " - 0s - loss: 210.1666 - val_loss: 295.4889\n",
      "Epoch 12/50\n",
      " - 0s - loss: 200.0947 - val_loss: 264.0391\n",
      "Epoch 13/50\n",
      " - 0s - loss: 191.6091 - val_loss: 227.0484\n",
      "Epoch 14/50\n",
      " - 0s - loss: 184.5603 - val_loss: 227.3274\n",
      "Epoch 15/50\n",
      " - 0s - loss: 185.0217 - val_loss: 226.4115\n",
      "Epoch 16/50\n",
      " - 0s - loss: 177.5141 - val_loss: 179.5493\n",
      "Epoch 17/50\n",
      " - 0s - loss: 171.5956 - val_loss: 191.5054\n",
      "Epoch 18/50\n",
      " - 0s - loss: 166.6600 - val_loss: 152.2822\n",
      "Epoch 19/50\n",
      " - 0s - loss: 169.6225 - val_loss: 154.4236\n",
      "Epoch 20/50\n",
      " - 0s - loss: 163.2562 - val_loss: 150.9853\n",
      "Epoch 21/50\n",
      " - 0s - loss: 161.0279 - val_loss: 136.7948\n",
      "Epoch 22/50\n",
      " - 0s - loss: 159.3855 - val_loss: 133.2606\n",
      "Epoch 23/50\n",
      " - 0s - loss: 157.2832 - val_loss: 139.1869\n",
      "Epoch 24/50\n",
      " - 0s - loss: 156.2064 - val_loss: 121.3773\n",
      "Epoch 25/50\n",
      " - 0s - loss: 153.9140 - val_loss: 136.5943\n",
      "Epoch 26/50\n",
      " - 0s - loss: 154.2135 - val_loss: 130.0108\n",
      "Epoch 27/50\n",
      " - 0s - loss: 154.3717 - val_loss: 111.2258\n",
      "Epoch 28/50\n",
      " - 0s - loss: 151.0240 - val_loss: 126.5060\n",
      "Epoch 29/50\n",
      " - 0s - loss: 150.2357 - val_loss: 124.1480\n",
      "Epoch 30/50\n",
      " - 0s - loss: 149.1730 - val_loss: 121.4213\n",
      "Epoch 31/50\n",
      " - 0s - loss: 147.1657 - val_loss: 104.7542\n",
      "Epoch 32/50\n",
      " - 0s - loss: 146.2035 - val_loss: 106.0939\n",
      "Epoch 33/50\n",
      " - 0s - loss: 143.8381 - val_loss: 102.5982\n",
      "Epoch 34/50\n",
      " - 0s - loss: 143.0442 - val_loss: 100.1400\n",
      "Epoch 35/50\n",
      " - 0s - loss: 141.9503 - val_loss: 94.1253\n",
      "Epoch 36/50\n",
      " - 0s - loss: 140.0485 - val_loss: 98.0368\n",
      "Epoch 37/50\n",
      " - 0s - loss: 139.4643 - val_loss: 97.3484\n",
      "Epoch 38/50\n",
      " - 0s - loss: 138.8303 - val_loss: 94.3791\n",
      "Epoch 39/50\n",
      " - 0s - loss: 138.9156 - val_loss: 90.8572\n",
      "Epoch 40/50\n",
      " - 0s - loss: 137.3172 - val_loss: 96.8890\n",
      "Epoch 41/50\n",
      " - 0s - loss: 136.5769 - val_loss: 87.5501\n",
      "Epoch 42/50\n",
      " - 0s - loss: 134.2313 - val_loss: 88.2795\n",
      "Epoch 43/50\n",
      " - 0s - loss: 135.5404 - val_loss: 82.0101\n",
      "Epoch 44/50\n",
      " - 0s - loss: 135.4680 - val_loss: 82.1650\n",
      "Epoch 45/50\n",
      " - 0s - loss: 134.2204 - val_loss: 94.6588\n",
      "Epoch 46/50\n",
      " - 0s - loss: 131.3765 - val_loss: 82.0805\n",
      "Epoch 47/50\n",
      " - 0s - loss: 130.2147 - val_loss: 80.1061\n",
      "Epoch 48/50\n",
      " - 0s - loss: 130.3189 - val_loss: 88.2135\n",
      "Epoch 49/50\n",
      " - 0s - loss: 128.8223 - val_loss: 78.9604\n",
      "Epoch 50/50\n",
      " - 0s - loss: 131.8396 - val_loss: 81.7868\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 11905.9888 - val_loss: 6226.7924\n",
      "Epoch 2/50\n",
      " - 0s - loss: 4997.8532 - val_loss: 4318.7767\n",
      "Epoch 3/50\n",
      " - 0s - loss: 4339.6058 - val_loss: 3786.6839\n",
      "Epoch 4/50\n",
      " - 0s - loss: 3864.7304 - val_loss: 3355.8557\n",
      "Epoch 5/50\n",
      " - 0s - loss: 3484.5837 - val_loss: 2952.8353\n",
      "Epoch 6/50\n",
      " - 0s - loss: 3172.0007 - val_loss: 2593.3737\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2851.7616 - val_loss: 2298.3643\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2574.2624 - val_loss: 1971.7986\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2301.9418 - val_loss: 1723.9222\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2041.6722 - val_loss: 1426.8599\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1785.2908 - val_loss: 1195.2314\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1529.2343 - val_loss: 977.4517\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1294.0593 - val_loss: 799.0836\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1053.9873 - val_loss: 601.6370\n",
      "Epoch 15/50\n",
      " - 0s - loss: 827.2053 - val_loss: 498.9789\n",
      "Epoch 16/50\n",
      " - 0s - loss: 660.8927 - val_loss: 394.1325\n",
      "Epoch 17/50\n",
      " - 0s - loss: 538.7304 - val_loss: 400.0484\n",
      "Epoch 18/50\n",
      " - 0s - loss: 463.0642 - val_loss: 338.1682\n",
      "Epoch 19/50\n",
      " - 0s - loss: 388.7394 - val_loss: 238.6394\n",
      "Epoch 20/50\n",
      " - 0s - loss: 341.0496 - val_loss: 205.3153\n",
      "Epoch 21/50\n",
      " - 0s - loss: 307.5335 - val_loss: 195.9031\n",
      "Epoch 22/50\n",
      " - 0s - loss: 276.5868 - val_loss: 191.0046\n",
      "Epoch 23/50\n",
      " - 0s - loss: 253.6147 - val_loss: 159.0921\n",
      "Epoch 24/50\n",
      " - 0s - loss: 231.6281 - val_loss: 146.4949\n",
      "Epoch 25/50\n",
      " - 0s - loss: 214.7027 - val_loss: 134.9348\n",
      "Epoch 26/50\n",
      " - 0s - loss: 201.7131 - val_loss: 144.8439\n",
      "Epoch 27/50\n",
      " - 0s - loss: 193.4580 - val_loss: 161.2149\n",
      "Epoch 28/50\n",
      " - 0s - loss: 190.7839 - val_loss: 146.0720\n",
      "Epoch 29/50\n",
      " - 0s - loss: 176.8554 - val_loss: 105.4958\n",
      "Epoch 30/50\n",
      " - 0s - loss: 169.6159 - val_loss: 104.6308\n",
      "Epoch 31/50\n",
      " - 0s - loss: 162.5855 - val_loss: 92.0731\n",
      "Epoch 32/50\n",
      " - 0s - loss: 163.4329 - val_loss: 90.3397\n",
      "Epoch 33/50\n",
      " - 0s - loss: 154.3887 - val_loss: 100.3490\n",
      "Epoch 34/50\n",
      " - 0s - loss: 149.8358 - val_loss: 87.5454\n",
      "Epoch 35/50\n",
      " - 0s - loss: 146.1999 - val_loss: 90.0693\n",
      "Epoch 36/50\n",
      " - 0s - loss: 144.6337 - val_loss: 101.6227\n",
      "Epoch 37/50\n",
      " - 0s - loss: 142.5001 - val_loss: 91.6601\n",
      "Epoch 38/50\n",
      " - 0s - loss: 142.0998 - val_loss: 99.4870\n",
      "Epoch 39/50\n",
      " - 0s - loss: 139.6835 - val_loss: 86.5817\n",
      "Epoch 40/50\n",
      " - 0s - loss: 137.3215 - val_loss: 90.8543\n",
      "Epoch 41/50\n",
      " - 0s - loss: 136.8942 - val_loss: 99.0943\n",
      "Epoch 42/50\n",
      " - 0s - loss: 135.8243 - val_loss: 109.0754\n",
      "Epoch 43/50\n",
      " - 0s - loss: 133.8471 - val_loss: 88.9832\n",
      "Epoch 44/50\n",
      " - 0s - loss: 133.4756 - val_loss: 90.7725\n",
      "Epoch 45/50\n",
      " - 0s - loss: 133.1927 - val_loss: 91.5574\n",
      "Epoch 46/50\n",
      " - 0s - loss: 133.3853 - val_loss: 85.9322\n",
      "Epoch 47/50\n",
      " - 0s - loss: 133.5054 - val_loss: 85.6781\n",
      "Epoch 48/50\n",
      " - 0s - loss: 131.7067 - val_loss: 85.6444\n",
      "Epoch 49/50\n",
      " - 0s - loss: 136.1689 - val_loss: 103.5595\n",
      "Epoch 50/50\n",
      " - 0s - loss: 131.9940 - val_loss: 91.1037\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 28154.1513 - val_loss: 7203.6314\n",
      "Epoch 2/50\n",
      " - 0s - loss: 5548.6653 - val_loss: 3772.1562\n",
      "Epoch 3/50\n",
      " - 0s - loss: 3686.3537 - val_loss: 3693.3125\n",
      "Epoch 4/50\n",
      " - 0s - loss: 3309.7351 - val_loss: 3102.4595\n",
      "Epoch 5/50\n",
      " - 0s - loss: 3047.3755 - val_loss: 2795.5164\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2801.7050 - val_loss: 2603.8495\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2604.4202 - val_loss: 2350.6117\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2396.7073 - val_loss: 2228.6025\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2239.4595 - val_loss: 1997.5062\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2066.0342 - val_loss: 1890.6609\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1924.2830 - val_loss: 1742.8221\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1792.0839 - val_loss: 1585.1359\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1676.7118 - val_loss: 1478.2338\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1563.8392 - val_loss: 1387.1202\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1467.9038 - val_loss: 1278.6914\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1374.1465 - val_loss: 1223.8331\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1290.3799 - val_loss: 1152.8202\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1213.4811 - val_loss: 1063.1504\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1143.7156 - val_loss: 1028.5650\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1080.8759 - val_loss: 968.0664\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1030.6072 - val_loss: 930.2576\n",
      "Epoch 22/50\n",
      " - 0s - loss: 968.2640 - val_loss: 853.1542\n",
      "Epoch 23/50\n",
      " - 0s - loss: 927.1146 - val_loss: 811.2767\n",
      "Epoch 24/50\n",
      " - 0s - loss: 874.4403 - val_loss: 780.0136\n",
      "Epoch 25/50\n",
      " - 0s - loss: 835.1788 - val_loss: 748.4847\n",
      "Epoch 26/50\n",
      " - 0s - loss: 795.4316 - val_loss: 704.4089\n",
      "Epoch 27/50\n",
      " - 0s - loss: 762.2910 - val_loss: 684.8177\n",
      "Epoch 28/50\n",
      " - 0s - loss: 731.9618 - val_loss: 706.7039\n",
      "Epoch 29/50\n",
      " - 0s - loss: 704.8979 - val_loss: 647.2126\n",
      "Epoch 30/50\n",
      " - 0s - loss: 682.3198 - val_loss: 634.2401\n",
      "Epoch 31/50\n",
      " - 0s - loss: 664.1822 - val_loss: 607.7518\n",
      "Epoch 32/50\n",
      " - 0s - loss: 644.2140 - val_loss: 585.5019\n",
      "Epoch 33/50\n",
      " - 0s - loss: 627.2002 - val_loss: 596.5224\n",
      "Epoch 34/50\n",
      " - 0s - loss: 615.4344 - val_loss: 568.5292\n",
      "Epoch 35/50\n",
      " - 0s - loss: 595.3044 - val_loss: 552.1002\n",
      "Epoch 36/50\n",
      " - 0s - loss: 582.5841 - val_loss: 556.8624\n",
      "Epoch 37/50\n",
      " - 0s - loss: 572.1004 - val_loss: 515.4279\n",
      "Epoch 38/50\n",
      " - 0s - loss: 559.8097 - val_loss: 548.4995\n",
      "Epoch 39/50\n",
      " - 0s - loss: 545.9145 - val_loss: 532.8809\n",
      "Epoch 40/50\n",
      " - 0s - loss: 535.4594 - val_loss: 474.2656\n",
      "Epoch 41/50\n",
      " - 0s - loss: 526.7240 - val_loss: 508.7988\n",
      "Epoch 42/50\n",
      " - 0s - loss: 513.2358 - val_loss: 509.6128\n",
      "Epoch 43/50\n",
      " - 0s - loss: 502.5739 - val_loss: 459.1720\n",
      "Epoch 44/50\n",
      " - 0s - loss: 494.8697 - val_loss: 465.3378\n",
      "Epoch 45/50\n",
      " - 0s - loss: 484.3806 - val_loss: 462.6445\n",
      "Epoch 46/50\n",
      " - 0s - loss: 474.8802 - val_loss: 450.5431\n",
      "Epoch 47/50\n",
      " - 0s - loss: 463.7634 - val_loss: 459.0015\n",
      "Epoch 48/50\n",
      " - 0s - loss: 454.4627 - val_loss: 447.4001\n",
      "Epoch 49/50\n",
      " - 0s - loss: 446.6596 - val_loss: 451.4922\n",
      "Epoch 50/50\n",
      " - 0s - loss: 439.1113 - val_loss: 413.0463\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 358605.2651 - val_loss: 294268.0646\n",
      "Epoch 2/50\n",
      " - 0s - loss: 265218.0986 - val_loss: 225056.2026\n",
      "Epoch 3/50\n",
      " - 0s - loss: 203939.1186 - val_loss: 178264.2264\n",
      "Epoch 4/50\n",
      " - 0s - loss: 162499.5541 - val_loss: 144755.1854\n",
      "Epoch 5/50\n",
      " - 0s - loss: 132660.7359 - val_loss: 119218.4987\n",
      "Epoch 6/50\n",
      " - 0s - loss: 109703.0150 - val_loss: 99019.7594\n",
      "Epoch 7/50\n",
      " - 0s - loss: 91337.4881 - val_loss: 82779.3758\n",
      "Epoch 8/50\n",
      " - 0s - loss: 76433.3755 - val_loss: 69527.3273\n",
      "Epoch 9/50\n",
      " - 0s - loss: 64239.7825 - val_loss: 58593.9858\n",
      "Epoch 10/50\n",
      " - 0s - loss: 54179.0882 - val_loss: 49620.5889\n",
      "Epoch 11/50\n",
      " - 0s - loss: 45890.3394 - val_loss: 42167.5431\n",
      "Epoch 12/50\n",
      " - 0s - loss: 38994.7691 - val_loss: 35965.8783\n",
      "Epoch 13/50\n",
      " - 0s - loss: 33252.4166 - val_loss: 30761.5727\n",
      "Epoch 14/50\n",
      " - 0s - loss: 28433.7002 - val_loss: 26422.4691\n",
      "Epoch 15/50\n",
      " - 0s - loss: 24406.7758 - val_loss: 22754.3859\n",
      "Epoch 16/50\n",
      " - 0s - loss: 21001.7368 - val_loss: 19648.8154\n",
      "Epoch 17/50\n",
      " - 0s - loss: 18127.0980 - val_loss: 17014.0225\n",
      "Epoch 18/50\n",
      " - 0s - loss: 15693.9012 - val_loss: 14782.5441\n",
      "Epoch 19/50\n",
      " - 0s - loss: 13628.4496 - val_loss: 12868.0699\n",
      "Epoch 20/50\n",
      " - 0s - loss: 11860.8999 - val_loss: 11235.9992\n",
      "Epoch 21/50\n",
      " - 0s - loss: 10355.6852 - val_loss: 9831.4663\n",
      "Epoch 22/50\n",
      " - 0s - loss: 9064.8793 - val_loss: 8625.6904\n",
      "Epoch 23/50\n",
      " - 0s - loss: 7966.6762 - val_loss: 7572.1958\n",
      "Epoch 24/50\n",
      " - 0s - loss: 7014.9137 - val_loss: 6675.4459\n",
      "Epoch 25/50\n",
      " - 0s - loss: 6202.4626 - val_loss: 5904.6381\n",
      "Epoch 26/50\n",
      " - 0s - loss: 5505.4833 - val_loss: 5244.7815\n",
      "Epoch 27/50\n",
      " - 0s - loss: 4908.6452 - val_loss: 4665.8658\n",
      "Epoch 28/50\n",
      " - 0s - loss: 4389.4461 - val_loss: 4165.7346\n",
      "Epoch 29/50\n",
      " - 0s - loss: 3944.9587 - val_loss: 3734.1474\n",
      "Epoch 30/50\n",
      " - 0s - loss: 3565.1689 - val_loss: 3352.0027\n",
      "Epoch 31/50\n",
      " - 0s - loss: 3228.9740 - val_loss: 3028.9015\n",
      "Epoch 32/50\n",
      " - 0s - loss: 2945.7549 - val_loss: 2742.4845\n",
      "Epoch 33/50\n",
      " - 0s - loss: 2698.3601 - val_loss: 2495.4824\n",
      "Epoch 34/50\n",
      " - 0s - loss: 2486.3574 - val_loss: 2281.0161\n",
      "Epoch 35/50\n",
      " - 0s - loss: 2301.3460 - val_loss: 2095.8660\n",
      "Epoch 36/50\n",
      " - 0s - loss: 2141.8756 - val_loss: 1933.4293\n",
      "Epoch 37/50\n",
      " - 0s - loss: 2002.7026 - val_loss: 1791.2154\n",
      "Epoch 38/50\n",
      " - 0s - loss: 1879.4552 - val_loss: 1667.3830\n",
      "Epoch 39/50\n",
      " - 0s - loss: 1773.2145 - val_loss: 1558.9836\n",
      "Epoch 40/50\n",
      " - 0s - loss: 1680.5709 - val_loss: 1462.6270\n",
      "Epoch 41/50\n",
      " - 0s - loss: 1599.9313 - val_loss: 1380.2239\n",
      "Epoch 42/50\n",
      " - 0s - loss: 1530.1915 - val_loss: 1308.1213\n",
      "Epoch 43/50\n",
      " - 0s - loss: 1468.7250 - val_loss: 1246.0205\n",
      "Epoch 44/50\n",
      " - 0s - loss: 1416.1500 - val_loss: 1190.2440\n",
      "Epoch 45/50\n",
      " - 0s - loss: 1369.6351 - val_loss: 1142.0307\n",
      "Epoch 46/50\n",
      " - 0s - loss: 1329.1356 - val_loss: 1102.4203\n",
      "Epoch 47/50\n",
      " - 0s - loss: 1295.6101 - val_loss: 1064.2445\n",
      "Epoch 48/50\n",
      " - 0s - loss: 1264.2077 - val_loss: 1031.5083\n",
      "Epoch 49/50\n",
      " - 0s - loss: 1235.7365 - val_loss: 1003.2059\n",
      "Epoch 50/50\n",
      " - 0s - loss: 1211.5137 - val_loss: 977.6398\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 144542.4222 - val_loss: 80036.6384\n",
      "Epoch 2/50\n",
      " - 0s - loss: 58429.6360 - val_loss: 27732.6630\n",
      "Epoch 3/50\n",
      " - 0s - loss: 20818.1619 - val_loss: 8820.1011\n",
      "Epoch 4/50\n",
      " - 0s - loss: 7933.7727 - val_loss: 3379.5889\n",
      "Epoch 5/50\n",
      " - 0s - loss: 4250.4851 - val_loss: 2197.9902\n",
      "Epoch 6/50\n",
      " - 0s - loss: 3290.7205 - val_loss: 1978.5951\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2977.8903 - val_loss: 1906.7163\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2791.3576 - val_loss: 1817.9207\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2616.8335 - val_loss: 1720.5812\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2444.4874 - val_loss: 1609.3497\n",
      "Epoch 11/50\n",
      " - 0s - loss: 2277.5428 - val_loss: 1502.8527\n",
      "Epoch 12/50\n",
      " - 0s - loss: 2116.8335 - val_loss: 1413.8002\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1964.3879 - val_loss: 1316.7598\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1820.0627 - val_loss: 1233.1313\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1685.0344 - val_loss: 1143.9588\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1556.6796 - val_loss: 1063.7931\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1438.7066 - val_loss: 986.0530\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1326.2916 - val_loss: 923.3642\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1224.7404 - val_loss: 857.3410\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1129.7774 - val_loss: 803.6723\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1041.6310 - val_loss: 749.5888\n",
      "Epoch 22/50\n",
      " - 0s - loss: 962.2934 - val_loss: 703.0391\n",
      "Epoch 23/50\n",
      " - 0s - loss: 887.9156 - val_loss: 661.4297\n",
      "Epoch 24/50\n",
      " - 0s - loss: 821.7995 - val_loss: 616.8104\n",
      "Epoch 25/50\n",
      " - 0s - loss: 756.6688 - val_loss: 587.5705\n",
      "Epoch 26/50\n",
      " - 0s - loss: 699.6143 - val_loss: 549.2400\n",
      "Epoch 27/50\n",
      " - 0s - loss: 646.2064 - val_loss: 519.1595\n",
      "Epoch 28/50\n",
      " - 0s - loss: 598.3433 - val_loss: 489.1817\n",
      "Epoch 29/50\n",
      " - 0s - loss: 556.4770 - val_loss: 465.9098\n",
      "Epoch 30/50\n",
      " - 0s - loss: 516.9576 - val_loss: 439.9834\n",
      "Epoch 31/50\n",
      " - 0s - loss: 481.3582 - val_loss: 417.1023\n",
      "Epoch 32/50\n",
      " - 0s - loss: 448.9024 - val_loss: 396.8404\n",
      "Epoch 33/50\n",
      " - 0s - loss: 419.4974 - val_loss: 379.1774\n",
      "Epoch 34/50\n",
      " - 0s - loss: 393.0755 - val_loss: 359.7223\n",
      "Epoch 35/50\n",
      " - 0s - loss: 368.7392 - val_loss: 344.0941\n",
      "Epoch 36/50\n",
      " - 0s - loss: 346.7004 - val_loss: 328.2447\n",
      "Epoch 37/50\n",
      " - 0s - loss: 327.1756 - val_loss: 313.9031\n",
      "Epoch 38/50\n",
      " - 0s - loss: 309.6566 - val_loss: 297.3390\n",
      "Epoch 39/50\n",
      " - 0s - loss: 293.8840 - val_loss: 286.9097\n",
      "Epoch 40/50\n",
      " - 0s - loss: 279.7997 - val_loss: 273.7886\n",
      "Epoch 41/50\n",
      " - 0s - loss: 267.5072 - val_loss: 263.2895\n",
      "Epoch 42/50\n",
      " - 0s - loss: 255.3547 - val_loss: 251.2902\n",
      "Epoch 43/50\n",
      " - 0s - loss: 244.9516 - val_loss: 243.1823\n",
      "Epoch 44/50\n",
      " - 0s - loss: 235.5530 - val_loss: 234.2837\n",
      "Epoch 45/50\n",
      " - 0s - loss: 227.4998 - val_loss: 225.5878\n",
      "Epoch 46/50\n",
      " - 0s - loss: 220.3483 - val_loss: 218.0625\n",
      "Epoch 47/50\n",
      " - 0s - loss: 213.7598 - val_loss: 212.1157\n",
      "Epoch 48/50\n",
      " - 0s - loss: 207.4667 - val_loss: 203.9838\n",
      "Epoch 49/50\n",
      " - 0s - loss: 202.0092 - val_loss: 196.3854\n",
      "Epoch 50/50\n",
      " - 0s - loss: 196.9559 - val_loss: 190.5191\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 48397.1633 - val_loss: 29467.4719\n",
      "Epoch 2/50\n",
      " - 0s - loss: 19316.5571 - val_loss: 10753.4058\n",
      "Epoch 3/50\n",
      " - 0s - loss: 6932.5683 - val_loss: 3671.0901\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2673.2420 - val_loss: 1636.7396\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1842.2213 - val_loss: 1366.8081\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1712.4961 - val_loss: 1306.6772\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1624.2076 - val_loss: 1247.7931\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1547.3279 - val_loss: 1187.6422\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1476.3785 - val_loss: 1138.4077\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1410.4622 - val_loss: 1098.4661\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1347.1730 - val_loss: 1048.6072\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1283.7487 - val_loss: 1006.4721\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1231.3830 - val_loss: 968.3089\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1172.7847 - val_loss: 934.1772\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1120.4587 - val_loss: 903.8041\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1075.4091 - val_loss: 871.4094\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1027.7019 - val_loss: 842.5702\n",
      "Epoch 18/50\n",
      " - 0s - loss: 978.6654 - val_loss: 810.9198\n",
      "Epoch 19/50\n",
      " - 0s - loss: 935.9361 - val_loss: 792.1769\n",
      "Epoch 20/50\n",
      " - 0s - loss: 893.7066 - val_loss: 768.1896\n",
      "Epoch 21/50\n",
      " - 0s - loss: 856.7222 - val_loss: 744.0513\n",
      "Epoch 22/50\n",
      " - 0s - loss: 821.8856 - val_loss: 720.6574\n",
      "Epoch 23/50\n",
      " - 0s - loss: 787.4728 - val_loss: 703.3178\n",
      "Epoch 24/50\n",
      " - 0s - loss: 759.2491 - val_loss: 673.8360\n",
      "Epoch 25/50\n",
      " - 0s - loss: 731.4203 - val_loss: 651.7471\n",
      "Epoch 26/50\n",
      " - 0s - loss: 702.5812 - val_loss: 634.0370\n",
      "Epoch 27/50\n",
      " - 0s - loss: 680.4111 - val_loss: 614.0191\n",
      "Epoch 28/50\n",
      " - 0s - loss: 658.5809 - val_loss: 600.6837\n",
      "Epoch 29/50\n",
      " - 0s - loss: 637.4312 - val_loss: 589.5368\n",
      "Epoch 30/50\n",
      " - 0s - loss: 621.1655 - val_loss: 579.1077\n",
      "Epoch 31/50\n",
      " - 0s - loss: 601.6360 - val_loss: 559.8498\n",
      "Epoch 32/50\n",
      " - 0s - loss: 584.6722 - val_loss: 542.5631\n",
      "Epoch 33/50\n",
      " - 0s - loss: 568.5909 - val_loss: 539.8354\n",
      "Epoch 34/50\n",
      " - 0s - loss: 553.4404 - val_loss: 523.8254\n",
      "Epoch 35/50\n",
      " - 0s - loss: 538.3265 - val_loss: 506.1225\n",
      "Epoch 36/50\n",
      " - 0s - loss: 524.4156 - val_loss: 494.3136\n",
      "Epoch 37/50\n",
      " - 0s - loss: 513.1589 - val_loss: 484.0081\n",
      "Epoch 38/50\n",
      " - 0s - loss: 499.2054 - val_loss: 470.5599\n",
      "Epoch 39/50\n",
      " - 0s - loss: 487.1210 - val_loss: 452.8792\n",
      "Epoch 40/50\n",
      " - 0s - loss: 472.8267 - val_loss: 446.0787\n",
      "Epoch 41/50\n",
      " - 0s - loss: 459.4443 - val_loss: 432.2300\n",
      "Epoch 42/50\n",
      " - 0s - loss: 447.9524 - val_loss: 426.7971\n",
      "Epoch 43/50\n",
      " - 0s - loss: 436.6948 - val_loss: 408.8621\n",
      "Epoch 44/50\n",
      " - 0s - loss: 422.2394 - val_loss: 398.2443\n",
      "Epoch 45/50\n",
      " - 0s - loss: 409.5902 - val_loss: 385.3409\n",
      "Epoch 46/50\n",
      " - 0s - loss: 397.1003 - val_loss: 376.5878\n",
      "Epoch 47/50\n",
      " - 0s - loss: 385.4156 - val_loss: 362.9427\n",
      "Epoch 48/50\n",
      " - 0s - loss: 376.9519 - val_loss: 338.5691\n",
      "Epoch 49/50\n",
      " - 0s - loss: 363.1012 - val_loss: 334.9896\n",
      "Epoch 50/50\n",
      " - 0s - loss: 351.6458 - val_loss: 320.9552\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 3957.7774 - val_loss: 3766.7789\n",
      "Epoch 2/50\n",
      " - 0s - loss: 2157.3848 - val_loss: 3561.6073\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1879.5277 - val_loss: 3118.4477\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1688.4637 - val_loss: 2853.4987\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1527.0666 - val_loss: 2618.6887\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1376.8521 - val_loss: 2359.0047\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1254.5006 - val_loss: 2168.4949\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1143.0026 - val_loss: 1976.6859\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1036.9699 - val_loss: 1771.9784\n",
      "Epoch 10/50\n",
      " - 0s - loss: 944.4655 - val_loss: 1619.4082\n",
      "Epoch 11/50\n",
      " - 0s - loss: 860.6926 - val_loss: 1491.4978\n",
      "Epoch 12/50\n",
      " - 0s - loss: 788.6051 - val_loss: 1345.9116\n",
      "Epoch 13/50\n",
      " - 0s - loss: 724.3489 - val_loss: 1229.0840\n",
      "Epoch 14/50\n",
      " - 0s - loss: 666.0268 - val_loss: 1137.8431\n",
      "Epoch 15/50\n",
      " - 0s - loss: 619.0337 - val_loss: 1039.5035\n",
      "Epoch 16/50\n",
      " - 0s - loss: 574.2603 - val_loss: 956.8035\n",
      "Epoch 17/50\n",
      " - 0s - loss: 537.9097 - val_loss: 892.7184\n",
      "Epoch 18/50\n",
      " - 0s - loss: 505.7361 - val_loss: 827.5691\n",
      "Epoch 19/50\n",
      " - 0s - loss: 480.6093 - val_loss: 775.7471\n",
      "Epoch 20/50\n",
      " - 0s - loss: 461.9239 - val_loss: 723.4556\n",
      "Epoch 21/50\n",
      " - 0s - loss: 439.0894 - val_loss: 689.0255\n",
      "Epoch 22/50\n",
      " - 0s - loss: 420.2198 - val_loss: 648.2737\n",
      "Epoch 23/50\n",
      " - 0s - loss: 405.2228 - val_loss: 613.7636\n",
      "Epoch 24/50\n",
      " - 0s - loss: 391.5611 - val_loss: 580.7264\n",
      "Epoch 25/50\n",
      " - 0s - loss: 379.3357 - val_loss: 552.5351\n",
      "Epoch 26/50\n",
      " - 0s - loss: 367.9406 - val_loss: 531.7130\n",
      "Epoch 27/50\n",
      " - 0s - loss: 357.9144 - val_loss: 500.9980\n",
      "Epoch 28/50\n",
      " - 0s - loss: 348.4568 - val_loss: 481.3121\n",
      "Epoch 29/50\n",
      " - 0s - loss: 339.7115 - val_loss: 464.3333\n",
      "Epoch 30/50\n",
      " - 0s - loss: 332.8672 - val_loss: 447.7920\n",
      "Epoch 31/50\n",
      " - 0s - loss: 324.5094 - val_loss: 428.3074\n",
      "Epoch 32/50\n",
      " - 0s - loss: 317.8252 - val_loss: 409.5056\n",
      "Epoch 33/50\n",
      " - 0s - loss: 312.0976 - val_loss: 399.8892\n",
      "Epoch 34/50\n",
      " - 0s - loss: 305.3514 - val_loss: 382.5130\n",
      "Epoch 35/50\n",
      " - 0s - loss: 300.3329 - val_loss: 373.6541\n",
      "Epoch 36/50\n",
      " - 0s - loss: 293.9525 - val_loss: 355.9885\n",
      "Epoch 37/50\n",
      " - 0s - loss: 289.1397 - val_loss: 346.9208\n",
      "Epoch 38/50\n",
      " - 0s - loss: 284.6670 - val_loss: 338.3355\n",
      "Epoch 39/50\n",
      " - 0s - loss: 279.5613 - val_loss: 323.9984\n",
      "Epoch 40/50\n",
      " - 0s - loss: 275.6682 - val_loss: 313.7777\n",
      "Epoch 41/50\n",
      " - 0s - loss: 271.4484 - val_loss: 306.7648\n",
      "Epoch 42/50\n",
      " - 0s - loss: 267.2125 - val_loss: 298.9612\n",
      "Epoch 43/50\n",
      " - 0s - loss: 263.4614 - val_loss: 294.5743\n",
      "Epoch 44/50\n",
      " - 0s - loss: 260.2720 - val_loss: 277.2957\n",
      "Epoch 45/50\n",
      " - 0s - loss: 256.5289 - val_loss: 273.1030\n",
      "Epoch 46/50\n",
      " - 0s - loss: 252.3767 - val_loss: 269.0212\n",
      "Epoch 47/50\n",
      " - 0s - loss: 249.8707 - val_loss: 262.9662\n",
      "Epoch 48/50\n",
      " - 0s - loss: 245.4325 - val_loss: 251.6645\n",
      "Epoch 49/50\n",
      " - 0s - loss: 242.8235 - val_loss: 250.6161\n",
      "Epoch 50/50\n",
      " - 0s - loss: 241.2702 - val_loss: 234.2024\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 95357.3296 - val_loss: 67345.4400\n",
      "Epoch 2/50\n",
      " - 0s - loss: 47435.9041 - val_loss: 33184.5894\n",
      "Epoch 3/50\n",
      " - 0s - loss: 21760.8529 - val_loss: 14240.4286\n",
      "Epoch 4/50\n",
      " - 0s - loss: 8427.1105 - val_loss: 5002.5303\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2666.6215 - val_loss: 1476.8559\n",
      "Epoch 6/50\n",
      " - 0s - loss: 884.2527 - val_loss: 536.2642\n",
      "Epoch 7/50\n",
      " - 0s - loss: 572.3295 - val_loss: 365.6788\n",
      "Epoch 8/50\n",
      " - 0s - loss: 552.2080 - val_loss: 342.9921\n",
      "Epoch 9/50\n",
      " - 0s - loss: 547.2446 - val_loss: 338.5837\n",
      "Epoch 10/50\n",
      " - 0s - loss: 542.1939 - val_loss: 339.2864\n",
      "Epoch 11/50\n",
      " - 0s - loss: 537.5732 - val_loss: 334.9003\n",
      "Epoch 12/50\n",
      " - 0s - loss: 532.5294 - val_loss: 329.6230\n",
      "Epoch 13/50\n",
      " - 0s - loss: 527.6529 - val_loss: 328.0209\n",
      "Epoch 14/50\n",
      " - 0s - loss: 522.5966 - val_loss: 320.2587\n",
      "Epoch 15/50\n",
      " - 0s - loss: 517.3524 - val_loss: 314.6363\n",
      "Epoch 16/50\n",
      " - 0s - loss: 512.5107 - val_loss: 308.7443\n",
      "Epoch 17/50\n",
      " - 0s - loss: 507.0989 - val_loss: 307.0625\n",
      "Epoch 18/50\n",
      " - 0s - loss: 502.2058 - val_loss: 303.0832\n",
      "Epoch 19/50\n",
      " - 0s - loss: 497.1955 - val_loss: 300.8880\n",
      "Epoch 20/50\n",
      " - 0s - loss: 492.0032 - val_loss: 289.8182\n",
      "Epoch 21/50\n",
      " - 0s - loss: 487.2719 - val_loss: 289.1245\n",
      "Epoch 22/50\n",
      " - 0s - loss: 482.0620 - val_loss: 284.4130\n",
      "Epoch 23/50\n",
      " - 0s - loss: 476.9617 - val_loss: 281.3337\n",
      "Epoch 24/50\n",
      " - 0s - loss: 472.4709 - val_loss: 273.5405\n",
      "Epoch 25/50\n",
      " - 0s - loss: 467.1359 - val_loss: 272.2696\n",
      "Epoch 26/50\n",
      " - 0s - loss: 462.8054 - val_loss: 268.3887\n",
      "Epoch 27/50\n",
      " - 0s - loss: 457.4625 - val_loss: 264.6065\n",
      "Epoch 28/50\n",
      " - 0s - loss: 452.9015 - val_loss: 256.3943\n",
      "Epoch 29/50\n",
      " - 0s - loss: 447.9045 - val_loss: 257.2377\n",
      "Epoch 30/50\n",
      " - 0s - loss: 443.2839 - val_loss: 251.4843\n",
      "Epoch 31/50\n",
      " - 0s - loss: 438.5762 - val_loss: 249.2451\n",
      "Epoch 32/50\n",
      " - 0s - loss: 433.8107 - val_loss: 249.7272\n",
      "Epoch 33/50\n",
      " - 0s - loss: 429.3296 - val_loss: 241.0496\n",
      "Epoch 34/50\n",
      " - 0s - loss: 424.7601 - val_loss: 235.7827\n",
      "Epoch 35/50\n",
      " - 0s - loss: 420.1394 - val_loss: 237.4748\n",
      "Epoch 36/50\n",
      " - 0s - loss: 416.2797 - val_loss: 229.9937\n",
      "Epoch 37/50\n",
      " - 0s - loss: 411.7549 - val_loss: 225.5799\n",
      "Epoch 38/50\n",
      " - 0s - loss: 406.4577 - val_loss: 228.7568\n",
      "Epoch 39/50\n",
      " - 0s - loss: 402.4701 - val_loss: 220.5739\n",
      "Epoch 40/50\n",
      " - 0s - loss: 399.3379 - val_loss: 217.1408\n",
      "Epoch 41/50\n",
      " - 0s - loss: 393.4310 - val_loss: 218.4885\n",
      "Epoch 42/50\n",
      " - 0s - loss: 388.7526 - val_loss: 210.6956\n",
      "Epoch 43/50\n",
      " - 0s - loss: 384.8969 - val_loss: 205.4106\n",
      "Epoch 44/50\n",
      " - 0s - loss: 380.7802 - val_loss: 206.4379\n",
      "Epoch 45/50\n",
      " - 0s - loss: 376.9394 - val_loss: 200.3416\n",
      "Epoch 46/50\n",
      " - 0s - loss: 371.7138 - val_loss: 202.4992\n",
      "Epoch 47/50\n",
      " - 0s - loss: 368.0383 - val_loss: 191.4932\n",
      "Epoch 48/50\n",
      " - 0s - loss: 363.3993 - val_loss: 194.2256\n",
      "Epoch 49/50\n",
      " - 0s - loss: 359.7810 - val_loss: 193.1674\n",
      "Epoch 50/50\n",
      " - 0s - loss: 355.2223 - val_loss: 180.5029\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 258432.2073 - val_loss: 210199.8119\n",
      "Epoch 2/50\n",
      " - 0s - loss: 178407.2522 - val_loss: 141918.3573\n",
      "Epoch 3/50\n",
      " - 0s - loss: 112653.0017 - val_loss: 79700.0205\n",
      "Epoch 4/50\n",
      " - 0s - loss: 57845.5988 - val_loss: 36568.1325\n",
      "Epoch 5/50\n",
      " - 0s - loss: 25540.5547 - val_loss: 16212.7695\n",
      "Epoch 6/50\n",
      " - 0s - loss: 12428.1989 - val_loss: 8761.7144\n",
      "Epoch 7/50\n",
      " - 0s - loss: 8267.7853 - val_loss: 6562.7725\n",
      "Epoch 8/50\n",
      " - 0s - loss: 7257.1593 - val_loss: 5914.7223\n",
      "Epoch 9/50\n",
      " - 0s - loss: 6918.5521 - val_loss: 5648.5660\n",
      "Epoch 10/50\n",
      " - 0s - loss: 6685.9991 - val_loss: 5453.9438\n",
      "Epoch 11/50\n",
      " - 0s - loss: 6470.5245 - val_loss: 5289.3377\n",
      "Epoch 12/50\n",
      " - 0s - loss: 6246.0315 - val_loss: 5079.2343\n",
      "Epoch 13/50\n",
      " - 0s - loss: 6020.0059 - val_loss: 4923.1742\n",
      "Epoch 14/50\n",
      " - 0s - loss: 5808.0686 - val_loss: 4736.6962\n",
      "Epoch 15/50\n",
      " - 0s - loss: 5602.4163 - val_loss: 4586.8110\n",
      "Epoch 16/50\n",
      " - 0s - loss: 5393.6104 - val_loss: 4412.7076\n",
      "Epoch 17/50\n",
      " - 0s - loss: 5201.2465 - val_loss: 4264.2543\n",
      "Epoch 18/50\n",
      " - 0s - loss: 5026.3490 - val_loss: 4114.2989\n",
      "Epoch 19/50\n",
      " - 0s - loss: 4846.8983 - val_loss: 4000.6059\n",
      "Epoch 20/50\n",
      " - 0s - loss: 4682.5331 - val_loss: 3879.0483\n",
      "Epoch 21/50\n",
      " - 0s - loss: 4517.4340 - val_loss: 3736.0383\n",
      "Epoch 22/50\n",
      " - 0s - loss: 4374.0277 - val_loss: 3600.2656\n",
      "Epoch 23/50\n",
      " - 0s - loss: 4236.4048 - val_loss: 3494.9889\n",
      "Epoch 24/50\n",
      " - 0s - loss: 4094.3605 - val_loss: 3428.3695\n",
      "Epoch 25/50\n",
      " - 0s - loss: 3976.1822 - val_loss: 3328.0319\n",
      "Epoch 26/50\n",
      " - 0s - loss: 3857.2054 - val_loss: 3201.9624\n",
      "Epoch 27/50\n",
      " - 0s - loss: 3746.7215 - val_loss: 3131.2814\n",
      "Epoch 28/50\n",
      " - 0s - loss: 3643.2680 - val_loss: 3029.1365\n",
      "Epoch 29/50\n",
      " - 0s - loss: 3541.5092 - val_loss: 2958.9672\n",
      "Epoch 30/50\n",
      " - 0s - loss: 3443.6342 - val_loss: 2877.4528\n",
      "Epoch 31/50\n",
      " - 0s - loss: 3354.6950 - val_loss: 2793.3418\n",
      "Epoch 32/50\n",
      " - 0s - loss: 3266.4797 - val_loss: 2728.6667\n",
      "Epoch 33/50\n",
      " - 0s - loss: 3183.8613 - val_loss: 2677.4722\n",
      "Epoch 34/50\n",
      " - 0s - loss: 3105.2919 - val_loss: 2617.8576\n",
      "Epoch 35/50\n",
      " - 0s - loss: 3034.2972 - val_loss: 2555.5999\n",
      "Epoch 36/50\n",
      " - 0s - loss: 2957.6773 - val_loss: 2464.5320\n",
      "Epoch 37/50\n",
      " - 0s - loss: 2887.6074 - val_loss: 2423.9271\n",
      "Epoch 38/50\n",
      " - 0s - loss: 2818.6388 - val_loss: 2363.3835\n",
      "Epoch 39/50\n",
      " - 0s - loss: 2752.6530 - val_loss: 2307.7054\n",
      "Epoch 40/50\n",
      " - 0s - loss: 2700.2967 - val_loss: 2255.8911\n",
      "Epoch 41/50\n",
      " - 0s - loss: 2637.9221 - val_loss: 2241.8056\n",
      "Epoch 42/50\n",
      " - 0s - loss: 2575.7905 - val_loss: 2156.9618\n",
      "Epoch 43/50\n",
      " - 0s - loss: 2516.0678 - val_loss: 2123.9420\n",
      "Epoch 44/50\n",
      " - 0s - loss: 2460.7290 - val_loss: 2066.7241\n",
      "Epoch 45/50\n",
      " - 0s - loss: 2405.7390 - val_loss: 2027.7572\n",
      "Epoch 46/50\n",
      " - 0s - loss: 2356.7952 - val_loss: 1992.8061\n",
      "Epoch 47/50\n",
      " - 0s - loss: 2305.3955 - val_loss: 1948.5689\n",
      "Epoch 48/50\n",
      " - 0s - loss: 2258.3013 - val_loss: 1903.2470\n",
      "Epoch 49/50\n",
      " - 0s - loss: 2209.9486 - val_loss: 1877.0954\n",
      "Epoch 50/50\n",
      " - 0s - loss: 2163.7789 - val_loss: 1838.1296\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 31972.9589 - val_loss: 17142.7073\n",
      "Epoch 2/50\n",
      " - 0s - loss: 6361.2532 - val_loss: 4192.4385\n",
      "Epoch 3/50\n",
      " - 0s - loss: 2972.8973 - val_loss: 3111.1938\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2787.5583 - val_loss: 3164.2129\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2562.7966 - val_loss: 2992.1938\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2394.6426 - val_loss: 2764.4645\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2242.8308 - val_loss: 2584.3884\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2120.6558 - val_loss: 2448.5233\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2005.2947 - val_loss: 2271.3775\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1895.1137 - val_loss: 2080.7388\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1794.2479 - val_loss: 1994.4841\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1684.7806 - val_loss: 1822.1145\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1574.9626 - val_loss: 1767.3173\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1471.0832 - val_loss: 1648.5895\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1363.4750 - val_loss: 1516.3548\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1236.3309 - val_loss: 1444.4910\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1096.5412 - val_loss: 1338.1056\n",
      "Epoch 18/50\n",
      " - 0s - loss: 955.4707 - val_loss: 1236.1134\n",
      "Epoch 19/50\n",
      " - 0s - loss: 833.9230 - val_loss: 1057.7051\n",
      "Epoch 20/50\n",
      " - 0s - loss: 749.8712 - val_loss: 998.5481\n",
      "Epoch 21/50\n",
      " - 0s - loss: 684.9656 - val_loss: 1022.3927\n",
      "Epoch 22/50\n",
      " - 0s - loss: 616.6763 - val_loss: 809.2277\n",
      "Epoch 23/50\n",
      " - 0s - loss: 571.5169 - val_loss: 812.2158\n",
      "Epoch 24/50\n",
      " - 0s - loss: 531.3216 - val_loss: 679.0038\n",
      "Epoch 25/50\n",
      " - 0s - loss: 497.3339 - val_loss: 687.0367\n",
      "Epoch 26/50\n",
      " - 0s - loss: 467.2786 - val_loss: 644.6758\n",
      "Epoch 27/50\n",
      " - 0s - loss: 439.0333 - val_loss: 589.6310\n",
      "Epoch 28/50\n",
      " - 0s - loss: 413.4484 - val_loss: 566.2932\n",
      "Epoch 29/50\n",
      " - 0s - loss: 397.7576 - val_loss: 517.7831\n",
      "Epoch 30/50\n",
      " - 0s - loss: 371.7677 - val_loss: 478.2998\n",
      "Epoch 31/50\n",
      " - 0s - loss: 349.8716 - val_loss: 492.2610\n",
      "Epoch 32/50\n",
      " - 0s - loss: 334.8695 - val_loss: 482.3192\n",
      "Epoch 33/50\n",
      " - 0s - loss: 322.9439 - val_loss: 432.9050\n",
      "Epoch 34/50\n",
      " - 0s - loss: 306.9324 - val_loss: 385.4951\n",
      "Epoch 35/50\n",
      " - 0s - loss: 294.8018 - val_loss: 420.3682\n",
      "Epoch 36/50\n",
      " - 0s - loss: 279.1270 - val_loss: 347.2283\n",
      "Epoch 37/50\n",
      " - 0s - loss: 269.0508 - val_loss: 333.4711\n",
      "Epoch 38/50\n",
      " - 0s - loss: 258.6005 - val_loss: 322.5740\n",
      "Epoch 39/50\n",
      " - 0s - loss: 249.4029 - val_loss: 298.0650\n",
      "Epoch 40/50\n",
      " - 0s - loss: 242.3523 - val_loss: 322.8777\n",
      "Epoch 41/50\n",
      " - 0s - loss: 236.7520 - val_loss: 290.7344\n",
      "Epoch 42/50\n",
      " - 0s - loss: 228.8368 - val_loss: 271.3291\n",
      "Epoch 43/50\n",
      " - 0s - loss: 225.9009 - val_loss: 241.7488\n",
      "Epoch 44/50\n",
      " - 0s - loss: 219.6508 - val_loss: 225.3373\n",
      "Epoch 45/50\n",
      " - 0s - loss: 215.9221 - val_loss: 226.0131\n",
      "Epoch 46/50\n",
      " - 0s - loss: 209.0538 - val_loss: 233.9149\n",
      "Epoch 47/50\n",
      " - 0s - loss: 203.8197 - val_loss: 219.7336\n",
      "Epoch 48/50\n",
      " - 0s - loss: 201.1917 - val_loss: 214.7950\n",
      "Epoch 49/50\n",
      " - 0s - loss: 198.1607 - val_loss: 230.3138\n",
      "Epoch 50/50\n",
      " - 0s - loss: 194.8084 - val_loss: 234.5985\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 12619.1725 - val_loss: 3598.5798\n",
      "Epoch 2/50\n",
      " - 0s - loss: 3491.3189 - val_loss: 3150.6589\n",
      "Epoch 3/50\n",
      " - 0s - loss: 3012.1048 - val_loss: 2865.8586\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2607.6668 - val_loss: 2670.9629\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2298.3278 - val_loss: 2499.8423\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2003.5045 - val_loss: 2341.4342\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1762.5430 - val_loss: 2167.7471\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1542.1904 - val_loss: 2022.0812\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1368.2882 - val_loss: 1878.7132\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1211.0176 - val_loss: 1750.2707\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1070.5727 - val_loss: 1632.2910\n",
      "Epoch 12/50\n",
      " - 0s - loss: 964.8346 - val_loss: 1540.1361\n",
      "Epoch 13/50\n",
      " - 0s - loss: 850.0384 - val_loss: 1401.9844\n",
      "Epoch 14/50\n",
      " - 0s - loss: 768.9862 - val_loss: 1300.2511\n",
      "Epoch 15/50\n",
      " - 0s - loss: 687.5254 - val_loss: 1193.8849\n",
      "Epoch 16/50\n",
      " - 0s - loss: 621.8049 - val_loss: 1097.2241\n",
      "Epoch 17/50\n",
      " - 0s - loss: 562.1365 - val_loss: 1017.7963\n",
      "Epoch 18/50\n",
      " - 0s - loss: 509.1710 - val_loss: 935.7023\n",
      "Epoch 19/50\n",
      " - 0s - loss: 460.9422 - val_loss: 867.1426\n",
      "Epoch 20/50\n",
      " - 0s - loss: 426.0576 - val_loss: 790.3803\n",
      "Epoch 21/50\n",
      " - 0s - loss: 384.9384 - val_loss: 721.9163\n",
      "Epoch 22/50\n",
      " - 0s - loss: 352.9343 - val_loss: 665.0710\n",
      "Epoch 23/50\n",
      " - 0s - loss: 322.4637 - val_loss: 607.4648\n",
      "Epoch 24/50\n",
      " - 0s - loss: 298.4672 - val_loss: 556.1896\n",
      "Epoch 25/50\n",
      " - 0s - loss: 275.2908 - val_loss: 506.8187\n",
      "Epoch 26/50\n",
      " - 0s - loss: 253.7189 - val_loss: 463.1566\n",
      "Epoch 27/50\n",
      " - 0s - loss: 236.0852 - val_loss: 422.8198\n",
      "Epoch 28/50\n",
      " - 0s - loss: 218.9524 - val_loss: 389.0784\n",
      "Epoch 29/50\n",
      " - 0s - loss: 204.1497 - val_loss: 351.5621\n",
      "Epoch 30/50\n",
      " - 0s - loss: 191.9980 - val_loss: 324.0161\n",
      "Epoch 31/50\n",
      " - 0s - loss: 180.9044 - val_loss: 297.9402\n",
      "Epoch 32/50\n",
      " - 0s - loss: 169.4319 - val_loss: 273.4842\n",
      "Epoch 33/50\n",
      " - 0s - loss: 160.8756 - val_loss: 251.7783\n",
      "Epoch 34/50\n",
      " - 0s - loss: 152.3525 - val_loss: 233.5417\n",
      "Epoch 35/50\n",
      " - 0s - loss: 145.8280 - val_loss: 215.1014\n",
      "Epoch 36/50\n",
      " - 0s - loss: 141.6240 - val_loss: 201.2591\n",
      "Epoch 37/50\n",
      " - 0s - loss: 134.3496 - val_loss: 189.5599\n",
      "Epoch 38/50\n",
      " - 0s - loss: 131.3796 - val_loss: 177.0167\n",
      "Epoch 39/50\n",
      " - 0s - loss: 127.1078 - val_loss: 165.0624\n",
      "Epoch 40/50\n",
      " - 0s - loss: 122.9322 - val_loss: 156.5355\n",
      "Epoch 41/50\n",
      " - 0s - loss: 120.7686 - val_loss: 146.4540\n",
      "Epoch 42/50\n",
      " - 0s - loss: 118.5931 - val_loss: 139.8653\n",
      "Epoch 43/50\n",
      " - 0s - loss: 115.7152 - val_loss: 132.2051\n",
      "Epoch 44/50\n",
      " - 0s - loss: 112.3670 - val_loss: 127.5763\n",
      "Epoch 45/50\n",
      " - 0s - loss: 109.4261 - val_loss: 121.6886\n",
      "Epoch 46/50\n",
      " - 0s - loss: 107.6919 - val_loss: 117.5189\n",
      "Epoch 47/50\n",
      " - 0s - loss: 107.3521 - val_loss: 117.3504\n",
      "Epoch 48/50\n",
      " - 0s - loss: 104.9487 - val_loss: 109.9815\n",
      "Epoch 49/50\n",
      " - 0s - loss: 105.7085 - val_loss: 109.4685\n",
      "Epoch 50/50\n",
      " - 0s - loss: 103.2510 - val_loss: 106.6564\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 48227.4190 - val_loss: 13253.5271\n",
      "Epoch 2/50\n",
      " - 0s - loss: 5926.1376 - val_loss: 2491.7495\n",
      "Epoch 3/50\n",
      " - 0s - loss: 3244.5362 - val_loss: 2106.9413\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2419.4954 - val_loss: 1610.0108\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1891.1724 - val_loss: 1308.1737\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1582.6134 - val_loss: 1075.7354\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1334.0944 - val_loss: 895.3166\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1142.3648 - val_loss: 757.8172\n",
      "Epoch 9/50\n",
      " - 0s - loss: 980.0648 - val_loss: 665.1153\n",
      "Epoch 10/50\n",
      " - 0s - loss: 840.4092 - val_loss: 548.2960\n",
      "Epoch 11/50\n",
      " - 0s - loss: 721.0476 - val_loss: 483.2335\n",
      "Epoch 12/50\n",
      " - 0s - loss: 617.0570 - val_loss: 419.7119\n",
      "Epoch 13/50\n",
      " - 0s - loss: 529.6724 - val_loss: 366.1578\n",
      "Epoch 14/50\n",
      " - 0s - loss: 456.5117 - val_loss: 330.3641\n",
      "Epoch 15/50\n",
      " - 0s - loss: 395.8954 - val_loss: 285.5885\n",
      "Epoch 16/50\n",
      " - 0s - loss: 349.4763 - val_loss: 259.8504\n",
      "Epoch 17/50\n",
      " - 0s - loss: 310.3530 - val_loss: 240.2049\n",
      "Epoch 18/50\n",
      " - 0s - loss: 278.1295 - val_loss: 228.5687\n",
      "Epoch 19/50\n",
      " - 0s - loss: 256.1196 - val_loss: 214.5932\n",
      "Epoch 20/50\n",
      " - 0s - loss: 235.6161 - val_loss: 209.7220\n",
      "Epoch 21/50\n",
      " - 0s - loss: 222.7741 - val_loss: 197.9917\n",
      "Epoch 22/50\n",
      " - 0s - loss: 211.8682 - val_loss: 188.3013\n",
      "Epoch 23/50\n",
      " - 0s - loss: 204.1549 - val_loss: 183.1243\n",
      "Epoch 24/50\n",
      " - 0s - loss: 193.9447 - val_loss: 179.2807\n",
      "Epoch 25/50\n",
      " - 0s - loss: 188.6782 - val_loss: 183.0369\n",
      "Epoch 26/50\n",
      " - 0s - loss: 181.8206 - val_loss: 174.4401\n",
      "Epoch 27/50\n",
      " - 0s - loss: 177.6896 - val_loss: 170.0380\n",
      "Epoch 28/50\n",
      " - 0s - loss: 171.1236 - val_loss: 174.1911\n",
      "Epoch 29/50\n",
      " - 0s - loss: 167.2764 - val_loss: 164.3254\n",
      "Epoch 30/50\n",
      " - 0s - loss: 164.4912 - val_loss: 166.1385\n",
      "Epoch 31/50\n",
      " - 0s - loss: 160.0613 - val_loss: 166.8621\n",
      "Epoch 32/50\n",
      " - 0s - loss: 155.6612 - val_loss: 164.3253\n",
      "Epoch 33/50\n",
      " - 0s - loss: 152.0515 - val_loss: 170.1564\n",
      "Epoch 34/50\n",
      " - 0s - loss: 150.9496 - val_loss: 155.3108\n",
      "Epoch 35/50\n",
      " - 0s - loss: 146.3336 - val_loss: 162.4929\n",
      "Epoch 36/50\n",
      " - 0s - loss: 146.2811 - val_loss: 161.7856\n",
      "Epoch 37/50\n",
      " - 0s - loss: 146.2954 - val_loss: 155.6593\n",
      "Epoch 38/50\n",
      " - 0s - loss: 138.7536 - val_loss: 156.4357\n",
      "Epoch 39/50\n",
      " - 0s - loss: 136.0236 - val_loss: 157.3234\n",
      "Epoch 40/50\n",
      " - 0s - loss: 137.5175 - val_loss: 157.6983\n",
      "Epoch 41/50\n",
      " - 0s - loss: 132.8196 - val_loss: 151.5676\n",
      "Epoch 42/50\n",
      " - 0s - loss: 131.4547 - val_loss: 149.4994\n",
      "Epoch 43/50\n",
      " - 0s - loss: 132.4589 - val_loss: 147.7015\n",
      "Epoch 44/50\n",
      " - 0s - loss: 128.3332 - val_loss: 152.1921\n",
      "Epoch 45/50\n",
      " - 0s - loss: 126.3056 - val_loss: 150.1944\n",
      "Epoch 46/50\n",
      " - 0s - loss: 125.7707 - val_loss: 154.5065\n",
      "Epoch 47/50\n",
      " - 0s - loss: 123.4608 - val_loss: 146.8633\n",
      "Epoch 48/50\n",
      " - 0s - loss: 124.2909 - val_loss: 147.4564\n",
      "Epoch 49/50\n",
      " - 0s - loss: 120.6237 - val_loss: 146.6040\n",
      "Epoch 50/50\n",
      " - 0s - loss: 119.1381 - val_loss: 146.0537\n",
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 15156.8831 - val_loss: 4499.6788\n",
      "Epoch 2/50\n",
      " - 0s - loss: 4582.5539 - val_loss: 3581.7948\n",
      "Epoch 3/50\n",
      " - 0s - loss: 3810.3912 - val_loss: 3026.1208\n",
      "Epoch 4/50\n",
      " - 0s - loss: 3175.4012 - val_loss: 2492.7981\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2631.6376 - val_loss: 2035.0726\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2146.7708 - val_loss: 1634.8255\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1720.7517 - val_loss: 1273.8347\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1399.6500 - val_loss: 1008.9039\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1171.6438 - val_loss: 859.0048\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1025.4214 - val_loss: 759.7197\n",
      "Epoch 11/50\n",
      " - 0s - loss: 894.9619 - val_loss: 692.4868\n",
      "Epoch 12/50\n",
      " - 0s - loss: 786.4951 - val_loss: 624.6344\n",
      "Epoch 13/50\n",
      " - 0s - loss: 708.0582 - val_loss: 588.7666\n",
      "Epoch 14/50\n",
      " - 0s - loss: 649.0541 - val_loss: 538.3068\n",
      "Epoch 15/50\n",
      " - 0s - loss: 603.4210 - val_loss: 517.6411\n",
      "Epoch 16/50\n",
      " - 0s - loss: 563.4563 - val_loss: 481.7834\n",
      "Epoch 17/50\n",
      " - 0s - loss: 529.7486 - val_loss: 460.5043\n",
      "Epoch 18/50\n",
      " - 0s - loss: 502.1595 - val_loss: 424.6487\n",
      "Epoch 19/50\n",
      " - 0s - loss: 477.9198 - val_loss: 423.2589\n",
      "Epoch 20/50\n",
      " - 0s - loss: 456.9735 - val_loss: 394.7155\n",
      "Epoch 21/50\n",
      " - 0s - loss: 439.4151 - val_loss: 388.6578\n",
      "Epoch 22/50\n",
      " - 0s - loss: 420.6625 - val_loss: 372.8038\n",
      "Epoch 23/50\n",
      " - 0s - loss: 404.5002 - val_loss: 362.6236\n",
      "Epoch 24/50\n",
      " - 0s - loss: 388.0850 - val_loss: 328.0247\n",
      "Epoch 25/50\n",
      " - 0s - loss: 376.6933 - val_loss: 328.1069\n",
      "Epoch 26/50\n",
      " - 0s - loss: 359.4191 - val_loss: 307.8573\n",
      "Epoch 27/50\n",
      " - 0s - loss: 347.7138 - val_loss: 293.0052\n",
      "Epoch 28/50\n",
      " - 0s - loss: 332.8010 - val_loss: 301.9772\n",
      "Epoch 29/50\n",
      " - 0s - loss: 320.7403 - val_loss: 295.6041\n",
      "Epoch 30/50\n",
      " - 0s - loss: 308.6778 - val_loss: 275.3120\n",
      "Epoch 31/50\n",
      " - 0s - loss: 298.5747 - val_loss: 255.1836\n",
      "Epoch 32/50\n",
      " - 0s - loss: 287.6165 - val_loss: 264.1144\n",
      "Epoch 33/50\n",
      " - 0s - loss: 276.8424 - val_loss: 256.2541\n",
      "Epoch 34/50\n",
      " - 0s - loss: 266.9442 - val_loss: 245.2087\n",
      "Epoch 35/50\n",
      " - 0s - loss: 258.1113 - val_loss: 232.7517\n",
      "Epoch 36/50\n",
      " - 0s - loss: 249.0170 - val_loss: 243.9658\n",
      "Epoch 37/50\n",
      " - 0s - loss: 241.2603 - val_loss: 223.0828\n",
      "Epoch 38/50\n",
      " - 0s - loss: 232.7362 - val_loss: 217.9337\n",
      "Epoch 39/50\n",
      " - 0s - loss: 224.8586 - val_loss: 198.9265\n",
      "Epoch 40/50\n",
      " - 0s - loss: 217.3866 - val_loss: 197.7759\n",
      "Epoch 41/50\n",
      " - 0s - loss: 209.4460 - val_loss: 196.7601\n",
      "Epoch 42/50\n",
      " - 0s - loss: 200.1820 - val_loss: 207.1861\n",
      "Epoch 43/50\n",
      " - 0s - loss: 192.4109 - val_loss: 176.9896\n",
      "Epoch 44/50\n",
      " - 0s - loss: 183.1496 - val_loss: 192.8596\n",
      "Epoch 45/50\n",
      " - 0s - loss: 177.1564 - val_loss: 167.3756\n",
      "Epoch 46/50\n",
      " - 0s - loss: 171.0225 - val_loss: 163.1584\n",
      "Epoch 47/50\n",
      " - 0s - loss: 166.2512 - val_loss: 168.3827\n",
      "Epoch 48/50\n",
      " - 0s - loss: 160.8352 - val_loss: 163.0818\n",
      "Epoch 49/50\n",
      " - 0s - loss: 156.1797 - val_loss: 154.5013\n",
      "Epoch 50/50\n",
      " - 0s - loss: 151.8845 - val_loss: 146.9910\n"
     ]
    }
   ],
   "source": [
    "s=[]\n",
    "i=0\n",
    "while i<50:\n",
    "    i=i+1\n",
    "    def regression_model():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "        model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    model = regression_model()\n",
    "\n",
    "    model.fit(predictors, target, validation_split=0.3, epochs=50, verbose=2)\n",
    "    a=model.predict(predictors, batch_size=1000, verbose=0, steps=None)\n",
    "\n",
    "\n",
    "#calucalte mean squared error\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    k=mean_squared_error(target,a)\n",
    "    s.append(k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[194.21230931211898,\n",
       " 542.936926019063,\n",
       " 450.46350662482564,\n",
       " 135.0120493740727,\n",
       " 164.76827648957828,\n",
       " 163.00331481548363,\n",
       " 674.4140130631632,\n",
       " 584.7152545045728,\n",
       " 245.11486997959798,\n",
       " 94.6396166380021,\n",
       " 117.46660527135586,\n",
       " 384.90975845764706,\n",
       " 305.97766042289925,\n",
       " 144.440630241604,\n",
       " 178.80926082861504,\n",
       " 627.9068690069162,\n",
       " 551.2798260171966,\n",
       " 1602.264517485649,\n",
       " 399.2225985154853,\n",
       " 291.8931062791363,\n",
       " 114.52321653572822,\n",
       " 127.90764492335315,\n",
       " 269.3371161414865,\n",
       " 278.4943715724672,\n",
       " 112.86357007664228,\n",
       " 156.77600199819818,\n",
       " 155.86229942218665,\n",
       " 2000.068545904929,\n",
       " 245.37599824260502,\n",
       " 177.68139704548216,\n",
       " 118.91508041223493,\n",
       " 135.63913810543457,\n",
       " 2967.0185039737025,\n",
       " 116.69911652528026,\n",
       " 107.64211205870481,\n",
       " 136.53499226458823,\n",
       " 141.89964557090036,\n",
       " 113.60674706669916,\n",
       " 117.75562766261399,\n",
       " 427.4103378995232,\n",
       " 1132.9604485053887,\n",
       " 193.2483833399,\n",
       " 337.7668262401872,\n",
       " 236.76697924949488,\n",
       " 301.3931055891374,\n",
       " 2049.804275474326,\n",
       " 208.39296813781573,\n",
       " 104.03219924665754,\n",
       " 126.10700630973533,\n",
       " 148.45034988954697]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414.2876994946387"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate mean of meansqured errors\n",
    "import statistics\n",
    "statistics.mean(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571.9294776135224"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate standard deviation of mean squared errors\n",
    "statistics.stdev(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
